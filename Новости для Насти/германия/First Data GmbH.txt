Story 0
Global Retail Automation Market Data Analysis 2019-2025 : Datalogic S.P.A., First Data Corporation, NCR Corporation, Fujitsu Limited
The global "Retail Automation Market" report comprises a valuable bunch of information that enlightens the most imperative sectors of the Retail Automation market. The data available in the report delivers comprehensive information about the Retail Automation market, which is understandable not only for an expert but also for a layman. The global Retail Automation market report provides information regarding all the aspects associated with the market, which includes reviews of the final product, and the key factors influencing or hampering the market growth. Moreover, the global Retail Automation market report, particularly emphasizes on the key market players Datalogic S.P.A., First Data Corporation, NCR Corporation, Fujitsu Limited, Toshiba Global Commerce Solutions Inc., Honeywell Scanning and Mobility, Kuka AG, Wincor Nixdorf AG, Zebra Technologies Corporation, Pricer AB, Posiflex Technology Inc., E&K Automation GmbH, Probiz Technologies Prvt Ltd., Simbe Robotics, Inc., Greyorange, Inmarket LLC., Arkrobot that are competing with each other to acquire the majority of share in the market, financial circumstances, actual certainties, and geographical analysis.
Click Here To Access The Sample Report:: https://www.promarketresearch.com/request-for-sample.html?repid=22185
For in-depth analysis and thorough understanding, the report presents a demand for individual segment in each region. It demonstrates various segments PoS, Barcode & RFID, Barcode & RFID, Electronic Shelf Labels (ESL), Autonomous Guided Vehicle (AGV), Automatic Storage and Retrieval (ASRS), Automated Conveyor and sub-segments Hypermarkets, Supermarkets, Single Item Stores, Fuel Stations, Retail Pharmacies of the global Retail Automation market. The global Retail Automation market report explains in-depth about the quantitative as well as the qualitative scenario of the market. The global Retail Automation market report delivers the precise analytical information that explains the future growth trend to be followed by the global Retail Automation market, based on the past and current situation of the market.
In addition, the global Retail Automation market report delivers concise information about the federal regulations and policies that may indirectly affect market growth as well as the financial state. The situation of the global market at the global and regional level is also described in the global Retail Automation market report through geographical segmentation.
Read Detailed Index Of Full Research Study @:: https://www.promarketresearch.com/global-retail-automation-market-2018-by-manufacturers-regions-22185.html
The information available in the global Retail Automation market report is not only based on the facts but also on the case studies, which analysts have included to deliver appropriate information to the clients in a well-versed manner. Moreover, for better understanding, the report includes statistical figures, graphs, tables, and charts related to the information mentioned in textual form.
There are 15 Chapters to display the Global Retail Automation market
Chapter 1, Definition, Specifications and Classification of Retail Automation , Applications of Retail Automation , Market Segment by Regions;
Chapter 2, Manufacturing Cost Structure, Raw Material and Suppliers, Manufacturing Process, Industry Chain Structure;
Chapter 3, Technical Data and Manufacturing Plants Analysis of Retail Automation , Capacity and Commercial Production Date, Manufacturing Plants Distribution, R&D Status and Technology Source, Raw Materials Sources Analysis;
Chapter 4, Overall Market Analysis, Capacity Analysis (Company Segment), Sales Analysis (Company Segment), Sales Price Analysis (Company Segment);
Chapter 5 and 6, Regional Market Analysis that includes United States, China, Europe, Japan, Korea & Taiwan, Retail Automation Segment Market Analysis (by Type);
Chapter 7 and 8, The Retail Automation Segment Market Analysis (by Application) Major Manufacturers Analysis of Retail Automation ;
Chapter 9, Market Trend Analysis, Regional Market Trend, Market Trend by Product Type PoS, Barcode & RFID, Barcode & RFID, Electronic Shelf Labels (ESL), Autonomous Guided Vehicle (AGV), Automatic Storage and Retrieval (ASRS), Automated Conveyor, Market Trend by Application Hypermarkets, Supermarkets, Single Item Stores, Fuel Stations, Retail Pharmacies;
Chapter 10, Regional Marketing Type Analysis, International Trade Type Analysis, Supply Chain Analysis;
Chapter 11, The Consumers Analysis of Global Retail Automation ;
Chapter 12, Retail Automation Research Findings and Conclusion, Appendix, methodology and data source;
Chapter 13, 14 and 15, Retail Automation sales channel, distributors, traders, dealers, Research Findings and Conclusion, appendix and data source.
Enquire Here Get customization & check discount for report @: https://www.promarketresearch.com/inquiry-for-buying.html?repid=22185
Reasons for Buying Retail Automation market
This report provides pin-point analysis for changing competitive dynamics
It provides a forward looking perspective on different factors driving or restraining market growth
It provides a six-year forecast assessed on the basis of how the market is predicted to grow
It helps in understanding the key product segments and their future
It provides pin point analysis of changing competition dynamics and keeps you ahead of competitors
It helps in making informed business decisions by having complete insights of market and by making in-depth analysis of market segments
Thanks for reading this article; you can also get individual chapter wise section or region wise report version like North America, Europe or Asia.

Story 1
Global Retail Automation Equipment Market Growth Analysis, Forecasts to 2025 – Datalogic S.p.A , First Data Corporation , NCR Corporation
Global "Retail Automation Equipment Market" research report has all the necessary vital details asked by the clients or any audiences in terms of market advantages or disadvantages and future market scope all mentioned in a very crystal clear manner. The report eloquently mentioned all the information regarding market competitors, growth rate, revenue ups and downs, regional players, industrial players, and applications. Even the most measly information depicting market figures are comprehensively analyzed and before being presented to the clients. The industrial players Datalogic S.p.A (Italy), First Data Corporation (US), NCR Corporation (US), Fujitsu Limited (Japan), Toshiba Global Commerce Solutions(US), Honeywell Scanning and Mobility (US), Kuka AG (Germany), Wincor Nixdorf AG (Germany), Pricer AB (Sweden), Zebra Technologies Corporation (US), Posiflex Technology(Taiwan), E&K Automation GmbH (Germany), Kiosk & Display LLC (US), Hunan Kimma Intelligent Equipment Manufacture are all provided so as to make it easier for the audiences to understand the market growth rate. The current Retail Automation Equipment market research report has demonstrated all the vital market growth factors and economic fluctuations mentioned owing to the immense attention gained in recent years.
Click Here To Access The Sample Report:: https://www.promarketresearch.com/request-for-sample.html?repid=4509
Global Market portal aims to provide reports like these in order to draw the attention of many of the clients wanting to extrapolate some of the vital details of the Retail Automation Equipment market on a global scale. The Retail Automation Equipment market dossier talks about the market segmentation created on the basis of consensus made, product type, governments norms, key industrial players, competitive landscapes, applications, end-user, topological players, and more. The report presents a demand for individual segment in each region. It demonstrates various segments PoS, Barcode & RFID, Electronic Shelf Labels (ESL) and sub-segments Hypermarkets, Supermarkets, Single Item Stores, Fuel Stations, Retail Pharmacies of the global Retail Automation Equipment market. The current report data simulates the market status and investment gains or losses in a very illustrative manner so as to provide the analyzed data in a very refreshed format.
Read Detailed Index Of Full Research Study @:: https://www.promarketresearch.com/global-retail-automation-equipment-market-2018-by-manufacturers-4509.html
Though the paper may have certain limitations in terms of providing the information, the record has purported all the deep-seated intricate information. The clients and other readers can have all the global Retail Automation Equipment market highlights provided in this very report. The geographical regions also play an important role in enhancing the growth and development of the global Retail Automation Equipment market. The report has all the vital information regarding supply and demand, market development enhancers, market share, sales distributors, and more advocated in a very formal pattern.
There are 15 Chapters to display the Global Retail Automation Equipment market
Chapter 1, Definition, Specifications and Classification of Retail Automation Equipment , Applications of Retail Automation Equipment , Market Segment by Regions;
Chapter 2, Manufacturing Cost Structure, Raw Material and Suppliers, Manufacturing Process, Industry Chain Structure;
Chapter 3, Technical Data and Manufacturing Plants Analysis of Retail Automation Equipment , Capacity and Commercial Production Date, Manufacturing Plants Distribution, R&D Status and Technology Source, Raw Materials Sources Analysis;
Chapter 4, Overall Market Analysis, Capacity Analysis (Company Segment), Sales Analysis (Company Segment), Sales Price Analysis (Company Segment);
Chapter 5 and 6, Regional Market Analysis that includes United States, China, Europe, Japan, Korea & Taiwan, Retail Automation Equipment Segment Market Analysis (by Type);
Chapter 7 and 8, The Retail Automation Equipment Segment Market Analysis (by Application) Major Manufacturers Analysis of Retail Automation Equipment ;
Chapter 9, Market Trend Analysis, Regional Market Trend, Market Trend by Product Type PoS, Barcode & RFID, Electronic Shelf Labels (ESL), Market Trend by Application Hypermarkets, Supermarkets, Single Item Stores, Fuel Stations, Retail Pharmacies;
Chapter 10, Regional Marketing Type Analysis, International Trade Type Analysis, Supply Chain Analysis;
Chapter 11, The Consumers Analysis of Global Retail Automation Equipment ;
Chapter 12, Retail Automation Equipment Research Findings and Conclusion, Appendix, methodology and data source;
Chapter 13, 14 and 15, Retail Automation Equipment sales channel, distributors, traders, dealers, Research Findings and Conclusion, appendix and data source.
Enquire Here Get customization & check discount for report @: https://www.promarketresearch.com/inquiry-for-buying.html?repid=4509

Story 2
Massive Growth of Retail Automation Market by 2025 with Top Key Players like Datalogic S.p.A, First Data Corporation, NCR Corporation, Fujitsu Limited, Toshiba Global Commerce Solutions, Honeywell Scanning and Mobility, KUKA AG
Retail automation provides an integrated tool to manage the retail activities such as product handling, time & attendance, workforce management, task management, store audit, and others. The software increases workforce productivity and enhances store productivity. Changes in customer behavior and increase in product measurements drive the market.
The Analyst Forecast Global Retail Automation Market is expected to represent Significant CAGR of +10% During Forecast Period (2019-2025).
Retail Automation Market research report comprises innovative tool in order to evaluate overall scenario of Industry along with its opportunities, and supporting strategic and tactical decision-making. Report analyzes changing trends and competitive analysis which becomes essential to monitor performance and make critical decisions for growth and development. It also provides market information in terms of development and its capacities.
Get Sample Copy of this report @:
https://www.a2zmarketresearch.com/sample?reportId=115475
Some of the Top companies Influencing in this Market are: Datalogic S.p.A, First Data Corporation, NCR Corporation, Fujitsu Limited, Toshiba Global Commerce Solutions, Honeywell Scanning and Mobility, KUKA AG, Wincor Nixdorf AG, Zebra Technologies Corporation, Pricer AB, Posiflex Technology, E & K Automation GmbH.
The report offers a multi-step view of the Global Retail Automation Market. The first approach focuses through an impression of the market. This passage includes several arrangements, definitions, the chain assembly of the industry in one piece, and the various uses for the global market. This section also integrates an all-inclusive analysis of the different enlargement plans and government strategies that influence the market, its cost assemblies and industrialized processes. The second subdivision of the report includes analytics on the Global Retail Automation Market based on its size in terms of value and volume.
In this Retail Automation Market research report, the prominent factors driving the advancement of this market were recorded and the business accomplices and end administrators were indulgent. The setup of the business division, examples, and challenges monitoring the market comprehensively are in like manner a bit of this wide examination. Different meetings and social events were driven by the distinguishable pioneers of this industry to get persisting and revived encounters concerned to the market.
Get Exclusive Discount on this report @:
https://www.a2zmarketresearch.com/discount?reportId=115475
Reasons to access this research report:
It offers informative data on recent advancements and technological trends.
For a comparative study of the Retail Automation market.
It offers extensive research on market dynamics such as drivers, restraints, and opportunities.
Furthermore, it offers an in-depth analysis of the economic aspects of the businesses.
The global analysis of global trading, import, export, and local consumption.
Global Retail Automation Market analysis of sellers, vendors, and buyers.
It offers an evaluation of competitive landscape.
Table of Contents
Global Retail Automation Market Research Report
Chapter 1 Retail Automation Market Overview
Chapter 2 Global Economic Impact on Industry
Chapter 3 Global Market Competition by Manufacturers
Chapter 4 Global Production, Revenue (Value) by Region
Chapter 5 Global Supply (Production), Consumption, Export, Import by Regions
Chapter 6 Global Production, Revenue (Value), Price Trend by Type
Chapter 7 Global Market Analysis by Application
Chapter 8 Manufacturing Cost Analysis
Chapter 9 Industrial Chain, Sourcing Strategy and Downstream Buyers
Chapter 10 Marketing Strategy Analysis, Distributors/Traders
Chapter 11 Market Effect Factors Analysis
Chapter 12 Global Retail Automation Market Forecast
Buy Customized Report Only @ 2800 USD:
https://www.a2zmarketresearch.com/buy?reportId=115475
If you have any special requirements, please let us know and we will offer you the report as you want.

Story 3
We employ the use of cookies. Find out more.

Story 4
The “Data Center Rack Market” research report 2019 has been estimated considering the application and regional segments, market share, and size, while the forecast for each product type and application segment has been provided for the global and regional markets. Data Center Rack report offers detailed profiles of the key players to bring out a clear view of the competitive landscape of the Data Center Rack outlook. It also comprehends market new product analysis, financial overview, strategies and marketing trends.
In Data Center Rack Market Report, Following Companies Are Covered:
The Research Document Will Answer Following Questions Such as:
What are the cutting-edge technologies responsible for driving the growth of the market?
What are the main applications of the market? What are the growth prospects to the market applications into the market?
At what stage of development are the key market products?
What are the shortcomings that has to face to become commercially viable? Is their growth and commercialization dependent on cost declines or technological/application breakthroughs?
What is the outlook for the industry?
What difference does performance characteristics of Data Center Rack create from those of established entities?
For More Information or Query or Customization Before Buying, Visit at – https://www.industryresearch.co/enquiry/pre-order-enquiry/14245219
Key Market Trends:
IT & Telecom Sector Expected to Hold a Significant Share
– IT and Telecom is the most significant segment for this market. The IT infrastructure requirement is the highest for this segment. Colocation providers, who are a major adopter of data center racks, are also considered under the scope of the study under the IT & Telecom sector.
– The amount of data that is being stored and processed by this segment is huge. The advent of mobile data and subscriptions and their rapid usage has proliferated the growth of data traffic and hence data centers. With the introduction of 5G and Cloud, the demand is expected to increase exponentially. Major companies are investing in new infrastructure to meet the additional requirements. Companies, like American Tower, bought its first data centers in April 2019 through the acquisition of Colo Atl.
– Other regions like Singapore also witnessed a rapid expansion in April 2019. The data center, colocation, and interconnection provider, Digital Realty commenced the construction of its third data center facility in Singapore. The facility will be capable of supporting up to 50 megawatts (MW) of IT capacity. The new facility will span a gross floor area of 34,000 sq. meter.
– Moreover, with the number of colocation providers growing significantly, and expanding in remote locations, it is expected that the demand for integrated data center racks is expected to witness significant growth during the forecast period.
Asia-Pacific Region to Record the Highest Growth Rate
– In the Asia-Pacific region, the market is anticipated to witness rapid growth, owing to increasing data traffic, energy efficiency and growing need for deployment of data centers in economically developing countries, such as India and China, are boosting the growth of the data center rack market in the Asia-Pacific region.
– The market is witnessing a rise in the number of businesses coupled with the shifting trend toward digitalization of all processes. In India, the number of data centers are growing, owing to government projects, such as Digital India, Make in India, Smart Cities, growth in the internet penetration, and the strong resurgence of growth-related projects across different verticals, such as e-commerce and retail, IT/ITeS, BFSI (primarily non-critical workloads).
– Data center investments are expected continue to grow in Asia-Pacific, with investor interest rising in the emerging markets of China, India, Singapore, and Indonesia. Tencent is constructing a data center in the hills of Guizhou, China, reportedly designed to the highest standards of civil air defense.
– The Singapore government is anticipated to move the bulk of its IT systems to commercial cloud services over the forecast period in ongoing efforts to deliver citizen services in a faster and cheaper way. This is anticipated to impact the markets growth positively. The evolution of Japan into more of an international data center market has been driven by the global hyperscale clouds expanding in the Tokyo and Osaka markets.
Reasons for Buying Data Center Rack Market Report:
This report provides pin-point analysis for changing competitive dynamics
It provides a forward looking perspective on different factors driving or restraining market growth
It provides a five-year forecast assessed on the basis of how the market is predicted to grow
It helps in understanding the key product segments and their future
It provides pin point analysis of changing competition dynamics and keeps you ahead of competitors
It helps in making informed business decisions by having complete insights of market and by making in-depth analysis of market segments
Purchase this Report (Price 4250 USD for single user license) – https://www.industryresearch.co/purchase/14245219
Detailed TOC of Data Center Rack Market Report 2019-2024:
1 INTRODUCTION
1.1 Scope of the Study
1.2 Study Assumptions
1.3 Market Definition
2 RESEARCH METHODOLOGY
3 EXECUTIVE SUMMARY
4 MARKET INSIGHTS
4.1 Market Overview
4.2 Industry Attractiveness – Porter’s Five Forces Analysis
4.2.1 Threat of New Entrants
4.2.2 Bargaining Power of Buyers/Consumers
4.2.3 Bargaining Power of Suppliers
4.2.4 Threat of Substitute Products
4.2.5 Intensity of Competitive Rivalry
4.3 Value Chain / Supply Chain Analysis
5 MARKET DYNAMICS
5.1 INTRODUCTION to Market Drivers and Restraints
5.2 Market Drivers
5.2.1 Increasing Deployment of Data Center Facilities
5.3 Market Challenges
5.3.1 Increasing Use of Blade Servers
6 TECHNOLOGY SNAPSHOT
7 MARKET SEGMENTATION
7.1 By Rack Units
7.1.1 Small
7.1.2 Medium
7.1.3 Large
7.2 By End-user Industry
7.2.1 BFSI
7.2.2 IT and Telecom
7.2.3 Manufacturing
7.2.4 Retail
7.2.5 Other End-user Industries
7.3 Geography
7.3.1 North America
7.3.2 Europe
7.3.3 Asia-Pacific
7.3.4 Latin America
7.3.5 Middle East & Africa
8 COMPETITIVE LANDSCAPE
8.1 Company Profiles
8.1.1 Rack Manufacturers
8.1.1.1 Kendall Howard LLC
8.1.1.2 Belkin International, Inc.
8.1.1.3 Martin International Enclosures
8.1.1.4 nVent Schroff GmbH
8.1.1.5 Black Box Corporation
8.1.1.6 Rittal GmbH & Co. KG
8.1.1.7 Tripp Lite
8.1.1.8 Cheval Electronic Enclosure Co. Ltd
8.1.1.9 Belden Inc.
8.1.1.10 Chatsworth Products Inc.
8.1.1.11 Panduit Corp.
8.1.1.12 Great Lakes Case & Cabinet Co. Inc.
8.1.1.13 ELMA Electronics, Inc.
8.1.2 Integrated Solution Poviders
8.1.2.1 Vertiv Group Corporation
8.1.2.2 Eaton Corporation PLC
8.1.2.3 Hewlett Packard Enterprise
8.1.2.4 Dell EMC
8.1.2.5 Schneider Electric SE
8.1.2.6 Fujitsu Corporation
8.1.2.7 Oracle Corporation
8.1.2.8 Legrand SA
9 INVESTMENT ANALYSIS
10 MARKET OPPORTUNITIES AND FUTURE TRENDS
Contact Us:
Name: Ajay More
Phone: US +14242530807/ UK +44 20 3239 8187
Email: [email protected]
Our Other Reports:
Smartphone Audio Codecs Market 2019 Global Industry Size, Segments, Share and Growth Factor Analysis Research Report 2024
2019-2025 Isopropyl Alcohol (IPA) Market Global Size | Outlook by Growth Rate, Share, Gross Margin, Business Strategies and Forecast Analysis
Online Data Science Training Programs Market: Global Industry Analysis, Size, Share, Growth, Trends, and Forecasts 20192022
CDN Market 2018 Global Industry Size, Future Trends, Growth Key Factors, Demand, Business Share, Sales & Income, Manufacture Players, Application, Scope, and Opportunities Analysis by Outlook  2023

Story 5
DUBLIN, Oct. 30, 2019 /PRNewswire/ -- The "Contract Manufacturing: Global Markets to 2023" report has been added to ResearchAndMarkets.com's offering.
Globally, contract manufacturing is expected to grow at a CAGR of over 6.6% during the forecast period.

The contract manufacturing market is segmented based on verticals that have a noteworthy contribution to market growth. Some verticals included in the market analysis are consumer electronics, aerospace and defense, energy, food processing and manufacturing, personal care, healthcare and life sciences, packaging, automotive and furniture.

The consumer electronics vertical further renders information about electronic equipment used in home appliances, Smartphones, IT components, laptops and computers and accessories. The aerospace and defense sector provides contract manufacturing services for engines, airframes, fabrication, parts of satellites, assembly of components and space electronics.

The report includes information about the energy sector for solar energy, wind energy and hydropower. The report provides supply chain analysis of original equipment manufacturers (OEMs), sub-contract manufacturers, raw material suppliers and product design and engineering firms, among others.

The competitive landscape of the global market for contract manufacturing is discussed at length. Major companies involved in contract manufacturing are profiled in the report, with a description of product portfolios and recent developments. All categories are discussed in detail, describing each segment, measuring market size, identifying market drivers, forecasting for 2018-2023 and assessing competitors and competitor market shares.

Estimated values are based on manufacturers' total revenues. Projected and forecasted revenue values are in constant U.S. dollars (USD), unadjusted for inflation. The study covers the global market for contract manufacturing. The selection of countries included in this report was mainly based on the total revenue generated. Major countries included in the report are the U.S., Canada, Germany, the U.K., Spain, Italy, France, China, Japan and India.

Report Includes:
Analyses of global market trends with data from 2017 and 2018, and projections of compound annual growth rates (CAGRs) through 2023
Discussion of underlying technologies and factors influencing the demand, including current trends, stringent government regulations, technological achievements and other macroeconomic factors
Identification of the companies that are best positioned to meet this demand because of their proprietary technologies, strategic alliances or other advantages
A relevant patent analysis
Competitive landscape covering major manufacturers and suppliers of contract manufacturing equipment. Major companies including Catalent Inc., Foxconn Technology Group, Flextronics International Ltd., Jabil Inc., Patheon N.V., and Zober Industries
Key Topics Covered:

Chapter 1 Introduction
Study Goals and Objectives
Reasons for Doing This Study
Scope of Report
Information Sources
Methodology
Geographic Breakdown
Analyst's Credentials
Custom Research
Related Reports
Chapter 2 Summary and Highlights

Chapter 3 Market and Technology Background
Description of Market Trends
Asia-Pacific
Automotive Contract Manufacturing
Consumer Electronics
Supply Chain
Market Dynamics
Patent Cliffs
Chapter 4 Market Breakdown by Technology Type
Aerospace and Defense
Consumer Electronics
Home Appliances
Smartphones
Laptops, Computers and IT Components
Accessories
Semiconductors
Energy
Solar Energy
Wind Energy
Hydropower
Healthcare and Life Science
Pharmaceuticals
Medical Devices
Biotechnology
Plant Science
Food Processing and Manufacturing
Personal Care
Packaging
Automotive
Furniture
Chapter 5 Market Breakdown by Region

Chapter 6 Analysis of Market Opportunities
Key Suppliers and Manufacturers
Top EMS Providers
Hon Hai Precision Industry (Foxconn)
Flextronics International Ltd.
Jabil Circuit
Top Pharmaceutical/Medical Contract Manufacturers
Patheon N.V.
Catalent Inc.
Top Aerospace and Defense Contract Manufacturing Services Providers
Boeing
General Dynamic Corp.
Chapter 7 Company Profiles
Abbvie
Advanced Circuit Technology Inc.
Advanced Electronics Manufacturing (Aem)
Aeonova Group
Aesica Pharmaceuticals Ltd.
Ajinomoto Althea Inc.
Allegiant Health
Almac Group
Altadox, Inc.
Altron Inc.
Ansen Corp.
Arc-Tronics Inc.
Asteelflash Group
Aurena Laboratories
Aurobindo Pharma
Baxter
BDR Pharmaceuticals Internationals Pvt., Ltd.
Benchmark Electronics Inc.
Beyonics Pte Ltd.
Bluegum Pharmaceuticals
Boehringer Ingelheim International Gmbh
Cadence Inc.
Catalent Inc.
Celestica Inc.
Chip Star Technology Llc
Ciron Group
Cofidur Ems Sa
Coghlin Companies Inc.
Computrol Inc.
Confab Laboratories Inc.
Corden Pharma International Gmbh
Creation Technologies Lp
Daito Pharmaceutical Co., Ltd.
Dataed
Delpharm
Dishman Group
Divis Laboratories Ltd.
Douglas Manufacturing Ltd.
DPT Laboratories Inc.
Dr. Reddy's Laboratories Ltd.
Dravon Medical Inc.
East West Manufacturing Llc
Eca Inc.
Eit Llc
Ei Microcircuits Inc.
Elite Electronic Systems
Enercon Technologies
Esteve Qumica S.A.
Euticals S.P.A.
Ever Neuro Pharma Gmbh
Evonik Industries Ag
Express Manufacturing Inc.
Fabrinet
Famar S.A.
Fareva Group
Finecure Pharmaceuticals Ltd.
First Electronics Inc.
Flextronics International Ltd.
Foxconn Technology Group
Global Equipment Services And Manufacturing Inc.
Gracure Pharmaceuticals Ltd.
Hindustan Aeronautics Ltd.
Hana Microelectronics Public Co., Ltd.
Hisun Pharmaceutical Co., Ltd.
HTI Plastic
IEC Electronics
Integrated Micro-Electronics Inc.
Jabil Inc.
Jubilant Life Sciences Ltd.
Keytronicems
Kimball Electronics Inc.
Kimchuk Inc.
Korten Pharmaceuticals Pvt., Ltd.
Lee Biosolutions Inc.
Libra Industries Inc.
Logican Technologies Inc.
Lonza Group Ltd.
Mack Technologies Inc.
Manufactured Assemblies Corp.
Mc Assembly
Mcguff Pharmaceuticals Inc.
Mcnally Group
Mflex
Mikart Inc.
Morey Corp.
MTI Electronics Inc.
Natel Engineering Co., Inc.
Needletech Products Inc.
Nextpharma Technologies
Nextphase Medical Devices Llc
Nikol Formulation Pvt., Ltd.
Nipro Group
Nissha Co., Ltd.
Nortech Systems Inc.
Onyx Scientific Ltd.
Orient Semiconductor Electronics Ltd.
Patheon
Peko Precision Products Inc.
Pfizer Centerone
Pharmasynth Formulations Ltd.
Phoenix Deventures Inc.
Piramal Pharma Solutions
Quantronic Corp.
Radico Remedies
Recipharm Ab
Riverside Electronics Ltd.
Sain Medicaments Pvt., Ltd.
Sanmina Corp.
Schneider Electric President Systems Ltd.
Shandong Xinhua Pharmaceutical Co., Ltd.
Siegfried Ag
Siix Corp.
SMC Ltd.
SMS Electronics Ltd.
SMTC Corp.
Sonic Manufacturing Tech
Sopharma Ad
Sparton
Stason Pharmaceuticals
Sumitronics Corp.
Synecco Ltd.
Synokem Pharma
Sypris Electronics Llc
Teva Pharmaceutical Industries Ltd. ( Teva Api )
) TT Electronics-Ims
Vetter Pharma International Gmbh
Vtech Holdings Ltd.
West Pharmaceutical Services Inc.
Yash Pharma Laboratories Pvt., Ltd.
Zober Industries
Zollner Elektronik

For more information about this report visit https://www.researchandmarkets.com/r/yt52oe

Media Contact:
Research and Markets
Laura Wood, Senior Manager
press@researchandmarkets.com

For E.S.T Office Hours Call +1-917-300-0470
For U.S./CAN Toll Free Call +1-800-526-8630
For GMT Office Hours Call +353-1-416-8900

U.S. Fax: 646-607-1907
Fax (outside U.S.): +353-1-481-1716
SOURCE Research and Markets
Related Links
http://www.researchandmarkets.com


Story 6
Dynabook has announced it will be partnering with Microsoft to offer up the first in the company's new Windows 10 Secured-core PCs.
The first Dynabook devices to offer this next-level hardware, software and identity protection are available now which makes the company one of the first manufacturers to bring Secured-core PCs to market.
The Portégé X30-F and Tecra X40-F, which were first announced on July 9, are the first 13” and 14” notebooks to be Dynabook-branded in Europe following the re-brand of Toshiba's computer business in April of this year. These laptops are elegantly designed and come equipped with a range of features intended to provide seamless connectivity and reliability.
The Tecra X50F, announced on September 5, weighs in at just 1.42kg and boasts an impressive 17-hour battery life. The device offers the high brightness of a 15” Sharp IGZO FHD LCD screen without compromising portability, performance or reliability on the go.
Secured-core PCs
Secured-core PCs are designed to handle mission-critical data and protect workers in some of the most data-sensitive industries such as healthcare providers handling medical records and other personally identifiable information (PII), high profile industries targeted by phishing and other attacks and businesses that employ mobile workers who need to be able to access business-critical information outside of the office.
Managing director of Dynabook Europe GmbH, Damian Jaume explained why the company decided to partner with Microsoft to develop its new Secured-core PCs, saying:
“Dramatic developments in digital technologies have fuelled the growth and needs of the mobile workforce. Now in an age of mass data proliferation and an increased threat landscape, organisations need to rapidly adapt to this changing environment. Current network infrastructures were not built with the requirements of today’s security in mind. Devices are often the first line of defence for organisations – but those operating in the most data-sensitive of industries need an added layer of security to ensure comprehensive protection. That is why we’re partnering with Microsoft to develop an integrated hardware and software approach to security.”
Dynabook may be one of the first device manufacturers to offer Secured-core PCs but expect others to follow suit now that Microsoft has officially announced its new security-focused initiative.

Story 7
Von Heinz-Roger Dohms
Doppelter Paukenschlag bei Payone, dem Acquiring-Joint-Venture der deutschen Sparkassen und des französischen Ingenico-Konzerns: Mittwochfrüh erreichte uns zunächst die offizielle Mitteilung, dass einer der beiden Gründer, nämlich Technik-Chef Jan Kanieß, das Unternehmen „auf eigenen Wunsch verlässt“. Nach exklusiven Informationen von „Finanz-Szene.de“ kommt es allerdings noch dicker für den Bezahlspezialisten. Denn wie uns eine Payone-Sprecherin gestern Abend bestätigte, ist auch der Abgang des zweiten Gründers Carl Frederic Zitscher ausgemachte Sache. Er soll im Laufe der ersten Jahreshälfte 2020 offiziell aus dem Unternehmen ausscheiden.
Der Doppel-Abschied zeigt, dass die neue Payone GmbH mit der gleichnamigen Ursprungsgesellschaft nicht mehr allzu viel zu tun hat – und Ingenico dank seines über 50%-igen Anteils die Geschicke des Joint-Ventures inzwischen maßgeblich bestimmt. Kanieß und Zitscher hatten Payone Anfang der Nullerjahre als Zahlungsdienstleister für das E-Commerce gegründet. 2015 folgte dann die Übernahme durch die BS Card Service, also den klassischen Acquirer der deutschen Sparkassen. Der Deal sorgte damals für großes Aufsehen, weil es das erste Mal war, dass ein bankeneigener Bezahldienst einen der neuen Online-Player übernahm.
Trotz des Exits blieben Zitscher und Kanieß damals an Bord – nicht nur als Mitglieder des Managements, sondern auch als Anteilseigner. Die Sparkassen hielten fortan 80% an der neuen „BS Payone“, die beiden Gründer jeweils 10%. Der nächste Einschnitt ließ allerdings nur wenige Jahre auf sich warten – denn 2017 stellte der Deutsche Sparkassenverlag die „BS Payone“ zum Verkauf. Nachdem zunächst der US-Konzern First Data mit seiner deutschen Tochter Telecash als Favorit für die Übernahme galt, setzten sich im Bieterrennen letztlich der französische Ingenico-Konzern samt seiner hiesigen Tochter Easycash durch (siehe unsere Exklusiv-Berichterstattung aus dem Mai letzten Jahres).
So entstand in letzter Konsequenz aus ursprünglich drei Unternehmen (nämlich die alte Payone, B+S Card Service und Easycash) die neue Payone GmbH, an der Ingenico etwas mehr als 50% hält, der Sparkassenverlag etwas weniger. Als Nachfolger für Technikchef Kanieß wurde am Mittwoch Roland Schaar präsentiert, bislang Chief Technology Officer beim europäischen Fintech-Konzern „4Finance Group“ (das hierzulande hinter diversen Kredit-Startups steht). Schwerer als der Abgang von Kanieß dürfte allerdings der Verlust von Zitscher wiegen, der gerade für viele E-Commerce-Kunden das Gesicht von Payone war. Ein Nachfolger steht noch nicht fest.

Story 8
Zunehmend mehr Unternehmen haben heutzutage eine Cloud-First-Strategie. Und die, die noch nicht soweit sind, werden bald eine definieren. Denn sie alle wollen von der Agilität und der Automatisierung profitieren, die Anwendungen in der Cloud mit sich bringen.
Zunehmend mehr Unternehmen haben heutzutage eine Cloud-First-Strategie. Und die, die noch nicht soweit sind, werden bald eine definieren. Denn sie alle wollen von der Agilität und der Automatisierung profitieren, die Anwendungen in der Cloud mit sich bringen. Die Unternehmen wollen sich aber dabei auf den Nutzen, den die Anwendung für ihr Geschäft selbst bringt, konzentrieren und sich nicht mit der Zusammenführung von Einzelkomponenten beschäftigen müssen. Große Unternehmen, die geschäftskritische Anwendungen in die Cloud schieben wollten, hatten in der Vergangenheit jedoch Sicherheitsbedenken, die eine Cloud Migration verhinderten. Diese Herausforderungen wurden erkannt und um diesen Hinderungsgrund zu eliminieren, wurde das Sicherheitsmodell weiterentwickelt.
Das erlaubt Unternehmen jetzt auch in der Cloud auf hochentwickelte Sicherheitsfunktionen zuzugreifen, um extrem komplexe und sensible Workloads in der Cloud zu betreiben. So betreibt beispielsweise The Centers for Medicare & Medicaid Services das Programm Affordable Care Act (ACA) – bei uns besser als Obamacare bekannt, was mehr als 24 Millionen US-Amerikanern erstmalig eine Krankenversicherung ermöglicht hat – vollständig in der Cloud. Wenn auch solche Organisationen mit derart sensiblen Datenschätzen in die Cloud migrieren, wird klar, wie streng die Sicherheitsanforderungen sein müssen.
Multi-Model-Datenbanken haben für vergleichbare Anwendungen mittlerweile deutlich aufgerüstet und bieten umfangreiche Sicherheitsfunktionen. Aber eine hochsichere Datenbank allein reicht nicht aus. Für eine deutlich bessere Cloud-Sicherheit können sogenannte Data Hub Services sorgen, die mit komplexen Sicherheitsmodellen die Anwendungen in der Cloud auf eine neue Sicherheitsstufe heben.
Drei zentrale Punkte für maximale Cloud-Sicherheit
Virtuelle Private Cloud. Im Gegensatz zu anderen Diensten, bei denen mehrere Berechtigte auf eine gemeinsame Infrastruktur zugreifen, befindet sich bei einem Data Hub Service jeder berechtigte Teilnehmer in seiner eigenen Virtual Private Cloud (VPC). Damit agiert jedes Unternehmen in einer völlig anderen Umgebung und ist komplett getrennt von den Daten, dem Netzwerk, dem Speicherort und der Datenverwaltung anderer Unternehmen. Statt also Teil eines Pools zu sein, bei dem jedem Kunden ein Platz zugewiesen wird, erhält jeder Teilnehmer seine eigene Virtuelle Private Cloud. Data Hub Services, die mit diesem Ansatz arbeiten, bieten die höchste Sicherheitsstufe: Es gibt keine Möglichkeit, VPC an- oder auszuschalten oder gar falsch zu konfigurieren. Es ist genau dieses hohe Maß an Isolation, das Unternehmen brauchen, um ihren Datenschatz zu schützen.
Hochentwickelte Verschlüsselung. Daten im Data Hub Service sollten standardmäßig immer verschlüsselt sein. Auf Datenbankebene bedeutet die Verschlüsselung, dass selbst AWS oder Azure Administratoren die Daten des Unternehmens nicht sehen können. Auch innerhalb eines Unternehmens gibt es verschiedene Arten und Klassen von Daten, die unterschiedlich verschlüsselt werden können. So wird sichergestellt, dass nur berechtigte Personen zur richtigen Zeit auf die richtigen Daten zugreifen können. Diese Verschlüsselung stellt eine weitere Stufe der Datentrennung dar, die Unternehmen für eine sichere Anwendung in der Cloud benötigen. Durch Funktionen wie der Zugriffskontrolle auf Elementebene und der Anonymisierung sind Daten in einem Data Hub deshalb extrem sicher und – in Bezug auf berechtigte Personen – dennoch in höchstem Maße teilbar.
Maximale Sicherheit durch Zertifizierung. Die im Data Hub integrierte Sicherheit erhöht also die bereits in der Datenbank selbst integrierte Sicherheit um ein Vielfaches. Eine Common-Criteria Zertifizierung, wie sie SOC 2 Type II für die Prinzipien – Sicherheit, Verfügbarkeit, Integrität der Verarbeitung, Vertraulichkeit und Datenschutz bietet, ist ein zusätzlicher Nachweis darüber, dass angemessene Richtlinien, Verfahren und Kontrollen für die Cloud-Sicherheit vorhanden sind. Sie stellen sicher, dass mit granularen Zugriffskontrollen gemäß den vorgegebenen Richtlinien des Unternehmens ausschließlich berechtigte Personen im richtigen Kontext auf die Daten zugreifen können.
Data Hub Services setzen Standards
Unternehmen erwarten zu Recht maximale Cloud-Sicherheit. Data Hub Services bringen auch hochsensible Unternehmensanwendungen schnell und sicher in die Cloud und setzen heute jene Sicherheitsstandards, die Unternehmen von Datenbank- und Cloud-Service-Technologien erwarten. In allen Branchen wie zum Beispiel im Gesundheits-, Finanz- und Versicherungssektor spielen zertifizierte Anbieter eine wichtige Rolle.
Dr. Stefan Grotehans, MarkLogic Deutschland GmbH. (Bild: © Daniel Gaines / MarkLogic)
Eine SOC2 Type II Zertifizierung ist zum Beispiel eine zentrale Voraussetzung in der Finanzbranche. Data Hub Services können ein höheres Maß an Sicherheit bieten, als vergleichbare On-Premise Lösungen. Grund dafür ist die zentrale Verwaltung der Anwendungen, die erweiterten Sicherheitsmodelle und die Trennung von Aufgaben, ermöglicht durch das fein granulare Zugriffsmodel. Die Basis ist geschaffen, auch unternehmenskritische Daten in die Cloud zu migrieren, um schneller und kostengünstiger zu werden.
* Der Autor Dr. Stefan Grotehans ist Senior Director Solutions Engineering DACH bei der MarkLogic Deutschland GmbH.

Story 9
SAN JOSE, Calif.--(BUSINESS WIRE)--Samsung Electronics Co., Ltd., a world leader in advanced memory technology, today announced that it has begun mass producing the industry's first 12-gigabyte (GB) low-power double data rate 4X (LPDDR4X) UFS-based multichip package (uMCP). The announcement was made as part of the company’s annual Samsung Tech Day at its Device Solutions’ America headquarters in San Jose, California.
" Leveraging our leading-edge 24-gigabit (Gb) LPDDR4X chips, we can offer the highest mobile DRAM capacity of 12GB not only for high-end smartphones but also for mid-range devices," said Sewon Chun, executive vice president of Memory Marketing at Samsung Electronics. " Samsung will continue to support our smartphone-manufacturing customers with on-time development of next-generation mobile memory solutions, bringing enhanced smartphone experiences to many more users around the globe."
Samsung is introducing its 12GB uMCP solution just seven months after its launch of a 12GB LPDDRX package based on 16Gb DRAM. By combining four of the 24Gb LPDDR4X chips (featuring the latest 1y-nanometer process technology) and ultra-fast eUFS 3.0 NAND storage into a single package, the new mobile memory is able to break through the current 8GB package limit and provide 10+ GB memory to the broader smartphone market.*
As the trend toward larger, higher-resolution smartphone displays continues to grow, more users will benefit from Samsung's uMCP solution when running data-intensive tasks or multitasking. With 1.5X capacity of the previous 8GB package and a data transfer rate of 4,266 megabits per second (Mbps), the 12GB uMCP can support smooth 4K video recording as well as accommodate AI and machine learning features even for mid-end smartphones.
Samsung plans to rapidly expand the availability of 10+ GB LPDDR DRAM to address the increasing needs of global smartphone makers for higher-capacity memory solutions, while reinforcing its competitive edge in the memory marketplace.
###
* Editors’ note:
12GB LPDDR4X uMCP: four 24Gb (3GB) chips + eUFS 3.0
10GB LPDDR4X uMCP: two 24Gb (3GB) chips + two 16Gb (2GB) chips + eUFS 3.0
About Samsung Electronics Co., Ltd.
Samsung inspires the world and shapes the future with transformative ideas and technologies. The company is redefining the worlds of TVs, smartphones, wearable devices, tablets, digital appliances, network systems, and memory, system LSI, foundry and LED solutions. For the latest news, please visit the Samsung Newsroom at http://news.samsung.com.

Story 10
Access Denied - Sucuri Website Firewall
If you are the site owner (or you manage this site), please whitelist your IP or if you think this block is an error please open a support ticket and make sure to include the block details (displayed in the box below), so we can assist you in troubleshooting the issue.
Block details:

Story 11
A new Profession Intelligence Report released by Stats and Reports with the title Global Cloud Backup Market “can grow into the most important market in the world that has played an important role in making progressive impacts on the global economy. Global Cloud Backup Market Report presents a dynamic vision to conclude and research market size, market hope and competitive environment. The study is derived from primary and secondary statistical data and consists of qualitative and numerical analysis. The main company in this survey is Acronis International GmbH, Asigra Inc., Barracuda Networks, Inc, Carbonite, Inc., Code42 Software, Inc., Datto, Inc., Druva Software, Efolder, Inc., International Business Machines Corporation, Iron Mountain Incorporated, Microsoft Corporation, Veeam Software.
Free Sample Report @: www.statsandreports.com/request-sample/362285-global-cloud-backup-market-size-status-and-forecast-2019-2025
Preliminary Data:
Get raw market data and contrast from wide front. Data is constantly filtered so that only validated and authenticated sources are considered. The data is also collected from many reputable paid databases and many reports in our repository. A comprehensive understanding of the market is essential to understanding and facilitating the complete value chain. We collect data from raw material suppliers, distributors, and buyers.
Sample Table: Global Cloud Backup Market Size By Regions (USD Million) (2014-2025)
Regions 2014 2016 2018 2020 2022 2024 2025 CAGR %
(2019-2025) North America XXX XXX XXX XXX XXX XXX XXX XX% Europe XXX XXX XXX XXX XXX XXX XXX XX% APAC XXX XXX XXX XXX XXX XXX XXX XX% Rest of the World XXX XXX XXX XXX XXX XXX XXX XX% Total XXX XXX XXX XXX XXX XXX XXX XX%
Furthermore, the years considered for the study are as follows:
Historical year – 2014-2018
Base year – 2019
Forecast period** – 2019 to 2025
[** unless otherwise stated]

Research Methodology:
The market engineering process uses a top-down and bottom-up approach and several data triangulation methods to evaluate and validate the size of the entire market and other dependent sub-markets listed in this report. Numerous qualitative and quantitative analyzes have been conducted in the market engineering process to list key information / insights. The major players in the market were identified through the second survey and the market rankings were determined through the first and second surveys.
Exclusive Discount Offer on Quick Purchase @www.statsandreports.com/check-discount/362285-global-cloud-backup-market-size-status-and-forecast-2019-2025
Crucial Research:
During the first survey, we interviewed various key sources of supply and demand to obtain qualitative and quantitative information related to this report. Key supply sources include key industry participants, subject matter specialists from key companies, and consultants from several major companies and organizations active in the digital signage market.
Minor Research:
The second study was conducted to obtain key information on the supply chain of the industry, the market’s currency chain, pools of major companies, and market segmentation, with the lowest level, geographical market, and technology-oriented perspectives. Secondary data was collected and analyzed to reach the total market size, which was verified by the first survey.
Key Segments Studied in the Global Cloud Backup Market
Segment Details Market Analysis By Type Public Cloud, Private Cloud, Hybrid Cloud Market Analysis By Applications Small and Medium-Sized Enterprises, Large Enterprises Market Analysis By Regions North America, United States, Canada, Mexico, Asia-Pacific, China, Japan, South Korea, India, Australia, Indonesia, Thailand, Malaysia, Philippines, Vietnam, Europe, Germany, France, UK, Italy, Russia, Rest of Europe, Central & South America, Brazil, Rest of South America, Middle East & Africa, GCC Countries, Turkey, Egypt, South Africa and Rest of Middle East & Africa Market Analysis By Companies Acronis International GmbH, Asigra Inc., Barracuda Networks, Inc, Carbonite, Inc., Code42 Software, Inc., Datto, Inc., Druva Software, Efolder, Inc., International Business Machines Corporation, Iron Mountain Incorporated, Microsoft Corporation, Veeam Software
• What are the Major applications of the Cloud Backup Market?
Application’s cover in these Reports Is: Small and Medium-Sized Enterprises, Large Enterprises
• What are the Types of the Cloud Backup Market?
Types Cover in this Research :Public Cloud, Private Cloud, Hybrid Cloud
• Who are the main competitors in the market and what are their priorities, strategies, and developments?
Lists of Competitors in Research Is: Acronis International GmbH, Asigra Inc., Barracuda Networks, Inc, Carbonite, Inc., Code42 Software, Inc., Datto, Inc., Druva Software, Efolder, Inc., International Business Machines Corporation, Iron Mountain Incorporated, Microsoft Corporation, Veeam Software
Read Full TOC of Cloud Backup Research Study at @ www.statsandreports.com/report/362285-global-cloud-backup-market-size-status-and-forecast-2019-2025
All percent shares, breaks, and classifications were determined using the secondary sources and confirmed through the primary sources. All parameters that may affect the market covered in this study have been extensively reviewed, researched through basic investigations, and analyzed to obtain final quantitative and qualitative data. This has been the study of key quantitative and qualitative insights through interviews with industry experts, including CEOs, vice presidents, directors and marketing executives, as well as annual and financial reports from top market participants.
Years considered for the study are:
Historical year – 2014-2018
Disreputable year – 2019
Estimate period** – 2019 to 2025 [** unless otherwise stated]
Essentials of Table of Content:
1 Report Overview
1.1 Research Scope
1.2 Key Market Segments
1.3 Target Player
1.4 Market Analysis by Type
1.5 Market by Application
1.6 Learning Objectives
1.7 years considered
Buy the Up-to-date Full Report @www.statsandreports.com/placeorder?report=362285-global-cloud-backup-market-size-status-and-forecast-2019-2025
2 Global Growth Trends
2.1 Global Cloud Backup Market Size
2.2 Trends of Cloud Backup Growth by Region
2.3 Corporate trends
3 Cloud Backup Market shares by key players
3.1 Global Cloud Backup Market Size by Manufacturer
3.2 Global Cloud Backup Key players Provide headquarters and local
3.3 Major Players Products / Solutions / Services
3.4 Enter the Barriers in the Cloud Backup Market
3.5 Mergers, acquisitions and expansion plans
4 Market By-products
4.1 Global Cloud Backup Sales by Product
4.2 Global Cloud Backup by Product Revenue
4.3 Global Cloud Backup
Note: Regional Breakdown & Sectional purchase Available We provide Pie chats Best Customize Reports As per Requirements.
About Us
Stats and Reports is a global market research and consulting service provider specialized in offering wide range of business solutions to their clients including market research reports, primary and secondary research, demand forecasting services, focus group analysis and other services. We understand that how data is important in today’s competitive environment and thus, we have collaborated with industry’s leading research providers who works continuously to meet the ever-growing demand for market research reports throughout the year.
Contact:
Stats and Reports
Satish K. (Global Sales Manager)
Mangalam Chamber, Office No – 16, Paud Road
Sankalp Society, Kothrud, Pune, Maharashtra 411038
Phone: +1 650-646-3808
Email: sales@statsandreports.com
Web: https://www.statsandreports.com
Follow Us on: LinkedIN| Twitter|
loud Backup market Top Manufacturers,Cloud Backup Sales market

Story 12
From left to right: Professor Michele Solimena, Professor Anne-Claude Gavin, and Professor Kai Simons at the LEA press talk event. Image credit: Lipotype.
Dresden is the charming capital of the eastern German state of Saxony. Here, delicious freshly baked food is aplenty, classical music drifts out of shop windows as you saunter on by, and the cobbled streets are adorned with ornate Baroque architecture.

The city is a sweet spot for history, art and culture lovers alike. However, it's present and future position as a hub for innovative scientific research and discovery is equally as is impressive and draws in scientists from across the globe. Dresden is home to 46 research centers, including four Max-Planck Institutes, two Helmholtz Facilities and five Leibniz Institutes.


﻿Dresden, Germany. Image credit: Molly Campbell.

Insight into the lipid cosmos

My visit to Dresden orientates around a scientific research field that has garnered increasing attention over recent years – lipidomics. Research in this field entails the characterization and functional analysis of lipids: complex hydrophobic polymer biomolecules that drive metabolic regulation at both the cellular and whole-organism level. Advances in our understanding of the integral role that lipids play in health and disease have been enabled by developments in mass spectrometry (MS)-based technology for small molecule analysis. In the heart of Dresden, Lipotype GmbH host the press talk for their Lipidomics Excellence Award (LEA), the first prize to recognize innovation and drive for novelty in researchers using lipidomics.

Featuring an impressive panel of world-renowned researchers, including Professor Kai Simons, Director Emeritus of the Max Planck Institute of Molecular Cell Biology and Genetics and CEO of Lipotype, Professor Michele Solimena, Professor of Molecular Diabetology, TU Dresden, and the LEA laureate Professor Anne Claude-Gavin, Louis-Jeantet Professor at the University of Geneva, the press talk delivered its promise of being an educational event that explored the future directions of this exciting field.



About Lipotype Lipotype GmbH is a Max Planck spin-off company founded by Professor Simons that offers quantitative lipidomic analysis from clinical and biological samples using novel high-throughput shotgun lipidomics technology. The Lipotype team is composed of experts in membrane and lipid biology/chemistry, MS and bioinformatics. Their experience is based on years of academic research focusing primarily on the role of lipids in various cellular processes and on methodological/ technical aspects of lipidomics.
The cell and the city

Professor Simons opens the event with an eloquent metaphor, likening the cell to a city: "Think of a city, a city that has walls surrounding it and is compartmentalized into different sections. For example, a city might have a powerplant. Similarly, the cell has mitochondria. These individual compartments in the cell are "walled" by plasma membranes composed of lipids and proteins. 30% of proteins in an organism can be found within the plasma membrane, and lipids help the proteins to serve their physiological function within the cell."

Throughout his impressive career, Simons' research has focused on cell membrane organization and function, pioneering the concept of lipid rafts. Now, his focus is on translating lipidomics and lipid analysis to clinical and industrial applications.

"Lipidomics is a niche area," he emphasizes. "But there is a growing concentration of researchers that want to know what lipids do, and we want to continue to stimulate research in this area."

Want to learn more about the basic principles of lipidomics? Check out our article, Lipidomics: A Rising Star in "OMICS" Research.

Professor Solimena is one of a growing cohort of researchers that utilize Lipotype's Shotgun Lipidomics Analysis for their research projects.

"Lipidomics is step by step revealing processes and connections that stay hidden with traditional analysis methods." He continues, "In diabetes research, we make good progress thanks to lipidomics. For example, it is now possible to define molecular lipid signatures that tell us about the development of non-diabetic to diabetes type 2 and progression towards diabetes complications."

"We want to shine a light on the fact that lipid analyses really make the difference between research and ground-breaking research: by providing new data one gains even deeper insight into the lipid cosmos. It is high time to seize the potential, let us see what there is still to discover," says Simons.

The LEA has been developed by Lipotype to encourage research in lipidomics by providing a generous research prize: 50,000 EUR worth of high throughput quantitative shotgun lipidomic analysis, in addition to a speaking slot at the EMBO workshop Lipid Function in Health and Disease that took place in Dresden over the course of last weekend.

The first prize goes to…

Professor Gavin is the first LEA laureate, awarded the prize for her research proposal in lipid-transfer proteins. Thus far, ~131 lipid-transfer proteins have been identified in humans, with varied roles such as orchestrating the transport of lipids between membranes, thereby spatially organizing lipids and connecting lipid metabolic pathways within the body.

"I spent the last thirteen years running a group at the EMBL in Heidelberg. Here we have been applying new methods to measure how lipids can interact with proteins and thereby modify the functions of the cell," says Gavin. "For this, we integrated bioinformatics, MS, metabolomic analysis and microfluidics. Since April of this year we moved to the department of Cell Physiology and Metabolism at the University of Geneva."

Professor Gavin explains the background research that has led to the development of the LEA-winning project. "We don't yet know the size of the human lipidome, but we believe there may be up to 40,000 different types of lipids in the human body. So the question is, why do we need such diversity in lipids and what do they all do? We do know from genetic studies that lipid function can be altered in metabolic syndromes, but the exact mechanism behind these alterations isn't well understood."

Lipids catch a ride

"It is important to understand that lipids inside the cell are not marginally distributed. The lipids can accumulate in different compartments inside the cell, and they can work as scaffolds for cell signalling processes or for organizing cellular function." Profesor Gavin continues, "Different organelles in the cell accumulate different lipids. We know now the steps for lipid synthesis and the enzymes that are involved, but surprisingly the enzymes can be located in different compartments inside the cell. The lipid factories are sometimes identified in distant locations from where the lipid is actually required to serve a function. As lipids are hydrophobic and cannot meet with water, they cannot freely diffuse inside the cell. For a lipid to be metabolized and have activity, they need to be transported. We still don't know exactly how this happens."

Professor Gavin will therefore use the LEA research prize to develop the first molecular cartography of the lipid "highways", providing insight into metabolic signaling pathways as well as lipid-transfer protein mediated lipid movement. This will be integrated into a molecular model to describe cell-specific cancer associated alterations. The model will help to address several medically relevant questions.

Mapping the lipidome – why now?

After the press talk concludes I interview Gavin to delve further into the specifics of her research approach. But first I want to address one particular statement from the press talk that caught my attention – the comparison of Gavin's "lipid highways" research as a "metabolomics" equivalent to the Human Genome Project that was completed 16 years ago. Why is it only now that we are recognizing the need to map lipid and protein interactions in cells at the same level of detail? Gavin tells me "It simply comes down to technology. Having the technology available is critical. If you really want to address new questions and problems in biology, you need to develop new technology. Of course, you need a biological question," she laughs, "But without the technology the research is not possible. The EMBL has been a great place for us to develop new ways to measure protein-lipid interactions in a high throughput manner, adopting microfluidic and biochemistry approaches."


Professor Anne-Claude Gavin holds the first LEA prize with Professor Kai Simons. Image credit: Lipotype.


Lipotype specializes specifically in offering quantitative lipidomic analysis, and I am keen to know how this element of the prize will help to progress Gavin's research. She explains "In biology we need to divert away from taking binary measurements and looking at whether something is simply expressed or not. It is very rare that a disease will lead to the absence of something – rather, you will have an imbalance. We need to be able to quantitatively measure the imbalance, which is why the analysis offered by Lipotype as part of the LEA is key to our project."

The high throughput analysis offered in the LEA prize will undoubtedly help facilitate the lipid highway research project. Nonetheless, I'm interested to know whether Professor Gavin expects to encounter any hurdles further downstream in the study. "One of the big challenges will be data integration, as will be producing large data sets on lipidomic and proteomic interactions. We will have to integrate knowledge on metabolism. The first challenge is to understand what we see, what is the background and what is the signal we are detecting. This is relatively basic, but it is critical so that we can derive a hypothesis," she comments. "Ultimately, we would like to be [able] to create models where we can study the physiological impact of say a gain of function in the lipid transfer mechanisms, but data integration will be a big challenge."

How much data is too much data? "To provide context, our group just finished a few screens on lipid transfer proteins that took approximately one to two years to complete, but it then took us an additional one to two years to develop the bioinformatic tools to handle the data."

Future directions in an emerging field

Lipidomics is a field that is developing fast – in 2019 it was the highest growing "omics" field, with a growth increase of 46% in publications. What does Professor Gavin think the future of lipidomics research will look like? "In the shorter term I think we really need to do our homework and understand 'what is the human lipidome?' and what function do each of these lipids serve to create a reference map," she tells me.

"In the longer term we need to understand the interactions between lipids. When you perturbate a cell there is a metabolic response and we need to chart the role of lipids in this response. It is also important that we develop a community of researchers because lipidomics is still seen as a difficult discipline."

Gavin adds, "My personal goal is to develop a technology that allows us to visualize lipids in our body and trace them as they are transported in different organs."

A lipidomics "dreamland"

To conclude, I ask Gavin how it feels to be the first winner of the LEA – albeit, her beaming expression does already provide some insight. "We are very proud. It is reassuring to see that the type of biology that we do and the technology that we have developed is useful for the scientific community, and that other people share our enthusiasm for this area of research. This [the LEA prize] is really a great opportunity and allows us to conduct measurements that would have been otherwise challenging. It is really a lipidomics dreamland," she concludes.

Whilst it seems we are still scratching the surface on the intricate nature of lipid biology, mapping the lipid highways will undoubtedly provide further insight and necessary directions for future research strategies. Congratulations, Professor Gavin!

Professor Anne-Claude Gavin was speaking with Molly Campbell, Technology Networks.

Story 13
Global Data Center Rack Market – Growth, Trends, And Forecast (2019 – 2024)
The report presents an in-depth assessment of the Global Data Center Rack including enabling technologies, key trends, market drivers, challenges, standardization, regulatory landscape, deployment models, operator case studies, opportunities, future roadmap, value chain, ecosystem player profiles and strategies. The report also presents forecasts for Global Data Center Rack investments from 2019 till 2024.
The data center racks market was valued at USD 4044.8 million in 2019, and it is expected to reach a value of USD 6302.2 billion by 2024, at a CAGR of 7.9% during the forecast period (2019 – 2024).
The Global Data Center Rack market is highly competitive and consists of a number of major players. Companies, like Rack Manufacturers, Kendall Howard LLC, Belkin International, Inc., Martin International Enclosures, Black Box Corporation, Rittal GmbH & Co. KG, Tripp Lite, Cheval Electronic Enclosure Co. Ltd, Belden Inc., Chatsworth Products Inc., Panduit Corp., Great Lakes Case & Cabinet Co. Inc., ELMA Electronics, Inc., Integrated Solution Poviders, Vertiv Group Corporation, Eaton Corporation PLC, Hewlett Packard Enterprise, Dell EMC, Schneider Electric SE, Fujitsu Corporation, Oracle Corporation, Legrand SA among others.
Click the link to get a Sample Copy of the Report:
https://www.marketinsightsreports.com/reports/08071392220/data-center-rack-market-growth-trends-and-forecast-2019-2024/inquiry?&Mode=SD48
Scope of the Report:
A data center rack is a type of physical steel and electronic framework that is designed to house servers, networking devices, cables, and other data center computing equipment. Data center racks are deployed, primarily for infrastructure management in data centers. These are being used in the manufacturing, retail, BFSI, IT and telecom industry.
(Special Offer: Get flat 15% discount on this report)
Inquire for Discount:
https://www.marketinsightsreports.com/reports/08071392220/data-center-rack-market-growth-trends-and-forecast-2019-2024/discount?&Mode=SD48
Key Market Trends:
IT & Telecom Sector Expected to Hold a Significant Share
– IT and Telecom is the most significant segment for this market. The IT infrastructure requirement is the highest for this segment. Colocation providers, who are a major adopter of data center racks, are also considered under the scope of the study under the IT & Telecom sector.
– The amount of data that is being stored and processed by this segment is huge. The advent of mobile data and subscriptions and their rapid usage has proliferated the growth of data traffic and hence data centers. With the introduction of 5G and Cloud, the demand is expected to increase exponentially. Major companies are investing in new infrastructure to meet the additional requirements. Companies, like American Tower, bought its first data centers in April 2019 through the acquisition of Colo Atl.
– Other regions like Singapore also witnessed a rapid expansion in April 2019. The data center, colocation, and interconnection provider, Digital Realty commenced the construction of its third data center facility in Singapore. The facility will be capable of supporting up to 50 megawatts (MW) of IT capacity. The new facility will span a gross floor area of 34,000 sq. meter.
– Moreover, with the number of colocation providers growing significantly, and expanding in remote locations, it is expected that the demand for integrated data center racks is expected to witness significant growth during the forecast period.

Browse the Full report description and TOC at:
https://www.marketinsightsreports.com/reports/08071392220/data-center-rack-market-growth-trends-and-forecast-2019-2024?&Mode=SD48
What are the market factors that are explained in the report?
–Key Strategic Developments: The study also includes the key strategic developments of the market, comprising R&D, new product launch, M&A, agreements, collaborations, partnerships, joint ventures, and regional growth of the leading competitors operating in the market on a Global and regional scale.
–Key Market Features: The report evaluated key market features, including revenue, price, capacity, capacity utilization rate, gross, production, production rate, consumption, import/export, supply/demand, cost, market share, CAGR, and gross margin. In addition, the study offers a comprehensive study of the key market dynamics and their latest trends, along with pertinent market segments and sub-segments.
–Analytical Tools: Global Data Center Rack Market report includes the accurately studied and assessed data of the key industry players and their scope in the market by means of a number of analytical tools. The analytical tools such as Porter’s five forces analysis, feasibility study, and investment return analysis have been used to analyzed the growth of the key players operating in the market.
Finally, Global Data Center Rack Market report is the believable source for gaining the Market research that will exponentially accelerate your business. The report gives the principle locale, economic situations with the item value, benefit, limit, generation, supply, request and Market development rate and figure and so on. This report additionally Present new task SWOT examination, speculation attainability investigation, and venture return investigation.
Reasons to Purchase this report:
– The market estimate (ME) sheet in Excel format
– Report customization as per the client’s requirements
– 3 months of analyst support
Media Contact Us:
Irfan Tamboli (Head of Sales) – Market Insights Reports
Phone: + 1704 266 3234 | +91-750-707-8687
sales@marketinsightsreports.com
irfan@marketinsightsreports.com

Story 14
Thomson Reuters
Fintech deal activity hit an all-time high this year, according to a new Dealogic report.
The explosive mergers and acquisition volume comes as more people go cashless and companies compete for consumer data.
The total deal value has been driven by a few monster deals, like Fiserv buying First Data and Global Payments buying Total System Services.
Visit Markets Insider's homepage for more stories.
It's not just you. The fintech space really is red-hot this year.
Global fintech-targeted mergers and acquisition volume has increased "rapidly" over the last five years, and the value of deals in the space has hit a record high in 2019, according to Dealogic associate Chisa Tanaka.
Eighty-seven deals have totaled a record year-to-date value of $116.6 billion, a four-fold increase from the $31.8 billion through the same time last year. There were 89 deals done at this point in 2018.
"Clearly, technological innovation is causing intensifying consolidation in the electronic payment services market, while the acquisition of data on customer's purchasing and behavior trends further drives fintech acquisitions," Tanaka wrote.
A bonus just for you: Click here to claim 30 days of access to Business Insider PRIME
This explosive activity has been driven by three large US-based fintech transactions this year — Fidelity National Information Services' $43.3 billion acquisition of Worldpay in March, Fiserv's buying First Data in January for $39.4 billion, and Global Payments' $26.2 billion purchase of Total System Services in May.
Dealogic
Experts say that while methods of electronic payments are growing in popularity, the world is a long way away from becoming fully cash-free. And to be fair, cash usage varies by countries and regions. The BIS found ATM withdrawals were flat in advanced economies while rising in emerging markets.
Consumers around the world are relying "more and more" on e-payments, the Bank of International Settlements said in a report published last March.
"The use of e-payments is booming and technology companies as well as financial institutions are investing heavily to be the payment providers of tomorrow," the BIS economists wrote.
Read more: The companies disrupting the payments industry in major markets through digital
Although electronic payments have grown in popularity, the BIS concluded there is "scant evidence of a shift away from cash."
"As the appetite for cash remains unabated, few societies are close to 'cashless' or even 'less-cash,'" they wrote.
Notably, the US is the most popular country in the world for fintech deals, followed by the France and the UK, Tanaka found.
"The second half of 2019 will likely bring further market consolidation to boost costumer data retention and provide clarity on the financial ability of the different players," she wrote.
Now read more coverage from Markets Insider and Business Insider:
GameStop crashes after the video game retailer reported another disastrous quarter, new leadership frustrates Wall Street
Investing legend Stanley Druckenmiller reveals why the 'best economic predictor' has him worried about the next crisis — and breaks down where you should be putting your money
Global stocks are rallying as traders see Fed comments as 'central banks to the rescue'
The corporate-bond market is firing a 'warning shot' for stock investors

Story 15
Los Angeles, United State, October 07, 2019, –Global Cartoners market report is first of its kind research report that covers the overview, summary, market dynamics, competitive analysis, and leading player’s various strategies to sustain in the global market. This report covers five top regions of the globe and countries within, which shows the status of regional development, consisting of market value, volume, size, and price data. Apart from this, the report also covers detail information about various clients which is the most significant element for the manufacturers.
The global Cartoners market is valued at million US$ in 2018 is expected to reach million US$ by the end of 2025, growing at a CAGR of during 2019-2025.
Access PDF Version of this Report at: https://www.qyresearch.com/sample-form/form/930554/global-cartoners-manufacturers-profiles-market
The following Companies as the Key Players in the Global Cartoners Market Research Report:
Molins Langen, Industria Macchine Automatiche SpA, Robert Bosch GmbH, Omori Machinery Co. Ltd, Tetra Pak International S.A, Marchesini Group, OPTIMA Packaging Group GmbH, IWK Verpackungstechnik GmbH, ROVEMA GmbH, Shibuya Packaging System Corpoartion, Cama Group, Triangle Package Machinery Co, Douglas Machine Inc, ACG Pampac Machines Private Limited, Econocorp Inc, PMI Cartoning Inc, Pakona Engineers Pvt Ltd, Korber Medipak Sysems, Bradman Lake Group Ltd, Jacob White Packaging Ltd, ADCO Manufacturing,
In terms of region, this research report covers almost all the major regions across the globe such as North America, Europe, South America, the Middle East, and Africa and the Asia Pacific. Europe and North America regions are anticipated to show an upward growth in the years to come. While Cartoners Market in Asia Pacific regions is likely to show remarkable growth during the forecasted period. Cutting edge technology and innovations are the most important traits of the North America region and that’s the reason most of the time the US dominates the global markets. Cartoners Market in South, America region is also expected to grow in near future.
Cartoners Market Segmentation by Types:
Top-load, End-load, Wrap-around,
Cartoners Market Segmentation by Applications:
Consumer Goods, Food & Beverage, Healthcare, Personal Care, Others,
The report represents the statistical data in the form of tables, charts, and info-graphics to assess the market, its growth and development, and market trends of the Global Cartoners Market during the projected period. QY Research has used a framework of primary and secondary research to make this report a full-proof one.
Get Customized Report in your Inbox within 24 hours @ https://www.qyresearch.com/customize-request/form/930554/global-cartoners-manufacturers-profiles-market
Strategic Points Covered in TOC:
Chapter 1: Introduction, market driving force product scope, market risk, market overview, and market opportunities of the global Cartoners market
Chapter 2: Evaluating the leading manufacturers of the global Cartoners market which consists of its revenue, sales, and price of the products
Chapter 3: Displaying the competitive nature among key manufacturers, with market share, revenue, and sales
Chapter 4: Presenting global Cartoners market by regions, market share and with revenue and sales for the projected period
Chapter 5, 6, 7, 8 and 9: To evaluate the market by segments, by countries and by manufacturers with revenue share and sales by key countries in these various regions
Finally, the global Cartoners Market is a valuable source of guidance for individuals and companies. One of the major reasons behind providing market attractiveness index is to help the target audience and clients to identify the several market opportunities in the global Cartoners market. Moreover, for a better understanding of the market, QY Research has also presented a key to get information about various segments of the global Cartoners market.
About Us:
QY Research established in 2007, focus on custom research, management consulting, IPO consulting, industry chain research, database and seminar services. The company owned a large basic database (such as National Bureau of statistics database, Customs import and export database, Industry Association Database etc), expert’s resources (included energy automotive chemical medical ICT consumer goods etc.

Story 16
-Positive results from both Phase 3 LIBERTY trials and bioequivalence study supports submission of NDA for uterine fibroids which is expected by year end 2019 and MAA which is expected by Q1-2020-

-Top-line data from Phase 3 HERO trial in advanced prostate cancer expected by year end 2019 with Phase 3 SPIRIT data in endometriosis expected in Q1 and Q2 2020-
BASEL, Switzerland, Aug. 06, 2019 (GLOBE NEWSWIRE) -- Myovant Sciences (NYSE: MYOV), a clinical-stage healthcare company focused on developing and commercializing innovative therapies for women’s health and prostate cancer, today announced recent corporate updates and reported financial results for the first fiscal quarter ended June 30, 2019.
“Myovant Sciences recently announced positive top-line data for the LIBERTY 1 and LIBERTY 2 studies evaluating relugolix combination therapy in women with uterine fibroids, as well as the positive results from a separate bioequivalence study supporting a potential one pill, once-a-day dosing regimen of relugolix combination therapy,” said Lynn Seely, M.D., President and Chief Executive Officer of Myovant Sciences. “These results confirm the potential of relugolix to offer a constellation of attributes in a single pill, taken once-a-day and we are now focused on preparing for the New Drug Application (NDA) submission to the U.S. Food and Drug Administration (FDA), which we plan to file by the end of this calendar year. We also look forward to reporting data from our Phase 3 prostate cancer study later this calendar year and results from our two Phase 3 endometriosis studies in the first and second quarters of calendar year 2020.”
First Fiscal Quarter 2019 and Recent Business Highlights
Relugolix Phase 3 Clinical Programs
On May 14, 2019, Myovant Sciences announced positive top-line results from the LIBERTY 1 Phase 3 study evaluating relugolix combination therapy (relugolix 40 mg plus estradiol 1.0 mg and norethindrone acetate 0.5 mg) once-a-day in women with uterine fibroids and heavy menstrual bleeding. The study met its primary endpoint with a p-value of <0.0001 and achieved six key secondary endpoints with a well-tolerated safety profile.


On July 23, 2019, Myovant Sciences announced positive top-line results from the LIBERTY 2 Phase 3 study evaluating relugolix combination therapy in women with uterine fibroids and heavy menstrual bleeding. This study also met its primary endpoint with a p-value of <0.0001 and achieved six key secondary endpoints with a well-tolerated safety profile.


On July 23, 2019, Myovant Sciences also announced that the single-tablet relugolix combination therapy met all required FDA criteria in a separate bioequivalence study supporting a potential one-pill, once-a-day dosing regimen of relugolix.


Based on the positive top-line results for LIBERTY 1 and LIBERTY 2, Myovant Sciences currently plans to submit an NDA for one-pill, once-a-day relugolix combination therapy for the treatment of heavy menstrual bleeding and uterine fibroids to the FDA in the fourth quarter of calendar year 2019 and the Marketing Authorisation Application to the European Medicines Agency in the first quarter of calendar year 2020.


Enrollment of approximately 130 additional men with metastatic prostate cancer in the Phase 3 HERO study was completed in July 2019. The objective of enrolling these men was to assess the secondary objective of demonstrating that relugolix can delay the time to progression of the lethal state of the disease, castration-resistant prostate cancer, as compared to leuprolide.
MVT-602 Clinical Program
Myovant Sciences completed a successful dose-finding pharmacokinetic/pharmacodynamic Phase 2a study of MVT-602, a kisspeptin-1 receptor agonist, in healthy women undergoing a minimal controlled ovarian stimulation protocol. Top-line results were presented at the European Society of Human Reproduction in Vienna, Austria in June 2019. The study demonstrated that MVT-602 was generally well-tolerated and produced the desired luteinizing hormone surge associated with high and dose-dependent rates of ovulation in healthy women following a minimal controlled ovarian stimulation protocol.
Corporate
On June 4, 2019, Myovant Sciences completed an underwritten public equity offering, receiving net proceeds of approximately $134.5 million.


In the first quarter of fiscal year 2019, Myovant Sciences received aggregate net proceeds of $2.5 million pursuant to the issuance of common shares under its “at-the-market” equity offering program.
First Fiscal Quarter 2019 Financial Summary
Research and development (R&D) expenses for the quarter ended June 30, 2019, were $51.1 million compared to $51.3 million for the comparable prior year period. The composition of R&D expenses in both periods is similar, and primarily includes expenses related to Myovant Sciences’ Phase 3 clinical studies as well as personnel-related expenses for employees engaged in R&D activities. R&D expenses for the quarter ended June 30, 2018 reflected a ramp up in relugolix Phase 3 study costs primarily related to study enrollment, whereas R&D expenses for the quarter ended June 30, 2019 reflect lower relugolix Phase 3 study costs as certain studies are in the process of winding down. The decrease in relugolix Phase 3 study costs were partially offset by increases in other R&D spending related to Myovant Sciences’ preparations to seek regulatory approval for its product candidates.
General and administrative (G&A) expenses for the quarter ended June 30, 2019, were $14.2 million compared to $8.7 million for the comparable prior year period. The increase primarily reflects increases in personnel-related expenses, professional service fees, share-based compensation, and other general overhead and administrative expenses to support Myovant Sciences’ headcount growth and expanding operations.
Interest expense for the quarter ended June 30, 2019, was $3.8 million compared to $1.6 million in the comparable prior year period. The increase for the quarter was primarily the result of higher outstanding debt balances under the financing agreements as compared to the prior year period.
Interest income for the quarter ended June 30, 2019, was $0.8 million. There was no interest income for the quarter ended June 30, 2018. During the quarter ended June 30, 2019, a portion of Myovant Sciences’ cash was invested in a combination of money market funds and commercial paper. There were no such investments during the prior year period.
Net loss for the quarter ended June 30, 2019, was $67.9 million, compared to $62.1 million for the comparable prior year period. On a per common share basis, net loss was $0.89 and $0.98 for the quarters ended June 30, 2019, and 2018, respectively. The increase in the net loss for the quarter was driven primarily by the increase in costs outlined above.
Capital resources: Cash and cash equivalents totaled $226.7 million as of June 30, 2019. During the quarter ended June 30, 2019, Myovant Sciences raised net proceeds of approximately $134.5 million from an underwritten public equity offering and approximately $2.5 million from its “at-the-market” equity offering program. Myovant Sciences currently has approximately $10.4 million of capacity available under the “at-the-market” equity offering program that it initiated in April 2018.
About Relugolix
Relugolix is a once-a-day, oral gonadotropin-releasing hormone (GnRH) receptor antagonist that reduces ovarian estradiol and progesterone production, hormones known to stimulate uterine fibroids and endometriosis. Myovant Sciences has successfully completed two Phase 3 clinical studies (LIBERTY 1 and LIBERTY 2) evaluating relugolix combination therapy (relugolix 40 mg plus 1.0 mg estradiol with 0.5 mg norethindrone acetate) in women with heavy menstrual bleeding and uterine fibroids and is studying relugolix combination therapy in two Phase 3 clinical studies (SPIRIT 1 and SPIRIT 2) in women with endometriosis-associated pain. Data from SPIRIT 2 and SPIRIT 1 are expected in the first and second quarters, respectively, of calendar year 2020. Relugolix also lowers testosterone in men, an androgen known to drive the growth of prostate cancer. Myovant Sciences is evaluating relugolix, 120 mg once-a-day, in the Phase 3 HERO study in men with advanced prostate cancer. Top-line results from the HERO study are expected in the fourth quarter of calendar year 2019.
About MVT-602
MVT-602 is an oligopeptide kisspeptin-1 receptor agonist. Kisspeptin, the ligand, is a naturally-occurring peptide that stimulates GnRH release and is required for puberty and maintenance of normal reproductive function, including production of sperm, follicular maturation and ovulation, and production of estrogen and progesterone in women and testosterone in men. A Phase 2a clinical study in healthy female volunteers to characterize the dose-response curve in a minimal controlled ovarian stimulation setting has been completed.
About Myovant Sciences
Myovant Sciences aspires to be the leading healthcare company focused on innovative treatments for women’s health and prostate cancer. Myovant Sciences’ lead product candidate is relugolix, an oral, once-a-day small molecule that acts as a GnRH receptor antagonist. Myovant Sciences has three late-stage clinical programs for relugolix ongoing in uterine fibroids, endometriosis and prostate cancer. Myovant Sciences is also developing MVT-602, an oligopeptide kisspeptin-1 receptor agonist, that has completed a Phase 2a study for the treatment of female infertility as part of assisted reproduction. Takeda Pharmaceuticals International AG granted Myovant Sciences an exclusive, worldwide license to develop and commercialize relugolix (excluding Japan and certain other Asian countries) and an exclusive license to develop and commercialize MVT-602 in all countries worldwide. Over time, Myovant Sciences intends to expand its development pipeline to include other potential treatments for women’s health and prostate cancer. For more information, please visit Myovant Sciences’ website at www.myovant.com . Follow @Myovant on Twitter and LinkedIn (https://linkedin.com/company/myovant-sciences/).
Forward-Looking Statements
This press-release contains forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. Forward-looking statements include all statements regarding Myovant Sciences’ intent, belief, or expectations regarding future events or results and can be identified by words such as “anticipate,” “aspire,” “believe,” “can,” “continue,” “could,” “estimate,” “expect,” “intend,” “likely,” “may,” “might,” “objective,” “ongoing,” “plan,” “potential,” “predict,” “project,” “should,” “to be,” “will,” “would,” or the negative or plural of these words or other similar expressions or variations, although not all forward-looking statements contain these identifying words. In this press release, forward-looking statements include, but are not limited to, statements regarding Myovant Sciences’ aspirations to become the leading healthcare company focused on innovative treatments for women’s health and prostate cancer, Myovant Sciences’ intentions to expand its development pipeline to include other potential treatments for women’s health and prostate cancer, Myovant Sciences’ plans to submit the uterine fibroids NDA to the FDA in the fourth quarter of calendar year 2019 and the Marketing Authorisation Application to the European Medicines Agency in the first quarter of calendar year 2020, to report data from its Phase 3 prostate cancer study later this calendar year and the results from its two Phase 3 endometriosis studies in the first and second quarters of calendar year 2020.
Myovant Sciences’ forward-looking statements are based on management’s current expectations and beliefs and are subject to a number of risks, uncertainties, assumptions and other factors known and unknown that could cause actual results and the timing of certain events to differ materially from future results expressed or implied by the forward-looking statements. Myovant Sciences cannot assure you that the events and circumstances reflected in the forward-looking statements will be achieved or occur and actual results could differ materially from those expressed or implied by these forward-looking statements. Factors that could materially affect Myovant Sciences’ operations and future prospects or which could cause actual results to differ materially from expectations include, but are not limited to the risks and uncertainties listed in Myovant Sciences’ filings with the United States Securities and Exchange Commission (SEC), including under the heading “Risk Factors” in Myovant Sciences’ Annual Report on Form 10-K filed with the SEC on May 24, 2019, and in Myovant Sciences’ future filings with the SEC including without limitation, Myovant Sciences’ Quarterly Report on Form 10-Q expected to be filed with the SEC on or about August 6, 2019, as such risk factors may be amended, supplemented or superseded from time to time by other reports Myovant Sciences files with the SEC. These risks are not exhaustive. New risk factors emerge from time to time and it is not possible for Myovant Sciences’ management to predict all risk factors, nor can Myovant Sciences assess the impact of all factors on its business or the extent to which any factor, or combination of factors, may cause actual results to differ materially from those contained in any forward-looking statements. You should not place undue reliance on the forward-looking statements in this press release, which speak only as of the date hereof, and, except as required by law, Myovant Sciences undertakes no obligation to update these forward-looking statements to reflect events or circumstances after the date of such statements.
MYOVANT SCIENCES LTD.
Condensed Consolidated Statements of Operations
(Unaudited, in thousands, except share and per share data)
Three Months Ended June 30, 2019 2018 Operating expenses: Research and development (1) $ 51,117 $ 51,341 General and administrative (1) 14,152 8,742 Total operating expenses 65,269 60,083 Interest expense 3,793 1,617 Interest income (766 ) — Other (income) expense, net (705 ) 289 Loss before income taxes (67,591 ) (61,989 ) Income tax expense 313 145 Net loss $ (67,904 ) $ (62,134 ) Net loss per common share — basic and diluted $ (0.89 ) $ (0.98 ) Weighted average common shares outstanding — basic and diluted 76,468,347 63,310,177 (1) Includes the following share-based compensation expenses: Research and development $ 2,548 $ 1,561 General and administrative $ 3,904 $ 2,683


MYOVANT SCIENCES LTD.
Condensed Consolidated Balance Sheets
(Unaudited, in thousands)
June 30, 2019 March 31, 2019 Assets Current assets: Cash and cash equivalents $ 226,734 $ 156,074 Prepaid expenses and other current assets 8,693 10,194 Income tax receivable 331 524 Total current assets 235,758 166,792 Property and equipment, net 2,057 2,071 Operating lease right-of-use asset 9,181 — Other assets 3,877 4,114 Total assets $ 250,873 $ 172,977 Liabilities and Shareholders’ Equity Current liabilities: Accounts payable $ 10,004 $ 11,019 Interest payable 758 1,077 Accrued expenses 46,258 53,614 Operating lease liability 813 — Due to Roivant Sciences Ltd., Roivant Sciences, Inc., and Roivant Sciences GmbH 196 121 Current maturities of long-term debt 10,867 6,142 Total current liabilities 68,896 71,973 Deferred rent — 1,157 Deferred interest payable 3,790 2,273 Long-term operating lease liability 9,550 — Long-term debt, less current maturities 89,070 93,240 Total liabilities 171,306 168,643 Total shareholders’ equity 79,567 4,334 Total liabilities and shareholders’ equity $ 250,873 $ 172,977
Investor Contact:
Frank Karbe
Chief Financial Officer
Myovant Sciences
investors@myovant.com
SOURCE: Myovant Sciences

Story 17
At least 11 men and one woman detained on suspicion of attempting disrupt celebrations marking the 22nd anniversary of the handover
At least 12 people have been arrested in the first wave of detentions linked to anti-government protests in Hong Kong that led to the storming and vandalising of the city’s parliament.

At least 11 men and one woman were arrested on suspicion of trying to disrupt celebrations marking the 22nd anniversary of the former British colony’s return to Chinese rule on Monday.

On Thursday police said they have been been charged with offences that range from “possession of offensive weapons, unlawful assembly, assaulting a police officer, obstructing a police officer, offence against air navigation ( HK) order 1995 and failing to carry identity document”. The oldest was 31 and the youngest was just 14.
UK summons China ambassador in row over Hong Kong protests Read more
For the past month, protesters have been demanding the withdrawal of a bill that would allow extraditions to the Chinese mainland as anger has grown against Hong Kong authorities and morphed into a wider political crisis.
The occupation of the legislature on Monday night coincided with a massive peaceful protest in which organisers say more than half a million people marched through the city on the anniversary of Hong Kong’s 1997 return to Chinese rule.
Officers on Wednesday had gathered debris from the legislature as evidence, showing pictures of bricks, metal bars and shields stacked neatly outside the damaged legislature on their Facebook page on Wednesday.
“Police will certainly follow up and bring the culprits to justice for any unlawful acts,” the force said in a statement.

Police also arrested a 31-year-old man for assaulting police, criminal damage, forcible entry and disorderly conduct in a public place for his role on 1 July and and an earlier protest in June when thousands of demonstrators had gathered around police headquarters to voice concerns over police violence.
Play Video 1:40 How Hong Kong protesters used hand signals and human chains to storm government – video explainer
On 12 June, police fired 150 rounds of tear gas and rubber bullets at a mostly peaceful crowd.

Another eight people were arrested earlier on Wednesday for releasing personal information of police officer’s online, including phone numbers and addresses. Officers were harassed with late night phone calls and threatening text messages.
Hong Kong’s chief executive, Carrie Lam, has asked to meet with the city’s university students, her office said on Thursday. The student union at the Hong Kong University of Science and Technology, one of the eight major higher education institutions, turned down the request, saying that the city’s leader had requested a closed-door meeting and that any dialogue must be open to all.
Meanwhile, police also arrested people at a rally in support of police on 30 June.

Five men and one woman were arrested for possessing offensive weapons, assault occasioning actual bodily harm, common assault and fighting in a public place.
The fight for democracy in Hong Kong is the defining struggle of our age | Simon Tisdall Read more
On Thursday, Chinese state media blamed meddling by Western governments for unrest in Hong Kong amid an escalating diplomatic spat between China and the United Kingdom the protests.
“Ideologues in Western governments never cease in their efforts to engineer unrest against governments that are not to their liking, even though their actions have caused misery and chaos in country after country in Latin America, Africa, the Middle East and Asia,” the official China Daily said in an editorial.
“Now they are trying the same trick in China.”
Reuters contributed to this report



Story 18
Conclusions Clinical outcomes did not improve when the initial course of prednisolone treatment was extended from eight to 16 weeks in UK children with steroid sensitive nephrotic syndrome. However, evidence was found of a short term health economic benefit through reduced resource use and increased quality of life.
Results No significant difference was found in time to first relapse (hazard ratio 0.87, 95% confidence interval 0.65 to 1.17, log rank P=0.28) or in the incidence of frequently relapsing nephrotic syndrome (extended course 60/114 (53%) v standard course 55/109 (50%), P=0.75), steroid dependent nephrotic syndrome (48/114 (42%) v 48/109 (44%), P=0.77), or requirement for alternative immunosuppressive treatment (62/114 (54%) v 61/109 (56%), P=0.81). Total prednisolone dose after completion of the trial drug was 6674 mg for the extended course versus 5475 mg for the standard course (P=0.07). There were no statistically significant differences in serious adverse event rates (extended course 19/114 (17%) v standard course 27/109 (25%), P=0.13) or adverse event rates, with the exception of behaviour, which was poorer in the standard course group. Scores on the Achenbach child behaviour checklist did not, however, differ. Extended course treatment was associated with a mean increase in generic quality of life (0.0162 additional quality adjusted life years, 95% confidence interval −0.005 to 0.037) and cost savings (difference −£1673 ($2160; €1930), 95% confidence interval −£3455 to £109).
Main outcome measures The primary outcome measure was time to first relapse over a minimum follow-up of 24 months. Secondary outcome measures were relapse rate, incidence of frequently relapsing nephrotic syndrome and steroid dependent nephrotic syndrome, use of alternative immunosuppressive treatment, rates of adverse events, behavioural change using the Achenbach child behaviour checklist, quality adjusted life years, and cost effectiveness from a healthcare perspective. Analysis was by intention to treat.
Interventions Children were randomised to receive an extended 16 week course of prednisolone (total dose 3150 mg/m 2 ) or a standard eight week course of prednisolone (total dose 2240 mg/m 2 ). The drug was supplied as 5 mg tablets alongside matching placebo so that participants in both groups received the same number of tablets at any time point in the study. A minimisation algorithm ensured balanced treatment allocation by ethnicity (South Asian, white, or other) and age (5 years or less, 6 years or more).
Introduction
Idiopathic nephrotic syndrome is the commonest childhood glomerular disorder, with an annual incidence of two per 100 000 children in the United Kingdom. Children present with the disease at a median age of 2-3 years, and it is twice as common in boys and four to six times more common in people of South Asian origin.1234
More than 90% of children who present with idiopathic nephrotic syndrome respond to a course of high dose corticosteroid treatment, and current practice is to treat most patients empirically with prednisolone.56 Children who respond to treatment are given a diagnostic label of steroid sensitive nephrotic syndrome and generally have a good prognosis with a low incidence of end stage renal disease.
After initial successful treatment, around 80% of children with steroid sensitive nephrotic syndrome have disease relapses requiring further courses of high dose prednisolone. About 50% develop frequently relapsing nephrotic syndrome (two or more relapses within six months of presentation or four relapses within any 12 months) or steroid dependent nephrotic syndrome (relapse while receiving prednisolone or within 14 days of stopping the drug).7 Relapses and further high dose prednisolone treatment are associated with substantial morbidity.8 When complications develop or are anticipated after repeated courses of corticosteroids, alternative immunosuppressive treatment is indicated, such as levamisole, cyclophosphamide, ciclosporin, tacrolimus, mycophenolate mofetil, or rituximab.
The best initial prednisolone regimen for children presenting with steroid sensitive nephrotic syndrome remains unknown. The eight week course first described in the 1960s by the International Study of Kidney Disease in Children (prednisolone 60 mg/m2 for four weeks then 40 mg/m2 on alternate days for four weeks) continues to be used in most UK centres and in many other countries. However, systematic review data suggest that a more intensive initial treatment course improves clinical outcomes.9 When the prednisolone in nephrotic syndrome (PREDNOS) trial started, six randomised controlled trials had compared the eight week course with a range of different prednisolone regimens of three months or longer.101112131415 A 2005 Cochrane review concluded that prednisolone treatment of three months or longer statistically significantly reduced the rate of relapse at 12-24 months and the rate of frequently relapsing nephrotic syndrome.16 The Kidney Disease: Improving Global Outcomes guidelines published in 2012 supported the conclusions of this Cochrane review. These guidelines recommended daily prednisolone treatment of 60 mg/m2 or 2 mg/kg for four to six weeks followed by 40 mg/m2 or 1.5 mg/kg on alternate days and continued for two to five months, with tapering of the dose.17 Despite these recommendations, several methodological concerns relating to these six studies have resulted in the continued use of the eight week course in the UK and elsewhere.
We conducted the PREDNOS trial to compare this eight week course with a longer 16 week course in UK children. The study design was optimised to overcome the methodological concerns relating to previous studies. We first performed an external pilot study over a year that included 55 participants. This pilot study helped us to develop the design of the main trial and found that participants of different ethnicities could be recruited in district hospitals and tertiary nephrology centres. The primary objective of the main trial was to determine whether an initial 16 week extended course of prednisolone treatment increased the time to first relapse in children with steroid sensitive nephrotic syndrome compared with the eight week standard course. Secondary objectives were to determine whether the extended course reduced the relapse rate, the proportion of participants who developed frequently relapsing nephrotic syndrome or steroid dependent nephrotic syndrome, and the requirement for second and third line immunosuppressive agents. Additionally, we considered whether the extended course was associated with an increased incidence of corticosteroid related adverse events, including behavioural problems. We also performed a cost effectiveness analysis by comparing costs and quality adjusted life years for the two regimens, and the methods and results are reported in supplementary appendices 1, 3, and 4.

Story 19
Democratic governor says she wants to stop companies that are using candy flavors to ‘hook children on nicotine’
This article is more than 1 month old
This article is more than 1 month old
Michigan will become the first state to ban flavored e-cigarettes, joining liberal US cities in an effort to curb teen vaping. The move comes on the heels of reports of a severe, rare and unexplained respiratory illness affecting heavy vape users.
Vaping’s other problem: are e-cigarettes creating a recycling disaster? Read more
Michigan’s Democratic governor Gretchen Whitmer announced the state health department would immediately ban retail and online sales of flavored e-cigarettes through an emergency rule-making process. The move will prohibit the sale, and the misleading marketing, of flavored nicotine vaping products.
“I’ve got teenagers at home,” Whitmer said on MSNBC’s Morning Joe on Wednesday. “I was talking with them about the prevalence of vaping in their schools, and it’s everywhere.”
Whitmer said she was concerned about fruit and candy flavored e-cigarettes being marketed to children as healthier alternatives to smoking.
She said: “It would be great if, at the federal level, we knew there was a [US] surgeon general warning on all vape products, that they were treated like tobacco, taxed like tobacco, but none of that is happening.”
Although there is no long-term evidence about the health effects of vaping, experts widely regard the devices as less harmful than smoking. However, more than 200 cases of severe, unexplained lung illness among heavy vape users has alarmed many doctors.
Recent US government surveys found a more than 900% increase in vaping among high school students between 2011 and 2015, prompting an advisory from the US surgeon general on their popularity. Seven in 10 teens have been exposed to e-cigarette advertisements, studies have found.
The American Vaping Association, a lobbying group for the e-cigarette industry, called Whitmer’s call for new rules a “backdoor prohibition”. Without citing specific evidence, the group said the ban would hurt thousands of businesses and force adults to go back to smoking.
Researchers and anti-tobacco advocates in the US have taken a more hardline stance against e-cigarettes compared to the UK and continental Europe.
Some US cities have already moved to ban flavored e-cigarettes. New York is considering bills to ban flavored e-cigarettes and tobacco, such as menthol. In June, San Francisco went a step further, and became the first US city to ban e-cigarettes outright.
However, San Francisco’s ban has split public health experts. Many researchers have argued e-cigarettes help many low-income smokers move to a less harmful type of smoking. Others say an epidemic of teen vaping demands bans or restrictions, even without complete scientific conclusions on the devices’ health effects.
Steven Schroeder, a professor of medicine at the University of California San Francisco and an expert on smoking cessation, said he believes removing the flavor from e-cigarettes could also “reduce their appeal” to smokers trying to cut back.
He said: “How you weight that is, again, part of the big debate.”
Vaping advocates are likely to challenge any new rules in court. Attempts to regulate e-cigarettes through the US Food and Drug Administration have been met with lengthy legal challenges by lobbying groups, which often have close ties to traditional cigarette manufacturers.
Cigarette manufacturers have invested heavily in vaping in recent years. Altria, bought a more than one-third stake in Juul, the sleek vape that dominates the US market. RJ Reynolds owns its competitor Vuse.

Story 20
Shutterstock
Google is acquiring Looker, a California-based data-analysis startup, in a $2.6 billion all-cash transaction that's expected to close later this year.
Looker will join Google Cloud once the acquisition is complete, Google said Thursday in a statement.
Watch Alphabet trade live.
Google is acquiring Looker, a California-based data-analysis startup, in a $2.6 billion all-cash transaction, Google said Thursday in a statement. The deal is the first major acquisition for Google Cloud CEO Thomas Kurian, who joined the company in January after spending more than two decades at Oracle.
"Looker extends our business analytics offering with two important capabilities — first, the ability to define business metrics once in a consistent way across data sources," Kurian said.
"Second, Looker also provides users with a powerful analytics platform that delivers applications for business intelligence and use-case specific solutions such as Sales Analytics, as well as a flexible, embedded analytics product to collaborate on business decisions," Kurian added.
Read more: Experts say that new CEO Thomas Kurian's Oracle-like playbook could cause a 'culture clash' at Google Cloud — and that could be a good thing
Google's acquisition of Looker, which was founded in 2012, is expected to close later this year, pending regulatory approvals. Once the deal closes, the Santa Cruz-based Looker will join Google Cloud. The Looker deal is Google's largest since its $3.2 billion Nest acquisition in 2014.
Some experts had expected Kurian to oversee deals like this one.
As he was set to take the reins of Google Cloud earlier this year, industry analysts and insiders told Business Insider's Becky Peterson that Kurian was likely to execute large acquisitions. He'd replaced the former Google Cloud head Diane Greene, who was at the helm for three years.
Read more: Insiders say Google's new cloud boss is likely to make some very large acquisitions

Looker in December raised $103 million in a series E funding round that valued it at $1.6 billion, Business Insider's Rosalie Chan reported.
Earlier this year Business Insider named Looker as one of "44 enterprise startups to bet your career on in 2019," pointing to its business intelligence data that's easy to analyze.
Shares of Google's parent, Alphabet, traded modestly lower Thursday, just over $1,041. Alphabet shares are little changed this year, underperforming the broader market.
Markets Insider

Story 21
Reuters
Industrial output unexpectedly fell in March, the Federal Reserve said Tuesday.
The data was the latest pointing to slowing activity in the manufacturing sector, which economists say could enter a mild recession this year.
Economists say the slowdown is in part due to the fading effects of stimulus measures, but trade tensions haven't helped.
A gauge of the American industrial sector unexpectedly slipped in March, offering the latest sign of a slowdown in manufacturing activity as global growth cools and trade tensions continue.
The Federal Reserve said Tuesday that industrial production — which measures factory, mine, and utility output — fell 0.1% last month. Economists surveyed by the Wall Street Journal had expected a 0.2% increase.
Manufacturing activity was flat in March after sliding in January and February. In the first three months of 2019, factory output declined 1.1% to mark the first quarterly drop since late 2017.
That was just the latest sign of a slowdown in manufacturing activity, which accounts for about a tenth of output in the US economy. Last month, the US shed 6,000 manufacturing jobs after nearly two years of steady gains.
Some think the manufacturing sector could enter a recession this year as the American economy grows at a much slower pace in coming months, with first-quarter GDP estimates of between 1% and 2%.
Data on Tuesday also showed mining output fell 0.8% in March, while utility activity edged slightly higher.
The broader slowdown is in part thanks to the fading effects of stimulus measures, including a $1.5 trillion tax-cut package passed in the US in 2017, but trade tensions between the US and its major trading partners haven't helped.
Tariffs levied last year as part of the Trump administration's crackdown on trade practices seen as unfair have raised company costs, lowered access to foreign markets, and disrupted supply chains.

Story 22
Rightmove says average price down by £730 as sellers wait to see how Brexit plays out
House prices have fallen in September for the first time since 2010 as Brexit uncertainty continues to cast a long shadow over the UK housing market, according to the estate agent Rightmove.
The UK’s biggest property website said the traditional “autumn bounce” in the market was simply not happening this year. Instead, the average price of newly listed homes fell by 0.2%, or £730, compared with August.
September is usually the start of an upturn in housing market activity, with price rises recorded every year for the past eight years. However, this year there is growing evidence that sellers are waiting to see how Brexit plays out before deciding whether to move.
Rightmove said the number of properties coming to market was down by 7.8% this month compared with the same period a year ago. The number of sales agreed is down 5.5% in all regions.
“In August, we reported a pre-Brexit buying spree with the number of sales agreed up by over 6% compared [with] the prior year, as buyers and sellers decided to get deals secured well before the next Brexit deadline,” Miles Shipside, Rightmove director and housing market analyst, said.
“But a month later, as the deadline gets closer and tensions heighten, there has been a big swing the other way with sales agreed numbers now over 5% below those of a year ago.”
He said the political uncertainty was particularly affecting London, where the number of new properties coming on to the market was 20% down on last year.
While Brexit uncertainty is holding the market back now, it has been predicted that prices could crash if the UK departs Europe without a deal. Last Monday, the accountancy firm KPMG warned that UK house prices could fall by as much as 20% if Boris Johnson pursues a no-deal Brexit. The biggest falls would be in London and Northern Ireland, it said.
A no-deal exit could trigger a nationwide decline of about 6% in 2020, and a drop of between 10% and 20% was “not out of the question” if the market reacted more strongly than expected, KPMG predicted.

Story 23
Women have been kicking in college for years, but the NFL remains a glass ceiling. Could last week’s viral video of the World Cup hero be a tipping point?
Carli Lloyd’s well-publicized visit with the Philadelphia Eagles wasn’t her first appearance at an NFL training camp, but this one ended with a Hall of Fame executive advising teams to give her a tryout.
Carli Lloyd deserves 'honest tryout' after drilling 55-yard field goal at NFL practice Read more
The footage of Lloyd, a two-time Fifa player of the year, booting 55-yard field goals reignited the discussion of whether a woman will appear in an NFL game. Lloyd’s visit to Houston Texans in 2015 garnered headlines for a humorous kicking competition against defensive tackle Vince Wilfork. Last week, her seamless execution of long-range field goals during a joint practice between the Eagles and Baltimore Ravens triggered the conversation that her Hard Knocks cameo didn’t. The spark came from NFL Hall of Fame executive Gil Brandt.
To Brandt and Tucker, Lloyd has the physical capabilities to kick in the NFL. Women have earned college scholarships to kick, scored points in college and professional games and even broken into professional coaching ranks.
So what would it take for her or any other woman to be the first to make a NFL roster? It’s not a question of physical limitations. Instead, it’s mastering the skills necessary for anybody to kick in the NFL: Precision, focus, and a willingness to embrace a job known for psychological torment.
Gil Brandt (@Gil_Brandt) Honestly, I don't think it will be long before we see a woman break through this NFL barrier. I'd give her an honest tryout if I were, say, the Bears. https://t.co/pyIlIY6Jxv
While college and professional football combat a participation decline caused by fears of head trauma, women are playing more than ever before. Kicker Becca Longo was the first woman to receive a college scholarship in 2018 to attend Adams State University (she left the school after an injury and is currently training in Arizona); free safety Antoinette Harris became the first non-specialist to receive a scholarship after playing for two years at East Los Angeles College and will attend Central Methodist University in the fall; in 2017, kicker K-Lani Nava was the first woman to ever score points in a Texas state championship game.
One of those kickers was Julie Harshbarger. After starting her career as a high school freshman at Hononegah High Schol in Rockton, Illinois, she kicked at Rockford College for two years and seven seasons for various Chicago teams in the Continental Indoor Football League. In 2014, she was the first woman to win an award in professional football when she was named Special Teams Player of the Year in 2014, which she’d win again in 2015.
“I always felt comfortable partly because I played beginning in high school,” Harshbarger says. “My name was recognized by teammates in college. Social media was helpful as well. I guess my timing was good as I had a lot of people played with me and against me. When I started kicking around the indoor leagues, I wasn’t the new girl showing up anymore.”
Indianapolis Colts star Andrew Luck retires aged 29 in all-time NFL shocker Read more
Harshbarger’s path mirrors a few of her contemporaries. In 1997, Willamette’s Liz Heaston became the first woman to score in a collegiate game; in 2003, New Mexico’s Katie Hnida was the first woman to score points in a bowl game. Kent State’s April Goss remains the last woman to kick in a FBS game after scoring an extra point against Delaware State in 2016. A woman hasn’t emerged as a regular on a Division I team yet, but higher participation from women makes it increasingly likely that a woman can kick at the highest collegiate level within the next few years.
“I think [kicker or punter] would be the first positions because of their independent practice model,” says Dr Jen Welter, who became the first woman to coach in the NFL when she joined the Arizona Cardinals staff in 2015. “If you have a superior athlete like Lloyd and access to the right coaching then there is no reason why it couldn’t happen or develop.”
When Welter mentions an “independent practice model”, she’s describing the solitary life of kickers and punters. While most players hone their technique among teammates, kicking specialists are often practicing alone on a separate field. To perfect a field goal requires working in concert with the long snapper and holder: the kicker must know when the holder is ready to call for the snap, the snapper must deliver a ball easy for the holder to catch and balance on the turf, and the kicker must strike it high enough, hard enough and accurately enough in between the goal posts. Run too quickly toward the ball and the kicker can’t generate enough height or power; run too slowly and the defense will converge to block the attempt.
Kickers aren’t always at fault for missed field goals, but they often bear the entire blame. If the coaching staff trusts its kicker, then the job can be secure for years, even decades. But since points are always on the line, second chances aren’t guaranteed.
“Once you get a reputation as a head case, it’s hard to come back even when it wasn’t your fault,” Welter says. “There could be timing issues from the long snapper, poor communication from the holder or the kicking coach messing with the player’s mechanics.”
NFL teams are notorious for treating kickers like perishable goods. In Anthony Lynn’s first 22 games as head coach of the Los Angeles Chargers, the team employed six different kickers. The cruel “double-doink” that ended the Chicago Bears’ 2018 season led to the dismissal of kicker Cody Parkey and triggered a sort of mania in head coach Matt Nagy. Not only has the team tried out nine kickers since Parkey’s dismissal, a detailed report from Sports Illustrated chronicled Nagy’s insistence to randomly stop practice and force kickers to attempt field goals from the same place Parkey missed his kick while the team and front office watched in silence. The team currently has just one kicker on their roster – Eddy Piñero – and he’s never attempted a kick in an NFL game.
“I think kickers have to be the mentally toughest athletes in sports,” Welter says. “Every time you’re on the field, it’s a scoring opportunity. Imagine if a golfer’s job was to sink putts with thousands of people hollering while an entire team was running at him to stop it from going in”.
The 'Formula One' secret behind Tom Brady's time-cheating dominance Read more
Even those considered sure bets often fail. In 2016, the Tampa Bay Buccaneers drafted Florida State’s Roberto Aguayo in the second round, making him just the third kicker to be drafted in the first 60 picks since 1994. Expected to solve the team’s kicking woes, Aguayo finished last in field goal percentage as a rookie. When the Buccaneers cut him midway through the 2017 preseason, he was just 23 years old. He hasn’t appeared in a regular season game since his rookie year and is currently working out of football.
A coaching staff will justify a player’s poor progress at virtually every other position. But when you’re a kicker, blame is seldom directed anywhere but toward the player himself. When a team doctor once notified Hall of Fame coach Bill Parcells that the team’s kicker was barely healthy enough to play, Parcells memorably responded: “He don’t have to play, Doc. All he has to do is kick.”
If the first woman to play in the NFL is a kicker, she’ll assume one of the game’s least forgiving and most psychologically taxing jobs. And if the first woman to kick in the NFL struggles, it could be a convenient excuse for NFL teams never to take a chance on a woman again.
“To be the first of anything means setting the trajectory for anybody who comes afterward,” Welter says. “They could be the reason why the door could be closed tighter after you. You’re in a microscope to a degree that other people aren’t. Nobody is going to ask that question if she’s injured, it’s just that the girl didn’t make it.”
Welter thinks that if the public is going to see a woman in the NFL soon, she may be from Australia. Colleges are actively recruiting rugby and Australian League Football players to punt and kick because of the skills necessary to kick during the run of play and from different angles all over the field. The growth of women’s rugby in the country has increased girls’ participation, meaning young women are receiving the necessary reps and perfection of a kicking skill set.
Harshbarger senses a more traditional trajectory for any woman to make it to the NFL: prove yourself to be one of the best at each level, then teams will have no choice but to take you.
“You don’t typically see 25-year-old guys just pick up kicking in the NFL because they have been doing it for an extended period of time,” Harshbarger says. “If it’s going to be the first female to do this, she will probably need to be even better than the men, especially since teams don’t carry more than one kicker.”
Lloyd told SI’s Planet Futbol TV that she received calls from some NFL teams gauging her interest. Would it be too much too quickly to give her a tryout now? Harshbarger believes that a woman will need to prove herself in college before an NFL team actually allows her to take a snap, but isn’t opposed to wondering how it would look tomorrow.
“Being a kicker in the NFL is one of the most exclusive positions in sports. There are only 32 of them since no team carries two,” she says.
“But If you put [Lloyd] in a game situation and she can still do it, then why not right? That’d be pretty sweet.”

Story 24
The city is fighting the rise of youth vaping despite Juul, the biggest producer of e-cigarettes, being right in its backyard
This article is more than 4 months old
This article is more than 4 months old
San Francisco voted to ban e-cigarettes in the first legislation of its kind in the United States.
Supervisors approved a measure banning the sale and distribution of e-cigarettes in an effort to curb the rise of youth vaping. The measure will now go for final approval to San Francisco’s mayor, London Breed, who said she will sign the legislation, and stores in the city will be required to remove e-cigarettes from their shelves after the change goes into effect in seven months.
However, it will still be legal to purchase traditional cigarettes and marijuana products, including vapes for cannabis, in the city of San Francisco.
Number of US teens using e-cigarettes surges to 5m in one year – study Read more
After decades of decline in youth cigarette smoking, the rise of vaping has led to a major boost in nicotine use for people under the age of 21. More than 4.9 million American teens used e-cigarettes in 2018, an increase of 1.5 million teens in just one year.
San Francisco is home to Juul, with more than a 50% share of the market making it the biggest producer of e-cigarettes in the country. Juul markets itself as a smoking alternative for adults seeking to quit, but the San Francisco supervisor Shamann Walton, who co-authored the legislation, sees it as a continuation of big tobacco.
“We spent a few decades fighting big tobacco in the form of cigarettes,” Walton said. “Now we have to do it again in the form of e-cigarettes.”
Juul has continued to expand its headquarters, announcing the purchase of a new 29-story skyscraper to accommodate its “rapidly growing team” on the same day the e-cigarette ban first passed the committee.
A spokesman from Juul told the Guardian the company will continue to push back against the legislation and is reportedly developing a ballot measure in November to keep e-cigarettes available for purchase.
Juul and other advocates for vaping say the ban could result in more adults smoking cigarettes. “This full prohibition will drive former adult smokers who successfully switched to vapor products back to deadly cigarettes, deny the opportunity to switch for current adult smokers, and create a thriving black market instead of addressing the actual causes of underage access and use,” spokesman Ted Kwong said.
Juul has taken some measures to prevent young people from taking up vaping , including banning the sale of flavored pods and restricting bulk purchases to prevent sharing products.
Purveyors of Juuls, including vape shops and corner stores, have expressed outrage at the impact of the decision on small businesses in the city. Some argued that stores in Oakland and Daly City, just across the Bay, stand to see major profits from the decision as people travel to get nicotine products.
While the ban on e-cigarettes is clearly a blow to Juul, it is also a gesture directed at the US Food and Drug Administration, which has been slow to legislate the devices despite their explosion in popularity in recent years.
In December 2018, the US surgeon general issued an advisory calling youth vaping an “epidemic”.
“San Francisco is taking action to protect our kids,” the San Francisco city attorney, Dennis Herrera, said in a statement regarding the legislation. “This temporary moratorium wouldn’t be necessary if the federal government had done its job.”

Story 25
Supervisors vote eight to one to restrict surveillance: ‘We can have security without being a security state’
This article is more than 5 months old
This article is more than 5 months old
San Francisco supervisors have voted to make the city the first in the United States to ban police and other government agencies from using facial recognition technology.
Supervisors voted eight to one in favor of the “Stop Secret Surveillance Ordinance”, which will also strengthen existing oversight measures and will require city agencies to disclose current inventories of surveillance technology.
Supervisor Aaron Peskin, who championed the legislation, said: “This is really about saying: ‘We can have security without being a security state. We can have good policing without being a police state.’ And part of that is building trust with the community based on good community information, not on Big Brother technology.”
Two supervisors were absent for Tuesday’s vote. The board of supervisors is expected to vote on the new rules a second time next week, when they are expected to pass again.
Critics argued that police need all the help they can get, especially in a city with high rates of property crime. That people expect privacy in public space is unreasonable given the proliferation of cellphones and surveillance cameras, said Meredith Serra, a member of a resident public safety group Stop Crime SF.
San Francisco could ban government agencies from using facial recognition technology Read more
But those who support the ban say facial recognition technology is flawed and a serious threat to civil liberties.
Matt Cagle, a technology and civil liberties attorney at the ACLU of Northern California, said the legislation was a positive step towards slowing the rise of technologies that may infringe on the rights of people of color and immigrants. “Face surveillance won’t make us safer, but it will make us less free,” Cagle told the Guardian after the proposal passed a committee vote last week.
The ordinance applies to a wider range of technology, including automated license plate reading and gunshot-detection tools. It also expands a 2018 law requiring the San Francisco public transportation system Bart to outline how it surveils passengers.
Speaking to the Guardian last week, Peskin said the new regulations were designed to address concerns about the accuracy of technology and put a stop to creeping surveillance culture.
He said: “We are all for good community policing but we don’t want to live in a police state. At the end of the day it’s not just about a flawed technology. It’s about the invasive surveillance of the public commons.”

Story 26
Welcome to Morningstar.co.uk!
You have been redirected here from Hemscott.com as we are merging our websites to provide you with a one-stop shop for all your investment research needs.To search for a security, type the name or ticker in the search box at the top of the page and select from the dropdown results.Registered Hemscott users can log in to Morningstar using the same login details. Similarly, if you are a Hemscott Premium user, you now have a Morningstar Premium account which you can access using the same login details.

Story 27
Ingrid Torjesen London
Ketamine is the first truly new pharmacological approach to treating depression in the past 50 years and could herald a new generation of rapid acting antidepressants, researchers have predicted.
“We haven’t had anything really new for about 50 or 60 years,” said Allan Young, professor of mood disorders at the Institute of Psychiatry, Psychology and Neuroscience at King’s College, London, at a briefing on 12 July at London’s Science Media Centre.
Most of the new launches have been “tinkering with drugs which were really discovered in the ’50s and ’60s,” he explained. “Even the famous Prozac, which came in in the late ’80s, is really just a refinement of the tricyclic antidepressants that came in the ’50s. People say we are still in the age of steam, and we need to go to the next technological advance.”

Story 28
Hans-Christian Dirscherl
Betrüger versuchen mit Mails, die sich als Rechnungen tarnen, Malware auf Windows-PCs einzuschmuggeln. Eine aktuelle Liste der angeblichen Absender.
Vergrößern Polizei: Mails mit gefälschten Rechnungen und Malware © istockphoto.com/foto-ruhrgebiet
Die Polizei von Niedersachsen warnt davor, dass Internet-Betrüger immer noch im großen Stil Fake-Rechnungen per Mail an potenzielle Opfer verschicken. Die Ganoven verwenden unterschiedliche Firmennamen als Absender für ihre angeblichen Rechnungen. Die Firmennamen sind teilweise frei erfunden, teilweise handelt es sich aber auch um tatsächlich existierende Unternehmen.
Die Betreffzeile der Betrügermails nimmt Bezug auf eine angeblich nicht durchführbare Kontoabbuchung. Die Mails sind in der Regel in nahezu einwandfreiem Deutsch geschrieben und wirken vergleichsweise authentisch. In den Mails wird den Adressaten mit unterschiedlichen Maßnahmen gedroht, beispielsweise mit Einleitung eines Gerichtsverfahrens oder der Hinzuziehung eines Inkassobüros. In der Mail stehen, wie die Polizei betont, „fast ausschließlich komplette Personendatensätze (Vorname, Nachname, Anschrift und Rufnummer) der Angeschriebenen“, die laut den Betroffenen, die sich bei der Polizei gemeldet haben, auch real seien beziehungsweise waren.
Die Betrüger wollen mit den gefakten Rechnungsmails Schadsoftware auf die PCs der Adressaten schmuggeln. Die Malware verbirgt sich entweder in einem Mailanhang oder soll per Link heruntergeladen werden.
Die Mailadressen, von denen diese Betrügermails verschickt werden, sind vorgetäuscht. Meist handelt es sich dabei um private Mailadressen, beispielsweise von t-online.de.
Wichtig: Seriöse Unternehmen verschicken Mahnung in der Regel per Postbrief.
Die Polizei hat diese Liste mit den missbräuchlich genutzten Unternehmensnamen zusammengestellt (die Liste erhebt keinen Anspruch auf Vollständigkeit; links die Namen aus den Spammails und rechts die echten Unternehmensnamen):
Commdoo GmbH/AG - CommDoo GmbH
Easycash AG - Ingenico Payment Services GmbH
Giropay eG - giropay GmbH
Concardis GmbH/GbR - Concardis GmbH
EOS GmbH & Co KG - EOS Deutscher Inkasso-Dienst GmbH
DirectPay AG - scheint es im deutschsprachigen Raum nicht zu geben, aber vermutlich in Anlehnung an den Dienst paydirekt der Sparkassen
VR-Pay Virtuell GmbH - VR Payment GmbH (Volks&Raiffeisenbank)
Wirecard GmbH - Wirecard AG
EasyPay GbR - scheint es im deutschsprachigen Raum nicht zu geben, aber vermutlich in Anlehnung an den Dienst von Swisscom
Paycom GmbH - scheint es im deutschsprachigen Raum nicht zu geben
SecuPay GmbH - secupay AG
Micropayment GmbH/AG/eG - micropayment GmbH
Heidelpay Co KG/Limited & Co KG/eG - heidelpay GmbH
Novalnet GmbH/Limited & Co KG - Novalnet AG
Sofortueberweisung/Sofortüberweisung AG/eG - Sofort GmbH/Klarna
Expercash Limited & Co KG/ GmbH & Co KG - scheint es im deutschsprachigen Raum nicht zu geben
SafeCharge GmbH - SafeCharge Limited
Girosolution - GiroSolution GmbH
Worlpay - Worldpay, LLC
Paymorrow - InterCard AG / Geschäftsbereich Paymorrow
Docdata Payments Co KG - CM Payments B.V. - Part of CM Payments
Payone GmbH - BS PAYONE GmbH (Tochterunternehmen der Deutscher Sparkassen Verlag GmbH)
Telecash eG - Telecash von First Data GmbH
Ecardon - ecardon payments GmbH

Wie immer gilt: Klicken Sie nicht auf Mailanhänge von Ihnen unbekannten Mails und auch nicht auf Links in Ihnen unbekannten Mails. Vergewissern Sie sich bei unerwarteten Mails oder Ihnen verdächtig erscheinenden Mails immer auf einem anderen Weg beim Absender, ob dieser die Mail tatsächlich verschickt hat.

Falls Sie Opfer einer derartigen Betrugsmail werden, dann erstatten Sie Anzeige bei der Polizei.

Halten Sie den Virenscanner Ihres Windows-Rechners immer auf dem aktuellen Stand und spielen Sie Sicherheitsupdates für Ihr Windows zeitnah auf. Heute hat Microsoft übrigens für Windows wieder neue Sicherheits-Updates bereitgestellt.


Story 29
• New coach intends to ‘make players know they are wanted’ • His first squad has combined tally of 14 international goals
Steve Clarke has said he will not take a hardline approach towards players who have made themselves unavailable for Scotland. A week after becoming the national manager, Clarke’s squad for next month’s Euro 2020 qualifiers against Cyprus and Belgium was notable for the number of absentees. Such situations were commonplace during the tenure of his predecessor, Alex McLeish.
John Fleck has been given dispensation to miss the matches because he is getting married. Steven Fletcher is being rested as he manages ankle issues. Robert Snodgrass and Matt Ritchie remain absent from the Scotland scene but Clarke has been boosted by the availability of Tom Cairney, who it was thought planned to switch allegiance to England.
“I think there are conversations to be had on every single one of them,” Clarke said. “I’m not going to close the door on anybody. If it takes two or three conversations and I feel that they are the right people to help the squad, to make the squad better, then I am prepared to keep trying.
Scotland calling: five areas new head coach Steve Clarke must focus on Read more
“Hopefully you will see over the time I’m in the job we can get these players to come and play for us. What’s happened before has happened before. There’s nothing I can do about that. It’s my job to speak to these players and try to convince them –not even convince them, make them know they are wanted in Scotland. I think if you make people feel wanted, then they are more likely to come and play for you.
“There’s enough talent in that squad to get results in both games, I’m convinced of that.”
It has been suggested Clarke should cut off those who have previous for not accepting Scotland calls or routinely invoke Fifa’s five-day rule, under which a national association can prevent a player who rejects a call-up from playing for his club for five days after the fixture.
“Every individual case has to be taken on its own merits,” said the former Kilmarnock manager. “There is no way you can throw down a blanket ‘this is what we are going to do and this is the way we will deal with people who don’t come to the squad’. I don’t think that would be right. I think it is always better to have a conversation, speak to the club involved and try to find a reasonable solution.”
Clarke said he had only a rough idea as to why the mood regressed under McLeish. “Some of the more senior ones felt after the qualifying campaign under Gordon [Strachan] that they’d been pushed aside a wee bit,” said Clarke. “That’s something we can work on.”
The same applies to goalscoring. Clarke’s 27-man squad has a combined tally of 14 international goals, five from defenders.
Goalkeepers: Scott Bain (Celtic), Liam Kelly (Livingston), David Marshall (Hull City), Jon McLaughlin (Sunderland)
Defenders: Michael Devlin (Aberdeen), Stuart Findlay (Kilmarnock), Scott McKenna (Aberdeen), Charlie Mulgrew (Blackburn Rovers), Stephen O’Donnell (Kilmarnock), Liam Palmer (Sheffield Wednesday), Andrew Robertson (Liverpool), John Souttar (Heart of Midlothian), Greg Taylor (Kilmarnock)
Midfielders: Stuart Armstrong (Southampton), Tom Cairney (Fulham), John McGinn (Aston Villa), Callum McGregor (Celtic), Kenny McLean (Norwich City), Scott McTominay (Manchester United), Graeme Shinnie (Aberdeen)
Forwards: Eamonn Brophy (Kilmarnock), Oliver Burke (Celtic, on loan from West Brom), James Forrest (Celtic), Ryan Fraser (Bournemouth), Marc McNulty (Hibernian, on loan from Reading), Lewis Morgan (Sunderland, on loan from Celtic), Johnny Russell (Sporting Kansas City)

Story 30
Make informed decisions with the FT
Keep abreast of significant corporate, financial and political developments around the world. Stay informed and spot emerging risks and opportunities with independent global reporting, expert commentary and analysis you can trust.

Story 31
Conclusions It was feasible to develop a tool to measure data sharing policies and practices among large companies and have an impact in improving company practices. Among large companies, 25% made participant level trial data accessible to external investigators for new drug approvals in accordance with the current study’s measures; this proportion improved to 33% after applying the ranking tool. Other measures of trial transparency were higher. Some companies, however, have substantial room for improvement on transparency and data sharing of clinical trials.
Results Only 25% of large pharmaceutical companies fully met the data sharing measure. The median company data sharing score was 63% (interquartile range 58-85%). Given feedback and a chance to improve their policies to meet this measure, three companies made amendments, raising the percentage of companies in full compliance to 33% and the median company data sharing score to 80% (73-100%). The most common reasons companies did not initially satisfy the data sharing measure were failure to share data by the specified deadline (75%) and failure to report the number and outcome of their data requests. Across new drug applications, a median of 100% (interquartile range 91-100%) of trials in patients were registered, 65% (36-96%) reported results, 45% (30-84%) were published, and 95% (69-100%) were publicly available in some form by six months after FDA drug approval. When examining results on the drug level, less than half (42%) of reviewed drugs had results for all their new drug applications trials in patients publicly available in some form by six months after FDA approval.
Main outcome measures Company level, multicomponent measure of accessibility of participant level clinical trial data (eg, analysis ready dataset and metadata); drug and trial level measures of registration, results reporting, and publication; company level overall transparency rankings; and feasibility of the measures and ranking tool to improve company data sharing policies and practices.
Data sources Data sharing measures were adapted from 10 prominent data sharing guidelines from expert bodies and refined through a multi-stakeholder deliberative process engaging patients, industry, academics, regulators, and others. Data sharing practices and policies were assessed using data from ClinicalTrials.gov, Drugs@FDA, corporate websites, data sharing platforms and registries (eg, the Yale Open Data Access (YODA) Project and Clinical Study Data Request (CSDR)), and personal communication with drug companies.
As part of a larger project called the Good Pharma Scorecard, we developed a harmonized, practical set of measures and a tool for assessing sharing of participant level clinical trial data by research sponsors and applied them to measure policies and practices among large pharmaceutical companies with drugs newly approved by the FDA in 2015. We also evaluated the feasibility of the tool (a ranking system) in improving companies’ practices. We further report companies’ performance on other measures of clinical trial transparency, such as trial registration and publication.
Evaluating and tracking progress on the implementation of data sharing policies and practices among pharmaceutical companies is, however, difficult. Existing guidelines for what should be shared, how, and when vary widely and are often vague. As might be expected, given this lack of standardization and concreteness, an analysis of 42 pharmaceutical companies’ transparency policies as of early 2016 found considerable heterogeneity in companies’ commitments. 5
Today, the transparency discussion has shifted to new terrain: sharing of patient level clinical trial data. Initiatives by the European Medicines Agency, research funders, medical journal editors, pharmaceutical companies and trade associations, the Institute of Medicine (now the National Academies of Sciences, Engineering, and Medicine), and others have heightened expectations that data sharing be a routine part of clinical trial research. 2 3 An abundance of data sharing policies and guidelines and several online platforms have supported this shift. 4
Public expectations for transparency in the conduct and reporting of clinical trials continue to evolve. In the late 1990s, US law required only that clinical trials relating to life threatening conditions be registered. In 2007, the Food and Drug Administration Amendments Act (FDAAA) expanded registration requirements to trials for all conditions and mandated the posting of results for many phase II and phase III trials for FDA approved drugs. A decade later the Department of Health and Human Services’ Final Rule expanded trial registration and results reporting requirements to still more types of trials, including those for unapproved drug indications and phase I trials funded by the National Institutes of Health. 1
Summary statistics (medians and interquartile ranges) were calculated to show how commonly trials for each approved drug met the transparency measures. All data were recorded and analyzed in Microsoft Excel V.15.11 (Redmond, WA).
Next, we ranked companies on their overall clinical trial transparency, by averaging companies’ scores on three items: the data sharing measures applied to data sharing applicable trials, the other transparency measures applied to trials in patients, and the other transparency measures applied to FDAAA trials (details of calculations presented in table 2 ). If companies had multiple new drug applications approved in a reporting year, trials were pooled and aggregated, then categorized into our three trial samples for scoring. The approval of one combination drug (Tresiba) and one new molecular entity (Ryzodeg) relied on the same trial data, so we treated them as a single drug.
Firstly, we ranked companies on their data sharing policies and practices by calculating an overall data sharing score for each company based on averaging their scores from the five constituent elements of our data sharing measure ( box 1 ). For four elements, a score of 100% or 0% was assigned depending on whether a company’s policy or practice did or did not meet the requirement, respectively. Because one objective of the project was to improve data sharing, companies were given 30 days to improve their policies to satisfy the data sharing measures. We present both the initial and the final scores.
We made one change to the methods applied in our previous reports—in the drug and company rankings, we shortened the cut-off date for assessing whether results were published from 13 to six months after FDA approval. The time was shortened because payers and others making formulary decisions often review the medical literature for new drugs earlier than 13 months post-FDA approval of a drug. 21 We continue to report the public availability of trial information at the time of FDA approval and at 3, 6, and 12 months after approval so that our results can be compared year after year; however, the drug and company rankings for 2015 are based on trial reporting and publication at six months.
Following our previously published methods, the transparency measures were applied to three samples of trials from the 2015 FDA approved new drug applications, described in table 1 . The “all trials” registration sample consisted of every clinical trial in each new drug application for novel drugs approved in 2015, sponsored by a large company. Although including trials in healthy volunteers in transparency requirements is controversial, we provide this analysis because the National Institutes of Health policy and some companies now require the disclosure of such trials, and these trials generate useful scientific information. For results reporting only, the all trials sample excluded trials terminated without enrollment, expanded access trials, observational studies, and trials that were ongoing or less than one year past their primary completion date by the study assessment cut-off date. Observational studies were excluded because they were generally ongoing as of our study cut-off date. From the all trials sample we selected two subsamples: one comprising trials conducted in patients (including phase I trials), as opposed to healthy volunteers; and a subsample of FDAAA trials, which consisted of trials that appear to be subject to the registration and results reporting requirements in the FDAAA Final Rule.
Previously, the Good Pharma Scorecard project 18 developed and published a suite of other measures of clinical trial transparency and applied them to drugs approved by the FDA in 2012 and 2014. 19 20 Those measures related to clinical trial registration, reporting of trial results in a public registry, publication of results in the medical literature, and adherence to the transparency requirements of FDAAA. Using our previously published methodology (described in Appendix section 3), we applied those measures to our new sample of drugs approved by the FDA in 2015.
In April-May 2018, we gathered and analyzed again company policies and practices to capture any changes after the 30 day amendment window. At least two research assistants who received training and worked independently assessed the company policies. Discrepancies between their evaluations were resolved by consensus of the authors.
In February 2018, we sent to companies the raw data underpinning our analyses, not rankings. The companies had a 30 day window in which to amend their policies and practices to meet our measures and to request correction of any errors; error corrections were adopted if confirmable through public data sources. In the rare case a new drug application holder stated it was not the responsible party for a trial and did not have control over data, we reassigned responsibility to another company if the other company confirmed responsibility in writing.
In June 2017 we abstracted data sharing policies from company websites and trial repositories. We assessed the data sharing policies and practices from June 2017 through January 2018 (we confirmed policies did not change on company websites in January 2018). Phase II and phase III trials conducted to gain FDA approval of each drug were identified from FDA drug approval packages on Drugs@FDA. This included the FDA summary; medical, pharmacology, clinical pharmacology, and biopharmaceutics reviews; and all other review documents. During this period, we also assessed the registration of data sharing applicable trials in ClinicalTrials.gov and reports on the number of data requests received and how each data request was handled (ie, granted or rejected), with data gathered from data sharing repositories (such as clinicalstudydatarequest.com and yoda.yale.edu ) and corporate websites and repositories.
Phase I trials were excluded from our data sharing analysis primarily because of a lack of consensus on the value of reporting basic summary results for these trials that examine small numbers of healthy volunteers, let alone on the investment of resources to protect patient privacy to make these individual patient data available. Phase IV trials were not included because they are completed after the FDA approves a novel new drug application and were therefore out of our sample frame (which is focused on the trials that support a new approval). We specified that trials with a high risk of reidentifying individual participants could be excluded upon request, but sponsors made no such request.
We applied the new data sharing measures to phase II and phase III clinical trials in new drug applications for novel drugs approved by the FDA in 2015 that were sponsored by the 20 largest biopharmaceutical companies (based on 2015 market capitalizations). 17 Novel new drugs are defined as new molecular entities and new combination drugs containing at least one new molecular entity component. We confined our analysis to large companies because they sponsor most of the novel drugs approved by the FDA.
At the end of the study, we will convene our annual multi-stakeholder meeting which includes patients, regulators, academics, healthcare professionals, ethicists, and industry to disseminate results, in keeping with our methods from the past several years. We will invite the patients who participated in past events as well as new groups. We also plan to engage the news and social media about the results of this research project.
Company’s policy provides access to both analysis ready datasets and either clinical study reports or all the following: statistical analysis plan, study protocol, dataset codebook, and synopsis of clinical study report
Six months after drug approval by the FDA, six months after drug approval by the European Medicines Agency (if requested), or 18 months after the trial completion date, whichever is latest
The revised measures were then piloted on a sample of drugs to ensure scoring feasibility and evaluate their feasibility in improving company practices. Box 1 summarizes the final measures, with full text and a flow chart provided in Appendix sections 2 and 7. The elements assessed included whether companies registered all data sharing applicable trials so that interested parties could learn about them and request data, whether they publicly reported the number and outcome of data requests, and whether their policies provided access to analysis ready datasets and clinical study reports for applicable trials, explained how data could be requested, and shared data by our deadline. A clinical study report is a “written description of a study of any therapeutic, prophylactic, or diagnostic agent conducted in human subjects, in which the clinical and statistical description, presentations, and analysis are fully integrated into a single report.” 16
The research team discussed each comment received and documented a decision on what revisions, if any, should be made in response. Comments from companies, along with our documented decision on each comment, were collated and will be shared publicly on the Bioethics International website ( https://bioethicsinternational.org/good-pharma-scorecard/scorecard-methodology/ ).
Because the Institute of Medicine recommendations are guidelines, not measures, we had to create methods for assessing their implementation. This included identifying data sources for our assessment and clarifying ambiguous language. After translating the guidelines into draft measures, we engaged a multi-stakeholder group for review and feedback on the measures and our Scorecard/ranking concept. This group included 10 non-industry experts on data sharing (academics, regulators, medical journal editors, and trial repository experts), representatives from 11 large pharmaceutical companies, and 12 patient representatives. Companies were invited if they had a novel drug approved by the FDA between 2012 and 2015. We identified patient groups based on the relevance and responsiveness of our work to theirs. This involved applying two selection criteria—they had to have an interest in clinical trial data sharing or in conditions treated by our cohort of ranked drugs from 2012 through present. When producing the invitations, we made efforts to invite patients from organizations known to be independent from industry and provided financial support to patient participants as a way of ensuring that funding was not a barrier to participation. Appendix section 1 lists participant names and organizations.
Following this review, a decision was made to adhere closely to the Institute of Medicine guidelines unless there was a compelling reason to depart from them on certain measures, as they proved the most detailed and reflected both in-depth deliberation by national experts and multi-stakeholder consultation. Although we did not explicitly prespecify principles in our project, several guided our decision making—that is, that the data sharing standards must require companies to provide all the information necessary to achieve the potential benefits of data sharing, they must be clear and objectively measurable, and they should not be unreasonably burdensome on any stakeholder.
To develop the data sharing measures, we first reviewed and characterized 10 prominent data sharing guidelines, produced by the Institute of Medicine, 6 Biotechnology Industry Organization, 7 European Medicines Agency, 8 Pharmaceutical Research and Manufacturers of America (PhRMA) and European Federation of Pharmaceutical Industries and Associations (EFPIA), 9 World Health Organization, 10 International Committee of Medical Journal Editors, 11 National Institutes of Health, 12 New England Journal of Medicine, 13 Association of American Medical Colleges, 14 and United Kingdom’s Medical Research Council. 15 Characteristics extracted from the guidelines included which data the guidelines stated should be shared, the types of trials covered or excluded, and the timeline for sharing. At least two researchers blinded to one another’s work and trained on variable extraction independently reviewed each guideline. Reviewers noted conflicts across guidelines and vague language (eg, recommendations to share data within a “reasonable amount of time”).
The median overall transparency score among the 12 companies was 92% (interquartile range 78-95%) ( table 6 ). Two companies, Roche and Novo Nordisk, tied for the top ranking in overall transparency; each with scores of 100%. Roche, Novo Nordisk, and Janssen/Johnson & Johnson all achieved scores of 100% on the data sharing measure.
When we examined all trials in successful new drug applications, including those in healthy volunteers, a median of 61% (49-93%) of trials per drug were registered, 33% (14-59%) reported results or shared a CSR summary, and 31% (23-54%) were published by six months post-FDA approval of the drug ( table 4 ). Overall, results for a median of 55% (31-72%) of all trials were publicly available in some form. Only 11% of reviewed drugs had public results (reported, published, or CSR summary) for all new drug application trials by six months post-FDA approval. However, public availability of trial results for the sample comprising all trials also improved over time, with 29% (interquartile range 15-56%) available at FDA approval, 41% (24-62%) 30 days later, 50% (26-63%) three months later, 55% (28-80%) six months later, and 63% (29-96%) 12 months later (see Appendix section 5).
When we examined results on the drug level, less than half (42%) of reviewed drugs had results for all their new drug application trials in patients publicly available in some form by six months after FDA approval. Of drugs with FDAAA applicable trials (17), 35% of these drugs did not fully meet the FDAAA applicable measures for timely registration and results reporting.
Trials became increasingly more available over time, with 60% (interquartile range 25-76%) of patient trials available at FDA approval, 76% (46-96%) 30 days later, 80% (46-97%) three months later, and 100% (77-100%) 12 months later (see Appendix section 5). A median of four trials for each new drug application were FDAAA applicable trials, with a median of 100% (83-100%) of these trials per drug meeting our FDAAA trial measures (see Appendix section 6).
When we examined trials conducted in patients, a median of 100% (interquartile range 91-100%) of patient trials per drug were registered, 65% (36-96%) reported results or provided a clinical study report (CSR) summary, and 45% (30-84%) were published ( table 4 ). Overall, results for a median of 95% (69-100%) of trials in patients were publicly available in some form (reported, shared in a CSR, or published) within six months of FDA approval of the drug ( table 4 ).
A few companies’ data sharing commitments exceeded the standards measured. Novo Nordisk, for example, provides access to trial data sooner than our standard required. Some companies also commit to sharing data for additional types of trials, such as phase I and phase IV trials.
At the end of the 30 day window in which companies could amend their policies to meet our measure, the number of companies meeting our measure increased from 25% to 33%, and the median overall data sharing score for the 12 companies increased from 63% to 80% (interquartile range 73-100%) ( table 5 ). Three companies changed their policies. AstraZeneca added a new provision to report annually the number of received data requests and the outcome of each. Novartis added timelines for data sharing where previously none were specified. Gilead substantially expanded its data sharing policy (eg, by adding timelines for data sharing), although we could not confirm whether this was in direct response to our preliminary scoring. In our sensitivity analysis, results were similar whether completion date or primary completion date was used as the benchmark for adhering to the measure (see Appendix section 4).
One quarter of companies fully met our data sharing measure ( table 5 ). The median overall data sharing score among companies was 63% (interquartile range 58-85%). The most common reason companies did not satisfy the data sharing measure before the 30 day amendment window (75%) was failure to share trial data by the specified deadline. Several companies’ policies did not commit to a deadline for sharing data, whereas others committed to sharing data only after publication in a medical journal. The next most common problem was not reporting the number and outcome of data requests (six of 12 companies) and failure to register all data sharing trials so interested parties could learn about and request data (five of 12 companies). Two companies did not have data sharing policies ( table 5 ).
In 2015, 12 of the 20 largest pharmaceutical companies (60%) had novel new drugs approved by the FDA. Collectively, they sponsored 56% (19/34) of the new drug applications for novel drugs approved in 2015, which were based on a total of 674 clinical trials. We analyzed 628 of these trials, a median of 25 (interquartile range 18-49) trials for each new drug application, after excluding trials that were not at least one year past the completion date, expanded access trials, and trials terminated without enrollment ( table 4 ). These 628 trials reported data on more than 154 000 participants, 92% of whom were patients and 8% of whom were healthy volunteers.
After analyzing existing policies and engaging with our multi-stakeholder advisory team, a decision was made that our data sharing measures should adhere closely to the US Institute of Medicine’s data sharing guidelines unless there was a compelling reason to depart from them on certain measures, as they proved the most detailed and reflected both in-depth deliberation by national experts and multi-stakeholder consultation. We departed from the Institute of Medicine guidelines in three key ways (see table 3 for a comparison of our measures to the Institute of Medicine and PhRMA/EFPIA guidelines). Firstly, we closed a loophole allowing companies to share data only after publication in a medical journal, which permitted companies to evade data sharing requirements by not publishing trials. 22 Secondly, we added a requirement that all data sharing applicable trials be registered in ClinicalTrials.gov, so that interested parties can easily learn about the existence of trials and request data for their purposes. Thirdly, we added a requirement that companies report annually the number of data requests received and the decision made upon each request.
Discussion
Tracking and incentivizing progress in the journey towards routine sharing of participant level clinical trial data requires harmonized, practical measures that can be applied to any research sponsor. In this study, we developed such a data sharing measure through a rigorous process, demonstrated its feasibility, and assessed current practices for data sharing among large pharmaceutical companies. We also studied the feasibility of using our data sharing measures and tool (a ranking process) to improve company policies and practices. Additionally, we reported on how adherence to transparency standards relating to trial registration and results publication has changed over time.
Application of our newly developed data sharing measure to the 12 large pharmaceutical companies with drugs approved in 2015 showed moderate initial adherence (median score of 63%; one quarter of companies achieved perfect scores), which increased after companies were offered one month to improve their policies (median final score 80%; one third of companies with perfect scores). Most (83%) companies we studied had data sharing policies, all of which now provide access to analysis ready datasets and CSRs and explain how data can be requested.
However, one quarter of companies’ policies still do not report on how the company deals with requests, and 58% do not commit to furnishing data by a reasonable or defined time point. These are important omissions. Documenting that most data requests are granted, as some companies have done,23 is an important accountability mechanism that shows companies’ practices adhere to their policies. Committing to timely provision of data and metadata also helps ensure data sharing policies result in dissemination on a useful timeline.
Comparison with our other studies on data sharing and trial transparency Juxtaposing our results concerning rates of trial registration and results reporting to our earlier analyses of trials in new drug applications approved in 2012 and 2014 reveals improvement over time in key measures.1920 The median proportion of trials in patients with publicly available results at 12 months after FDA approval increased from 87% for 2012 drugs to 100% for 2015 drugs. On the other hand, improvements in transparency were not observed for the sample of all trials, which includes trials in healthy volunteers. The median proportion of such trials with publicly available results (in any form) was lower for 2015 (63%) than for 2012 (65%). These findings generally accord with reports conducted by other colleagues on results reporting in the European Union.24 Our results reveal some persistent heterogeneity among large pharmaceutical companies in their commitments to data sharing, confirming results from other recent studies,52526 one of which examined whether companies had data sharing policies but imposed no standards for what constituted an acceptable policy nor measured adherence to policies. In our analysis, companies’ data sharing scores ranged from 14% to 100% and overall transparency scores from 47% to 100%. Three companies were in the bottom tercile of the overall transparency rankings in both 2014 and 2015; two of these have not adopted data sharing policies. In contrast, three other companies showed willingness to strengthen their data sharing policies after receiving feedback from our project, suggesting that public ranking and benchmarking can be helpful in moving at least some companies toward greater transparency.
Comparison with other studies These finding are in keeping with other studies showing that ranking, rating, and benchmarking are associated with improved quality and firm performance. Evaluating 598 firms subject to environmental ratings, Chatterji and Toffel found low scoring firms substantially changed practices in response to poor ratings; responsive action was particularly prevalent in heavily regulated industries and when “faced (with) less costly opportunities to improve.”2728 Many examples exist of successful grading and rating systems using reputational incentives to improve firm behaviors. Restaurant grades, for instance, have catalyzed restaurants to substantially improve cleanliness, which in turn has reduced the number of hospital admissions for foodborne illnesses.29 Because the legitimacy and even the survival of institutions are often threatened when negative information is disclosed about the operations of firms, companies are incentivized to pay attention to ratings and improve their performance upon receiving poor scores. The knowledge that other companies are performing better, along with opportunities to learn and refine beliefs about previously unobserved quality, further helps catalyze change.
Conclusions and policy implications In the case of the pharmaceutical industry, external stakeholders such as patients/carers, clinicians, and investors can further speed change by demanding that low scoring companies commit to reform as a condition of partnering with or supporting them.30 Empowering these groups to be effective levers for change is one reason we report aggregate scores on the company level. More detailed information about companies’ scores can be found in the appendix of this paper and more easily understandable information on the Bioethics International website. Five years ago, few companies had policies to share participant level trial data. Data sharing gained traction around 2013 with leading efforts by GSK,31 Yale’s YODA Project with Johnson & Johnson,3233 and Project DataSphere.34 In 2014, Duke and Bristol-Myers Squibb partnered to form the DCRI-BMS Data Sharing Initiative (SOAR).35 Other companies are now voluntarily coming along, some quicker than others. Clearly, major shifts are occurring in data sharing. Although evidence documenting tangible benefits of data sharing has not emerged, optimism about the potential clinical and scientific benefits is considerable.6 For these benefits to be quickly and fully realized, however, we need a way to benchmark progress—and by doing so, further encourage it. The Good Pharma Scorecard, along with efforts by others,3637 provides a means of monitoring progress and identifying areas where research sponsors’ transparency and data sharing practices can improve. These measures should help solidify consensus about the standards that companies must meet. This, in turn, may stimulate companies to improve transparency practices by reducing uncertainty about what is expected and frustration from trying to satisfy conflicting standards. Developed through a detailed process including review of leading transparency guidelines and multi-stakeholder consultation, the Good Pharma Scorecard measures represent standards that set a high ethical bar for companies but are both operationally feasible and not unduly burdensome to meet, as shown when one quarter of companies achieved perfect scores.
Limitations of this study Our study has several limitations. Firstly, at the drug level, we attribute transparency scores to the company that sponsored a drug’s new drug application, although a few trials were sponsored by other companies (eg, companies the sponsor acquired). We report details of such trials in the results tables and reassigned trials to other companies where both agreed that was appropriate. Secondly, our analysis was limited to large companies with drugs approved in the US in 2015. A recent analysis of company policies suggests commitments might differ between large and smaller companies.5 Further, some companies that appeared in our 2012 and 2014 rankings do not appear for 2015, because they did not have a novel drug approval, complicating longitudinal comparisons. Thirdly, our study focused on companies’ data sharing, reporting, and publication policies and practices; it was not feasible to review the quality of disseminated data, the ease with which data could actually be obtained, or criteria used by each company to evaluate data requests. Fourthly, our company rankings are not adjusted for the volume of trials conducted. For some companies, the number of trials relating to drugs approved in 2015 was small. Finally, the company rankings weight different disclosure methods differently (see table 3), which may be controversial. Trial registration, for instance, is weighted more heavily than whether a company reports the number of data requests received. We did this to keep evaluations easy to interpret; each evaluated sample (eg, trials in patients, data sharing applicable trials) accounts for one third of the company score, regardless of the number of parts the measure comprises. Because trial registration is essential for achieving all benefits of trial transparency, including recruiting participants into trials, it is not unreasonable to weight it more heavily than other factors in determining company rankings.

Story 32
The BMW PGA Championship, a Rolex Series Event on the European Tour, saw the beginning of the Ryder Cup Points Race and a win for former Masters Tournament champion Danny Willett.
The Englishman shot to the top of the Ryder Cup Points List after picking up 1,165.00 points for his triumph around Wentworth Golf Club.
It’s been a strong year for Willett, who finished the 2018 BMW PGA Championship ranked 462nd in the world but now finds himself ranked as high as 31st in the Official World Golf Rankings.
After tasting defeat at The 2016 Ryder Cup, Willett will no doubt be looking to avenge that result should he still qualify for the team at Whistling Straits.
Jon Rahm also put in a strong performance at Wentworth Golf Club. After battling with Willett for the most part of the final round, he eventually came up three shots short as he looked to add a third Rolex Series title to his name.
Although early days in the qualifying race, there is an eclectic mix of experienced players such as Rafa Cabrera-Bello, Paul Casey, Rory McIlroy and Justin Rose, as well as potential rookies in Norway’s Viktor Hovland, fan favourite Andrew Johnston, Open Champion Shane Lowry and Scotland’s Richie Ramsay all within the automatic places.
Without a doubt the team will chop and change majorly over the coming year, but if this week is anything to go by it looks as if Europe will be sending a strong team across the pond to Whistling Straits.

Story 33
Berlin, Germany, Feb. 21, 2019 (GLOBE NEWSWIRE) -- Blockchain startup Lition, an innovation partner of SAP, is launching its Testnet on February 21 at the SAP Data Space in Berlin, to publicly demonstrate the technical capabilities of the Lition blockchain. Watch the livestream here (12:30 PM EST).
Lition is the first and only blockchain network offering openness, privacy and deletability, which is accomplished by connecting an immutable public mainchain with permissioned, deletable sidechains. The Testnet will ensure all blockchain functions work as intended using test tokens before Lition conducts its Initial Coin Offering on March 18 and launches its mainnet in Q3 / 2019.
After the Testnet is online, Lition will migrate its commercially live P2P energy exchange onto the infrastructure. During the testing period, developers will put the network through a trial by fire, allowing any bugs to be identified and providing a proof of concept for all promised functionalities, like deletability and scalability.
Lition has also been working closely with German lawmakers to help shape new blockchain-centric legislation and deployment strategies. These efforts ensure the Lition platform is GDPR compliant, and able to provide user data protection while maintaining an uncompromised blockchain network. The EU enforces strict data deletion mandates and has thus rendered many of the current networks illegal within its jurisdiction.
Dr. Richard Lohwasser, Lition’s CEO and Co-Founder, “deletability is the missing element of the enterprise blockchain networks. Our GDPR compliant blockchain allows enterprise use and mass-market adoption by bringing together ‘privacy’ and ‘immutability’ in the most technically sound way!”
About Lition Technology AG - Lition is a blockchain infrastructure and dApp developer, with 20 employees mostly based in Berlin. Lition’s new blockchain infrastructure addresses key commercial and business issues that have prevented blockchain networks from reaching widespread mainstream adoption so far. With scalable public-private blockchain and ‘deletable’ data features, the Lition network allows businesses and large enterprises to bring innovative blockchain applications to the mass-market that are legally compliant. Lition has also developed and launched the world’s first commercially live P2P energy trading platform, currently serving customers in 29 cities across Germany.
Stephan Vogel Lition Energie GmbH stephan.vogel@lition.de

Story 34
Getty Images / Bloomberg / Contributor
With all the phone and watch and TV and game and chip and other chip news coming out of Apple's big event last week, it was easy to forget the company's longest-running background process: an augmented-reality wearable. That's by design. Silicon Valley's advent calendar clearly marks September as the traditional time for Apple to talk finished hardware, not secretive projects.
But those secretive projects have a weird habit of poking their heads into the light. A slew of features and language discovered recently inside iOS 13 and 13.1 seem to explicitly confirm the very thing Apple executives have steadfastly refused to acknowledge—an honest-to-Jobs AR headset. In fact, taken in conjunction with acquisitions and patent filings the company has made over the past several years, those hidden features have painted the clearest view yet of Apple's augmented dreams.
Advertisement
Hard to StarBoard
First came StarBoard. At the very beginning of September, a leaked internal build of iOS 13 was found to contain a "readme" file referring to StarBoard, a system that allows developers to view stereo-enabled AR apps on an iPhone. The build also included an app called StarTester to accomplish exactly that. That marked the first explicit mention stereo apps—i.e., those that output to separate displays, like those found in AR/VR headsets—in Apple material.
Not long after, on the day of the hardware event, Apple released Xcode 11, the newest version of the company's macOS development environment. Inside that set of tools lurked data files for what appeared to be two different headsets, codenamed Franc and Luck. The same day, iOS developer Steve Troughton-Smith found the StarBoard framework in the official "golden master" of iOS 13; he also pointed out references to "HME," which many speculated stood for "head-mounted experience." (HMD, or head-mounted display, is a common term for a VR/AR headset.)
Read next Apple's new AirPods Pro get noise cancelling and a design makeover Apple's new AirPods Pro get noise cancelling and a design makeover
So far, so unprecedented. When Apple first released ARKit in 2017, it was the beginning of a long journey to familiarise developers with augmented reality and get them playing with the possibilities. Yet, the company has always been careful to situate AR as a mobile technology, people peeking through iPhones or iPads to shop or play with Legos, or even experience public art installations. Finding this kind of data, even hidden deep within OS developer files, marks an uncharacteristic transparency from Apple—as though the company is planning something sooner rather than later.
What that thing might be depends who you ask. Reports from Bloomberg News and Taiwanese analyst Ming-Chi Kuo have long claimed that Apple would be beginning production on an AR headset this year for release in 2020—one that acts more like a peripheral than an all-in-one device, depending on the iPhone to handle the processing power.
Advertisement
Troughton-Smith came to a similar conclusion after poking through iOS 13. "The picture of Apple’s AR efforts from iOS 13 is very different to what one might expect," he tweeted. "It points to the headset being a much more passive display accessory for iPhone than a device with an OS of its own. The iPhone seems to do everything; ARKit is the compositor."
That idea of a passive display accessory got fleshed out late last week, when another developer got StarTester up and running on a beta of iOS 13.1, which officially comes out today.
@stroughtonsmith Managed to get into apple glasses test mode (aka StarTester mode) in 13.1 beta 3 on iPhone X, but right-eye view in glitchy. (Scene contents are from my area light test, not from StarBoard) pic.twitter.com/71chJTBJaA — xSnow (@__int32) September 20, 2019
Read next iPhone 11 Pro and Pro Max review: the best yet, but you don’t care iPhone 11 Pro and Pro Max review: the best yet, but you don’t care
That person also found specific numbers in the iOS framework referring to the fields of view for the two specific headset codenames: 58 and 61 degrees for Luck and Franc, respectively. (A third codename, Garta, seems to refer to a testing mode rather than a specific device.)
Advertisement
All of which matches up with the thought that Apple is planning a small, lightweight product—one that lives up to the term "wearable" by being more like smart glasses instead of an unwieldy Microsoft HoloLens. "Fifty-eight degrees doesn't sound like much compared to an Oculus Rift, but compared to an nreal Light, which is 52 degrees, it's already pretty competitive," says JC Kuang, an analyst with AR/VR market intelligence firm VRS. "That's the exact class of product we need to be looking at when we talk about what the architecture might look like."
Mark Boland, chief analyst at ARtillery Intelligence, which tracks the augmented-reality mark, calls such a product a "notification layer," and posits it as an introductory device of sorts—one that acts as a bridge between the mobile AR of today and a more powerful headset that could ultimately replace the smartphone. "I've always been skeptical of 2020," he says. "If you look across the industry at the underlying tech, it's just not ready to build something sleek and light." However, an intermediary device like the one iOS 13 seems to point to could strike a balance, giving developers the chance to get used to building stereo experiences and develop best practices before needing to fully integrate with the "mirror world."
A recent patent seems to support the idea as well. "Display System Having Sensors," which Apple filed in March and was published in July, describes a companion system: a head-mounted device with inward- and outward-facing sensors feeds its inputs to a "controller," which then "render[s] frames for display by the HMD." A patent isn't the same as a plan, obviously, but it's a hell of a data point.
From Here to ARternity
How Apple gets from phone-tethered smart-glasses to something a fully realised spatial-computing platform—or how long it takes to do so—remains unclear, but elements of the road map are hidden in plain sight. "A lot of the tech they've already built and fully deployed is critical to their goal of building a discreet AR HMD platform," Kuang says. As an example, he points to last week's announcement that the iPhone 11 models could take photos of pets in Portrait Mode: "That's a good example of them working in little tweaks that don't appear to have relevance to AR, but are super-meaningful if you're a developer. The ability to recognise nonhuman faces significantly expands your ability to build tools and experiences."
Read next More radio, more live: where Apple Music's headed in 2020 More radio, more live: where Apple Music's headed in 2020
Two acquisitions Apple has made in recent years also suggest how the company might get there. Kuang traces the current StarBoard testing mode to the 2017 acquisition of a company called Vrvana. At the time, Vrvana's chief product was a mixed-reality headset—however, rather than rely on a transparent "waveguide" display like those in the HoloLens or Magic Leap One, it used front-facing cameras to deliver passthrough video to the user. (This is also how a company like Varjo delivers mixed reality using an VR headset.)
"It ruffled some feathers because nobody was really down with a discreet headset using pass-through," Kuang adds of Vrvana. "But the StarBoard stuff presents exactly that: a Google Cardboard sort of functionality for iPhones. It's obviously for testing purposes, but it maybe gives us a little more insight into how Apple has been testing AR without having to resort to building a couple of hundred waveguide-enabled devices for testing purposes."
Apple's other strategic move, buying Colorado company Akonia Holographics in 2018, looks to have two possible reasons: not just for the waveguide displays that Akonia was working on, but for the "holographic storage" that was the company's original goal. The term, which refers to storing and accessing data in three dimensions rather than on the surface of a material (optical storage), has long eluded commercialisation, but could prove pivotal to the long-term vision of AR. "The utopian vision of the end user device is super-lightweight and does functionally no computing compared to where we currently are," Kuang says. "Everything happens on the cloud. The kind of speed and transfer that comes with holographic storage could be a key part of that."
Kuang points to another recent Apple patent, published just last week, proposing an AR display that delivers three-dimensional imagery through an Akonia-like waveguide system. In his view, it confirms the company's commitment to getting past the limitations of today's devices—particularly the eyestrain that results from trying to focus on virtual objects and real-world ones at the same time." The fact that Apple is acknowledging it's a big problem and intends to fix it is huge," he says. "It's more than Microsoft can be said to be doing."
It also suggests that while the iOS discoveries speak to an interim device, they're also likely only just the beginning. Much has been made of Apple's push into services to offset declining iPhone revenue; subscriptions like Arcade and TV+ are steps toward the company's stated goal of making more than $50 billion from such services annually. But that doesn't solve the question of what comes after the phone—and Boland sees AR as an integral part of any "succession plan" for Apple.
Read next Apple iPhone 11 review: forget the Pro, this is the iPhone you need Apple iPhone 11 review: forget the Pro, this is the iPhone you need
Kuang agrees. "It's a very forward-looking vision for AR," he says of Apple's approach. "They're treating it as a computing modality rather than a display modality, which is critical."
This story was originally published in WIRED US
More great stories from WIRED
🔋 Tesla has created a battery that could last one million miles
🗓️ Four-day working weeks aren't the utopia they seem
💩 Japanese self-cleaning toilets are conquering the West
Advertisement
🍫 The foods you'll really need to stockpile for no-deal Brexit
📧 Get the best tech deals and gadget news in your inbox

Story 35
Elisabeth Mahase The BMJ
Measles cases have risen by 300% so far in 2019 as compared with the same period last year, data from the World Health Organization have shown.
Provisional figures released this week showed that 112 163 cases were reported by 170 countries from January to April this year.1 This compares with 28 124 cases from 163 countries reported over the same period in 2018.
While this represents a global increase of 300%, the increase was much higher in the African region (700%) and much lower in regions such as the eastern Mediterranean (100%) and South East Asia (40%). …

Story 36
HONG KONG, July 24, 2019 /PRNewswire/ -- amg International GmbH (amg), a wholly owned subsidiary of Dublin, Ireland based Q3 Medical Devices Limited (Q3), announced that Professor Anthony Teoh of the Chinese University of Hong Kong, Prince of Wales Hospital successfully implanted the first ARCHIMEDES Biodegradable Biliary/Pancreatic Stent in Hong Kong.
ARCHIMEDES Biodegradable Biliary/Pancreatic Stent
The patient was presented with pain and an elevated bilirubin score which necessitated further investigation. A 2 cm ampullary benign tumor or adenoma was discovered in and around the duodenal papilla. An Endoscopic Ultrasound (EUS) was performed to rule out further intraductal growth and then an ampullectomy was performed to remove the benign tumor. An ARCHIMEDES stent was then placed to minimize the risk of pancreatitis post the ampullectomy.
Professor Anthony Teoh stated after the case, "[I] wanted to use the biodegradable stent for this patient, as it is extremely beneficial to avoid having to bring the patient back for a repeat procedure."
"This represents a great milestone to have the first ARCHIMEDES stent placed in China," remarked Paul Li, President and General Manager of China Pioneer Pharma Holdings Ltd. "ARCHIMEDES and the biodegradable product pipeline as a whole represent a major paradigm shift and we are proud to be a principle driver in the technology."
Eric Mangiardi, CEO and President of Q3 Medical said, "We continue to see the global adoption of our innovative products and how powerful they have been in changing the treatment algorithm for physicians and their patients. We are incredibly honored and proud to have Professor Teoh be the first user in Hong Kong of our groundbreaking technology, as we see this as a direct link to China and helping people there suffering from these life-threatening diseases."
The ARCHIMEDES Biodegradable Biliary/Pancreatic Stent is the only fully biodegradable stent approved for placement in obstructed biliary or pancreatic ducts, in the world. While biliary and pancreatic duct stents are typically made of plastic or metal, amg's ARCHIMEDES stent is made of a combination of dissolving materials permitting different rates of degradation depending on the clinical indication. The ARCHIMEDES stent is designed to completely degrade via hydrolysis in approximately 12 days, 20, days or 11 weeks, depending on its composition. The stent is designed to maintain duct patency, without occlusion as it degrades, due to its patented design. It is intended as an option to potentially avoid repeat procedures to remove traditional non-biodegradable plastic stents, avoiding additional cost of care and risk for patients.
If you would like more information, please contact Eric K. Mangiardi at 218759@email4pr.com or +353867827296.
About Q3 Medical Devices Ltd.
Q3 Medical Devices Ltd. is an Ireland based holding company with multiple global operations in Germany, China, & the United States along with a strong global partnership, and an ever growing strategic investor base, including China Pioneer Pharma Holdings Limited listed on the Hong Kong Exchange and Boill Holding Group, Shanghai China. The holding and its companies are focused on the development, manufacturing and distribution of its novel bioresorbable, micro invasive, drug delivery, and core products platforms for interventional cardiology, peripheral vascular, and non-vascular diseases.
Q3 Medical Devices Ltd. was formed by a global group of entrepreneurs, manufactures, distributors, industry doctors, and investors, focused on the development and acquisition of medical device businesses with annual revenues between 1-10 Million. The acquisitions are targeted in areas that expand the groups manufacturing base and capabilities, grow its distribution channel and accelerate its products offering, focusing on the minimally invasive treatment of patients with cardiology, peripheral vascular and non-vascular diseases.
For further information, visit http://www.q3medical.com/.
About China Pioneer Pharma Holdings Ltd
China Pioneer Pharma Holdings Ltd. is an investment holding company principally engaged in the marketing, promotion and sales of pharmaceutical products and medical devices. The Company operates through two business segments. The Ophthalmic Pharmaceutical Products segment is engaged in the sales of ophthalmic pharmaceutical products by provision of channel management services and co-promotion services. The Products Sold Via the Provision of Comprehensive Marketing, Promotion and Channel Management Services segment is engaged in the sales of all pharmaceutical products and medical devices except for ophthalmic pharmaceutical products. The Company is also engaged in the manufacturing of chemical and pharmaceutical products through its subsidiaries.
http://www.pioneer-pharma.com/
About Boill Holding Group
Boill Holding Group is an international Diversified Enterprise Group with a global presence focused on real estate development, international trade, asset management, and transformational investments in the emerging industries of comprehensive healthcare and intelligent manufacturing sectors. With over 1 Trillion RNB in Assets Boill will continue to focus on expanding its global presence in the Asset Management and Financial Investment areas with focus on the comprehensive healthcare and intelligent manufacturing sectors.
Founded in 1996 and headquartered in Shanghai, China Boill Holding Group, though the visionary leadership of Chairman Qui Dongfang has lead the transformation from a traditional real estate development enterprise to a diversified conglomerate with a global presence in Hong Kong, Japan, Australia, France, Ireland, and the USA.
http://www.boill.com/
Forward Looking Statements
This announcement includes "forward-looking statements" which incorporate all statements other than statements of historical facts, including, without limitation, those regarding the Group's financial position, business strategy, plans and objectives of management for future operations (including development plans and objectives relating to the Group's products and services), and any statements preceded by, followed by or that include forward-looking terminology such as the words "targets", "believes", "estimates", "expects", "aims", "intends", "will", "can", "may", "anticipates", "would", "should", "could" or similar expressions or the negative thereof. Such forward-looking statements involve known and unknown risks, uncertainties and other important factors beyond the Group's control that could cause the actual results, performance or achievements of the Group to be materially different from future results, performance or achievements expressed or implied by such forward-looking statements. Such forward-looking statements are based on numerous assumptions regarding the Group´s present and future business strategies and the environment in which the Group will operate in the future. Among the important factors that could cause the Group's actual results, performance or achievements to differ materially from those in forward-looking statements include those relating to Q3 Medical's & QualiMed's funding requirements, regulatory approvals, clinical trials, reliance on third parties, intellectual property, key personnel and other factors. These forward-looking statements are valid at the date of this announcement. The Group expressly disclaims any obligation or undertaking to disseminate any updates or revisions to any forward-looking statements contained in this announcement to reflect any change in the Group's expectations with regard thereto or any change in events, conditions or circumstances on which any such statements are based. As a result of these factors, readers are cautioned not to rely on any forward-looking statement.
SOURCE Q3 Medical Devices Ltd.
Related Links
http://www.q3medical.com


Story 37
In den Vereinigten Staaten kommt es zu einer dritten Großfusion in der Branche der Zahlungsabwickler. Der Kurs von Total System Services steigt.
Die Branche der Zahlungsabwickler konsolidiert weiter. Der amerikanische Dienstleister Global Payments will für 21,5 Milliarden Dollar den Rivalen Total System Services übernehmen. Es ist in diesem Jahr bereits der dritte Großfusion in der Branche, die durch den verstärkten Online-Handel in den vergangenen Jahren extrem schnell gewachsen ist. Anleger von Total System sollen 119,86 Dollar je Aktie erhalten, das entspricht einem Aufschlag von gut 20 Prozent auf den Schlusskurs vom Montag. Die Transaktion soll im vierten Quartal abgeschlossen werden.
In Deutschland reagieren die Aktienkurse deutlich. Der Kurs von Total System steigt um knapp 5 Prozent auf ein Allzeithoch von 106 Euro. Am Ende der Vorwoche war der Kurs schon in den Vereinigten Staaten um knapp 14 Prozent gestiegen. Global Payments geben dagegen 3 Prozent 133,24 Euro nach. Der Kurs jener Aktie war am Freitag in Amerika noch um 3,7 Prozent auf ein Allzeithoch von 153,44 Dollar gestiegen. Am Montag waren die Börsen in den Vereinigten Staaten wegen eines Feiertags geschlossen geblieben.
Im März hatte der amerikanische Finanzdienstleister Fidelity National Information Services 35 Milliarden Dollar für Worldpay geboten. Anfang des Jahres hatte die ebenfalls in den Vereinigten Staaten ansässige Fiserv den Kauf des Rivalen First Data für 22 Milliarden Dollar angekündigt.
TOTAL SYSTEM SERV. DL-,10 -- -- (--) NYSE Tradegate London Lang & Schwarz Frankfurt Stuttgart 1T
1W
3M
1J
3J
5J Zur Detailansicht
Die Zahlungsabwicklungsbranche profitiert von der Digitalisierung der Geldströme. Bis zum Jahr 2023 werden sie nach einer Studie der Unternehmensberatung McKinsey ein Volumen von rund drei Billionen Dollar pro Jahr abwickeln.
Dieser Boom hat auch den seit vergangenem Jahr im Dax gelisteten Wirecard-Konzern enorm wachsen lassen. Im ersten Quartal stieg dessen Umsatz um 35 Prozent auf 567 Millionen Euro. Das Unternehmen aus dem Münchener Vorort Aschheim macht den Großteil seiner Geschäfte in Asien und ist an der Börse mit 20 Milliarden Euro rund 7 Milliarden Euro mehr wert als die Deutsche Bank. Global Payments und Total System kommen zusammen auf ein Marktkapitalisierung von umgerechnet rund 43 Milliarden Euro.
GLOBAL PAYMENTS INC. -- -- (--) NYSE Tradegate Frankfurt London Lang & Schwarz Stuttgart 1T
1W
3M
1J
3J
5J Zur Detailansicht

Story 38
STR/AFP/Getty Images
Tesla shares were volatile in after-hours trading on Wednesday after the electric-car maker reported first-quarter results that fell short of analysts' expectations.
The company also said it expected to return to profitability in the third quarter and reduce its losses in the second quarter.
Shares have fallen 21% this year amid concerns around underlying demand for Tesla's vehicles.
Watch Tesla trade live.
Tesla shares rose 2% during a volatile after-hours session on Wednesday after the electric-car maker reported a wider-than-expected loss and a 37% quarter-over-quarter drop in revenue.
The company said it expected to return to profitability in the third quarter and reduce its losses in the second quarter — a reversal from prior expectations that profitability would resume in the second quarter. Tesla also expects to see positive free cash flow, excluding capital expenditures, in every quarter of 2019.
"If our Gigafactory Shanghai is able to reach volume production early in Q4 this year, we may be able to produce as many as 500,000 vehicles globally in 2019," CEO Elon Musk and Zachary Kirkhorn, Tesla's chief financial officer, wrote in a letter to shareholders.
"This is an aggressive schedule, but it is what we are targeting. However, based on what we know today, being able to produce over 500,000 vehicles globally in the 12-month period ending June 30, 2020 does appear very likely."
Tesla produced about 63,000 Model 3 vehicles in the first quarter, a 3% jump from the prior quarter. Meanwhile, Model S and Model X deliveries declined to 12,100 vehicles — falling short of the company's two-year run rate of about 25,000 per quarter.
Here's what Tesla just reported, compared with what analysts polled by Bloomberg were expecting:
Adjusted loss per share: $2.90 versus $1.30 expected.
$2.90 versus $1.30 expected. Revenue: $4.54 billion versus $4.84 billion expected.
Morgan Stanley auto analysts earlier this month described the first quarter as one Tesla "may want to forget."
The beginning of 2019 has been dotted with a legal battle between Musk and the Securities and Exchange Commission, disappointing first-quarter deliveries, a plunging stock, employee layoffs, and a concern among Wall Street analysts that underlying demand has faltered.
The California automaker also unveiled its long-awaited $35,000 Model 3 in February, its Model Y crossover SUV in March, and plans for its self-driving technology this week.
Musk warned earlier this year that Tesla probably wouldn't turn a profit in the first quarter, reversing his prior forecast. He does expect Tesla to achieve profitability in the second quarter, however.
Ahead of Tesla's results, short sellers ramped up their bets against the company, according to the financial-analytics firm S3 Partners. Short interest in the name now hovers around the highest level of the year, the firm's data showed.
Read more: Inside Tesla Twitter, where legendary short-sellers and amateur investors gather to trash and praise Elon Musk's electric empire
At the same time, Wall Street analysts have become increasingly negative on Tesla, with the number of "sell" ratings on Wall Street topping "buys." According to data compiled by Bloomberg, 15 suggest "sell," 13 say "buy," and eight recommend "hold."
Tesla shares fell 2% on Wednesday, bringing the stock's 2019 loss to 21%.
Read more Tesla coverage:
Tesla's 'Autonomy Day' fell flat with analysts — now Wall Street is bracing for its Q1 results
Tesla is under pressure after shaking up its board and receiving a demand-fueled downgrade from Wall Street
Elon Musk's most hated group of investors are ratcheting up their bets against Tesla ahead of the company's earnings
Why Tesla won't hit its AV ride-hailing goals
Markets Insider

Story 39
BERLIN--(BUSINESS WIRE)-- LabTwin ﻿﻿GmbH, the world's first voice and AI-powered digital lab assistant, today announced partnerships with CA-based life science shared lab facilities Bonneville Labs and Lab Launch. Both groups provide smart lab facilities to scientists and emerging biotech companies. Bonneville Labs and Lab Launch have selected LabTwin’s digital assistant to augment their smart lab capabilities and allow their resident scientists to be more productive, spend more time focused on their experiments and make informed data-driven decisions.
Through these partnerships, the resident companies of the CA coworking labs receive a free fixed-period LabTwin trial followed by preferred rates.
“LabTwin is a very impressive tool for scientists, making it simple and easy to access information, run through protocols or take notes while they are performing experiments at the bench,” said Kelly Bryant, Vice President, Corporate Development at Bonneville Labs. “This is a major benefit for our companies who are always pressed for time and pushing to improve efficiencies on limited budgets.”
Justin Jarrell, Senior Scientist of Indee Labs, a Bonneville Labs member company shares, “Keeping track of everything that goes into an experiment can be challenging. Important details can fall through the cracks, making it difficult to interpret results and verify key findings. Therefore, we’re very excited to trial LabTwin to help us simplify documentation, increase productivity and accelerate our research.”
LabTwin, works alongside scientists to collect data, connect internal and external information streams, help manage experiments and streamline documentation. Powered by voice recognition and machine learning technology, LabTwin’s smart assistant simplifies data capture, structures valuable data, provides on-demand access to scientific information, guides scientists through interactive protocols and provides suggestions to scientists in real-time.
“Creating a state-of-the-art smart lab means bringing in the most innovative tools for scientists and entrepreneurs,” said Marie Rippen, CEO of Lab Launch. “LabTwin gives our biotech startups an intelligent, AI-powered digital assistant to eliminate time-consuming manual note-taking and help them automatically structure their data. This is a game changer for scientists who are time constrained and need ways to make their research more reproducible.”
“We want to see scientists thrive and help speed up scientific discoveries by making day-to-day life in the lab easier,” said Magdalena Paluch, co-founder and CEO of LabTwin. “We designed LabTwin specifically for scientists. It is a mobile solution that stays with the scientist, granting access to information or instruments from anywhere in the lab. LabTwin further reduces the cognitive load on scientists by tracking timers, scheduling events, ordering stock and more, all while working completely hands-free.”
“We are dedicated to helping scientists accelerate their discoveries by using the latest in voice and AI technology to automate manual tasks and structure important findings,” said Guru Singh, Head of Growth of LabTwin. “By partnering with Californian coworking lab spaces like Bonneville Labs and Lab Launch, we can make our technology available to many more scientists and innovative startups who are conducting experiments and bringing important discoveries to market.”
About LabTwin
LabTwin is creating the next generation of digital lab tools for smart labs, starting with the world's first voice-activated lab assistant. With LabTwin, scientists can collect data, access information, manage experiments and streamline documentation simply by talking. Using voice recognition and machine learning technology, LabTwin’s smart assistant simplifies data capture, structures valuable information, and provides suggestions to scientists in real-time so they can make more informed data-driven decisions. With a mission to empower scientists, LabTwin is backed by Sartorius and BCG Digital Ventures. Its voice-powered assistant is used by hundreds of scientists in leading biopharma companies and academic institutions around the world including Deutsches Primatenzentrum (DPZ), University Medical Center Göttingen, and the University of California, San Francisco.
Visit the LabTwin website﻿﻿ to learn more, sign up to access the app and follow us on LinkedIn, Facebook and Twitter to get company updates.
About Bonneville Labs
Bonneville Labs is creating a global life science ‘hard tech’ community empowered to go forward, faster. This coworking lab and office community provides comprehensive and supported environments enabling life science companies to focus on discovery and outdistance the conventional. Bonneville Labs is an adaptable, shared workspace that eliminates operational barriers and reduces the cost of development through shared services and pre-negotiated discounts. Backed by years of industry experience, it manages laboratories and services so members can focus on their science.
About Lab Launch
Lab Launch Inc is a 501(c)(3) non-profit working to establish a more dynamic biotech startup environment in Los Angeles. Our mission is to enable LA’s scientists and entrepreneurs to develop their ideas in affordable, high-quality lab facilities, with access to services and a supportive innovation community to accelerate their success.
View source version on businesswire.com: https://www.businesswire.com/news/home/20190730005268/en/

Story 40
EHT Collaboration
A black hole is invisible by nature. One of the strangest predictions to come out of Albert Einstein's theory of general relativity, a black hole emits no radiation we can detect, and it swallows up everything that falls on it, matter and light alike.
So it might seem paradoxical to talk about capturing an image of a black hole, but this is precisely the mission of the Event Horizon Telescope (EHT). Today, April 10, 2019, will go down in history as the day EHT scientists released the very first direct image of a black hole.
Advertisement
It's not one in our own Galactic centre, but is at the centre of the galaxy M87 – a resident of the neighbouring Virgo galaxy cluster, which is the home of several trillion stars. The feat marks the first time in history that astronomers have seen the shape of an event horizon. It's an unprecedented map of gravity at its strongest, involving hundreds of astronomers, engineers, and data scientists from around the world.
"This is truly something no one has ever seen before and we actually didn't ever imagine it would be possible," says Priyamvada Natarajan, an astronomer at Yale University. She is not part of the EHT collaboration, but studies how supermassive black holes are born and evolve. "It's something that moved from the realm of the imagination to the real."
Read next The strange science of the US Air Force's top-secret space plane The strange science of the US Air Force's top-secret space plane
Astronomers believe that nearly every large galaxy, including our Milky Way, contains a supermassive black hole at its centre. The M87 black hole weighs in at 6.5 billion times the mass of the Sun, making it one of the larger supermassive black holes known. The EHT image shows the glowing plasma — matter where electrons have been stripped from their atoms by the intense friction — surrounding the black hole, with the "shadow" at the centre revealing the shape and size of the event horizon itself.
In a very real sense, the gravitational influence of a black hole is the way we can see it, and that's precisely what the EHT image reveals. The asymmetrical shape of the matter shows both the way plasma swirls around the event horizon, and also how the gravitational distortion of spacetime affects the path of the light emitted by the material. The M87 event horizon shape is precisely in agreement with the predictions of general relativity, including an estimate of how rapidly the black hole is rotating.
Advertisement
The theory of black holes, including the nature of real astronomical black holes, was developed by a large number of researchers over the past century. In 2000, astronomer Dimitrios Psaltis of the University of Arizona and his team calculated how to see the event horizon of a black hole. Today, he's one of the leaders of the theoretical side of the EHT - and says that the image is an amazing proof that Einstein was right.
The implications of this image go beyond testing general relativity, though. "A black hole collects matter and grows by eating that matter up," says Becky Smethurst, an astronomer at Oxford University. Sometimes the pressures get so great around the black hole that it can throw out material in a wind before it gets to the event horizon – and the energy that it expels affects the galaxy as a whole. In other words, what happens at the event horizon can influence what atoms get distributed throughout an entire galaxy. That includes the types of atoms responsible for life as we know it on Earth, meaning black holes may even have a role in our own existence.
"Even though I'm interested in what happens on the big scale, it all comes down to what's happening at the very small scale," Smethurst says.
Read next This company wants to 3D print rockets on the surface of Mars This company wants to 3D print rockets on the surface of Mars
Imaging that small scale presents many challenges. Despite its huge mass, M87's black hole could fit inside the Solar System; since the galaxy is 53.5 million light-years away, astronomers need a very large number of telescopes to observe it, detecting radiation with wavelength of 1.3 mm. And they need a lot of computer storage which thankfully has become cheap enough to allow EHT data scientists to purchase petabyte-size disks for the huge amounts of data from each telescope.
Advertisement
The initial phase of EHT in 2017 consisted of eight observatories acting in concert, forming a worldwide array of telescopes with enough power for the first time in history to see light emitted right from the edge of a black hole. These telescopes are located in the US (both the mainland and Hawaii), Europe, Chile, and Antarctica.
The EHT has also been observing Sagittarius A*, the supermassive black hole at the centre of the Milky Way. However, our galaxy is much 'messier' than M87 - meaning there is much more gas and dust that obscure the picture. The collaboration is still processing how to mitigate the effects of the matter lying between the Solar System and the Galactic centre. To help with that process, four more observatories are now joining the EHT.
"When Apollo [8] turned and took a picture of the Earth, we had this wonderful moment of seeing a picture that had not been seen before," Psaltis says, adding that the first image of a black hole might carry a similar emotional weight. "It's something that inspires and excites us."
Natarajan agrees. "Black holes have this incredible gravitational pull for us. It's amazing that one happens to be alive at a time right when we're learning so much about black holes."
Read next The wild science behind Starship, Elon Musk’s planet-hopping rocket The wild science behind Starship, Elon Musk’s planet-hopping rocket
More great stories from WIRED
– The Play Store is packed with nasty, violent games for kids
– Why does the London Tube still not have Wi-Fi in tunnels?
– Netflix's Love, Death & Robots is just tedious sexist sci-fi
Advertisement
– The grim reality of life under London's Gangs Matrix
– Care about online privacy? Then change your phone number

Story 41
Privacy : We take our visitors' privacy seriously and will not share your information with any third parties without your permission. For details, please refer to our privacy policy

Story 42
In 2013, Facebook opened its first data centre outside the US in the Swedish town of Luleaa, which lies just 150 kilometres from the Arctic Circle Susanne Lindholm/AFP/Getty Images
Apple has solar panels in Chinese yak fields. And Google and Apple both claim to be 100 per cent carbon neutral. Last year, Microsoft sunk a data centre into the ocean, and last month, announced it was ahead of schedule to hit its target of 60 per cent renewable energy in its data centres and would get there by 2020, while settling on a new milestone of 70 per cent by 2023.
That’s great. But there’s a but. Microsoft also doubled its in-house carbon tax to $15/ton, signalling it would boost that to $40/ton with its membership of the Climate Leadership Council — a controversial group that wants to give legal immunity to fossil fuel companies.
Advertisement
That last point highlights how environmentally-friendly stories make for positive headlines, but risk obscuring the real achievements and challenges on building sustainable data centres. And failing to get it right could have real consequences.
Analysts estimate that some 50 billion devices will be connected by next year — and to support all this tech, more and more data centres are being built around the world, rapidly becoming the biggest energy consumers on the planet.
Read next The climate crisis issue that no one is talking about? Your gas boiler The climate crisis issue that no one is talking about? Your gas boiler
Research suggests about two to four per cent of carbon emissions are from computing, be it the internet or cloud computing or corporate data centres. The environmental impact could rise as technologies such as 5G, the internet of things and driverless cars mean more data is collected, analysed and stored. John Andresen, associate professor at Heriot Watt University, suggests that figure could rise above ten per cent in the next five years — though others predict it could be more.
Despite that, you could be forgiven for thinking the problem was solved, or heading that way. Microsoft's company-wide aim is to cut its carbon footprint by 75 per cent by 2030, driven by doubling its in-house carbon tax. That carbon tax was started back in 2012 and is now in line with California's carbon pricing — it's also the reason Microsoft joined the CLC, as that organisation argues carbon taxes are the best way to cut emissions, though it also wants to avoid companies being held legally responsible for climate change. "This is all on the path to 100 per cent renewable energy," says Lucas Joppa, Microsoft's chief environmental officer.
Advertisement
Last year, Amazon and Google both claimed to have already reached that goal, flipping entirely to renewable energy sources for their global operations, which includes data centres. But exactly what they mean by renewable energy is complicated. The energy comes from two sources: directly purchased and from the grid.
The former involves long-term contracts that let companies buy truly renewable energy directly.
A decade ago, Google bought all the electrical output from a wind farm in Iowa. Microsoft did the same last year, signing a purchase agreement with a wind farm in Ohio. Such projects spur investment in renewables, letting energy companies build wind farms knowing they have a long-term customer. "Such agreements give the supplier confidence of a market for energy over a period of time, and so make it easier for them to invest in new renewable energy projects," says Chris Preist, professor of sustainability and computer systems at the University of Bristol. "So, in regions where the political will is there, it will certainly result in the deployment of more renewable energy over time." Or, as Joppa puts it, such contracts "help green the grid".
Read next An old coal power station is being turned into a clean energy provider An old coal power station is being turned into a clean energy provider
However, some percentage of Google, Apple and Microsoft's energy mix still comes from the grid. "After efficiencies, after direct purchasing of renewables, what's left we cover with renewable energy credits in the open market," Joppa says. Those renewable energy credits (RECs) are certificates that show an energy company generated renewable power and supplied it to the grid. To make the claim that they're carbon neutral, companies such as Microsoft or Google may buy the certificates when they have to draw energy from the national grid, as you can't trace the provenance of an electron bouncing around the grid. It's akin to any of us buying from a green energy supplier, but still drawing power from the same grid as everyone else; we feel like do-gooders, but it's purely metaphorical — the same amount of coal is being burned.
Advertisement
Lars Schedin is the CEO of EcoDataCentre, and finds such green consumption certificates frustrating. "That doesn't minimise any carbon dioxide emissions," he says. "It only means that I, as a private person, get the [non-renewable] mix in my home. You haven't done any good at all. It's just fooling society that they are improving the situation when they are not."
Microsoft said most of its 60 per cent renewable-sourced energy was from direct purchase, rather than credits, but would not confirm the ratio. Google and Apple both acknowledged the use of RECs or equivalents in their sustainability reports. Apple noted in its report that as of January last year, 66 per cent of its renewable energy comes from projects it created — either those it owns, such as the solar panels on its headquarters, or long-term purchase projects — with the remaining third coming from local renewable energy projects. If that's not enough, then it turns to RECs, though it does require them to be in the same state as the data centre it supports.
Apple breaks down the energy mix of its US data centres in its sustainability report, and that shows where real progress is being made. Its Newark, California data centre pulls from the grid, but via that state's Direct Access system Apple can buy directly from suppliers. There, it claims its energy is "mostly wind", and takes that to mean there were no emissions. On the other hand, its Reno, Nevada data centre is 99 per cent powered by Apple's own solar panels, with less than one per cent from purchase agreements — there's no question where the power is coming from.
Google, meanwhile, buys or generates more carbon-free energy than it uses at any given moment in its data centres, to make up for times when it needs to turn to the grid for more power. In one example, a data centre in North Carolina was 55 per cent carbon-free in April, 82 per cent carbon-free in September, and 49 per cent carbon-free in December, largely owing to a seasonal decline in solar-power generation — it's darker in winter, after all.
Read next Tesla has created a battery that could last one million miles Tesla has created a battery that could last one million miles
Those gaps were made up with excesses of Google-contracted solar power; there's more than it needs in sunnier hours of the day, so that power is pumped onto the grid. That means Google's data centre is still run on some carbon-based energy from the grid during darker hours, but it tries to displace that with cleaner energy for others during the day. Google's aim is to be entirely carbon free, but at the time of the report in 2017, in regions where purchasing agreements were signed, the reality was closer to 65 per cent, with none of its data centres fully matched at all times with totally carbon-free sources.
In short, when a tech company says its data centre and other operations rely entirely on renewable energy, it's actually a complicated mix of clean energy generated from their own buildings, renewable power projects they've signed long contracts with, and credits or excess power to fill the gaps. Whether that latter category counts as truly renewable or not will impact whether you think those 100 per cent claims hold water.
Of course, there are other ways to cut carbon emissions in data centres beyond buying cleaner energy, in particular around efficiency. "Reduce and renewable should be our mantra," says Preist. Schedin points to three considerations: efficiencies, reusing heat, and, as above, the source of energy.
The tech industry is getting better with efficiency. As Joppa explains, the cleanest energy is the energy you don't use — handily, it's also the cheapest, hence the investment into everything from reprogrammable chips to data centres powered locally by fuel cells. Andresen says more than half of the energy chewed through by a data centre is for cooling. "All the electricity going into the boards is converted to heat," he says. "For every unit of energy you put for data, you need 1.2 units for cooling — that's normally by fans."
This is why Microsoft sunk a data centre off the coast of Orkney in Scotland — it's sealed in a shipping container, so don't fret about the servers drowning. "Because the sea is only four degrees, it's kind of self-cooling," says Andresen. This is why cold climates (such as Iceland or Sweden) are so popular for data centre companies. If your servers are too hot, just pump in some cold air from outside.
Read next Don’t write lithium off yet – more efficient batteries are on the way Don’t write lithium off yet – more efficient batteries are on the way
But that causes another problem. "All the heat they are generating, they're just throwing it out the window," Schedin says. "You can actually see changes in the microclimate around big data centres. If you're looking to have palm trees in the northern part of Sweden, then that's good, but if you want to maintain the current climate in northern Sweden, then you should force data centres to reuse the heat somehow."
Heat generated by data centres at Schedin's company heat local buildings in the winter, while in the summer the excess warmth is put to making wood pellets, which he describes as a combination of wood shavings, pressure and heat. "Pellets are nothing but 100 per cent energy," he says. "Once you produce them they're easy to store. In the wintertime, when it's really getting cold, you burn those pellets instead of using oil or gas." That further helps reduce carbon emissions in the wider community, but excess heat could be used to warm or power any local building, with Schedin suggesting colocating anything from a greenhouse to a brewery next to data centres.
That's similar to Andresen's own project, which uses non-conductive liquids to cool the servers. "There's nothing new in that, but we can use that fluid for something useful," he says, explaining that it can hold heat up to 60 degrees Celsius. "It's enough to heat up water for homes." The project is based in Malaysia, which needs cooling more than heat, but there the hot liquid is used to power a heat pump to generate power. Using that excess heat saves emissions created elsewhere — it's a real carbon credit — but such systems are rare, says Schedin.
Aside from improving efficiency and reusing heat produced by a data centre, the third consideration Schedin says is the source of power, as above. But even with solid progress in long-term purchase contracts and generating their own clean power, there's still an environmental debt that needs to be counted. Building a wind farm or solar panels requires power and leads to carbon emissions, after all. Schedin calculates that into his firm's energy efficiency score, but most others don't. "They say that now they're using wind power, it's carbon neutral from the very beginning — no, it's not, sorry guys," he says. "It has an environmental debt from the very beginning – they forget about this part of the calculation because it's not their debt, it's the construction company who has the debt."
None of this belittles the progress made by the tech industry switching its data centres to renewable sources and cutting power use through technological and cooling efficiency — that should all be applauded, Microsoft included. "The work they do is genuinely useful, making them one of the leaders in the corporate world," says Preist. "But we all need to up our game." Despite the headlines suggesting 100 per cent renewable sources and the innovations such as sunken servers, there remains an alarming amount of work still to be done.
More great stories from WIRED
– The WIRED guide to the best sci-fi movies ever made
– Why Tim Cook is a better Apple CEO than Steve Jobs
Advertisement
– The UK's MPs are on the verge of mental breakdown
– WIRED Recommends the best backpacks

Story 43
Why did this happen?
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.

Story 44
SAN DIEGO, May 8, 2019 /PRNewswire/ -- Arena Pharmaceuticals, Inc. (Nasdaq: ARNA) today provided a corporate update and reported financial results for the first quarter ended March 31, 2019.
"We are continuing to make significant progress on advancing our internally developed potential first- or best-in-class compounds," said Amit D. Munshi, President and CEO of Arena. "Today, we are excited to share additional detail around the ELEVATE UC program for etrasimod in ulcerative colitis that we plan to initiate mid-year. With the exciting data shown to date, demonstrating etrasimod's sustained, long-term efficacy and safety, we hope to address the significant unmet need that still remains in inflammatory bowel disease, where 60-80% of patients are either not receiving or failing a biologic."
Pipeline Update
Etrasimod – Next generation, once-daily, oral, selective sphingosine-1-phosphate (S1P) receptor modulator in development for the treatment of multiple immune and inflammatory diseases
Ulcerative colitis (UC): The etrasimod global Phase 3 ELEVATE UC registrational program aims to include over 40 countries and will consist of two key trials to evaluate etrasimod 2 mg in subjects with moderately to severely active ulcerative colitis. Firstly, ELEVATE UC 52, a treat-through trial with a 12-week induction period followed by 40 weeks of maintenance in approximately 370 subjects, is expected to initiate mid-year. Secondly, ELEVATE UC 12, a 12-week induction period trial in approximately 330 subjects, is expected to initiate at a later date to optimize time to market. We plan to conduct additional studies to provide evidence of differentiation for health care providers and payers.
Crohn's disease (CD):
Phase 2b -3 planning ongoing
-3 planning ongoing Atopic dermatitis (AD):
Phase 2 planning ongoing
Olorinab – Oral, peripherally active, highly selective, full agonist of cannabinoid receptor type 2 (CB 2 ) in development for the treatment of visceral pain associated with gastrointestinal (GI) diseases
Irritable bowel syndrome (IBS) pain
Phase 2b planning ongoing
APD418 – First-in-class, calcium-independent myofilament derepressor (CMD) in preclinical development for the treatment of decompensated heart failure (DHF)
Preclinical program advancing
Etrasimod, olorinab and APD418 are investigational compounds that are not approved for any use in any country.
Financial Update
First Quarter 2019 Financial Results
Revenues totaled $801.1 million , consisting of $800.0 million of revenue from the United Therapeutics upfront payment ( $785.4 million net of costs associated with the transaction) and $1.0 million of royalty revenue.
, consisting of of revenue from the United Therapeutics upfront payment ( net of costs associated with the transaction) and million of royalty revenue. Research and development expenses totaled $45.4 million , including $3.2 million related to ralinepag development program incurred prior to the transition to United Therapeutics and $6.7 million related to non-cash share-based compensation
, including related to ralinepag development program incurred prior to the transition to United Therapeutics and related to non-cash share-based compensation General and administrative expenses totaled $16.6 million , including $6.3 million related to non-cash share-based compensation
, including related to non-cash share-based compensation The Company recorded a tax provision of $110.3 million as a result of utilizing the deferred tax assets that were recorded in the fourth quarter of 2018
as a result of utilizing the deferred tax assets that were recorded in the fourth quarter of 2018 Net income attributable to stockholders of Arena was $620.1 million , the basic earnings per share was $12.53 per share and the diluted earnings per share was $12.10
At March 31, 2019, Arena's cash, cash equivalents and investments balance was approximately $1.3 billion and approximately 49.5 million shares of Arena common stock were outstanding.
Conference Call & Webcast Information
Arena will host a conference call and live webcast with the investment community today, Wednesday, May 8, 2019, at 4:30 PM EDT to discuss the financial results and provide a corporate update.
When: Wednesday, May 8, 2019, at 4:30 PM EDT
Dial-in: (877) 643-7155 (United States) or (914) 495-8552 (International)
Conference ID: 5285824
Please join the conference call at least 10 minutes early to register. You can access the live webcast under the investor relations section of Arena's website at: www.arenapharm.com. A replay of the conference call will be archived under the investor relations section of Arena's website for 30 days shortly after the call.
About Arena Pharmaceuticals
Arena Pharmaceuticals is driven to deliver novel, transformational medicines with optimized pharmacology and pharmacokinetics to patients globally. Arena's proprietary pipeline includes multiple potentially first- or best-in-class assets with broad clinical utility. Etrasimod (APD334), with potential utility in a broad range of immune and inflammatory conditions, is being evaluated in late-stage clinical programs in ulcerative colitis (UC) and Crohn's disease, as well as in programs for other indications such as atopic dermatitis. Arena is also evaluating olorinab (APD371) in a Phase 2 program for gastrointestinal pain. Arena continues to assess other earlier research and development stage drug candidates, including APD418 for decompensated heart failure.
Arena has additional license agreements and partnerships, including with United Therapeutics (ralinepag in a Phase 3 program for pulmonary arterial hypertension), Everest Medicines Limited (etrasimod in Greater China and select Asian countries), Boehringer Ingelheim International GmbH (undisclosed target – preclinical), Outpost Medicine, LLC (undisclosed target – preclinical), and Eisai Co., Ltd. and Eisai Inc. (BELVIQ® – marketed product).
Forward-Looking Statements
Certain statements in this press release are forward-looking statements that involve a number of risks and uncertainties. Such forward-looking statements may be identified by words such as "expected," "potential," "plan," "in development for," "targeting," "will," "driven to," "evaluated" or "evaluating," and include, without limitation, statements about the following: design, initiation, enrollment, data and results, and timing relating to ongoing and intended trials; the potential of Arena's drug candidates, including to be first- or best-in-class or transformative, have optimized pharmacology and pharmacokinetics, have broad clinical utility, and be delivered to patients globally; Arena's position and ability to execute on its programs; Arena's drive; and the potential of Arena's assets, programs, licenses, and collaborations. For such statements, Arena claims the protection of the Private Securities Litigation Reform Act of 1995. Actual events or results may differ materially from Arena's expectations. Factors that could cause actual results to differ materially from the forward-looking statements include, but are not limited to, the following: clinical trials and other studies may not proceed at the time or in the manner expected or at all; the timing and outcome of research, development and regulatory review is uncertain, and Arena's drug candidates may not advance in development or be approved for marketing; enrolling patients in Arena's ongoing and intended clinical trials is competitive and challenging; risks related to developing and commercializing drugs; Arena may need additional funds to advance all of its programs, and you and others may not agree with the manner Arena allocates its resources; risks and uncertainties relating to cash and revenues that may be generated from product sales or other sources, including the impact of competition; Arena's revenues are based in part on estimates, judgment and accounting policies, and incorrect estimates or disagreement regarding estimates or accounting policies may result in changes to Arena's guidance or previously reported results; risks related to unexpected or unfavorable new data; nonclinical and clinical data is voluminous and detailed, and regulatory agencies may interpret or weigh the importance of data differently and reach different conclusions than Arena or others, request additional information, have additional recommendations or change their guidance or requirements before or after approval; results of clinical trials and other studies are subject to different interpretations and may not be predictive of future results; topline data may not accurately reflect the complete results of a particular study or trial; satisfactory resolution of litigation or other disagreements with others; government and third-party payor actions, including relating to reimbursement and pricing; risks related to relying on licenses or collaborative arrangements, including lack of control and potential disputes; the entry into or modification or termination of licenses or collaborative arrangements; and Arena's and third parties' intellectual property rights. Additional factors that could cause actual results to differ materially from those stated or implied by Arena's forward-looking statements are disclosed in Arena's filings with the Securities and Exchange Commission (SEC), including but not limited to Arena's Annual Report on Form 10-K for the year ended December 31, 2018, which was filed with the SEC on February 28, 2019. These forward-looking statements represent Arena's judgment as of the time of this release. Arena disclaims any intent or obligation to update these forward-looking statements, other than as may be required under applicable law.
Corporate Contact:
Kevin R. Lind
Arena Pharmaceuticals, Inc.
Executive Vice President and
Chief Financial Officer
klind@arenapharm.com
858.210.3636
Media Contact:
Matt Middleman, MD
LifeSci Public Relations
matt.middleman@lifescipublicrelations.com
646.627.8384
(Tables Follow)
Arena Pharmaceuticals, Inc. Condensed Consolidated Statements of Operations (In thousands, except per share amounts)

Three months ended
March 31,
2019
2018
(unaudited)
(unaudited) Revenues


United Therapeutics revenue $ 800,000
$ — Royalty revenue 973
727 Collaboration and other revenue 84
1,028 Total revenues 801,057
1,755



Operating Costs & Expenses


Research & development 45,396
21,573 General & administrative 16,578
11,151 Transaction costs 14,573
— Total operating costs & expenses 76,547
32,724 Income (loss) from operations 724,510
(30,969)



Total interest & other income (expense), net 5,957
(164) Income (loss) from continuing operations before income taxes 730,467
(31,133) Income tax provision (110,333)
— Income (loss) from continuing operations 620,134
(31,133) Loss from discontinued operations —
(830) Net income (loss) 620,134
(31,963)



Net income (loss) per share, basic:


Continuing operations $ 12.53
$ (0.78) Discontinued operations —
(0.02)
$ 12.53
$ (0.80)



Net income (loss) per share, diluted:


Continuing operations $ 12.10
$ (0.78) Discontinued operations —
(0.02)
$ 12.10
$ (0.80)



Shares used in calculating net income (loss) per share, basic 49,478
39,996 Shares used in calculating net income (loss) per share, diluted 51,255
39,996
Arena Pharmaceuticals, Inc. Condensed Consolidated Balance Sheet Data (In thousands)









March 31, 2019
December 31, 2018
(unaudited)
(unaudited)1 Assets


Cash & cash equivalents $ 727,404
$ 161,037 Accounts receivable 3,083
5,086 Deferred tax assets —
110,333 Prepaid expenses & other current assets 18,520
10,008 Total available-for-sale investments 542,265
367,006 Land, property & equipment, net 23,445
23,114 Other non-current assets 15,336
10,319 Total assets $ 1,330,053
$ 686,903



Liabilities & Stockholders' Equity


Accounts payable & accrued liabilities $ 28,299
$ 26,635 Total lease financing obligations & other long-term liabilities 58,317
54,010 Total stockholders' equity 1,243,437
606,258 Total liabilities & stockholders' equity $ 1,330,053
$ 686,903

1 The Condensed Consolidated Balance Sheet Data has been derived from the audited financial statements as of that date.
SOURCE Arena Pharmaceuticals, Inc.
Related Links
http://www.arenapharm.com


Story 45
Virginia has completed the ultimate redemption arc, winning its first NCAA championship, 85-77 in overtime, against Texas Tech on Monday in Minneapolis.
Just one year ago, the Cavaliers became the first No. 1 seed to lose to a No. 16 seed. Now the Cavaliers are NCAA champions.
De'Andre Hunter scored 27 and Kyle Guy added 24 for Virginia in the first national title game to go to overtime since Kansas beat Memphis in 2008. Virginia, which went 12-for-12 on free throws in overtime, is also the first first-time champion since Florida in 2006. Both Virginia and Texas Tech were playing in the NCAA final for the first time. Brandone Francis led the Red Raiders with 17 points.
Virginia-Texas Tech: Score, updates
2019 NCAA tournament bracket
Click or tap here for a printable bracket.
2019 NCAA tournament: Schedule, scores
2019 NCAA tournament: Teams
Here is the complete list of teams in the tournament. They are listed in alphabetical order:
Abilene Christian
Arizona State
Auburn
Baylor
Belmont
Bradley
Buffalo
Cincinnati
Colgate
Duke
Fairleigh Dickinson
Florida
Florida State
Gardner-Webb
Georgia State
Gonzaga
Houston
Iona
Iowa
Iowa State
Kansas
Kansas State
Kentucky
Liberty
Louisville
LSU
Marquette
Maryland
Michigan
Michigan State
Minnesota
Mississippi State
Montana
Murray State
Nevada
New Mexico State
North Carolina
North Carolina Central
North Dakota State
Northeastern
Northern Kentucky
Ohio State
Oklahoma
Old Dominion
Ole Miss
Oregon
Prairie View A&M
Purdue
Saint Louis
Seton Hall
St. John’s
St. Mary’s
Syracuse
Temple
Tennessee
Texas Tech
UC Irvine
UCF
Utah State
VCU
Vermont
Villanova
Virginia
Virginia Tech
Washington
Wisconsin
Wofford
Yale
Who won the first March Madness?
The inaugural tournament had just eight teams, and saw Oregon beat Ohio State 46-33 for the title in 1939:.
Who has won every NCAA tournament?
In the 80 years since the tournament’s inception, 35 different teams have won a championship, but no team has won more than UCLA, which has 11, 10 of which came a span of 12 years from 1964 to 1975.
Here is the list of every men’s basketball national championship since the NCAA tournament first started in 1939:
YEAR CHAMPION (RECORD) COACH SCORE RUNNER-UP SITE 2019 Virginia (35-3) Tony Bennett 85-77 (OT) Texas Tech Minneapolis, Minn. 2018 Villanova (36-4) Jay Wright 79-62 Michigan San Antonio, Tex. 2017 North Carolina (33-7) Roy Williams 71-65 Gonzaga Phoenix, Ariz. 2016 Villanova (35-5) Jay Wright 77-74 North Carolina Houston, Texas 2015 Duke (35-4) Mike Krzyzewski 68-63 Wisconsin Indianapolis, Ind. 2014 Connecticut (32-8) Kevin Ollie 60-54 Kentucky Arlington, Texas 2013 Louisville (35-5)* Rick Pitino 82-76 Michigan Atlanta, Ga. 2012 Kentucky (38-2) John Calipari 67-59 Kansas New Orleans, La. 2011 Connecticut (32-9) Jim Calhoun 53-41 Butler Houston, Texas 2010 Duke (35-5) Mike Krzyzewski 61-59 Butler Indianapolis, Ind. 2009 North Carolina (34-4) Roy Williams 89-72 Michigan State Detroit, Mich. 2008 Kansas (37-3) Bill Self 75-68 (OT) Memphis San Antonio, Texas 2007 Florida (35-5) Billy Donovan 84-75 Ohio State Atlanta, Ga. 2006 Florida (33-6) Billy Donovan 73-57 UCLA Indianapolis, Ind. 2005 North Carolina (33-4) Roy Williams 75-70 Illinois St. Louis, Mo. 2004 Connecticut (33-6) Jim Calhoun 82-73 Georgia Tech San Antonio, Texas 2003 Syracuse (30-5) Jim Boeheim 81-78 Kansas New Orleans, La. 2002 Maryland (32-4) Gary Williams 64-52 Indiana Atlanta, Ga. 2001 Duke (35-4) Mike Krzyzewski 82-72 Arizona Minneapolis, Minn. 2000 Michigan State (32-7) Tom Izzo 89-76 Florida Indianapolis, Ind. 1999 Connecticut (34-2) Jim Calhoun 77-74 Duke St. Petersburg, Fla. 1998 Kentucky (35-4) Tubby Smith 78-69 Utah San Antonio, Texas 1997 Arizona (25-9) Lute Olson 84-79 (OT) Kentucky Indianapolis, Ind. 1996 Kentucky (34-2) Rick Pitino 76-67 Syracuse East Rutherford, N.J. 1995 UCLA (31-2) Jim Harrick 89-78 Arkansas Seattle, Wash. 1994 Arkansas (31-3) Nolan Richardson 76-72 Duke Charlotte, N.C. 1993 North Carolina (34-4) Dean Smith 77-71 Michigan New Orleans, La. 1992 Duke (34-2) Mike Krzyzewski 71-51 Michigan Minneapolis, Minn. 1991 Duke (32-7) Mike Krzyzewski 72-65 Kansas Indianapolis, Ind. 1990 UNLV (35-5) Jerry Tarkanian 103-73 Duke Denver, Colo. 1989 Michigan (30-7) Steve Fisher 80-79 (OT) Seton Hall Seattle, Wash. 1988 Kansas (27-11) Larry Brown 83-79 Oklahoma Kansas City, Mo. 1987 Indiana (30-4) Bob Knight 74-73 Syracuse New Orleans, La. 1986 Louisville (32-7) Denny Crum 72-69 Duke Dallas, Texas 1985 Villanova (25-10) Rollie Massimino 66-64 Georgetown Lexington, Ky, 1984 Georgetown (34-3) John Thompson 84-75 Houston Seattle, Wash. 1983 North Carolina State (26-10) Jim Valvano 54-52 Houston Albuquerque, N.M. 1982 North Carolina (32-2) Dean Smith 63-62 Georgetown New Orleans, La. 1981 Indiana (26-9) Bob Knight 63-50 North Carolina Philadelphia, Pa. 1980 Louisville (33-3) Denny Crum 59-54 UCLA Indianapolis, Ind. 1979 Michigan State (26-6) Jud Heathcote 75-64 Indiana State Salt Lake City, Utah 1978 Kentucky (30-2) Joe Hall 94-88 Duke St. Louis, Mo. 1977 Marquette (25-7) Al McGuire 67-59 North Carolina Atlanta, Ga. 1976 Indiana (32-0) Bob Knight 86-68 Michigan Philadelphia, Pa. 1975 UCLA (28-3) John Wooden 92-85 Kentucky San Diego, Calif. 1974 North Carolina State (30-1) Norm Sloan 76-64 Marquette Greensboro, N.C. 1973 UCLA (30-0) John Wooden 87-66 Memphis State St. Louis, Mo. 1972 UCLA (30-0) John Wooden 81-76 Florida State Los Angeles, Calif. 1971 UCLA (29-1) John Wooden 68-62 Villanova Houston, Texas 1970 UCLA (28-2) John Wooden 80-69 Jacksonville College Park, Md. 1969 UCLA (29-1) John Wooden 92-72 Purdue Louisville, Ky. 1968 UCLA (29-1) John Wooden 78-55 North Carolina Los Angeles, Calif. 1967 UCLA (30-0) John Wooden 79-64 Dayton Louisville, Ky. 1966 UTEP (28-1) Don Haskins 72-65 Kentucky College Park, Md. 1965 UCLA (28-2) John Wooden 91-80 Michigan Portland, Ore. 1964 UCLA (30-0) John Wooden 98-83 Duke Kansas City, Mo. 1963 Loyola (Ill.) (29-2) George Ireland 60-58 (OT) Cincinnati Louisville, Ky. 1962 Cincinnati (29-2) Ed Jucker 71-59 Ohio State Louisville, Ky. 1961 Cincinnati (27-3) Ed Jucker 70-65 (OT) Ohio State Kansas City, Mo. 1960 Ohio State (25-3) Fred Taylor 75-55 California Daly City, Calif. 1959 California (25-4) Pete Newell 71-70 West Virginia Louisville, Ky. 1958 Kentucky (23-6) Adolph Rupp 84-72 Seattle Louisville, Ky. 1957 North Carolina (32-0) Frank McGuire 54-53 (3OT) Kansas Kansas City, Mo. 1956 San Francisco (29-0) Phil Woolpert 83-71 Iowa Evanston, Ill. 1955 San Francisco (28-1) Phil Woolpert 77-63 LaSalle Kansas City, Mo. 1954 La Salle (26-4) Ken Loeffler 92-76 Bradley Kansas City, Mo. 1953 Indiana (23-3) Branch McCracken 69-68 Kansas Kansas City, Mo. 1952 Kansas (28-3) Phog Allen 80-63 St. John's Seattle, Wash. 1951 Kentucky (32-2) Adolph Rupp 68-58 Kansas State Minneapolis, Minn. 1950 CCNY (24-5) Nat Holman 71-68 Bradley New York, N.Y. 1949 Kentucky (32-2) Adolph Rupp 46-36 Oklahoma A&M Seattle, Wash. 1948 Kentucky (36-3) Adolph Rupp 58-42 Baylor New York, N.Y. 1947 Holy Cross (27-3) Doggie Julian 58-47 Oklahoma New York, N.Y. 1946 Oklahoma State (31-2) Henry Iba 43-40 North Carolina New York, N.Y. 1945 Oklahoma State (27-4) Henry Iba 49-45 NYU New York, N.Y. 1944 Utah (21-4) Vadal Peterson 42-40 (OT) Dartmouth New York, N.Y. 1943 Wyoming (31-2) Everett Shelton 46-34 Georgetown New York, N.Y. 1942 Stanford (28-4) Everett Dean 53-38 Dartmouth Kansas City, Mo. 1941 Wisconsin (20-3) Bud Foster 39-34 Washington State Kansas City, Mo. 1940 Indiana (20-3) Branch McCracken 60-42 Kansas Kansas City, Mo. 1939 Oregon (29-5) Howard Hobson 46-33 Ohio State Evanston, Ill.
*Louisville’s participation in the 2013 tournament was later vacated by the Committee on Infractions.
What were the most memorable championship games in March Madness history?
Some recent classics include the 1989 title game, when No. 3 Michigan defeated No. 3 Seton Hall, 70-69 in overtime and the 2016 national title game when Villanova beat North Carolina, 77-74, on a shot at the buzzer by Kris Jenkins.
You can read more about classic NCAA games here and watch them all on NCAA on Demand on YouTube.
How are March Madness teams selected?
There are two ways that a team can earn a bid to the NCAA tournament. The 32 Division I conferences all receive an automatic bid, which they each award to the team that wins the postseason conference tournament. Regardless of how a team performed during the regular season, if they are eligible for postseason play and win their conference tournament, they receive a bid to the NCAA tournament. These teams are known as automatic qualifiers.
The second avenue for an invitation is an at-large bid. The selection committee (more on them in a second) convenes on Selection Sunday, after all regular season and conference tournament games are played, and decides which 36 teams that are not automatic qualifiers have the pedigree to earn an invitation to the tournament.
Who is on the March Madness Selection Committee?
School and conference administrators are nominated by their conference. Those who are selected serve five-year terms and represent a cross-section of the Division I membership.
Currently, the chair of the committee is Bernard Muir, the director of athletics at Stanford.
Here are the rest of the committee members:
Mitch Barnhart, director of athletics, University of Kentucky
Tom Burnett, commissioner, Southland Conference
Janet Cone, director of athletics, University of North Carolina Asheville
Bernadette McGlade, commissioner, Atlantic 10 Conference
Michael O’Brien, vice president and director of athletics, University of Toledo
Jim Phillips, vice president for athletics and recreation, Northwestern University
Chris Reynolds, vice president for intercollegiate athletics, Bradley University
Craig Thompson, commissioner, Mountain West Conference
Kevin White, director of athletics, Duke University
What is the importance of seeding?
The NCAA men’s basketball tournament is made up of 68 teams. On Selection Sunday, before any tournament game is played, those teams are ranked 1 through 68 by the Selection Committee, with the best team in college basketball — based on regular season and conference tournament performance — sitting at No. 1. Four of those teams are eliminated in the opening round of the tournament (known as the First Four), leaving us with a field of 64 for the first round.
Those 64 teams are split into four regions of 16 teams each, with each team being ranked 1 through 16. That ranking is the team’s seed.
In order to reward better teams, first-round matchups are determined by pitting the top team in the region against the bottom team (No. 1 vs. No. 16). Then the next highest vs. the next lowest (No. 2 vs. No. 15), and so on. In theory, this means that the 1 seeds have the easiest opening matchup in the bracket.

Story 46
SAN DIEGO, June 17, 2019 /PRNewswire/ -- Arena Pharmaceuticals, Inc. (Nasdaq: ARNA) today announced that the first subject has been dosed in ELEVATE UC 52, the first of two pivotal trials within the Phase 3 ELEVATE UC registrational program evaluating etrasimod 2 mg in subjects with moderately to severely active ulcerative colitis (UC). ELEVATE UC 52 is a treat-through trial with a 12-week induction period followed by 40 weeks of maintenance. The ELEVATE UC registrational program aims to include more than 40 countries worldwide.
"We are pleased to enroll the first patient in the ELEVATE UC trial, supporting etrasimod's potential as an important future therapy for ulcerative colitis," stated Darshan Anandu, MD, Gastroenterology, G.I. Specialists of Houston. "With 60-80% of patients either not receiving or failing on the current standard of care, there is a clear and significant need for innovative options, especially orally-delivered treatments."
"We are thrilled to announce the first patient dosed in the ELEVATE UC 52 trial. The etrasimod data seen to date are highly encouraging, and we believe represent a clear readthrough to our ELEVATE UC pivotal program, providing us confidence that it will demonstrate clinically meaningful and market-leading evidence of efficacy and safety," stated Preston Klassen, MD, MHS, Executive Vice President, Research and Development and Chief Medical Officer of Arena. "Initiating this trial is the next step towards bringing a potential game-changing therapy to UC patients globally. We are very grateful to the patients who have participated in etrasimod clinical trials thus far, and to the many additional patients who will enroll in the ELEVATE UC program. We also thank the physicians, medical professionals, and site coordinators, for their continued support."
About ELEVATE UC 52
ELEVATE UC 52 is one of two pivotal trials that are part of the ELEVATE UC global Phase 3 registrational program. ELEVATE UC 52 is a 2:1 randomized, double-blind, placebo-controlled trial to assess the efficacy and safety of etrasimod 2 mg once-daily in subjects with moderately to severely active ulcerative colitis (UC) defined as a baseline 3-domain, modified Mayo Score of 4 to 9 with an endoscopic score of 2 or more, and a rectal bleeding score of 1 or more. This is a one-year trial evaluating clinical remission at 12 weeks, or induction, and at 52 weeks. The trial consists of a 28-day screening period, a 12-week treatment period, a 40-week treatment period, and a 2-week follow-up period. The primary objective of this trial is to assess the safety and efficacy of etrasimod on clinical remission after both 12 and 52 weeks. The primary endpoint is the FDA-required, 3-domain, modified Mayo Score, which is similar to the primary endpoint in the Phase 2 OASIS study. Key secondary measures include the efficacy of etrasimod on clinical response, symptomatic response and remission, endoscopic changes, corticosteroid-free remission, and a total healing in these subjects at time points up to 52 weeks of treatment. The ELEVATE UC program will be conducted in approximately 450 sites across more than 40 countries.
About Etrasimod
Etrasimod (APD334), is a next generation, oral, selective sphingosine 1 phosphate (S1P) receptor modulator, discovered by Arena, designed to provide systemic and local cell modulation by selectively targeting S1P receptor subtypes 1, 4 and 5. Etrasimod has therapeutic potential in immune and inflammatory-mediated diseases such as ulcerative colitis, Crohn's disease, and atopic dermatitis. S1P receptors have been demonstrated to be involved in the modulation of several biological responses, including lymphocyte trafficking from lymph nodes to the peripheral blood. By isolating subpopulations of lymphocytes in lymph nodes, fewer immune cells are available in the circulating blood to effect tissue damage.
Etrasimod is an investigational compound that is not approved for any use in any country.
About Arena Pharmaceuticals
Arena Pharmaceuticals is driven to deliver novel, transformational medicines with optimized pharmacology and pharmacokinetics to patients globally. Arena's proprietary pipeline includes multiple potentially first- or best-in-class assets with broad clinical utility. Etrasimod (APD334), with potential utility in a broad range of immune and inflammatory conditions, is being evaluated in later-stage clinical programs in ulcerative colitis (UC) and Crohn's disease, as well as in programs for other indications such as atopic dermatitis. Arena is also evaluating olorinab (APD371) in a Phase 2 program for gastrointestinal pain. Arena continues to assess other earlier research and development stage drug candidates, including APD418 for decompensated heart failure.
Arena has additional license agreements and partnerships, including with United Therapeutics (ralinepag in a Phase 3 program for pulmonary arterial hypertension), Everest Medicines Limited (etrasimod in Greater China and select Asian countries), Boehringer Ingelheim International GmbH (undisclosed target – preclinical), Outpost Medicine, LLC (undisclosed target – preclinical), and Eisai Co., Ltd. and Eisai Inc. (BELVIQ® – marketed product).
Forward-Looking Statements
Certain statements in this press release are forward-looking statements that involve a number of risks and uncertainties. These forward-looking statements may be accompanied by words such as "aims to," "potential," "future," "believe," "confidence that," "will," "step towards," "objective," "designed to," "driven to," "potentially," "being evaluated for," "evaluating for," "assess for," or words of similar meaning, or they may be identified by the fact that they do not relate strictly to historical or current facts. Such forward-looking statements include, without limitation, statements about the following: the opportunity, development and potential of etrasimod, including to be an important future therapy, be game-changing, or satisfy an unmet medical need; the potential of prior etrasimod data, including to represent a clear readthrough to the ELEVATE UC pivotal program; the potential of the ELEVATE UC program, including to demonstrate clinically meaningful and market-leading evidence of etrasimod's efficacy and safety; Arena's drive; and the potential of Arena's assets, programs, licenses, and collaborations, including to be first- or best-in-class or have broad clinical utility. For such statements, Arena claims the protection of the Private Securities Litigation Reform Act of 1995. Actual events or results may differ materially from Arena's expectations. Factors that could cause actual results to differ materially from the forward-looking statements include: the timing and outcome of research, development and regulatory review is uncertain; results of clinical trials and other studies are subject to different interpretations and may not be predictive of future results; nonclinical and clinical data are voluminous and detailed, and regulatory agencies may interpret or weigh the importance of data differently and reach different conclusions than Arena or others, request additional information, have additional recommendations or change their guidance or requirements before or after approval; clinical trials and other studies may not proceed at the time or in the manner expected or at all; enrolling patients in our ongoing and intended clinical trials is competitive and challenging; we expect to need additional funds to advance all of our programs, and you and others may not agree with the manner we allocate our resources; our drug candidates may not advance in development or be approved for marketing; risks related to unexpected or unfavorable new data; risks related to developing and commercializing drugs; risks related to relying on partners and other third parties; Arena's and third parties' intellectual property rights; and satisfactory resolution of litigation or other disagreements with others. Additional factors that could cause actual results to differ materially from those stated or implied by Arena's forward-looking statements are disclosed in Arena's filings with the Securities and Exchange Commission (SEC), including but not limited to its most recent Annual Report on Form 10-K and Quarterly Report on Form 10-Q. These forward-looking statements represent Arena's judgment as of the time of this release. Arena disclaims any intent or obligation to update these forward-looking statements, other than as may be required under applicable law.
Corporate Contact:
Kevin R. Lind
Arena Pharmaceuticals, Inc.
Executive Vice President and
Chief Financial Officer
klind@arenapharm.com
858.210.3636
Media Contact:
Matt Middleman, MD
LifeSci Public Relations
matt.middleman@lifescipublicrelations.com
646.627.8384
SOURCE Arena Pharmaceuticals, Inc.
Related Links
http://www.arenapharm.com


Story 47
COLLEGE MEETING: Commission reports on the risks of investor citizenship and residence schemes in the EU and outlines steps to address them
For the first time, the Commission has presented a comprehensive report on investor citizenship and residence schemes operated by a number of EU Member States. The report maps the existing practices and identifies certain risks such schemes imply for the EU, in particular, as regards security, money laundering, tax evasion and corruption. A lack of transparency in how the schemes are operated and a lack of cooperation among Member States further exacerbate these risks, the report finds. Commissioner for Migration, Home Affairs and Citizenship Dimitris Avramopoulos said: "Legally residing in the EU and in the Schengen area comes with rights and privileges that should not be abused. Member States must at all times fully respect and apply existing obligatory checks and balances – and national investor residence schemes should not be exempt from that. The work we have done together over the past years in terms of increasing security, strengthening our borders, and closing information gaps should not be jeopardised. We will monitor full compliance with EU law." Commissioner for Justice, Consumers and Gender Equality, Věra Jourová, said: “Becoming a citizen of one Member State also means becoming an EU citizen with all its rights, including free movement and access to the internal market. People obtaining an EU nationality must have a genuine connection to the Member State concerned. We want more transparency on how nationality is granted and more cooperation between Member States. There should be no weak link in the EU, where people could shop around for the most lenient scheme.” A press release as well as a Q&A are available online. (For more information: Christian Wigand– Tel.: +32 229 62253; Mélanie Voin – Tel.: + 32 229 58659; Markus Lammert – Tel.: +32 229 58602)
COLLEGE MEETING: European Commission adopts adequacy decision on Japan, creating the world's largest area of safe data flows
The Commission has adopted today its adequacy decision on Japan, allowing personal data to flow freely between the two economies on the basis of strong protection guarantees. This is the last step in the procedure launched in September 2018, which included the opinion of the European Data Protection Board (EDPB) and the agreement from a committee composed of representatives of the EU Member States. Together with its equivalent decision adopted today by Japan, it will start applying as of today. Věra Jourová, Commissioner for Justice, Consumers and Gender Equality said: “This adequacy decision creates the world's largest area of safe data flows. Europeans' data will benefit from high privacy standards when their data is transferred to Japan. Our companies will also benefit from a privileged access to a 127 million consumers' market. Investing in privacy pays off; this arrangement will serve as an example for future partnerships in this key area and help setting global standards.” The key elements of the adequacy decision, which complements the EU-Japan Economic Partnership Agreement, include a set of rules (Supplementary Rules) that will bridge several differences between the two data protection systems, assurances regarding safeguards concerning the access of Japanese public authorities for criminal law enforcement and national security purposes, and a complaint-handling mechanismfor complaints from Europeans regarding access to their data by Japanese public authorities. A press release, a Q&A, a statement as well as a factsheet are available online. (For more information: Christian Wigand– Tel.: +32 229 62253;Mélanie Voin – Tel.: +32 229 58659)
COLLEGE MEETING: Brexit preparedness: European Commission adopts two contingency proposals to help mitigate impact of “no-deal” Brexit on EU fisheries
Given the continued uncertainty in the UK surrounding the ratification of the Withdrawal Agreement, the Commission has today adopted two legislative proposals to help mitigate the significant impact that a “no-deal” Brexit would have on EU fisheries. This is part of the Commission's ongoing preparedness and contingency work and will help ensure a coordinated EU-wide approach in such a scenario. The first proposal is to allow fishermen and operators from EU Members States to receive compensation under the European Maritime and Fisheries Fund for the temporary cessation of fishing activities. This will help off-set some of the impact of a sudden closure of UK waters to EU fishing vessels in a no-deal scenario. The second proposal amends the Regulation on the Sustainable Management of the External Fleets. The aim of this proposal is to ensure that the EU is in a position to grant UK vessels access to EU waters until the end of 2019, on the condition that EU vessels are also granted reciprocal access to UK waters. The proposal also provides for a simplified procedure to authorise UK vessels to fish in EU waters and EU vessels to fish in UK waters – should the UK grant that access. This proposal is limited to 2019 and is based on the agreement in the Agriculture and Fisheries Council of 17 and 18 December 2018 on the fishing opportunities for 2019. Full press release available here. (For more information: Enrico Brivio – Tel.: + 32 229 56172; Daniel Ferrie – Tel.: +32 229-86500; Daniela Stoycheva - Tel.: +32 229 53664)
COLLEGE MEETING: European Commission appoints new senior managers to both its human resources and home affairs departments and a new Head of the Euratom Supply Agency
The European Commission has today decided to appoint Mr Christian Roques to the position of Director for “Health and Wellbeing – Working Conditions” in its department for Human Resources and Security; Mr Michael Shotter to the position of Director for “Migration and Protection” in its Directorate-General for Migration and Home Affairs; and Ms Agnieszka Kazmierczak, as the New Head of the EU's Euratom Supply Agency. Mr Roques, a French national, joined the Commission in 1995. Since then, he worked in the areas of competition policy and European public law, with a focus on human resource management. Between 2006 and 2008, he worked in the European Union's General Court, first in the Cabinet of President Bo Vesterdorf and then in the Cabinets of two judges (Ms Ingrida Labucka and Vilenas Vadapalas). Mr Roques first became Head of Unit in 2010 and has, since then, been Head of Unit in the Commission's department for Human resources, in charge of European Civil Service Law and Social Dialogue. Mr Shotter, a British national, has nearly 23 years of experience in the European Commission, having first joined the institution in 1996. Following more than a decade in the Commission's Legal Service, he gained valuable experience, providing legal and political advice in the private office of Commissioner and then Vice-President Viviane Reding between 2007 and 2013. Mr Shotter worked as a Head of Unit for “Civil Justice Policy” in the Commission's justice department between 2013 and 2015 before joining the Cabinet of President Juncker as a senior legal advisor in charge of migration and home affairs. Ms Kazmierczak, a Polish national, is currently a Director in the shared resource directorate of the Commission's transport and energy departments. She joined the Commission from the private sector in 2005 to work in the area of internal audit. Before that, she held several management positions in the Polish civil service. (For more information: Mina Andreeva – Tel.: +32 229 91382; Andreana Stankova – Tel.: +32 229 57857)
Union de l'énergie: l'UE investit 800 millions d'euros supplémentaires dans des infrastructures énergétiques prioritaires
Les États membres de l'UE ont voté aujourd'hui sur une proposition de la Commission visant à investir près de 800 millions d'euros dans des projets d'infrastructures énergétiques clés en Europe présentant d'importants avantages transfrontaliers. Le financement de l'UE provient du mécanisme pour l'interconnexion en Europe (MIE), le programme européen de soutien aux infrastructures transeuropéennes. La priorité est donnée aux projets qui accroissent la compétitivité, renforcent la sécurité d'approvisionnement énergétique de l'UE en promouvant un fonctionnement sécurisé, fiable et efficace du réseau, et en contribuant au développement durable et à la protection de l'environnement. La création d'un réseau d'énergie moderne et interconnecté représente un élément fondamental de l'Union de l'énergie, l'une des priorités politiques de la Commission Juncker. La décision d'aujourd'hui accorde une aide financière pour les études et les travaux, pour un total de 14 projets: 7 projets concernant l'électricité, 2 projets relatifs aux réseaux intelligents, 2 projets de stockage de CO2 et 3 projets relatifs au gaz. Le montant total proposé pour le financement MIE-Energie s'élève à près de 800 millions d'euros, dont 504 millions d'euros pour l'électricité et les réseaux intelligents, 9,3 millions d'euros en support des études sur le développement d'une infrastructure de transport et de stockage de CO2; et 286 million d'euros alloués à des projets d'infrastructure du gaz. Le présent appel à propositions (2018-2) a été lancé le 11 juin 2018 et clôturé le 11 octobre 2018. Un communiqué de presse est disponible en ligne. (For more information: Anna-Kaisa Itkonen – Tel.: +32 229 56186; Lynn Rietdorf – Tel.: +32 229 74959)
Poland: Cohesion Policy invests in a modern hospital for the city of Toruń
€52.7 million from the European Regional Development Fund (ERDF) is invested to upgrade the largest public hospital in the city of Toruń, in northern Poland. This EU-funded project covers the construction of a new hospital complex centralising several medical services and of a helipad. Such an integrated rescue and treatment platform will significantly increase the quality and speed of the medical services provided to patients. Commissioner for Regional Policy Corina Creţu said: “Thanks to this Cohesion Policy investment, the inhabitants of Toruń will wait less for treatment and exams. They will access quality health services in a single modern hospital complex. This is a great project that shows what Cohesion Policy is about: improving the lives of the people.” When the project is completed, the hospital will host 59 specialist clinics and have a capacity of 1050 beds. (For more information: Christian Spahr – Tel.: +32 2 295 00 55; Sophie Dupin de Saint-Cyr – Tel.: +32 229 56169)
Les jeunes, l'esprit d'entreprise et de meilleures conditions de vie, fers de lance d'une nouvelle aide record de l'UE à la Tunisie
L'Union européenne a adopté un ensemble de mesures d'aide financière en faveur de la Tunisie se chiffrant à 305 millions d'euros, soit le montant le plus élevé jamais alloué au titre de l'instrument européen de voisinage. Ce financement record traduit la forte ambition de l'UE de créer de meilleures chances pour la jeunesse tunisienne, de favoriser un environnement plus florissant et plus attrayant pour les entreprises et de renforcer les capacités des administrations locales à améliorer les conditions de vie des populations locales. Johannes Hahn, commissaire pour la politique européenne de voisinage et les négociations d'élargissement, a déclaré: «Notre engagement envers la société tunisienne et notre intention de soutenir des mesures qui aideront les jeunes Tunisiens à trouver du travail et à créer leur propre entreprise sont clairs. Le soutien aux actions qui généreront de la croissance économique et élargiront les possibilités d'emploi constitue une priorité de premier plan dans le cadre de l'aide que nous avons adoptée récemment en faveur de la Tunisie et qui se chiffre à 305 millions d'euros, soit le montant le plus élevé jamais alloué pour une seule année. Les programmes adoptés faciliteront l'accès au marché du travail pour les jeunes Tunisiens, stimuleront l'innovation entrepreneuriale et permettront de faire en sorte que les communautés locales ne soient pas laissées pour compte.» Le communiqué de presse complet est disponible ici. (Pour plus d'informations: Maja Kocijančič – Tél.: +32 229 86570; Alceo Smerilli – Tél.:+32 229 64887)
Digital Single Market: EU negotiators agree on new rules for sharing of public sector data
The European Parliament, the Council of the EU and the Commission reached yesterday a political agreement on a revised directive that will facilitate the availability and re-use of public sector data. In full compliance with the EU General Data Protection Regulation, the new Directive on Open Data and Public Sector Information (PSI) - which can be for example anything from anonymised personal data on household energy use to general information about national education or literacy levels - updates the framework setting out the conditions under which public sector data should be made available for re-use, with a particular focus on the increasing amounts of high-value data that is now available. Vice-President for the Digital Single Market Andrus Ansip said: “Data is increasingly the lifeblood of today's economy and unlocking the potential of public open data can bring significant economic benefits. The total direct economic value of public sector information and data from public undertakings is expected to increase from €52 billion in 2018 to €194 billion by 2030. With these new rules in place, we will ensure that we can make the most of this growth”. Commissioner for Digital Economy and Society Mariya Gabriel said: “Public sector information has already been paid for by the taxpayer. Making it more open for re-use benefits the European data economy by enabling new innovative products and services, for example based on artificial intelligence technologies. But beyond the economy, open data from the public sector is also important for our democracy and society because it increases transparency and supports a facts-based public debate.” The European Parliament and the Council will now need to formally adopt the revised rules. For more information see our press release and updated factsheet. (For more information: Nathalie Vandystadt – Tel.: +32 229 67083 – Marietta Grammenou Tel.: +32 229 83583)
Commission launches consultations on the global role of the euro
The Commission launches today several targeted consultations to explore how to increase the international role of the euro in specific sectors: agricultural and food commodities, metals and minerals, and transport sector manufacturers in the field of aircraft, maritime and railway transport. Consultations in the financial and energy sectors will follow. A workshop on the international role of the euro in the energy sector is planned for 14 February. These steps are a follow-up to theDecember 2018 Communication “Towards a stronger international role of the euro”,which outlined the benefits of a strengthened international role of the euro for the EU and the international financial system and proposed initiatives to boost the euro's role. The Euro Summit of December took note of this Communication and encouraged work to be taken forward. Today's consultations aim to determine where more fine-tuned initiatives can be taken. They will remain open for two months until end-March 2019. In addition, the Commission will hold discussions on the increased international role of the euro in different public fora. The Commission will report on progress by the summer. (For more information: Annika Breidthardt – Tel.: +32 229 56153; Annikky Lamp– Tel.: +32 229 56151)
Mergers: Commission clears acquisition of control over the double clutch transmissions business of GFT by Magna
The European Commission has approved, under the EU Merger Regulation, the proposed acquisition of control over the double clutch transmissions business of Getrag Ford Transmissions Slovakia (“GFT”) of Slovakia by Magna Powertrain GmbH (“Magna”) of Austria. GFT is a contract manufacturer of transmission systems for passenger cars and light commercial vehicles. Magna is a subsidiary of Magna International Inc., a global automotive supplier of body, chassis, exterior, seating, powertrain, electronic, vision, closure and roof systems and modules, as well as complete vehicle engineering and contract manufacturing. The Commission concluded that the proposed transaction would raise no competition concerns as it does not create additional horizontal or vertical overlaps between the companies's activities. The transaction was examined under the simplified merger review procedure. More information is available on the Commission's competition website, in the public case register under the case number M.9176. (For more information: Ricardo Cardoso – Tel.: +32 229 80100; Maria Tsoni - Tel.: +32 229 90526)
Mergers: Commission clears acquisition of joint control of HeyCar by Daimler and Volkswagen
The European Commission has approved, under the EU Merger Regulation, the acquisition of joint control over Mobility Trader Holding (“HeyCar”) by Daimler AG and Volkswagen AG, all of Germany. HeyCar provides dealers and consumers in Germany with the online platform HeyCar for the sale and purchase of high quality used cars. Daimler and Volkswagen are active in the manufacture and sale of motor vehicles worldwide. The Commission concluded that the proposed acquisition would raise no competition concerns, considering HeyCar's negligible activities within the European Economic Area. The transaction was examined under the simplified merger review procedure. More information is available on the Commission's competition website, in the public case register under the case number M.9180. (For more information: Ricardo Cardoso – Tel.: +32 229 80100; Maria Tsoni - Tel.: +32 229 90526)
Eurostat: Le tourisme dans l'UE: Le nombre de nuitées dans l'UE a augmenté de 2% en 2018, plus forte hausses en Lettonie, en Lituanie et à Malte
En 2018, le nombre de nuitées passées dans des établissements d'hébergement touristique dans l'Union européenne (UE) devrait avoir atteint plus de 3,1 milliards, ce qui représente une progression de 2,2% par rapport à 2017. Depuis 2009, le nombre de nuitées passées dans des établissements d'hébergement touristique dans l'UE est en hausse constante; cette évolution est notamment imputable à l'augmentation des nuitées de non-résidents du pays visité. En 2018, l'Espagne (467 millions de nuitées, soit -0,9% par rapport à 2017) est restée en tête, devant la France (444 millions, +2,4%), l'Italie (429 millions, +1,9%) et l'Allemagne (419 millions, +4,3%). Un communiqué de presse Eurostat est disponible en ligne. (Pour plus d'informations: Lucía Caudet - Tél.: +32 229 56182; Victoria Von Hammerstein – Tél.: +32 229 55040)
STATEMENTS
Statement by Commissioner Thyssen on the 25th anniversary of the EU Agency for Health and Safety at Work
2019 marks the 25th birthday of the European Union Agency for Safety and Health at Work (EU-OSHA) in Bilbao. Celebrating the occasion, Commissioner for Employment, Social Affairs, Skills and Labour Mobility, Marianne Thyssen, said: "In the past twenty five years, European legislation and the relentless efforts of EU-OSHA have made our workplaces safer, healthier and more productive. Europe is a pioneer and boasts some of the highest standards on health and safety at work in the world. We are addressing the biggest killer in the workplace: occupational cancer. We have reduced the number of workers who died in an accident at work by almost 25% and the number of workers reporting health problems by 10%. The Agency has played a crucial role to achieve this, as well as the close involvement of social partners to adapt our efforts to the reality of companies. The European Pillar of Social Rights has provided support at the highest political level to make European workplaces even safer and healthier, and under my mandate I have put concrete proposals on the table to better protect workers against cancer-causing chemicals. We will continue our work to make Europe a better place where all European workers come home healthy and safe every day after work." The full statement can be found here. (For more information: Christian Wigand– Tel.: +32 229 62253; Sara Soumillion – Tel.: +32 229 67094)
ANNOUNCEMENTS
Commissioner Creţu visits Joint Research Centre in Ispra, Italy
Tomorrow, Commissioner for Regional Policy Corina Creţu will be in Ispra, Italy, to visit the Joint Research Centre (JRC), the European Commission's science and knowledge hub. Ispra is the third biggest Commission site after Brussels and Luxembourg. Commissioner Creţu will discuss with JRC Director-General Vladimír Šucha policy-related issues such as Smart Specialisation, to develop competitive advantages for regions. Corina Creţu will also meet the community of Romanian experts in Ispra and open the 'Romanian Semester', an initiative promoting culture and traditions of the country currently holding the Presidency of the Council of the EU. For each Presidency, officials organise various culture-related activities, starting with an opening ceremony at the JRC site. (For more information: Christian Spahr – Tel.: +32 2 295 00 55; Sophie Dupin de Saint-Cyr – Tel.: +32 229 56169)
Commissioner Gabriel in Germany to discuss EU initiatives to counter disinformation
Tomorrow, Commissioner for Digital Economy and Society Mariya Gabriel will be in Berlin to participate in the conference Democracy in a Digital Society and will deliver a speech on the actions of the EU to counter disinformation in Europe and beyond. In addition, Commissioner Gabriel will meet with Dr Katarina Barley, the Federal Minister of Justice and Consumer Protection in order to discuss various digital files, including the modernisation of the EU copyright rules in Europe, the recently agreed new rules on cross-border access to TV and radio programmes, the Commission's proposal for a Regulation on Privacy and Electronic Communications as well as the EU's Action Plan to step up efforts to counter disinformation in Europe and beyond. (For more information: Nathalie Vandystadt – Tel.: +32 229 67083 – Marietta Grammenou Tel.: +32 229 83583)
Upcoming events of the European Commission (ex-Top News)

Story 48
For the first time since 2015, a team not named Alabama is the preseason No. 1 in the Coaches Poll.
Defending national champion Clemson, which was No. 2 in the first poll a year ago, picked up 59 first-place votes to open No. 1. Alabama received six first-place votes and is No. 2.
Georgia, Oklahoma and Ohio State round out the top five. It's also the first time Clemson is the preseason No. 1.
Rank School (First place votes) Points 1 Clemson (59) 1,619 2 Alabama (6) 1,566 3 Georgia 1,447 4 Oklahoma 1,415 5 Ohio State 1,368 6 LSU 1,218 7 Michigan 1,155 8 Florida 1,103 9 Notre Dame 1,100 10 Texas 1,038 11 Texas A&M 893 12 Washington 834 13 Oregon 787 14 Penn State 699 15 Utah 642 16 Auburn 606 17 Wisconsin 436 17 UCF 436 19 Iowa 343 20 Michigan State 313 21 Washington State 274 22 Syracuse 227 23 Stanford 200 24 Iowa State 169 25 Northwestern 161
The Crimson Tide have ranked in the top three of every preseason Coaches Poll going back to the 2010 season. In four of the previous five times Alabama didn't open No. 1, it ended up winning the national title.
It's the third time in four seasons that Alabama and Clemson hold the top two spots in the preseason Coaches Poll. But this year marks the first time it's the Tigers and not 'Bama at No. 1.
The Coaches Poll doesn't have a connection to the College Football Playoff rankings, but the major polls have been solid at predicting the eventual semifinalists. For 2018, Alabama ranked No. 1 in the preseason, with Clemson second, Oklahoma fifth and Notre Dame at No. 11. In 2017, the Coaches Poll ranked the eventual CFP teams first (Alabama), fifth (Clemson), eighth (Oklahoma) and 15th (Georgia)
Nine of the 20 teams to make the CFP have ranked in the top four of the preseason Coaches Poll. However, Alabama has accounted for five of those; Clemson has accounted for two instances. A top-4 preseason team not named Alabama or Clemson hasn't reached the CFP since the first year (Oregon and Florida State in 2014).
Here's how it breaks down since the inaugural CFP for the 2014 season. Teams in bold were ranked in the top 4 in the preseason and reached the CFP.
Year Top 4 Preseason Coaches Poll CFP teams (Preseason rank) 2014 No. 1 Florida State
No. 2 Alabama
No. 3 Oklahoma
No. 4 Oregon Alabama (No. 2), Oregon (No. 4), Florida State (No. 1), Ohio State (No. 6) 2015 No. 1 Ohio State
No. 2 TCU
No. 3 Alabama
No. 4 Baylor Clemson (No. 12), Alabama (No. 3), Michigan State (No. 6), Oklahoma (No. 19) 2016 No. 1 Alabama
No. 2 Clemson
No. 3 Oklahoma
No. 4 Florida State Alabama (No. 1), Clemson (No. 2), Ohio State (No. 5), Washington (No. 18) 2017 No. 1 Alabama
No. 2 Ohio State
No. 3 Florida State
No. 4 USC Clemson (No. 5), Oklahoma (No. 8), Georgia (No. 15), Alabama (No. 1) 2018 No. 1 Alabama
No. 2 Clemson
No. 3 Ohio State
No. 4 Georgia Alabama (No. 1), Clemson (No. 2), Notre Dame (No. 11), Oklahoma (No. 5)
Last year, five of the preseason Top 10 teams ended ranked in the top 10, including the top three (though Clemson and Alabama switched Nos. 1 and 2). Here's how last year's Coaches Poll rankings changed week to week:

Story 49
Justin Sullivan / Staff
Compare Wikipedia entries for Jony Ive – Apple's outgoing chief design officer – and his de facto successor Jeff Williams and the contrast is stark. Ive's detailed entry is more than 2,000 words long. Williams's is 104. Just one paragraph.
Yet, despite there being comparatively very few profiles or pieces on Williams since he joined Apple in 1998, he has had a significant impact on product development at Apple. In fact, until recently he's been something of an unsung hero.
Advertisement
Promoted to chief operating officer in December 2015, Williams is the guy who gets shit done at Apple. He makes sure products are made and shipped on time, and to the company's typical high build standards. Described by Fortune back in 2011 as "Tim Cook's Tim Cook", as he does much of what Cook did when he was COO, Williams negotiates billion dollar deals and manages the company's mind-boggling complicated supply chain and production processes, including overseeing relationships with suppliers such as Foxconn, Corning and Hynix.
He may not have the art school credentials, or perhaps a cool bone in his body; he may have worked for IBM in operations and engineering roles with a degree in mechanical engineering and an MBA, but the move to give Williams a wider design brief now Ive is (technically) leaving Apple, placing him in charge of an experienced team of designers, actually makes sense.
Read next Apple's new AirPods Pro get noise cancelling and a design makeover Apple's new AirPods Pro get noise cancelling and a design makeover
First, not much is really changing. Nobody else at Apple will be taking Ive’s title of chief design officer, and it seems clear that the brand will be leaning very heavily on Ive's new LoveFrom design company for the foreseeable future. Apple will be the new firm's first client and, to stabilise things further, LoveFrom will even be based inside the Ive-designed Apple Park. In short, Ive's impeccable taste, design principles and rigour will be on hand for years to come. Second, Williams is in charge of one of Apple's most successful products in recent years - the Apple Watch.
According to research firm Asymco, Apple is now the world’s biggest watchmaker. In 2017 its revenues eclipsed those of Rolex. What makes this remarkable is that Apple isn’t a watchmaker per se. What makes this even more remarkable is that Apple wasn’t even making watches until 2015. So successful has this product been that it arguably saved the lacklustre smartwatch sector, and, in effect, legitimised the market. It is the best looking and performing product in its class by a country mile.
Advertisement
Apple Watch shipments increased 49 per cent in the 2019 Jan-March quarter year-on-year, according to Counterpoint Research. Apple has never disclosed specific Watch sales, but its "Wearables, Home, and Accessories" category set a new March quarter revenue record of $5.1 billion (£4b). Notably, this success came with the backdrop of falling iPhone sales.
Speaking of iPhones, it's Williams's involvement in the first iteration of Apple's smartphone that tells a story as to how valuable he has been to the company. Look down at your iPhone now, if you own one. In part it is because of Williams's ability to deliver that it exists at all. Giving an address at Corning’s Harrodsburg facility in Kentucky in 2017, the company that makes the Gorilla glass for the iPhones, Williams revealed that the original iPhone was designed with hard coated plastic on the front, the same kind used on the company's iPods that at the time had the little screens.
"When Steve held up the iPhone to introduce it to the world we'd only made a couple and he was holding up one that we designed with hard coated plastic on the front," Williams said. "The intro went wonderful, but then he called the next day and said everything is great except for one problem. He said, 'I've been carrying this thing around and it scratched in my pocket. I don't know if it is my keys or what it was, but it scratched. We need glass.'"
Read next iPhone 11 Pro and Pro Max review: the best yet, but you don’t care iPhone 11 Pro and Pro Max review: the best yet, but you don’t care
Williams explained that he'd been looking at doing that very thing and reckoned that within three to four years the technology may evolve to offer a glass screen on the iPhone. Job replied: "No you don't understand, when it ships in June it needs to be glass."
Advertisement
Despite his reservations, Williams duly went off and spoke to Corning who sourced some prototype glass they had sitting on a shelf in their R&D department. "It had no market and they didn't know what to do with it," said Williams. "We said, maybe we could make a go of that, so there were many months of sheer terror about whether this was going to work. It was a bit of a Hail Mary, but when we launched in June customers had an iPhone that had Corning glass with scratch resistance, and it helped set the tone for iPhone."
Williams also worked on the deal to prepay Hynix $1.25 billion (£985m) for flash memory, a move that helped Apple make the iPod Nano possible. He streamlined the iPod delivery process, allowing US consumers at the time to go online, buy an iPod, have it engraved, and then get it delivered all within three business days from start to finish. The list goes on.
What's more, his success and abilities have not gone to his head. Unlike many other top-flight executives looking to make a name for themselves or raise their profile to star status, Williams is apparently intensely private, a "salt-of-the-earth kind of guy". He wasn't mentioned once in Walter Isaacson’s 2011 biography of Steve Jobs. There are also reports he continued to drive his banged-up Toyota with a broken passenger-side door even after being promoted to management. He also supposedly knows how to get the best from his staff, being even tempered and collaborative when solving problems.
Neil Cybart from Apple analysts Above Avalon went as far as to say back in January 2015 that he “considered Jeff Williams as Tim Cook’s successor before Cook finished his first day as CEO... Regardless of what the future brings, people need to start watching Jeff Williams because he is executing at levels that few are able to achieve.”
Read next More radio, more live: where Apple Music's headed in 2020 More radio, more live: where Apple Music's headed in 2020
Whether you were surprised or not at Jony Ive's departure – and you shouldn't have been, the many signs were there for all to see – you could be forgiven for raising an eyebrow on hearing that Jeff Williams will now be leading Apple's design teams. But a few rumoured products aside, we're unlikely to see a radical design shift in Apple products in the next five years. That being the case and looking at his track record, Jeff Williams is just the person Apple needs right now as it transitions from hardware to services: sharp, smart and the guy that brings it home every time.
More great stories from WIRED
💰 Facebook's Libra cryptocurrency, explained
🔍 The disturbing return of scientific racism
🚕 Uber has a new London rival and it's much cheaper
🤵🏻 The NHS has a plan to get more men donating blood
💻 The 10 iPadOS features that will transform your iPad
Advertisement
🐄 How our addiction to big beef ended up ruining the planet
📧 Never miss an awesome story again with our weekly WIRED Weekender newsletter

Story 50
Global Sickle Cell Anemia Drug Market 2019 – Pfizer , Merck , St. Jude , … ,
Global Sickle Cell Anemia Drug Market 2019 report provides by Market Research Store is the representation of the Sickle Cell Anemia Drug Market area through research, development and analysis of information from multiple sources. The Global Sickle Cell Anemia Drug report bifurcates the Sickle Cell Anemia Drug Market based on various parameters, including the nature of products and services, technology development and end-user applications for a better understanding of analytical data.
In the Sickle Cell Anemia Drug Market 2019 research report professionals describe the different facets of the industry with a specific goal after assessing the key factors that could manipulate the development of the Sickle Cell Anemia Drug Industry sector.
The global market 2019 report Global Sickle Cell Anemia Drug Market includes identifying and comparing major competitors Pfizer
, Merck
, St. Jude
, …
,
, who compete for the success of the business expansion and determine the global and regional market.
Download Sample Copy Of Report : www.mrsresearchgroup.com/report/122483#request-sample
Scope Of The Global Sickle Cell Anemia Drug Industry 2019 Report
Based on the analysis, the Global Sickle Cell Anemia Drug Market report provides an assessment of future trends and future changes in the market 2019. Researchers analyze data using different formulas and analytical tools and prepare the surveyed data and predictions of key participants with such as diagrams, graphs and statistics for a better and faster understanding.
Various methodological techniques, such as the SWOT analysis, investment return analysis are used to obtain correct informative data for the analysis of impending financial fluctuations in relation to the current trends of Sickle Cell Anemia Drug market development.
The Global Sickle Cell Anemia Drug Industry report provides survey data based on the regional market 2019
Do Inquiry For More Details : www.mrsresearchgroup.com/report/122483#inquiry-for-buying
Chapters Covered In Global Sickle Cell Anemia Drug Industry 2019 :
Chapter 1: Introduction, Definition, Specifications, Classification and Scope the Sickle Cell Anemia Drug market 2019
Chapter 2: Exclusive Summery like Industry chain structure, Manufacturer cost structure, suppliers, etc
Chapter 3: Displays Trends, Drivers and Challenges of the Sickle Cell Anemia Drug market
Chapter 4: By the study of SWOT analysis it displays sales analysis, investment analysis, market analysis, etc
Chapter 5: It evaluate the market by segments, by countries and by manufacturers with revenue, share and sales by key countries in these various regions.
Chapter 6: Evaluate the leading manufacturers of the Global Sickle Cell Anemia Drug market which consists of its Competitive Landscape, Peer Group Analysis, BCG Matrix & Company Profile
Chapter 7: Sickle Cell Anemia Drug Research Findings and Conclusion, Appendix, system and information source
The report provides inclusive information to identify key market 2019 segments that help improve the quality of business decision-making based on sales, demand and production based on application-level analysis, and regional level. The report provides data analyzed graphically for a better explanation. Our experts have crafted the full study of Sickle Cell Anemia Drug market 2019 in a structured format for better interpretation.

Story 51
Reuters/Ivan Alvarado
Prices rocketed more than 130,000% in Venezuela last year, according to the first set of central bank data released since 2015.
Inflation topped 50% for most of 2018 and exceeded 850% in 2017.
Venezuela's GDP has dropped by at least 10% for 11 straight quarters.
Visit Markets Insiders' homepage for more stories.
Prices rocketed more than 130,000% in Venezuela last year, according to its central bank's first release of inflation data in more than three years.
The troubled South American nation reported monthly price rises north of 50% for most of 2018, and average inflation in excess of 850% in 2017, according to the data. For comparison, US inflation was 2% in the year to April, according to the Bureau of Labor Statistics.
While Venezuela's prices have surged, its economy has shrunk. Gross domestic product, a measure of economic growth, fell by about 23% year-on-year in the third quarter of 2018, the most recent period included in the central bank data. GDP has declined in every quarter since the start of 2014, and dropped by at least 10% year-on-year every quarter since the end of 2015, the data showed.
Given the continued GDP declines, the Venezuelan economy has more than halved in size over the past five years, marking one of the largest contractions in South America's history. More than 3 million people have fled the country since 2015, as inflation has made necessities unaffordable and contributed to shortages of food and medicine. The nation remains locked in a power struggle between President Nicolás Maduro and opposition leader Juan Guaidó, who accused Maduro of stealing elections and declared himself interim president earlier this year.
Relentless inflation and widespread shortages have translated into daily struggles for Venezuelans. A dozen eggs can cost upwards of $150 on the black market, according to CNN. A kilogram of maize flower or pasta goes for more than $300, and just over two pounds of powdered milk will run you $700 — nearly half the national minimum wage. Even criminals are feeling the pain: they're hesitant to open fire given the hefty cost of bullets, and reportedly struggle to find items worth stealing, according to the Associated Press.

Story 52
Pitt remained perfect by ending a long, long drought.
No. 6 Pitt (11-0) won its first game at Penn State since Oct. 4, 1980 with its sweep over the Nittany Lions on Friday night, snapping an 18-match losing streak at Penn State. It was also Pitt's first win against PSU anywhere since 1987.
we know you wanna see this match point video

and here it is#H2P pic.twitter.com/ZZ7qDAR81A — Pitt Volleyball (@Pitt_VB) September 21, 2019
Pitt outhit Penn State .337 to .129 and held Kaitlyn Hord to two kills and -.100 hitting.
Chinaza Ndee starred with 12 kills and a .611 hitting percentage for the Panthers' highest-ranked victory in program history. Kayla Lund followed close behind with her own spectacular performance of 14 kills and a .286 hitting percentage.
UNDEFEATED: Who else remains unbeaten?
The last time the Nittany Lions lost 3-0 at home to a nonconference foe was Sept. 18, 1986 against UC Santa Barbara (15-1, 15-7, 15-13).
Pitt commanded the court with dominant performances in the first two sets (25-17, 25-21), and the third set seemed like it would fall into that same rhythm. The Nittany Lions began the set off in communication and positioning, as they had throughout the most of the match. But Penn State then went on a 6-1 run to tie the third set at 10 and turned it into an 8-1 spurt to pull ahead 12-10. This seemed like it was it — that Penn State would turn it around.
But Pitt answered shortly after with a 10-3 run, making it a 20-15 lead — and the Panthers would not relinquish the lead.
RANKINGS: The updated AVCA Coaches poll
Hord, Penn State's co-leader in kills coming into the match, slammed her first of the night early in the third set. However, she would only record one more kill in the match and ended the night with a -.100 hitting percentage. She had entered the night with a .508 hitting percentage on the year.
Hord's overall performance was the most striking. Pitt's blockers stood tall as Penn State didn't hit better than .152 in any set.
SCOREBOARD: Follow other big matchups and final scores
The home-and-home series continues when Pitt hosts Penn State at 1 p.m. ET on Sunday.

Story 53
There was Northeast-10 football history made in Rindge, New Hampshire, in Week 2 of the DII football season.
Placekicker Morgan Smith had three pivotal extra points in Franklin Pierce’s 29-27 victory over Curry College to become the first woman to score in an NE10 football game, which also was Franklin Pierce’s first win as an official DII football program.
DII FOOTBALL, SO FAR: Week 3 top 25 | Best performances from Week 2
It's believed that Smith is the second woman to score a point in a DII football game. Tonya Butler of West Alabama was the first to achieve the feat — and reportedly in all of college football history — kicking a field goal on Sept. 13, 2003, nearly 16 years to the day of Smith's 3-for-3 PAT performance on Saturday.
We caught up with Smith to learn about her path to the Franklin Pierce Ravens and what's on the horizon for her.
Smith's DII football career started on the soccer pitch
Smith grew up in South Glens Falls, New York, where she began to play soccer year-round in the fourth grade. She was pretty darn good at it too, catching the eyes of the Franklin Pierce women's soccer team as early as her junior year in high school.
But it's also where she developed her love for football.
"I was always friends with the football players in high school," Smith told NCAA.com. "We were messing around in the summer before my senior year and I kicked a field goal. They told me I should try out for the football team. So, I built up the courage and decided to try out and wound up playing soccer and football my senior year."
DII FOOTBALL HISTORY: Longest all-time DII football winning streaks | Longest current home winning streaks
Smith loved the experience, but in her heart, she knew her path was on the pitch. She headed to Franklin Pierce as a member of the 2018 women's soccer team, where she appeared in just one game as a reserve.
That's when she realized something was missing.
"I missed football a lot," Smith said. "When I spoke to some of the football guys, they said I should try out, that they didn't have a set kicker yet. So, I decided in the spring that I would go and ask head coach [Russell] Gaskamp to give me a shot. He brought me down to the field, had me kick, and told me I had a spot in the fall."
The soccer experiment is now a thing of the past as Smith is a full-time member of the Ravens' football team. Now that she's making history on the gridiron, is she yearning to return to the pitch?
"I miss it a little bit, but I think my heart is set on football."
A historic win in DII football for Franklin Pierce
Franklin Pierce transitioned its Sprint Football team to an official DII program during the 2018 season. The Ravens became official members of the Northeast-10 in football for the 2019 season and opened at home against Division III Wesley, a game they lost 69-0. Smith would have to wait for that debut.
In Game 2, Frankin Pierce finally got on the board. After the Ravens were blanked in the first quarter, Chazz Bryant ran it in from nine yards out. Gaskamp opted to go for the two-point conversion, putting Smith's debut on hold even longer. Finally, in the waning seconds of the first half, Franklin Pierce completed its first touchdown pass in program history.
It was Smith's turn.
"I was super excited when we got the first touchdown and the fake play for a two-point conversion," Smith said. "My first actual PAT I was a little bit nervous, I wanted to make sure I did my part for the team. But I knew everyone else on the field was going to do their job 100 percent right, so I was very confident I'd be able to score."
Embrace the Journey: Today @FPUathletics' Morgan Smith became the first female to score in an NE10 football game!

Smith made all three of her extra points to help lead the Ravens to a 29-27 victory! #NE10Embrace #NCAADII #football pic.twitter.com/ZLYQB69JR4 — The NE10 (@TheNortheast10) September 14, 2019
Smith kicked the point-after attempt through the uprights and was successful twice more. Franklin Pierce's thrilling victory was clinched in the final minute of play at the goal line.
"It was amazing," Smith said. "We have a lot to work on still obviously, but we executed well, they took criticism well. It was a good experience for everyone. After that first game we really needed to pull out a win and I'm glad that we did.
"We need to be all on the same page, all willing to put in 100 percent. Most of the guys are pretty devoted to the team so we can work on the small things that will inevitably help us win in the end."
WATCH: Highlight-reel catches and a mind-boggling kick return
Morgan Smith: A role model and trailblazer for women athletes
Franklin Pierce Athletics Morgan Smith celebrates after a PAT in Franklin Pierce's first-ever DII football victory (photo credit: Meg Stokes).
When she wasn't winning World Cups with the U.S women's national soccer team, Carli Lloyd made waves this summer booting 55-yard field goals at Philadelphia Eagles training camp. Athletes like Lloyd have influenced Smith's path to the football field where she will, in turn, be a role model to young players in the future.
"I saw other females that could do stuff like that," Smith said. "I saw a girl that could participate in a men's sport, and I was like, 'If she could do it, then I could do it.'"
FROM AUSTRALIA TO BROWN: Meet Heather Marini, DI football's only female coach in 2019
That doesn't mean it's been easy, no matter how simple Smith may make it look. She'll have plenty eyes on her all the time, but no one is tougher on Smith than herself.
"I put a lot of pressure on myself," Smith said. "Being just a kicker, I feel like I don't do quite as much as everyone else. I have enormous respect for the rest of the guys, so I put this pressure on myself to do better so that I do my job. I've never felt pressure from the other guys, they all believe in me 100 percent."
Smith is a trailblazer in a sport not many women have played before.
"I thought about it a little bit, but I try not to boost my own ego or anything," Smith said. "I hope what I'm doing inspires other girls to join football. It's an amazing sport and it's a good experience. If more girls did it, it would make a better environment for football."
TOP STORIES: DII football news | Stay up to date with the DII hub | Join the DII newsletter
So, does Smith hope that one day she may be kicking on NFL fields?
"I mean, that's always the dream," Smith said. "But as of right now, I'm just focusing on Franklin Pierce and trying to help this team."

Story 54
Why did this happen?
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.

Story 55
Linked research
Health outcomes of young children born to mothers who received 2009 pandemic H1N1 influenza vaccination during pregnancy

Story 56
The US current corporate earnings season is all but over.
While the results aren't stellar, they've topped analysts' low expectations — especially when compared with results from their overseas counterparts — and are on track to avoid a decline.
Still, growth has markedly slowed from prior quarters.
Morgan Stanley continues to look for a corporate earnings recession this year, starting with the quarter that's wrapping up in the coming days.
Visit Markets Insider's homepage for more stories.
Public companies had a long list of worries in the first quarter.
The stock market was emerging from the severe late 2018 sell-off that gave way to a shaky start to 2019. Trade tensions between the US and China were simmering (and relations have only deteriorated since then). Signs of slowing growth were cropping up across the market at a late stage in the economic cycle.
Amid the waves of uncertainty, Morgan Stanley strategists told investors in February an earnings recession was imminent, defining that by two or more quarters of flat or negative growth. The consensus called for a 2.4% earnings-per-share decline, Credit Suisse said in early April.
Now with with nearly all of S&P 500 companies' results in the books this week, the numbers have come in slightly better than expected.
A bottom-line downturn appears likely to be narrowly avoided with a first-quarter earnings gain of 1.5%, according to Bloomberg data. That's compared with a rise of about 0.5% for companies in Europe, Australasia, and the Far East (EAFE), per Credit Suisse.
So the headline numbers look alright. But a closer analysis reflects fragility under the surface as investors and companies alike grapple with slowing global growth and the perpetual uncertainty of US-China trade negotiations.
"While the approximate 1.5 percent year-over-year earnings growth for the first quarter is above expectations, it pales in comparison to the double-digit year-over-year growth rate experienced over the past two years," Terry Sandven, the chief equity strategist at US Bank Wealth Management, told Markets Insider.
Growth 'pales in comparison' to prior quarters
Several measures of corporate earnings' health shows significant weakness on a sector-by-sector basis. Here's a quick rundown on where things stand.
While the first-quarter's earnings growth is the 11th-straight quarterly year-on-year rise, that's a significant decline from the fourth-quarter's 16.8% rise and the third-quarter's 28.4% growth, according to a Yardeni Research report.
Meanwhile the firm said just six of the S&P 500's 11 sectors have reported positive year-on-year earnings growth — with only one rising at a double-digit percentage rate. That compares with a respective 10 and seven sectors in the fourth quarter.
More granularly, real estate and utilities are the only sectors to have recorded stronger quarter-over-quarter growth.
Read more: Trump's tariffs are inflicting pain and uncertainty across the market. Comments from very different American companies show how.
And notably, earnings growth is trailing sales growth for the first time since the first half of 2016, a particularly volatile period for the financial markets, according to Yardeni Research.
S&P 500 sales have increased by 4.4% during the first quarter compared to the same period last year, with sales in the healthcare sector leading the pack, according to Oppenheimer.
Oppenheimer
That compares with profits growth of a tepid 1.5% compared to the same time last year.
Oppenheimer
And Morgan Stanley strategists, led by Michael Wilson, aren't backing off their call for an earnings recession.
"With 'Better than Feared' 1Q earnings now complete, our concerns about a 2H recovery remain," the strategists led by Wilson wrote in a Monday report.
When all is said and done it looks like first-quarter earnings-per-share growth will have declined 43 basis points, according to Wilson. He maintains broadly cautious about the stock market and has a year-end target of 2,750 on the S&P 500, just 0.8% below current levels.
"We continue to recommend a combination of defensive and reasonably priced quality stocks at this stage of the economic and volatility cycle," they wrote. "However, we expect the winners to get narrower as volatility picks up."
They think the next bout of volatility in the equity market will come from "weaker growth and earnings misses from stocks that are not priced for it."
Now read more markets coverage from Markets Insider and Business Insider:
Global stocks plunge after China hints it could unleash a 'powerful' trade war weapon by limiting US rare-earth supply
Beyond Meat is leaving Uber and Lyft in its dust. Here's how 2019's mega IPOs have performed so far.

Story 57
The Oval has not hosted England’s first Test of the summer since 1983 and is traditionally the venue for the final Test of the summer NIGEL KEENE/PROSPORTS/REX
England will break with tradition next year by playing their first Test of the summer at The Oval against the West Indies. The south London ground is usually the venue for the final international of the year, as it will be this season when hosting the fifth Ashes Test in September, and next year’s series opener against West Indies will be the first time it has staged the first Test of the summer since 1983.
While the final schedule has yet to be signed off The Times has seen a draft copy of next year’s international fixtures, with the West Indies playing three Test matches in June at The Oval, Edgbaston and Lord’s. A second Test series against Pakistan will take place in July and…

Story 58
IRELAND'S first reverse vending machine - which pays you for your plastic - opens today.
The reverse vending machine has opened at Market Square Shopping Centre in Carrickmacross, Co Monaghan.
1 The reverse vending machine is already in operation in other countries like the UK, Germany and Canada Credit: PA:Press Association
And Carrickmacross Tidy Towns hope that the initiative could be rolled out nationwide.
The machine, which has a database of thousands of different plastic bottles it can identify, will give the public a 10c voucher for each bottle recycled.
The voucher can then be redeemed in SuperValu in the shopping centre.
The Carrickmacross group has set a limit on the amount of bottles people can put in at a time at 20.

PLASTIC FANTASTIC
Tidy Towns treasurer Brenda McGuigan said another member of their committee brought the idea back from Germany, where it's been working since 2003.
She told RTE Radio One's Morning Ireland: "The idea behind the machine was to try and tackle plastic bottles being littered around the town, around the roadsides and play parks around the area.
"The idea is, you bring in your plastic bottle - empty and clean - put it into the machine, and the machine has a database of thousands of bottle sizes, barcodes, so it recognises the bottle and it will give you back a voucher out of the machine.
"In our case, we're setting it at 10c per bottle and then you can just walk across the corridor and redeem your voucher in O'Gorman's SuperValu."
The Carrickmacross scheme is being sponsored by Shabra Plastics and Quinn Packaging.
MOST READ IN NEWS ESSEX LORRY PROBE Wanted Irishman 'phoned police after driver Mo Robinson's arrest' Exclusive TWO HURT Man fights for life as garda hospitalised in separate Corduff incidents FIREARM SEIZED Three arrested after semi-automatic pistol found in car on Dublin road Exclusive SPOTTED Irishman wanted in lorry deaths probe seen 'walking about' as cops issued pic CAUGHT IN THE ACT Moment ‘cheating’ wife is caught ‘romping' in the back of her car Exclusive AMAZIN! Students sting Amazon for THOUSANDS after discovering reusable discount code glitch
It's expected to run for at least a year.
McGuigan said the plastic put into the machine will be processed locally into a plastic pellet, which will then be used to make plastic packaging for meat and vegetables.
She added: "It's like a 360 because that bottle that goes into the machine in Carrickmacross will probably eventually come back to Carrickmacross in the form of a recyclable meat or vegetable package."

Story 59
HILTON HEAD ISLAND, S.C. — C.T. Pan took advantage of Dustin Johnson’s back-nine meltdown to win the RBC Heritage for his first PGA Tour victory.
The 27-year-old Pan, from Taiwan, closed with a 4-under 67 on Sunday at Harbour Town Golf Links for a one-stroke victory over Matt Kuchar. Pan finished at 12-under 272.
The top-ranked Johnson, the third-round leader in his home-state event, had a 77 to tie for 28th at 4 under. He played a five-hole stretch in 7 over, making bogeys on Nos. 11-13 and double bogeys on Nos. 14-15.
Pan took the lead for good with a 9-foot birdie putt on the par-4 16th.
SCHEDULE & SCORES: Final RBC Hertiage leaderboard | Golf on TV
Kuchar closed with a 67.
Patrick Cantlay, Scott Piercy and Shane Lowry tied for third at 10 under. Cantlay and Piercy shot 69, and Lowry had a 70.
Pan headed to the practice range after the round to keep ready in case of a playoff, then raised his arms in triumph when told he’d won. He earned $1,242,000, a PGA Tour exemption through 2020-21 and spots in next month’s PGA Championship and next year’s Masters. He’s the RBC Heritage’s fourth straight first-time winner.
Pan won twice on the PGA Tour Canada in 2015 when he turned professional. He’s finished second twice in PGA Tour events, once at the Farmers Insurance Open in 2017 and last year at the Wyndham Championship.
Johnson, the 20-time PGA Tour champ, carried a one-shot lead into the final round and the South Carolina native seemed a strong bet to add the Palmetto State’s only tour stop to his trophy case. But Johnson never found a rhythm early and lost all hope with his uncharacteristic drop off.
He had a birdie on the fifth to keep on top. Johnson’s collapse started mildly with a bogey on the par-3 seventh hole. It took full flight on the back nine.
RYDER CUP: Register now for 2020 Ryder Cup tickets
Johnson’s frustrations were in full display on the par-4 13th when his approach went into the bunker, a foot or so from the wooden-board facing. He barely got it out, shook his head and tossed his wedge down against his bag.
He flew his tee shot into the water on the par-3 14th to drop two more shots. Johnson added a second double bogey on the par-5 15th, a hole he had birdied the first three rounds.
Johnson waved to the stands on the 18th when he closed with a birdie.
Lowry, who had three bogeys over his final six holes Saturday to lose a lead he held much of the week, appeared to regain his earlier form with birdies on the second, fifth and sixth holes to take a two-shot lead. But a bogey on the straightforward, par-4 ninth — Lowry had birdied it two of the first three rounds — dropped him back. He stubbed a pair of chips on the 12th hole and took double bogey.
Lowry scratched back within a shot of Pan with a birdie on the 14th, but could come no closer.
PGA CHAMPIONSHIP: 5 storylines to watch heading into Bethpage Black
Kuchar, the 2014 winner at Harbour Town, put together a charge of five birdies to tie Pan for the top. But a bogey on the par-3 17th following a tee shot into the bunker ruined his chances of a second tartan jacket.
Clutch.

Matt Kuchar ties the lead with a birdie on 18.#QuickHits pic.twitter.com/S94gYeyiwY — PGA TOUR (@PGATOUR) April 21, 2019
Cantlay looked like a second strong weekend — he went 64-68 his final two rounds at the Masters to tie for ninth — might bring him victory as he tied for the top with consecutive birdies on the 14th and 15th holes. He had a chip from just off the green on the 18th for a tying birdie, but did not come close.
This article was written by Pete Iacobelli from The Associated Press and was legally licensed through the NewsCred publisher network. Please direct all licensing questions to legal@newscred.com.

Story 60
Bang & Olufsen
The soundbar market is now so overcrowded, with so many entrants from high-end to bargain basement, that perhaps the most remarkable thing about the new Beosound Stage is that this is Bang & Olufsen’s first stab at such a sound system.
Mirroring the design aesthetic seen in B&O's dancing Beovision Harmony TV that debuted at Milan Design Week earlier this year, the Beosound Stage, due to be released in late October, is what you would expect from the brand in terms of minimalist style. It was designed in collaboration with Danish studio NORM Architects with a brief to use simple geometric shapes and natural materials.
Advertisement
The £1,250 soundbar’s simple frame can be specced in aluminium, bronze-tone aluminium or – if you want to pony up for the £1,900 version – smoked oak, complete with traditional dovetail joints. The natural and bronze frames are both made from a single piece of forged aluminium, so no messy seams. The frame runs all the way around the speaker with the only visible intrusion being the control panel. The cloth covering the speaker itself, which can be upgraded to fancy Kvadrat fabric, is of course acoustically transparent.
You may well think you've seen a B&O soundbar before, if so you might be recalling the Beolab 3500, which became 2016's Beosound 35. Bang & Olufsen is keen to point out that while these products indeed had a similar form factor, they were never optimised, sonically or in terms of TV-friendly connectors, to be soundbars. The Beosound 35 was, in fact, designed to be placed above a door or on a stand.
Read next Apple's new AirPods Pro get noise cancelling and a design makeover Apple's new AirPods Pro get noise cancelling and a design makeover
As seems to be the current fashion, B&O says it has created the Beosound Stage to be a soundbar that doesn’t rely on a subwoofer or satellites to create immersive audio for a television. To this end, the brand has squeezed in 11 speaker drivers, each provided power by its own 50-watt amplifier, resulting in a three-channel, active, DSP-based loudspeaker that you can plug into your TV.
Bang & Olufsen
Advertisement
The centre channel drivers include four custom four-inch woofers, designed to reduce distortion and allow greater movement, which in the real world should mean improved bass. The mid frequencies of this centre channel are taken care of by two 1.5-inch midrange drivers along with a 3/4-inch dome tweeter. The left and right sides have a 1.5-inch midrange and a 3/4-inch tweeters at each side, which are placed close together at a 45-degrees off-axis angle in what's known as a baffle design to create a '3D' sound effect. Speaking of 3D, B&O also ticks off one the current soundbar prerequisites with the inclusion of Dolby Atmos, going for that 'cinema experience at home' market.
Other familiar features include five different listening modes: TV, Music, Movie, Night Listening or None (which basically means flat EQ, leaving the incoming sound unchanged). Handily, after choosing a mode, it is then possible to fine-tune the sound using Bang & Olufsen’s simple and intuitive ToneTouch equaliser that those familiar to setting the EQ on B&O headphones will be familiar with.
An interesting omission, however, is there is no digital assistant in the Stage. B&O says it considered adding the tech but felt that it wasn't a best-use case for Alexa or Google Assistant in a soundbar, adding that users are usually some distance from the speaker itself and that dialogue is such common audio for such a device. This, of course has not stopped competitors putting assistants in their soundbars.
Read next These are the best wireless speakers in 2019 These are the best wireless speakers in 2019
The 8kg Beosound Stage has been designed to be placed flat in front of or beneath a TV, as well as wall-mounted on its side. Yes, the sound is adjusted depending on the orientation you opt for, but you have to tell the speaker through the accompanying app which way up the Stage is in your own setup. For multi-room enthusiasts, the usual suspects are included: Chromecast built-in, Apple AirPlay 2 and Bluetooth 4.2 (plus a 3.5mm stereo mini jack, too, if you want to go connected). HDMI boffins will be happy with EARC and ARC support, as well as 4K HDR support.
Advertisement
Bang & Olufsen
But the real question is has B&O come too late to the party? With so many choices out there, and some with comparable specs, much will depend on B&O finding those potential customers who care just as much about the looks of their tech as the performance. A good rival to bring up here is the phenomenal £2,199 Sennheiser Ambeo (also a first in category from the brand), which gets a perfect score from us for performance yet could never, ever be described as 'a looker' and is very expensive. We'd wager that most people would prefer something approaching B&O's design sensibilities. But then you have the Sonos Beam, which is lovely to look at and costs considerably less than either of these options, though admittedly there's no Dolby Atmos or DTS:X support to speak of.
Then there is the fact that it remains to be seen how well the Atmos system works on the Stage when you don't physically have the speakers facing upwards to bounce the sound off the ceiling. DSP can only do so much, after all. Our brief demo was not entirely convincing, but this is likely due to the triple-height conference room set up to show off the speaker was the very opposite of ideal conditions for Atmos to shine. Despite the acoustically awful room, the Stage still managed to handle music tracks with ease, delivering clean highs and impressive bass.
However, mentioning Sennheiser's Ambeo highlights that the Beosound Stage, for a B&O product, is not the most ridiculously priced speaker, being a whole thousand pounds less than the Sennheiser. Perhaps this is the influence of the 'budget' side-brand B&O Play being rolled into B&O proper last year. If it sounds as good as it looks, then B&O will have that rare thing in hi-fi, brawn and beauty all in one package.
Read next Why we're in love with this £3,000 speaker shaped like a massive egg Why we're in love with this £3,000 speaker shaped like a massive egg
Read the WIRED Recommends guide to the best soundbar to find out which models we rate above all others
More great stories from WIRED
🍔 World-class chef rates the best vegan burgers in the UK
😡 TikTok is fuelling India's deadly hate speech epidemic
🍫 The foods you'll really need to stockpile for no-deal Brexit
♻️ The truth behind the UK's biggest recycling myths
Advertisement
🤷🏼 How is the internet still obsessed with Myers-Briggs?
📧 Get the best tech deals and gadget news in your inbox

Story 61
Our analysis of KWP household purchase data for 2015-18 found an immediate impact of the introduction of MUP on reductions in total off-trade alcohol purchases in grams of ethanol in Scotland. The largest reductions in consumption were found for beer, spirits, and cider. Given that these categories include the own-brand spirits and high strength white ciders that MUP sought to target, our data suggest that the policy has achieved its ambition to make relatively cheap and strong alcohol less affordable, which in turn should positively impact public health over time. 43 Although the impact of MUP was greater on lower as opposed to higher income households, changes in weekly expenditure were not systematically related to household income but rather increased with increasing household purchases of alcohol. Thus, our data also indicate that MUP was a targeted policy, because it predominantly reduced purchases in the top fifth of alcohol purchasing households.
NHS Health Scotland has published a briefing based on initial alcohol purchase data released by market research company Nielsen, comparing the three months following MUP implementation with the same period for 2017. 46 They report a 14% increase in total value purchases in Scotland (in part due to a 10% increase in average prices), and an increase of 4% in volume purchases. These data contrast with those from England and Wales, which saw an increase of 8% in total value purchases, and 7% in volume purchases, but a decline in average prices during the same period. Our results, which include an additional five months of data compared to those published by NHS Health Scotland, indicate that off-trade purchases were reduced for the remainder of 2018. We also show that before the introduction of MUP, Scottish purchasing in terms of grams of alcohol was marginally cheaper than in England. Econometric modelling studies suggest that the 50p MUP for Scotland would result in an average increase of £5 in annual spending across the population. 18 Across all households, we found a non-significant weekly increase in off-licence expenditure on alcohol of 61p per adult per household following the introduction of MUP. Expenditure increased with the amount of alcohol purchased, being just under £3 per adult per household per week in the top fifth of purchasing households.
We found that the introduction of MUP led to a 7.6% reduction in purchases, 2.2 times as much as previous model based work. 18 This change is equivalent to a reduction in purchases of 328 g (41 UK units) per adult per household per year (adjusted for exclusion of on-sales, by dividing by 0.735, the proportion of total alcohol sales by volume of pure alcohol in Scotland that are due to off-trade sales 35 ), 1.6 times as much as previous estimates. The only other comparable empirical evidence of the real world impact of MUP on off-trade alcohol purchases used longitudinal data from 20 years of off-trade purchases in two Canadian provinces. These studies found that the introduction of a 10% increase in MUP of any given alcoholic product in British Columbia reduced its per capita alcohol consumption by between 14.6% and 16.1%. 44 A reduction of 8.4% was reported for total volume of pure alcohol sales or purchases in Saskatchewan province (where MUP was implemented across all beverage types) following the same percentage price increase, with larger effect sizes observed in off-trade versus on-trade alcohol sales. 45 Both the Saskatchewan and British Columbia analyses drew on a more extended period of post-intervention data than our study, and relate to a markedly different drinking culture than that found in Scotland, but the direction of effects are consistent with the results presented here.
Strengths and limitations of study
Our analyses had several important strengths. Data were obtained from a large number of households, with a large number of weekly data points before and after the introduction of MUP. Further, data on price and purchases were objective, based on product bar codes, and verified via digital receipts. By reporting changes in both the price per gram of alcohol purchased and in grams of alcohol purchased per individual per household, for all alcohol products, our analyses provide a balanced assessment of the initial impact of MUP. In contrast, simply reporting the total value of purchases does not offer a good measure of the impact of MUP, because this is influenced by the increase in average price.46
By comparison with purchase data from England, we were able to control for possible time varying confounders that occurred during the study period.33 Although northern England is arguably a more appropriate control in terms of its socioeconomic characteristics and geographical proximity to Scotland, we applied England as a whole to ensure sufficient data were available for robust analyses. The coefficients for the impact of introducing MUP were similar in size when using either all of England as a control or just northern England as a control, providing reassurance of no major dilution in effect due to cross border purchases. Additionally, although the randomised controlled trial remains the ideal research standard, interrupted time series analysis provides a strong alternative where an experimental study design is infeasible or unethical, such as the evaluation of policy initiatives in healthcare.47 Moreover, our study adheres to recognised appropriate quality criteria48 (supplementary table 4).
One key limitation concerns our use of off-trade purchase data only to assess the impact of MUP, meaning that we have no information about the effect on on-trade sales. As low income groups are more likely to buy more of their alcohol off-trade than high income populations, the restricting of our analyses to off-trade data could have resulted in an inflated overall level of impact.49 However, evidence suggests that the implementation of a 50p MUP will have limited impact on revenue in the on-trade, and that heavier drinkers consume a greater proportion of their alcohol in the off-trade.18 Additionally, and as NHS Health Scotland highlighted when publishing the Nielsen data, this period of analysis included a particularly hot summer in the UK and the 2018 World Cup, both of which could have increased alcohol purchases.46 However, our use of England as a control in our time series, with additional analyses conducted using northern England as a comparator, partially offsets the impact of any unusual seasonal trends or events on our findings.50
Another limitation of our study concerns our findings relating to the differential impact of MUP by income group, and by level of consumption. Although we identified a greater increase in the weekly price per gram of alcohol purchased for lower income groups, and a correspondingly larger decrease in the grams of alcohol purchased per week, we had no information on the actual drinking levels of panel respondents. When considering the equity implications of MUP, it is important to be able to separate heavier rather than lighter drinkers living in poverty.18
Although we partially controlled for lack of actual consumption data by looking at mean number of purchases over time,30 we acknowledge that heavy drinkers, particularly male drinkers or those with no fixed address or living in communal establishments, are likely to be under-represented in household panel data,5152 and that alcohol purchases are under-reported in general in these datasets.53 For example, compared with the UK Living Costs and Food Survey, KWP households tend to have lower incomes, are more likely to be female headed (as main or primary shoppers), and their expenditure on certain commodity items, including alcohol, tends to be lower.54 KWP households also include fewer single adult households than national population estimates for Scotland.37 At the same time, while these groups of heavy drinkers were likely less well represented in our dataset, they represent a small proportion of the population affected by MUP in Scotland. As such, our findings still have important implications for public health policy.
We also did not include any data to illustrate changes in health outcomes, which is crucial in order to fully evaluate the impact of MUP. As individuals in lower socioeconomic status experience the highest rates of alcohol attributable ill health and premature death,55 they are likely to benefit most from the policy implementation.29 Empirical published data relating to the Canadian provinces that have implemented and evaluated MUP, report impacts on reduced alcohol related morbidity,56 mortality,12 crime,57 and healthcare use,1358 particularly for lower income groups. NHS Health Scotland’s commissioned evaluation will focus specifically on assessing the impact of MUP on harmful drinkers, and will use primary qualitative and quantitative data collection from users and providers of alcohol treatment services, as well as secondary analyses of KWP data.34 This evaluation should permit additional scrutiny of any adverse impacts on this group of drinkers. Although very heavy drinkers, who are already experiencing severe economic deprivation, might respond to price increases by reducing their drinking, they might also respond to price increases by forgoing essentials, such as by rebudgeting to purchase alcohol instead of food.5960 As such, there is a risk that MUP could intensify the economic hardships experienced by both economically deprived very heavy drinkers and their families.61 A final limitation of our study was that we only had data for the eight months after the introduction of MUP. Future analyses should evaluate longer term effects.

Story 62
Relive some of the best college football moments of week 9
Relive some of the best college football moments of week 9
Clemson hasn’t lost a football game since falling to Alabama in the national championship on January 1, 2017. They avenged that loss with a perfect season and title of their own in 2018.
Can they stay perfect again in 2019?
Clemson Tigers 2019 full football schedule
Here is the full, detailed schedule for Clemson’s 2019 football season, with past games and results first, then the TV schedule for future games below.
PAST GAMES Opponent Date Time (ET) Location RESULT Georgia Tech Thursday, Aug. 29 8 p.m. Clemson, SC W, 52-14 Texas A&M Saturday, Sept. 7 3:30 p.m. Clemson, SC W, 24-10 Syracuse Saturday, Sept. 14 7:30 p.m. Syracuse, NY W, 41-6 Charlotte Saturday, Sept. 21 7:30 p.m. Clemson, SC W, 52-10 North Carolina Saturday, Sept. 28 3:30 p.m. Chapel Hill, NC W, 21-20 Florida State Saturday, Oct. 12 3:30 p.m. Clemson, SC W, 45-14 Louisville Saturday, Oct. 19 12:00 p.m. Louisville, KY W, 45-10 Boston College Saturday, Oct. 26 7:30 p.m. Clemson, SC W, 59-7
UPCOMING GAMES Opponent Date Time (ET) Location TV Wofford Saturday, Nov. 2 4:00 p.m. Clemson, SC ACCN NC State Saturday, Nov. 9 7:30 p.m. Raleigh, NC ABC Wake Forest Saturday, Nov. 16 TBD Clemson, SC TBD South Carolina Saturday, Nov. 30 TBD Columbia, SC TBD
2019 SEASON PREVIEW: 15 games that will impact the CFP race this season
Tickets
You can find tickets to each of Clemson’s home games here.
2018’s results
The Tigers went 15-0 last year, beating Alabama 44-16 in the national championship.
Here’s what happened in every game of Clemson’s 2018 schedule:
Opponent Date Location Result Score Furman Saturday, September 1 Clemson, SC W 48-7 Texas A&M Saturday, September 8 College Station, TEX W 28-26 Georgia Southern Saturday, September 15 Clemson, SC W 38-7 Georgia Tech Saturday, September 22 Atlanta, GA W 49-21 Syracuse Saturday, September 29 Clemson, SC W 27-23 Wake Forest Saturday, October 6 Winston-Salem, NC W 63-3 NC State Saturday, October 20 Clemson, SC W 41-7 Florida State Saturday, October 27 Tallahassee, FLA W 59-10 Louisville Saturday, November 3 Clemson, SC W 77-16 Boston College Saturday, November 10 Chestnut Hill, MA W 27-7 Duke Saturday, November 17 Clemson, SC W 35-6 South Carolia Saturday, November 24 Clemson, SC W 56-35 Pittsburgh Saturday, December 1 Charlotte, NC W 42-10 Notre Dame Saturday, December 29 Arlington, TEX W 30-3 Alabama Monday, January 7 Santa Clara, CA W 44-16
MORE: Programs with the most national championships
Top returning players
One of Clemson’s biggest strengths last season was its monstrous defensive line. But Clelin Ferrell, Christian Wilkins, and Dexter Lawrence are all gone thanks to the first round of the 2019 NFL Draft.
So which returning players will be leading the charge for the Tigers?
The first choice is obvious: Quarterback Trevor Lawrence. In 2018, the true freshman threw for 3,280 yards, 30 touchdowns, and 4 interceptions. On the biggest stage in the sport — the national championship — he was 20-for-32 for 347 yards, 3 touchdowns, and zero picks. Hard to get much better than that, but don’t be surprised if he puts up bigger numbers against a slightly easier regular season in 2019.
Lawrence’s partner in the backfield, Travis Etienne, is also poised for another monster year. Etienne improved drastically between his freshman and sophomore years, rushing for 1,658 yards and 24 touchdowns last season. Sustaining that level of production would be a tall task, but you can guarantee that Etienne will be one of the Tigers’ most lethal weapons this year.
Lawrence wouldn’t have had the coming out party that he did were it not for the talented duo of Justyn Ross and Tee Higgins. Ross racked up 1,000 yards and 9 touchdowns, while Higgins had 936 yards and 12 touchdowns. With Hunter Renfrow gone, those numbers might even go up this season.
Preseason ranking
We have Clemson sitting at No. 1 in our preseason Top 25. Here’s that breakdown:
1. Clemson
The Tigers will go into the season as the huge ACC favorites, national title favorites with Alabama and possibly the Heisman frontrunner in QB Trevor Lawrence. The schedule is also far from daunting, so it would be a slight surprise if the Tigers don’t go 12-0 (or 13-0 with an ACC crown). Can any ACC team even stay within two touchdowns?
LATEST RANKINGS: AP Top 25 | Coaches Poll
The 2020 College Football Playoff
The College Football Playoff era is entering its sixth season in the 2019-20 season. Will it be the first season since the inaugural playoff that Clemson and Alabama don’t play in either a CFP semifinal or national championship?
Whether the Tigers and Tide play each other or not, here are the dates and sites for the 2019 College Football Playoff semifinals and CFP national championship.
MORE: Clemson dominates Alabama to win 2018 College Football Playoff title
When is the 2019 College Football Playoff semifinals?
The CFP semifinals are set for Dec. 28, 2019. One semifinal is the Peach Bowl at Mercedes-Benz Stadium in Atlanta. The other semifinal is the Fiesta Bowl in Glendale, Arizona.
When is the 2020 College Football Playoff national championship?
The CFP national championship is a bit later in 2020. The two winners of the semifinals will meet on the second Monday of January in New Orleans on Jan. 13, 2020 at the Mercedes-Benz Superdome.
Below is a complete history of the College Football Playoff national championship game.
YEAR GAME 2015 No. 4 Ohio State 42, No. 2 Oregon 20 2016 No. 2 Alabama 45, No. 1 Clemson 40 2017 No. 2 Clemson 35, No. 1 Alabama 31 2018 No. 4 Alabama 26, No. 3 Georgia 23 2019 No. 1 Alabama vs. No. 2 Clemson
2021-2024 CFP national championship locations and dates
2021: Miami-South Florida (Hard Rock Stadium, Miami Gardens, Florida) - Jan. 11
2022: Indianapolis (Lucas Oil Stadium, Indianapolis, Indiana) - Jan. 10
2023: Los Angeles (Los Angeles Stadium at Hollywood Park, Inglewood, California) - Jan. 9
2024: Houston (NRG Stadium, Houston, Texas) - Jan. 8

Story 63
• Year-Over-Year Revenue Increases by 1,723%
• Licence Applications for Niagara Greenhouse, Port Perry Outdoor now Under Review
TORONTO, May 13, 2019 (GLOBE NEWSWIRE) -- Aleafia Health Inc. (TSX: ALEF, OTC: ALEAF, FRA: ARAH) (“Aleafia Health” or the “Company”) is pleased to provide a corporate update and report its First Quarter 2019 financial results for the period ended March 31, 2019. Aleafia Health has filed today its consolidated financial statements and related management’s discussion and analysis, both of which are available on Aleafia Health’s profile at www.SEDAR.com . All financial information in this press release is reported in Canadian dollars, unless otherwise indicated. The Company’s acquisition of Emblem Corp. (“Emblem”) closed on March 14, 2019, and as a result, Emblem financial results prior to the closing date are not reported in the financial statements.
“In 2018, Aleafia Health laid the groundwork for a breakthrough 2019, and we have now begun to see the results of this work. The closing of the transformative acquisition of Emblem has accelerated our global mission of growing, processing and selling high-margin value-added cannabis products by 12 to 18 months,” said Aleafia Health CEO Geoffrey Benic. “Our three production facilities will, when operational, truly leverage our global distribution platform, brands, and data-driven product expertise. Concurrently, we have achieved an improved capital markets profile, graduating to the Toronto Stock Exchange, while increasing our cash position despite making major investments in the buildout of our modern production facilities. I would like to thank our entire team, from the leadership of our Board, to clinic staff and physicians, production buildout crews, and management for the outstanding work and commitment shown to our shared cannabis health and wellness vision.”
Niagara Greenhouse and Port Perry Outdoor Grow Licence Application Updates
Aleafia Health is pleased to announce that it has received a status update letter from Health Canada indicating that Aleafia Health’s Cultivation Licence application for its Niagara Greenhouse facility has passed a high-level review and that Health Canada has no concerns at this point. Passing this mandatory review is an important requirement as outlined by the new licensing guidelines announced by Health Canada on May 8, 2019. The Company is also pleased to report that its Licence Amendment application for the Port Perry Outdoor Grow expansion is now officially under review by Health Canada.
Revenues & Expenses
Aleafia Health revenue was $1.5 million, compared to $0.1 million in Q1 2018, a 1,723 per cent year-over-year increase. The Company experience a net loss of $20.2 million, or a $7 million net loss, excluding $13.2 million in one-time, non-cash payments resulting from the closing of the Emblem acquisition. The Company has $36.8 million cash on hand at March 31, 2019, compared to $26.4 million at December 31, 2018. Current assets, including cash, totalled $61 million at March 31, 2019, compared to $29.2 million at December 31, 2018.
First Quarter Business Highlights
Emblem Acquisition: On March 14, 2019, Aleafia Health closed the acquisition of Emblem in an all share transaction. The acquisition accelerated the Company’s business strategy by creating; the leading Canadian medical cannabis clinic and education centre network with 60,000 patients seen to date; a high-value, highly differentiated product portfolio of oils, capsules and sprays; scaled production capacity and leading supply with three dedicated cultivation and product innovation facilities and the industry’s largest LP-to-LP cannabis supply agreement; a national and global distribution platform with provincial supply agreements, retail partnerships and a global expansion; and improved capital markets profile and liquidity, including up-listing to the TSX.
160,000 sq.ft. Niagara Greenhouse: During the reporting period, the Company brought its Niagara Greenhouse to a grow-ready state and submitted its evidence package to Health Canada, demonstrating that the facility meets all requirements to secure its Cultivation Licence.
1.1 million sq. ft. Port Perry Outdoor Grow: Aleafia Health submitted its Licence Amendment application for a 1.1 million sq. ft. (26 acres) Outdoor Grow expansion where its licensed and operational Port Perry Indoor facility resides. Subsequent to the reporting period, the Company completed the build-out of the Outdoor Grow site and on May 3, 2019, submitted its evidence package to Health Canada, demonstrating that the facility meets all requirements to secure its Licence Amendment.
International Expansion: On January 18, 2019, the Company announced the launch of its international expansion with the closing of its 10 per cent equity stake in Australian Licensed Producer CannaPacific Pty. Limited (“CannaPacific”). Subsequent to the reporting period, on April 11, 2019, the Company announced that it made an increased investment in CannaPacific by the purchase of AU $540,000 worth of ordinary shares to maintain the Company’s 10 per cent stake, following CannaPacific’s successful acquisition of a 108.000 sq. ft. greenhouse for cannabis cultivation in New South Wales, Australia. The Company has received an Import Permit from the Australian Office of Drug Control, and expects to complete its first international product shipment, following receipt of a Health Canada Export Permit, which the Company has applied for. Also following the reporting period, the Company announced on May 6, 2019, its entrance into the German medical cannabis market by expanding the scope of Emblem’s joint venture with German pharmaceutical wholesaler and logistics company Acnos Pharma GmbH (“Acnos”). The Company, through Emblem, owns 60 per cent of the JV, and will leverage Acnos’ supply chain network, including access to 20,000 pharmacies and 110 distribution centres in the world’s largest medical cannabis market.
Improved Capital Markets Profile: On March 19, 2019, the Company successfully graduated to the Toronto Stock Exchange. The Company believes that the TSX listing will benefit the Company due to greater liquidity and increased credibility with North American institutional investors. Prior to graduating to the TSX, the Company was also named the year’s top performing company for the entire TSX Venture Exchange in 2018.
Innovative Research: Aleafia Health collects millions of data points across patient interaction with doctors, nurses and educators including diagnosis, treatment, and monitoring forming the Company’s unique and highly differentiated 10 million point medical cannabis dataset. During the reporting period, the Company published a retrospective study in the peer-reviewed journal Cannabis and Cannabinoid Research which found that 45.2 per cent of patients regularly consuming benzodiazepines had stopped taking the medication within approximately six months of beginning medical cannabis.
Management Call & Presentation
Date: May 13, 2019
Time: 8:30 a.m. EDT
USA/Canada Toll-Free Participant Call-in: (866) 679-9046; Passcode: 5961515
International Toll-Free Participant Call-in: (409) 217-8323; Passcode: 5961515
Webcast Link: https://edge.media-server.com/m6/p/5csxr9np
This conference call will be webcast live over the internet and can be accessed through the link provided above. Audio of the call will be available to participants through both the conference call line and webcast; however the presentation may only be viewed via the webcast. Participants who miss the live call can view a replay at any time via the link provided.
For Investor and Media Relations, please contact:
Nicholas Bergamini, VP, Public Affairs
416-860-5665
IR@AleafiaHealth.com
LEARN MORE: www.AleafiaHealth.com
About Aleafia Health:
Aleafia Health is a leading, vertically integrated cannabis health and wellness company with four primary business units: Cannabis Cultivation & Products, Health & Wellness Clinics, Cannabis Education, and Consumer Experience with ecommerce, retail distribution and provincial supply agreements.
Aleafia Health owns three major cannabis product & cultivation facilities, two of which are licensed and operational. The Company produces a diverse portfolio of commercially proven, high-margin derivative products including oils, capsules and sprays. Aleafia Health operates the largest national network of medical cannabis clinics and education centres staffed by MDs, nurse practitioners and educators.
Aleafia Health maintains a medical cannabis dataset with over 10 million data points to inform proprietary illness-specific product development and treatment best practices. The Company is committed to creating sustainable shareholder value and has been named the 2019 top performing company of the year by the TSX Venture Exchange prior to graduation to the TSX.
Forward Looking Information
This news release contains forward-looking information within the meaning of applicable Canadian and United States securities laws. Often, but not always, forward-looking information can be identified by the use of words such as "plans", "expects" or "does not expect", "is expected", "estimates", "intends", "anticipates" or "does not anticipate", or "believes", or variations of such words and phrases or state that certain actions, events or results "may", "could", "would", "might" or "will" be taken, occur or be achieved. Forward-looking information involves known and unknown risks, uncertainties and other factors which may cause the actual results, performance or achievements of Aleafia Health or its subsidiaries to be materially different from any future results, performance or achievements expressed or implied by the forward-looking information contained in this news release. Examples of such statements include statements with respect to the future market share achieved in recreational markets, product development, clinical trial work, and planned expansion activities. Risks, uncertainties and other factors involved with forward-looking information could cause actual events, results, performance, prospects and opportunities to differ materially from those expressed or implied by such forward-looking information, including risks contained in the Company's annual information filed with Canadian securities regulators available on the Company's issuer profile on SEDAR at www.sedar.com . Although the Company believes that the assumptions and factors used in preparing the forward-looking information in this news release are reasonable, undue reliance should not be placed on such information and no assurance can be given that such events will occur in the disclosed time frames or at all. The forward-looking information included in this news release are made as of the date of this news release and the Company does not undertake an obligation to publicly update such forward-looking information to reflect new information, subsequent events or otherwise unless required by applicable securities legislation.
A photo accompanying this announcement is available at: http://www.globenewswire.com/NewsRoom/AttachmentNg/ad4d2599-1821-4b8a-9b70-70c78eb8e121
The photo is also available at Newscom, www.newscom.com, and via AP PhotoExpress.

Story 64
Undefeated no more, Stanford's 37-match winning streak came to an end on Sept. 14 when Minnesota beat the defending champions in four sets. The Cardinal were handed their first loss since Aug. 2018, paving the way for Nebraska to take over the top spot in the most recent AVCA Coaches Poll.
After spending three weeks behind Stanford, the Huskers reclaim the No. 1 ranking for the first time since the final poll of 2017. Nebraska became the top ranked team following a 3-0 week that includes straight-set wins over High Point and Denver, in addition to a four-frame victory against Loyola Marymount.
In Stanford's loss, Minnesota held the Cardinal to a .185 attacking percentage — a far cry from the .356 mark the team averaged through its first five matches. Gophers' opposite hitter Stephanie Samedy went for 21 kills and six blocks in the upset.
.@GopherVBall knocked off No. Stanford for the first time ever in program history last night to go undefeated at the Big Ten/Pac-12 Challenge!

Take a look at match point below ⬇️ pic.twitter.com/dPwDLcZz4d — Minnesota Gophers (@GopherSports) September 15, 2019
Despite the outcome, Stanford only dropped one spot to No. 2, a decision likely influenced by a four-set road win over Penn State. The rest of the top 5 (Texas, Penn State and Baylor) remained in place.
Here is the full poll.
Rank School Points record prev 1 Nebraska (37) 1550 7-0 2 2 Stanford (23) 1538 5-1 1 3 Texas (2) 1488 5-1 3 4 Penn State 1370 6-1 4 5 Baylor 1321 7-0 5 6 Pittsburgh (1) 1261 10-0 6 7 Minnesota (1) 1228 4-2 8 8 Marquette 1062 7-2 7 9 Wisconsin 1049 4-2 9 10 Washington 1011 7-1 12 11 Florida 912 5-2 11 12 BYU 859 7-2 13 13 Hawai'i 796 9-0 18 14 Oregon 673 2-3 10 15 Creighton 645 5-3 17 16 Kentucky 542 6-3 15 17 Missouri 528 8-0 21 18 Utah 520 8-2 16 19 Illinois 406 3-4 14 20 Southern California 397 5-3 20 21 Purdue 354 4-1 23 22 Colorado State 344 7-1 NR 23 Florida State 190 5-2 25 24 California 163 8-0 NR 25 Louisville 153 6-2 22
Nine of the top 10 teams remained in tact, with Washington being the lone newcomer. The Huskies moved up two places after picking up a win over then-No. 17 Creighton. Four top-10 teams — Stanford, Penn State, Marquette and Oregon — lost last week. However, the caliber of the losses were of high quality, resulting in those programs dropping a combined six spots. The Ducks were hit the hardest, falling from No. 10 to No. 14 after losing three times, albeit to Pittsburgh, Minnesota and Penn State.
DOWN GO THE CHAMPS: Minnesota ends Stanford's 37-game winning streak
Illinois was the only other team to drop more than three spots, sliding five to No. 19 after losing to Central Florida and Illinois State. The Illini did manage to salvage the weekend with a five-set win against then-No. 7 Marquette.
Biggest risers
Among teams previously ranked, Hawai'i and Missouri were this week's biggest risers.
The Rainbow Wahine surged to No. 13, a five-spot ascension after handling West Virginia, Utah Valley and UCLA in Honolulu. The Tigers won all four of their matches, earning straight-set wins in three of them over Austin Peay, Kansas City and Boise State.
Joining the rankings are Colorado State and California.
Both teams received votes last week, finding themselves inside the top 25 after convincing performances. California improved to 8-0 after wins against Buffalo and North Dakota State. The Golden Bears are one of 10 remaining unbeaten teams.
The Rams took both matches in a home-and-home with then-No. 19 Colorado. CSU swept the Buffaloes in Fort Collins before winning a five-set thriller in Boulder.
Dropped out
Colorado (19), Michigan (24)
MILESTONE VICTORY: Texas State's Chisum earns win No. 900
Looking Ahead
This week, Nebraska plays its first regular season match as the No. 1 team since Nov. 2016. It's also the first time Stanford won't compete as the top-ranked team since last November. Though the meeting takes place prior to the fall equinox, the atmosphere inside the Devaney Center should be comparable to a mid-December match when No. 2 Stanford comes to Lincoln on Wednesday for a rematch of the 2018 national championship game.
Pittsburgh held steady at No. 6 after wins over ranked Pac-12 foes Oregon and Utah. The Panthers showed an ability to win close as all six sets won were decided by five or fewer points. Their next challenge comes against in-state opponent Penn State. Pittsburgh and the No. 4 Nittany Lions are set to meet in a home-and-home series on Friday and Sunday.
As of Sept. 16, only 10 teams remain undefeated in Division I volleyball. Three of which — Baylor, Hawai'i and Missouri — are all ranked in the top 20 and will face each other this week in Waco. No. 5 Baylor plays No. 17 Missouri on Friday and Hawai'i on Sunday. The Tigers and the No. 13 Rainbow Wahine face off on Saturday as the number of unbeaten teams will continue to whittle down.
Wisconsin won both of its matches last week to remain in the top 10. To conclude their non-conference slate, the No. 9 Badgers have a home-and-home with No. 10 Washington, first playing in Madison on Thursday before the return game in Seattle on Saturday.
Both Utah and Brigham Young lost to ranked opponents in the previous week. The Utes dropped a 4-set match to Pittsburgh while the Cougars were beaten by Texas. With league play approaching, No. 18 Utah hosts No. 12 BYU in Salt Lake City on Thursday.

Story 65
One golf tournament changed Suzy Whaley's career path — not to mention a life in which she would become a trailblazer in the game — and she didn't even make the 36-hole cut.
It was the 1989 McDonald's Championship at DuPont Country Club in Wilmington. Whaley, known then as Suzy McGuire, a recent North Carolina graduate who intended to go to law school, qualified for the LPGA event and played well, but fell one shot short of qualifying for the weekend.
2019 PGA CHAMPIONSHIP: Complete field | Round 1 and 2 tee times
However, she so impressed two local businessmen that they offered to support her financially if she wanted to pursue a career on the LPGA Tour. She returned with her parents to their West Chester home and discussed the proposal.
"I told them that I was thinking about going to tour school and not law school," recalled Whaley, the first woman to serve as president of the PGA of America, "and my parents thankfully said, 'Hey, you can always go to law school. Why don't you give it a try?'
"So with my mom in tow, off we went, and made it through first stage in Venice, Fla., and then got my conditional card in Sweetwater, Texas. I got in the car, looked at my mom and said, 'What do we do now?' She said, 'I guess we go practice.' "
Whaley played full time on the LPGA Tour for just two years, 1990 and 1993, but her career flourished as a club professional in Connecticut. She made history when she won the 2003 Connecticut Section PGA championship, which earned her a berth in a PGA Tour event, the Greater Hartford Open.
She was the first woman since Babe Didrikson Zaharias in 1945 to qualify for a Tour event. She became the second woman to compete on Tour in 2003, joining Annika Sorenstam, who played in the Colonial tournament in Fort Worth, Texas, on a sponsor's exemption.
Whaley's involvement in growing the game and providing opportunities for young players, especially girls, to participate moved her into a more active role with the PGA of America. The process reached its peak last November when she was elected president of the organization, which represents 29,000 club professionals.
NEWS: 2017 champion Justin Thomas withdraws from PGA Championship with wrist injury
This week, Whaley will oversee the 101st PGA Championship at Bethpage State Park's Black course on Long Island.
She acknowledges that, yes, it was a good decision to choose golf over law school.
"I'm so blessed and thankful because the opportunities this game has given me are far more than I could ever give back to it," Whaley, 52, said last week in a phone interview from her home in Palm Beach Gardens, Fla., where she is director of instruction at the Country Club of Mirasol.
"I met my husband through the game, 28 years we've been married. I have two beautiful children; both went to college on Division I full scholarships because of the game of golf. I have so many friends, I have my business, I have my career, I have my joy and my passion because of the game. What a great decision that was. You never know until years later, but I'm so thankful that I took a right turn instead of a left."
Whaley grew up in Dewitt, New York, outside of Syracuse. Her parents, Mary Ann and Mick McGuire, moved to West Chester shortly after she graduated from high school and the family played golf at Radley Run Country Club. Whaley learned the game from her mother, a professor at Syracuse University who would caddie for her daughter in many tournaments.
"I loved playing golf and spending time with my mom," she said. "Her best handicap was about a 16, but she was an avid golfer and had a wonderful eye for the game. She could really help me. She studied the game and watched golf on television all the time."
There was one part of the game, however, that bothered her a little bit.
"I wanted to get out on the golf course as much as I could, but that was a time when girls really weren't invited to play the game," Whaley said. "It was a struggle for my mom to get me access and to explain to me why the boys could play when I couldn't play. Most places, I couldn't play but on Mondays."
Since becoming a club professional, Whaley has been in the forefront of creating more playing opportunities for girls and women. She proudly notes that National Golf Foundation data released last month showed the No. 1 demographic in the game's growth is girls.
HOW TO WATCH: TV schedule, streaming information for the 2019 PGA Championship
She credits in large part the PGA Junior League, which is in its seventh year and counts Alex Morgan, Rickie Fowler and Stephen Curry among its "ambassadors," and is team golf with boys and girls playing together as two-person teams in a scramble format.
"It's unbelievable how fast these boys and girls take to the game," she said. "Eighty percent of those who sign up are listed by their parents as developmental players. It's really exciting that we're having young boys and girls who may play three or four other sports now learning the game as well."
The creation in 2015 of the KPMG Women's PGA Championship, which comes next year to Aronimink Golf Club in Newtown Square, has generated clinics across the country for women who play or want to learn the game.
"We want them to come out, have some instruction, get some on-course opportunities, network, be a part of their community, and meet new women within their community that they can engage with on the golf course," she said.
Life remains busy for Whaley, who attended the graduation of her younger daughter, Kelly, from North Carolina last Friday before heading to Long Island. She is a mentor to her niece, Phoebe Brinker, a junior at Archmere Academy in Claymont, Del., who has won two state high school championships and will enter Duke in the fall of 2020.
Most of all, Whaley enjoys being a role model.
"The young children I teach, in elementary and middle school and even high school, what I love best is that they just see me as a strong leader and as a PGA professional and someone that's their coach," she said. "That's generational change. It's not, 'Oh, she's a woman and she's the president.' It's, 'Wow, she's the president.' To me, we've come a long way."
WHAT TO KNOW: History, tickets, field list, and FAQs about the PGA Championship

This article is written by Joe Juliano from The Philadelphia Inquirer and was legally licensed via the Tribune Content Agency through the NewsCred publisher network. Please direct all licensing questions to legal@newscred.com.

Story 66
Four-month-old Archie Harrison Mountbatten-Windsor has made his first public appearance on the Duke and Duchess of Sussex's Royal Tour of Africa. Archie joined Harry and Meghan as they met with Archbishop Desmond Tutu at his legacy foundation in Cape Town.
'Arch meets Archie!' Sussex Royal captioned the photograph of the young royal being introduced to the religious figurehead. The devoted parents reportedly told the Archbishop that Archie is an ‘old soul’ whilst Prince Harry explained that he is ‘constantly wanting to stand’.
Advertisement
The video of Archie was shared to Harry and Meghan's joint Instagram account, Sussex Royal. They posted a story of the two of them beaming, walking down a corridor in Cape Town with the Duchess of Sussex holding the very excitable baby dressed in H&M dungarees. The two parents look utterly besotted.
Read next Princess Haya made envoy as she prepares for epic legal battle against Sheikh Mohammed Princess Haya made envoy as she prepares for epic legal battle against Sheikh Mohammed
Ahead of the trip, a royal source had said that the Duke and Duchess of Sussex were keen to include their son at some point in the tour.
Archie emerged on Monday from the slightly delayed British Airways flight bundled up in a white bobble hat in the arms of his mother. The bobble-hatted vision has been compared to one worn by Prince Harry in Aberdeen, January 1985. The Duchess of Sussex reportedly slept with 'one eye open' on the flight. A guest disclosed that Harry and Meghan had been anxious because it was the longest flight they had ever taken with Archie.
Advertisement
Royal babies in dungarees Royals Royal babies in dungarees
The Duke and Duchess of Sussex have shared various anecdotes whilst meeting well-wishers on the tour. Harry revealed that Archie had evidenced an early appetite for culture on the trip; as the flight descended into South Africa he had been enjoying the local landmarks. ‘He was staring out the window as we flew in... looking at Table Mountain’.
Following the flight, the Duke reportedly apologised for his son. ‘He’s not grouchy, just exhausted,’ he explained. Harry also revealed that Archie ‘slept on Meghan’s chest for most of the journey’.
When asked by a friendly face where Archie was during a visit to the District Six neighbourhood on Monday afternoon, the parents revealed that Archie was, at that time, having a nap.
Advertisement
Archie's last public outing was to the polo in July, just a week after his private christening at Windsor Castle. He was born on 6 May 2019 at the Portland Hospital in London. Three days after the birth Meghan gushed, ‘It’s magic. It’s pretty amazing. And here I have the two best guys in the world, so I’m really happy’. After witnessing the photographs today, it seems safe to say that the family of three continue to delight in one another.
Royal Tour Africa: The Duchess of Sussex’s fashion highlights Royals Royal Tour Africa: The Duchess of Sussex’s fashion highlights

Story 67
Louisa Gosling in her early twenties. She says Johnson grabbed her by the arm in a row about his first wife COURTESY OF LOUISA GOSLING FOR THE SUNDAY TIMES
A woman who was a confidante of Boris Johnson’s first wife has told how the prime ministerial favourite harangued and threatened her over incendiary allegations about the couple’s private life.
Louisa Gosling, now a consultant on data privacy, has decided to break her silence about the incident after 30 years following last weekend’s revelations about Johnson’s row with his current girlfriend, which ended with the police being called.
Gosling: ‘Johnson bullied me’
Gosling was a 21-year-old Cambridge graduate when Johnson’s first wife, Allegra Mostyn-Owen, sought sanctuary in her flat late at night after what is said to have been a blazing row with the man who is odds-on to be Britain’s next prime minister.
Mostyn-Owen is understood to have made a serious allegation about Johnson’s conduct towards her and…

Story 68
Before the AVCA Division I Preseason Coaches Poll is announced on Tuesday, Aug. 13, it's time to look back at the 2018 NCAA women's volleyball season. (Editor's note: The new poll has been posted here. Full top 25 reactions, analysis here)
The Stanford Cardinal defeated the Nebraska Cornhuskers in five sets to claim its eighth national championship and second in the last three years. Outside hitter Kathryn Plummer led Stanford with 19 kills and 10 digs.
Plummer, an AVCA First-Team All-American in 2018, will return for her senior season this fall, along with Jenna Gray, Morgan Hentz and Audriana Fitzmorris. Gray and Hentz were also named First-Team All-Americans.
In contrast, Nebraska won't have a single senior on the roster in 2019. But the Huskers will have home-court advantage when they host Stanford in a rematch of last year's final on September 18. It'll be an early non-conference test for two clubs that have each won two of the last four national championships.
Reminder!!!

The #AVCA Division I Preseason Coaches Poll will be announced at 3pm ET tomorrow, Tuesday! We will first announce the top-10 at 2pm ET right here on Twitter! — AVCA (@AVCAVolleyball) August 12, 2019
Stanford and Nebraska finished first and second, respectively, in the final AVCA poll of 2018. Rounding out the top five were No. 3 Illinois, No. 4 BYU, and No. 5 Texas. The poll below was released on Dec. 17, 2018.
RANK SCHOOL POINTS 2018 RECORD PREVIOUS RANK 1 Stanford (64) 1600 34-1 1 2 Nebraska 1533 29-7 6 3 Illinois 1463 32-4 3 4 BYU 1408 31-2 4 5 Texas 1285 23-5 5 6 Penn State 1253 26-8 7 7 Minnesota 1187 27-4 2 8 Wisconsin 1162 25-7 8 9 Oregon 1095 23-11 14 10 Kentucky 1026 26-5 10 11 Florida 821 26-7 16 12 Michigan 799 24-10 18 13 Creighton 770 29-5 9 14 Pittsburgh 709 30-2 11 15 Marquette 689 28-7 15 16 Washington State 668 23-10 19 17 Purdue 645 24-9 12 18 Washington 625 20-13 22 19 Tennessee 398 26-6 19 20 San Diego 364 18-13 NR 21 Southern California 335 22-11 17 22 Cal Poly 287 25-3 13 23 Missouri 228 24-8 24 24 Baylor 197 20-9 25 T-25 Arizona 81 22-11 23 T-25 UCF 81 27-4 21 Others receiving votes: Louisville 35; Utah 31; Pepperdine 15; South Carolina 12; Northern Iowa 5; Florida Gulf Coast 2; Loyola Marymount 2. Notable Numbers: AVCA Division I Women's Poll Stanford and Nebraska have each been ranked a record 542 times.
The next closest is Southern California at 512.
Nebraska has earned the No. 1 ranking 99 times, more than any other program.
UC Santa Barbara has received 105 top-10 rankings, but has never been ranked No. 1.
Colorado State needs one more top-25 ranking to become the 14th school to reach the 300 mark.
Cal Poly hasn't been ranked No. 1 overall since Oct. 22, 1985, the longest drought for any school that's received the top ranking at least once.
Only 19 different schools have been ranked No. 1 overall since AVCA polling began in 1982. SCHEDULE: When does the 2019 women's college volleyball season start?
Most total times ranked
1. Nebraska and Stanford: 542
3. Southern California: 512
4. UCLA: 505
5. Hawai'i: 500
6. Penn State: 492
7. Texas: 484
8. Florida: 432
9. BYU: 399
10. Arizona: 325
Most times ranked No. 1
1. Nebraska: 99
2. Penn State: 95
3. Stanford: 73
4. UCLA: 56
5. Hawai'i: 48
6. Southern California: 47
7. Long Beach State: 27
8. Pacific: 18
9. Florida: 16
10. BYU: 15
Most timed ranked in the top 10
1. Nebraska: 486
2. Stanford: 481
3. Texas: 371
4. Hawai'i and Penn State: 366
6. UCLA: 340
7. Florida: 332
8. Southern California: 316
9. Washington: 210
10. Pacific: 189

Story 69
Ten different schools have won the NCAA Division I Women’s Volleyball title since it was first awarded in 1981. A number of acclaimed programs have reached the No. 1 spot in the AVCA Poll without a national title on their resume — so far.
Here’s a peek at five programs with the best shot at getting back to that No. 1 spot this season and potentially breaking through to win their first national titles.
RECAP: 2018 women's volleyball season in review
BYU
Since 2012, the NCAA tournament has been a regular venture for the Cougars. They reached the pinnacle of regular-season dominance last year, sitting atop the coaches poll on Nov. 19 — less than three weeks before postseason play.
Stanford (2018 National Champion) acted as the gatekeeper in the semifinal round, sweeping the Cougars and denying them a second final appearance in four years.
The West Coast Conference preseason coaches poll released on Monday favors BYU to win the conference championship for a sixth consecutive year, while the AVCA preseason coaches poll, released on Tuesday, ranks them No. 9 in the nation.
Perhaps this is their year to win it all.
Here's BYU's history at the NCAA tournament:
31-time tournament participant
2014 runner-up
1-time semifinalist
7-time regional finalist
We had some surprise visitors at practice today👀 How do you think our friends @BYUbasketball held up?🤔🏐#BYUWVB x #BYUhoops pic.twitter.com/CYHMNTz9kR — BYU Women’s Volleyball (@BYUwvolleyball) August 13, 2019
Florida
The Gators became a consistent tournament threat in the 90s with five semifinal appearances. They reached the finals in 2003 but lost to Southern California, which claimed its third NCAA national title.
Currently riding a 28 consecutive NCAA tournament appearance streak and 28 straight 25-win seasons dating back to 1991 (head coach Mary Wise's inaugural season), Florida seeks its first national title and a return to the No. 1 ranking. The last time the Gators reached No. 1 was Oct. 9, 2017.
They'll start the 2019 season ranked No. 10 after losing to BYU last season in the third round of the tournament.
Here's Florida's history at the NCAA tournament:
29-time tournament participant
2017, 2003 runner-up
6-time semifinalist
9-time regional finalist
Illinois
Last season's crushing loss to Nebraska (3-2) in the tournament semifinals prevented the Illini from reaching their second tournament finals in program history. To make another run at the title, Illinois' 2018 points leader, senior Jacqueline Quade (625), returns this season after nearly doubling last season's second-best scorer, Megan Cooney (385).
Illinois begins the year ranked No. 6 in the country.
Since Chris Tamas took the helm of the program in 2017, Illinois has reached the tournament each season. It's been eight years (Oct. 17, 2011) since the Illini ranked No. 1.
Here's Illinois' history at the NCAA tournament:
25-time tournament participant
2011 runner-up
3-time semifinalist
3-time regional finalist
PRESEASON POLL: See where these five teams rank against other top 10 programs
Minnesota
Just 11 months ago (Sept. 3), the Golden Gophers ranked No. 1 in the country, ahead of future No. 1 BYU and future national champion Stanford. And just nine months after Oregon beat them (3-1) in the tournament regional final.
There are five former No. 1, title-less programs in this preseason’s Top 10. Minnesota, at least night now, can be considered a leading candidate to break through to a title. AVCA coaches ranked them No. 3 behind Stanford and Nebraska. Minnesota's 2019 schedule is tough: eleven opponents either rank in the Top 25 or received votes in the preseason poll.
Here's Minnesota's history at the NCAA tournament:
23-time tournament participant
2004 runner-up
4-time semifinalist
2-time regional finalist
Wisconsin
Three seasons ago (Oct. 10, 2016), the Badgers were the No. 1 team in the nation. Now they rank No. 5 in the preseason poll — their fifth straight year being ranked in the preseason Top 10.
After a 25-7 regular season in 2018, Wisconsin lost in the regional final to Illinois (3-1).
Returning in 2019 is sophomore Dana Rettke, a playmaker who earned two Big Ten statistical titles in hitting percentage (.423) and blocks per set (1.54).
Head coach Kelly Sheffield's tenure began in 2013 as the tournament runner-up, becoming the lowest-seeded team to reach the championship round. The Badgers have returned to the postseason every year since with the hope of capturing the program's first national title.
Here's Wisconsin's history at the NCAA tournament:

Story 70
Interference of matter waves is at the heart of quantum physics and has been observed for a wide range of particles from electrons to complex molecules. Here, we demonstrate matter wave interference of single positrons using a period-magnifying Talbot-Lau interferometer based on material diffraction gratings. The system produced high-contrast periodic fringes, which were detected by means of nuclear emulsions capable of determining the impact point of each individual positron with submicrometric resolution. The measured energy dependence of fringe contrast in the range of 8 to 16 keV proves the quantum-mechanical origin of the periodic pattern and excludes classical projective effects, providing the first observation to date of antimatter wave interference. Future applications of this interferometric technique include the measurement of the gravitational acceleration of neutral antimatter systems exploiting the inertial sensing capabilities of Talbot-Lau interference.
In 1923, de Broglie ( 1 , 2 ) introduced the concept of wave-particle duality: the Planck constant h relates the momentum p of a massive particle to its de Broglie wavelength λ dB = h/p. The superposition principle is one of the main postulates of quantum mechanics; diffraction and interference phenomena are, therefore, predicted and have been observed on objects of increasing complexity, from electrons ( 3 , 4 ) to neutrons ( 5 , 6 ) and molecules ( 7 – 9 ). Beyond the early electron diffraction experiments ( 3 , 4 ), the demonstration of single-electron double-slit–like interference was a highly sought-after result. Initially proposed by Feynman as a thought experiment, it was last carried out in 1976 ( 10 ). A few years later, positron diffraction was first observed ( 11 ). However, an analog of the double-slit experiment has not been performed to date on any system containing antimatter. To bridge this gap, we designed and realized a Talbot-Lau interferometer ( 12 ) suited to a low-energy positron beam. This interferometric technique could also lead to studies of fundamental interest on neutral antimatter systems. For instance, several techniques are being considered to undertake the measurement of the gravitational acceleration of positronium, muonium, and antihydrogen ( 13 – 20 ). Talbot-Lau–based inertial sensing ( 21 ) offers the capability to work with low-intensity, weakly coherent beams similar to the one used in this work. This is a highly desirable feature for beam-based experiments with antimatter.
RESULTS
The experiment makes use of the variable energy positron beam facility of the L-NESS (Laboratory for Nanostructure Epitaxy and Spintronics on Silicon) in Como (Italy). Positrons (e+) from the beta decay of a 22Na radioactive source are implanted on a monocrystalline tungsten film and emitted with a kinetic energy of about 3 eV, determined by the work function of the material (22). Slow positrons are then accelerated up to 16 keV by means of a purely electrostatic system. A monochromatic and continuous beam is thus formed with an energy spread less than 0.1%, limited by the stability of the power supplies. The positron rate is (5 ± 1) × 103 e+/s, and beam focusing can be tuned to reach a spot size of the order of several millimeters of full width at half maximum (FWHM), an approximately Gaussian intensity profile (23) and an angular divergence at the level of a few milliradians (24). A suitable model (25) of grating-based interferometry with a partially coherent beam exploits the analogy with Gaussian Schell-model beams of classical optics (Materials and Methods). Within this formalism, incoherence translates physically into a broad transverse momentum distribution and mathematically to a short transverse coherence length l. The L-NESS beam features a coherence length of the order of a few nanometers. An effective configuration for these conditions was obtained with a novel period-magnifying two-grating interferometer (21, 26). It exploits an intermediate working regime between the standard Talbot-Lau setup, where the two gratings and the detector are equally spaced, and the so-called Lau interferometer (27), which has more stringent coherence requirements (25). By means of unequal grating periodicities, the system provides sizable period magnification in a relatively compact setup (21). In particular, we used gold-coated 700-nm-thick silicon nitride (SiN) gratings with periodicity d 1 = (1.210 ± 0.001) μm and d 2 = (1.004 ± 0.001) μm to produce a d 3 = (5.90 ± 0.04) μm periodic interference pattern. Both gratings have a nominal open fraction of 50%.
The periodic spatial distribution generated by the interferometer (Fig. 1) is revealed by a nuclear emulsion detector. Nuclear emulsions (28) offer submicrometer-level position resolution in the detection of ionizing particles (24, 29). They work as photographic films by exploiting the properties of silver bromide crystals embedded in a 50-μm-thick gelatin matrix. For this experiment, we developed a glass-supported emulsion detector (fig. S1) and experimentally demonstrated its capability to resolve periodic patterns at the micrometric scale even with low signal contrast and on large areas (24).
Fig. 1 Schematics of the Talbot-Lau interferometer. Positrons traverse two circular 2-mm-wide collimators 10.2 cm apart. The interferometer is composed of two SiN diffraction gratings with periodicity d 1 and d 2 , respectively, separated by L 1 = (118.1 ± 0.2) mm. Interference fringes with d 3 periodicity are expected at L 2 = (576 ± 5) mm. The emulsion is tilted so that the Y axis in the reference frame of the emulsion surface (X, Y) forms a 45° angle with the y axis of the laboratory. Gamma rays (511 keV) from positron annihilation in the emulsion are monitored with a high-purity germanium (HpGe) detector for rate measurement.
Interferometer alignment is particularly challenging, and it is intimately connected to beam coherence. The Talbot-Lau interferometer can produce high-contrast fringes if the resonance condition (21) L 1 L 2 = d 1 d 2 − 1 (1)is met, even for a fully incoherent (l → 0) beam. However, as this regime is approached, the required accuracy at which the above condition should be ensured increases. To improve the tolerance to possible misalignments, we collimated the beam by means of two circular openings (Fig. 1). Regardless of beam coherence, the experimental uncertainty on the optimal (resonance) value of the ratio L 1 L 2 that stems from the errors on the measured grating periods amounts to σ L 1 / L 2 = 0.002 . In the adopted geometry, this corresponds to an uncertainty of 5 mm on the ideal detector location L 2 . To circumvent this issue, we operated emulsion films tilted by 45° in such a way that the Y coordinate of the emulsion plane is correlated to L 2 , which varies along the z axis in the laboratory reference frame (Fig. 1). We thus performed a position scan in a single exposure by analyzing different horizontal slices of the emulsion detector.
The relative rotational alignment of the two gratings is a critical parameter, as contrast follows a Gaussian modulation as a function of the ϕ angle formed by the slits, with standard deviation (25) σ ϕ = 1 2 π d 2 l det L 2 λ dB (2)where ldet is the coherence length computed at the detector plane by an analytical model (Materials and Methods) (25). Throughout the measurements, the ratio l det λ dB ∼ 800 remained approximately constant, which yielded a tolerance σ ϕ ~ 550 μrad for the collimated beam. The second grating was mounted on a piezoelectric rotation stage with nominal resolution of 0.8 μrad; the adopted alignment protocol (Materials and Methods) ensures that ϕ < 70 μrad for the full duration of the exposures. All the components of the interferometer, including the rotation stage, were nonmagnetic, and the interferometer was surrounded by a mu-metal shield designed to reduce residual Earth magnetic field to less than 0.5 μT. Parallelism between the interferometer optical axis and the beam propagation axis was controlled at the level of 1 mrad by means of alignment lasers. The apparatus operated at a vacuum pressure between 10−7 and 10−6 mbar during each measurement. We configured the interferometer for maximum contrast at E = 14 keV (λ dB = 10.3 pm) by setting L 1 = d 1 d 2 λ dB (21). Since this geometry satisfies the Talbot-Lau resonance conditions, single-slit diffraction from the first to second grating plane is not negligible (as it would instead occur for L 1 λ dB d 1 ≪ d 2 ). Therefore, a quantum-mechanical description of the system is required, which predicts a peculiar contrast dependence on the positron energy. To ensure uniform working conditions throughout the explored energy range, we used nuclear emulsions prepared without the standard surface protective gelatin layer. The presence of even a micrometric layer would have introduced detection efficiency (23) and positron trajectory smearing (24) that are both energy dependent. Thermally induced grains are the dominant source of background noise in emulsion detectors. Nonetheless, no measurable increase in the average density of noise grains was observed for the unprotected emulsions compared to standard detectors used under the same conditions.
We now summarize the results of five beam exposures performed for the positron energies of 16, 14, 11, 9, and 8 keV. Since the transport efficiency through the collimated L-NESS electrostatic beam decreases rapidly below 8 keV, lower energies would have required unpractically long exposure times. On the other hand, energies higher than 16 keV would have run into power supply stability and vacuum discharge limitations. The residual beam rate at the detector after collimation (~80% loss) and the passage through the gratings (~90% loss) was about 100 e+/s. Exposure times between 120 and 200 hours were required to accumulate sufficient statistics (about 2 × 107 grains in the analysis region). These time intervals were selected to match the total counts under the 511 keV annihilation peak on the calibrated HpGe detector (23) measured at 14 keV. Beam focusing was tuned to ensure that beam spot size, and hence the geometrical features of the beam such as angular divergence, did not appreciably vary with the energy. Spot sizes deviated by less than 10% from the average value of 6.5 mm FWHM on the detector plane. Silver bromide crystals activated by the passage of the positrons through the emulsion become visible with optical microscopes after chemical development; we then processed the emulsions at the microscope scanning facility of the University of Bern. For each given X-Y position, the microscope grabbed a series of images by shifting the focal plane in the direction normal to the emulsion surface (Z). Grain clusters were reconstructed (30) to assign X, Y, and Z coordinates to the positron impact point (see Fig. 2). The data were subdivided in 370 × 294 μm2 wide regions, which we refer to as views.
Fig. 2 Representative example of view analysis. All panels refer to the highest contrast view for E = 14 keV. (A) Three-dimensional distribution of the reconstructed clusters limited to a 100-μm-wide region along X. A hint of the periodic fringes is even appreciable by visual inspection. (B) Raw microscope image cropped to a region of 250 × 160 μm2. (C) Histogram of the Z position of the clusters and Gaussian fit used to determine the analysis region.
Each view was independently analyzed to search for periodicity in the impact point distribution by maximizing the so-called Rayleigh test function (31) R ( α , d 3 ) = | 1 n ∑ j = 1 n exp ( 2 π i X j ( α ) d 3 ) | (3)with respect to the period d 3 and the angle α between the fringes and the microscope reference frame. We introduced X j (α) as the X coordinate of the jth grain in the view rotated by α. The effectiveness of this period-finding approach was experimentally demonstrated for similar applications (24, 32). Values of the parameters maximizing R, namely, ( α * , d 3 * ) , were searched in the range −0.05 rad < α < 0.05 rad and 5.7 μm < d 3 < 6.1 μm. If a consistent periodic signal spanned a large area, then a distinctive peak would be expected in the ( α * , d 3 * ) distribution over the analyzed views (24). A representative example is shown in Fig. 3 for the 14-keV exposure. A least-squares Gaussian fit to the data (Fig. 3) yields the detected period for each exposure, which is reported in Table 1. The statistical error (68% confidence interval) comes from the fit procedure, whereas the estimated 0.8% systematic error descends from the conversion between camera pixels and physical size (24). The measured period is compatible with the expected value d 3 = (5.90 ± 0.04) μm. Once the optimal period and angle were found, a histogram of X j (α*) mod d 3 * was constructed, where mod is the modulo operation on floating point numbers. The signal contrast was estimated by fitting the histogram with a d 3 * -periodic sinusoidal function appropriate for the phase structure of the fringes (Fig. 4A). We performed the subtraction of a constant background from the histogram by measuring the grain density in the bulk, as positrons can only penetrate a few micrometers of emulsion. This yielded an estimate of the number of grains due to the intrinsic emulsion noise entering the analysis region. This is limited to 340 × 270 μm2 on the X-Y plane to remove areas affected by sizeable optical aberration. The depth in Z was determined with a Gaussian fit on the positron implantation profile (24). The average width of the selected region along the Z direction was 2.9 μm. We performed this procedure only for views contained in the 3σ elliptical region defined in Fig. 3. As the signal-to-noise ratio decreased moving away from the center of the beam spot, maximization of the Rayleigh test essentially converged to random values of ( α * , d 3 * ) for views outside the elliptical region; contrast estimation for these views would give unphysical results. The contrast measured after noise subtraction is, in principle, independent from the signal-to-noise ratio. An average noise density ranging from 9 to 6 grains/1000 μm3 was measured in the different exposures. The average number of grains per view entering the analysis fluctuated within 10% from the mean value of 11,000. A two-dimensional heatmap of the measured contrast covering the scanned surface area is shown in Fig. 4B. Since Y is correlated to L 2 , a contrast modulation was observed in the Y direction. The contrast dependence on X displayed a marked asymmetry, likely as a result of the limited beam coherence and alignment accuracy. We emphasize that this feature would have been hidden in a moving mask–based detection scheme. On the other hand, emulsions allowed direct fringe detection on a substantially larger area than the surface of the gratings (3 × 3 mm2): The scanned area contained a sizable number (~104) of consecutive high-visibility d 3 -periodic fringes. Visual inspection of the two-dimensional maps already suggests that contrast is decreasing with the energy. To provide a quantitative estimate of the peak contrast, we selected views in a 1-mm-wide region (indicated by the dashed lines in Fig. 4B). The corresponding contrast for energies in the range of 8 to 14 keV encompassing the largest contrast modulation is shown in Fig. 4A as a function of the position of the geometrical center of the view. This is given in the reference frame of the center of the beam along the Y axis, which was estimated by means of a Gaussian fit to the intensity profile. The position of the beam is stable in the laboratory reference frame at the level of 0.5 mm. However, this reference frame is more robust with respect to manual positioning errors of the emulsion in the interferometer and in the microscope reference frame, both of which can be larger than 0.5 mm. The data were fit with a Gaussian function plus a constant background (Fig. 4A), which was used to estimate the maximum contrast for each energy. This is shown in Table 1, alongside the position of the contrast peak (Y 0 ) extracted from the same fit. Uncertainties on the contrast were computed from the fit parameters, whereas the error on Y 0 is dominated by the estimated stability of the beam and by the uncertainty in determining its center.
Fig. 3 Optimal angle and period found via the Rayleigh test. Scatter plot and profile histograms of the optimal period and angle ( α * , d 3 * ) for 14 keV. A total of 1620 views covering a surface of about 10 × 14 mm2 were analyzed. Histograms are fit with a Gaussian function plus a constant background. The black ellipse indicates the corresponding 99.7% confidence level region. The corresponding plots for the other energy points are shown in fig. S2.
Table 1 Summary of the results at different energies. Measured fringe period d 3 , contrast C, and peak contrast position Y 0 , as discussed in the text. View this table:

Story 71
“Immigration Behind Shortage of Drinking Water in Northern Stockholm,” read one recent headline. “Refugee Minor Raped Host Family’s Daughter; Thought It Was Legal,” read another. “Performed Female Genital Mutilation on Her Children — Given Asylum in Sweden,” read a third.
Russia’s hand in all of this is largely hidden from view. But fingerprints abound.
For instance, one writer for Samhallsnytt, who previously worked for the Sweden Democrats, was recently declined parliamentary press accreditation after the security police determined he had been in contact with Russian intelligence.
Fria Tider is considered not only one of the most extreme sites, but also among the most Kremlin-friendly. It frequently swaps material with the Russian propaganda outlet Sputnik. The site is linked, via domain ownership records, to Granskning Sverige, called the Swedish “troll factory” for its efforts to entrap and embarrass mainstream journalists. Among its frequent targets: journalists who write negatively about Russia.
“We’ve had death threats, spam attacks, emails — this year has been totally crazy,” said Eva Burman, the editor of Eskilstuna-Kuriren, a newspaper that found itself in the cross hairs after criticizing the Russian annexation of Crimea and investigating Granskning Sverige itself.
At the magazine Nya Tider, the editor, Vavra Suk, has traveled to Moscow as an election observer and to Syria, where he produced Kremlin-friendly accounts of the civil war. Nya Tider has published work by Alexander Dugin, an ultranationalist Russian philosopher who has been called “Putin’s Rasputin”; Mr. Suk’s writings for Mr. Dugin’s think tank include one titled “Donald Trump Can Make Europe Great Again.”
Nya Tider’s contributors include Manuel Ochsenreiter, editor of Zuerst!, a German far-right newspaper. Mr. Ochsenreiter — who has appeared regularly on RT, the Kremlin propaganda channel — worked until recently for Markus Frohnmaier, a member of the German Bundestag representing the far-right Alternative for Germany party. Documents leaked to a consortium of European media outlets — documents that Mr. Frohnmaier has called fake — have suggested that Moscow aided his election campaign in order to have an “absolutely controlled MP.”
Mr. Ochsenreiter, for his part, has been implicated in Polish court in the financing of a 2018 firebombing attack on a Hungarian cultural center in Ukraine. The plot, according to testimony from a Polish extremist charged with carrying it out, was designed to pin responsibility on Ukrainian nationalists and stoke ethnic tensions, to Russia’s benefit. Mr. Ochsenreiter has not been charged in Poland, but prosecutors in Berlin said they had begun a preliminary investigation. He has denied involvement.

Story 72
Northwest Missouri State University's Ben McCollum is the 2019 recipient of the John McLendon Collegiate Basketball Coach of the Year award as presented by CollegeInsider.com.
McCollum led the Bearcats to a perfect 38-0 record and the NCAA Division II national championship. Northwest became only the fifth program to complete an undefeated season and capture the NCAA Division II national title.
LOOK BACK: Northwest's perfect run one of many memorable moments at DII Elite Eight | Recap
McCollum has guided the Bearcats to six straight MIAA regular season titles and four consecutive MIAA tournament crowns. In 10 seasons at Northwest, McCollum has an overall record of 241-75. In NCAA tournament play, McCollum has a mark of 19-5 with two national championships (2017, 2019).
The Storm Lake, Iowa, native is the first non-Division I head coach to receive the McLendon Award.
The John McLendon Award is presented annually to the top collegiate head coach and includes Division I, Division II, Division III, NAIA, and NJCAA.
DII HISTORY: Bearcats record fifth undefeated season | Programs with most titles
A trailblazer and one of the true pioneers of the game, McLendon became the first African American coach to win an integrated national championship. His team went on to win the NAIA Division I Men's Tournament in 1957, 1958 and 1959, making him the first coach in history to win three consecutive NAIA championships.
In 1962 he became the first African American head coach in a major professional league (ABL) with the Cleveland Pipers. In 1966 he became the first African American head coach of a predominantly-white university when he took over the Cleveland State program. He led the team to their best record in school history.
In 1969, McLendon was hired by the Denver Rockets and became the first African American head coach in the American Basketball Association. After a brief stint with the Rockets, McLendon ended his 25-year professional coaching career with a winning percentage of .760 and a lifetime career average of 523 victories and 165 losses.
Past McLendon Award recipients
Chris Beard's Red Raiders are real and ready to win
2018 – Chris Beard (Texas Tech)
2017 – Chris Holtmann (Ohio State)
2016 – King Rice (Monmouth)
2015 – Jim Engles (New Jersey Institute of Technology)
2014 – Gregg Marshall (Wichita State)
2013 – John Thompson (Georgetown)
2012 – Horace Broadnax (Savannah State)

Story 73
DENVER, April 12, 2019 /PRNewswire/ - Intermap Technologies has been awarded its first contract for its new, high-resolution aviation terrain dataset announced in December. An international drone operator which delivers medical supplies has signed a multi-year contract in which Intermap will deliver its new Lido/SurfaceData NEXTView terrain dataset to improve flight efficiency, navigation and safety. Intermap's location data will enable payloads to be delivered within a landing zone of less than 5-meters in remote environments, where mountainous geography and poor road conditions make an aerial delivery system most efficient.
NEXTView, developed through a partnership with Lufthansa Systems GmbH & Co KG, provides unprecedented global situational awareness for aviation applications. NEXTView combines high-resolution terrain, obstacle, and aerodrome information into a single coherent and uniform global dataset with military-grade acuity. NEXTView will be certified to relevant industry standards and covers 100% of Earth's land area with 3-meter vertical accuracy.
The NEXTView product is one of a suite of elevation-related software solutions based on the Intermap's very successful NEXTMap® elevation terrain dataset. Intermap has been steadily building its portfolio of analytic solutions, including flood-risk mapping and telecommunications link planning, to expand into broader markets. According to Patrick Blott, Chairman and CEO, "NEXTView will help our customer shorten flight times and reduce the chance of crashes, while delivering emergency medical supplies to rural populations. In many austere environments, drones can substantially cut costs and save lives. This high-tech supply chain can be faster and more reliable than traditional aviation or motor vehicle means, and our NEXTView product is advancing its mission to improve situational awareness, efficiency, and save lives."
"After over a year working together with Intermap, we developed this unique terrain product specially designed for the needs of the aviation industry. We are very happy that after testing our dataset, an international drone operator was convinced that this solution would suit their specific needs and signed a contract for Lido/SurfaceData NEXTView," said Fabio Fornallaz, Product Owner for Lido/SurfaceData at Lufthansa Systems.
About Intermap Technologies
Headquartered in Denver, Colorado, Intermap (TSX: IMP) (ITMSF: BB) is an industry leader in geospatial intelligence solutions. These geospatial solutions are used in a wide range of applications including, but not limited to, location-based information, risk assessment, geographic information systems, engineering, utilities, global positioning systems, oil and gas, renewable energy, hydrology, environmental planning, land management, wireless communications, transportation, advertising, and 3D visualization. Intermap generates revenue from three primary business activities, comprised of i) data acquisition and collection, using proprietary, multi-frequency, radar sensor technologies, ii) value-added data products and services, which leverage the Company's proprietary NEXTMap® database, together with proprietary software and fusion technologies, and iii) commercial applications and solutions, including a webstore and software sales targeting selected industry verticals that rely on accurate high resolution elevation data. The Company is a world leader in geospatial data management and processing, including fusion, analytics, and orthorectification, and has decades of experience aggregating data derived from a number of different sensor technologies and data sources. For more information please visit www.intermap.com.
About Lufthansa Systems GmbH & Co KG
Lufthansa Systems GmbH & Co. KG is a leading airline IT provider. Based on long-term project experience, a deep understanding of complex business processes and strong technological know-how, the company provides consulting and IT services for the global aviation industry. Over 350 airlines worldwide rely on the know-how of IT specialists at Lufthansa Systems. Its portfolio covers innovative IT products and services which provide added value for its customers in terms of enhanced efficiency, reduced costs or increased profits. Headquartered in Raunheim near Frankfurt/Main, Germany, Lufthansa Systems has offices in 16 other countries.
Intermap Reader Advisory
Certain information provided in this news release, including statements in relation to the Company's product development and revenue-generating activities constitutes forward-looking statements. The words "anticipate", "expect", "project", "estimate", "forecast", "will be" and similar expressions are intended to identify such forward-looking statements. Although Intermap believes that these statements are based on information and assumptions which are current, reasonable and complete, these statements are necessarily subject to a variety of known and unknown risks and uncertainties. Intermap's forward-looking statements are subject to risks and uncertainties pertaining to, among other things, cash available to fund operations, availability of capital, revenue fluctuations, nature of government contracts, economic conditions, loss of key customers, retention and availability of executive talent, competing technologies, common share price volatility, loss of proprietary information, software functionality, internet and system infrastructure functionality, information technology security, breakdown of strategic alliances, and international and political considerations, as well as those risks and uncertainties discussed Intermap's Annual Information Form and other securities filings. While the Company makes these forward-looking statements in good faith, should one or more of these risks or uncertainties materialize, or should underlying assumptions prove incorrect, actual results may vary significantly from those expected. Accordingly, no assurances can be given that any of the events anticipated by the forward-looking statements will transpire or occur, or if any of them do so, what benefits that the Company will derive therefrom. All subsequent forward-looking statements, whether written or oral, attributable to Intermap or persons acting on its behalf are expressly qualified in their entirety by these cautionary statements. The forward-looking statements contained in this news release are made as at the date of this news release and the Company does not undertake any obligation to update publicly or to revise any of the forward-looking statements made herein, whether as a result of new information, future events or otherwise, except as may be required by applicable securities law.
SOURCE Intermap Technologies Corporation
Related Links
www.intermap.com


Story 74
A new “flying taxi” has been unveiled by German start-up Lilium, which claims the vertical take-off craft could be the basis for an on-demand air service within six years.
The electric jet-powered five-seater aircraft is designed to travel up to 300km, a journey that would take it an hour at top speed.
While a smaller version of its novel plane flew in 2017, Lilium said that the maiden flight of a full-scale prototype earlier this month – a brief, remote-controlled test hover in Munich – was a “huge step”.
The firm, which has attracted more than €100m (£87m) in investment since its founding in 2015, has set a target of offering Uber-style, app-based air taxis in multiple cities by 2025.
The latest iteration, with room for a pilot and four passengers, will be the template for Lilium’s mass production model. With sufficient economy of scale, Lilium believes fares would be around $70 (£55) per head for a cross-city hop from, for example, JFK airport to Manhattan.
Facebook Twitter Pinterest Lilium’s founders, left to right, Sebastian Born, Patrick Nathen, Daniel Wiegand and Matthias Meiner. Photograph: Lilium
Daniel Wiegand, co-founder and chief executive, said: “We are taking another huge step towards making urban air mobility a reality. The Lilium Jet itself is beautiful and we were thrilled to see it take to the skies for the first time.”
According to Lilium, the relatively simple design, beyond the 36 electric jet engines needed for vertical take-off and landing, make it more safe and affordable than other planes. Once in the air, the power needed in cruise is little more than that of an electric car, Lilium says. The fixed wing design gives a longer range than competitors with drone-based aircraft, which consume much more energy keeping airborne.
Lilium will now seek certification for its new plane through rigorous flight testing, the next landmark being to move the jet seamlessly from vertical to horizontal flight.
Although many people might have reservations about Lilium’s stated ambition – “a world where anyone can fly wherever they want, whenever they want” – Wiegand said that the firm was trying to meet society’s demands for quiet, green urban air travel.
Remo Gerber, chief commercial officer, said the jet made around 20% of the noise of a helicopter: “You could utilise this in cities where people live, it’s totally electric powered ... This is very different.”
He said that the ambition for an app-based on demand service would not mean “landing in every garden... You’d be working with regulation around the world, integrating with public transport systems where they have them. We’re coming at a respectful way of thinking how people live, how we create corridors and not just fill the skies with these things.”
For people in rural Britain, for example, Gerber said, any disruption would compare favourably to building HS2: “You don’t have to cut through their lovely countryside. You need a little take-off pad and you’re connected to the whole country. Compare that to building roads or building train lines, it’s a fraction of the cost.”
The market for flying taxis could be worth $1.5tn by 2040, according to a Morgan Stanley analysis, and a host of other eVTOLS – or electric vertical take-off and landing craft – are in development around the world. Uber itself unveiled a very different-looking concept model earlier this year, while Airbus is developing its autonomous Vahana craft. Chinese drone manufacturer Ehang was confident enough to carry VIPs on a helicopter-shaped eVTOL in 2018.

Story 75
Results 347 incident cases of dementia were recorded over a median follow-up of 24.7 years. Compared with an incidence rate of dementia of 3.2 (95% confidence interval 2.5 to 4.0) per 1000 person years among the group with poor cardiovascular health, the absolute rate differences per 1000 person years were −1.5 (95% confidence interval −2.3 to −0.7) for the group with intermediate cardiovascular health and −1.9 (−2.8 to −1.1) for the group with optimal cardiovascular health. Higher cardiovascular health score was associated with a lower risk of dementia (hazard ratio 0.89 (0.85 to 0.95) per 1 point increment in the cardiovascular health score). Similar associations with dementia were observed for the behavioural and biological subscales (hazard ratios per 1 point increment in the subscores 0.87 (0.81 to 0.93) and 0.91 (0.83 to 1.00), respectively). The association between cardiovascular health at age 50 and dementia was also seen in people who remained free of cardiovascular disease over the follow-up (hazard ratio 0.89 (0.84 to 0.95) per 1 point increment in the cardiovascular health score).
Exposures The cardiovascular health score included four behavioural (smoking, diet, physical activity, body mass index) and three biological (fasting glucose, blood cholesterol, blood pressure) metrics, coded on a three point scale (0, 1, 2). The cardiovascular health score was the sum of seven metrics (score range 0-14) and was categorised into poor (scores 0-6), intermediate (7-11), and optimal (12-14) cardiovascular health.
Using data from the Whitehall II cohort study spanning nearly three decades, we aimed to investigate the association of cardiovascular health score assessed at age 50 with incidence of late life dementia; to assess whether cardiovascular health score at age 50 is associated with incidence of dementia in people who remain free of cardiovascular disease until diagnosis of dementia; and, in a subcohort of the Whitehall study, examine the association of cardiovascular health score at age 50 with brain volume assessed 20 years later using magnetic resonance imaging.
The cardiovascular health score has recently been put forward as a tool for the promotion of brain health. 7 In studies on older populations, a higher cardiovascular health score has been shown to be associated with slower cognitive decline and reduced risk of dementia, 8 although the evidence is inconsistent across studies. 9 10 11 An important source of uncertainty in the evidence is failure to consider the long preclinical period preceding the diagnosis of dementia. 1 In studies with a short follow-up, risk factor levels might be affected by the preclinical phase of dementia, as shown for obesity and hypertension, 12 13 which are two of the seven metrics included in the cardiovascular health score.
Pathophysiological hallmarks of dementia appear 15-20 years before clinical symptoms, 1 highlighting the need for a long follow-up to identify risk factors and protective factors. Guidelines for prevention of dementia recommend targeting midlife cardiovascular risk factors. 2 3 Much of the evidence is on individual cardiovascular risk factors considered one at a time, although the importance of their clustering is increasingly recognised. In 2010 the American Heart Association (AHA) proposed the ideal cardiovascular health score, also referred to as Life’s Simple 7, composed of four behavioural and three biological metrics for primordial prevention of cardiovascular disease. 4 People with higher cardiovascular health scores have a lower risk of cardiometabolic diseases, such as type 2 diabetes, coronary heart disease, and stroke, than do those with lower scores. 5 6
Participants of the Whitehall II study were not involved in setting the research question or the outcome measures, nor were they involved in developing plans for recruitment, design, or implementation of the study. No participants were asked for advice on interpretation or writing up of results. However, all results are disseminated to study participants via newsletters and our website, which has a participant portal ( https://www.ucl.ac.uk/epidemiology-health-care/research/epidemiology-and-public-health/research/whitehall-ii/participants-area ). The dissemination plan targets a large audience, including members of the public, patients, and health professionals, and will be achieved through various channels, including media outreach via press release from the Inserm and University College London, networks, and social media.
We ran the multi-state models by using the “mstate” package of R software. For all other analyses, we used Stata 15.1. We rejected the null hypothesis for two sided values of P<0.05.
In the magnetic resonance imaging analysis, we examined the association of cardiovascular health at age 50 with whole brain volume (sum of grey and white matter), grey matter volume, and white matter volume, as well as with levels of white matter hyperintensities and hippocampal atrophy on average 20 years later by using linear regression adjusted for age at magnetic resonance imaging assessment, the magnetic resonance imaging scanner, and sociodemographic factors at age 50.
In subsequent analyses, we used multi-state models to examine the role of cardiovascular disease (incident coronary heart disease or stroke) over the follow-up in the association between cardiovascular health score at age 50 and risk of dementia. These models allow simultaneous estimation of the association of cardiovascular health score at age 50 with risk of cardiovascular disease over the follow-up (transition A), the association of cardiovascular health score at age 50 with risk of dementia in people without cardiovascular disease over the follow-up (transition B), and the association of cardiovascular health score at age 50 with risk of dementia following diagnosis of cardiovascular disease (transition C). As in the previous analyses, models were adjusted for sociodemographic factors and weighted using inverse probability weighting.
We used inverse probability weighting to account for missing data on cardiovascular health metrics. 21 This involved calculation of the probability of being included in the analytical sample by using data on the seven cardiovascular health metrics, sociodemographic factors, chronic conditions (coronary heart disease, stroke, diabetes, chronic obstructive pulmonary disease, cancer), and dementia status over the follow-up, including the interactions between dementia status and the cardiovascular health metrics. We used the inverse of these probabilities to weight the results from the Cox regression.
We examined the association of cardiovascular health score at age 50 with risk of incident dementia by using Cox regression with date of entry being the date of clinical examination at age 50. We followed participants to the date of record of dementia, death (to account for competing risk of mortality), or 31 March 2017, whichever came first. We first examined the shape of the association of the continuous cardiovascular health score with risk of dementia by using restricted cubic spline regressions with Harrell knots, 19 Stata command xblc, 20 with score 9 (mean cardiovascular health score) as the reference (hazard ratio=1). In addition, we examined the association with the cardiovascular health score categorised as poor (score 0-6), intermediate (score 7-11), and optimal (score 12-14) and then used cardiovascular health score as a linear variable to examine the risk reduction associated with a 1 point increment. We repeated the analysis for an increment of one additional cardiovascular health metric at the optimal level and for the behavioural and biological subscale scores. We used age as the timescale and adjusted analyses first for sex, ethnicity, educational level, occupational position, and marital status and then for time dependent cardiovascular disease. For the subsample with available data on apolipoprotein E ε4 genotype, we also adjusted for this variable.
Between 2012 and 2016, a magnetic resonance imaging substudy was implemented in 771 participants of the Whitehall II study. Details of the imaging protocol and the analysis pipelines have been published previously. 16 In brief, multimodal magnetic resonance imaging scans were acquired at the Oxford Centre for Functional MRI of the Brain (FMRIB Centre) by using a 3-tesla magnetic resonance imaging scanner (MAGNETOM Verio; Siemens Healthineers, Erlangen, Germany) with a 32 channel head coil. Structural images were acquired using a high resolution, three dimensional, T1 weighted sequence (repetition time 2530 ms, echo time 7.37 ms, flip angle 78 degrees, field of view 256 mm, voxel dimensions 1.0 mm isotropic). Data processing and analysis of magnetic resonance imaging was done using FMRIB Software Library (FMRIB, Oxford, UK). Brain tissues were segmented using FMRIB’s automated segmentation tool, which allows extraction of measures of total grey matter, white matter, and cerebrospinal fluid, which were summed to calculate intracranial volume. All volumes were normalised by converting them to percentages of the intracranial volume. Burden of white matter hyperintensities was estimated by using the Fazekas visual rating scale. 17 A score (range 0-3) was assigned for deep white matter and periventricular areas depending on the size, location, and confluence of lesions. Total burden of white matter hyperintensities was estimated by using the sum of the two scores (range 0-6). Three clinicians independently defined hippocampal atrophy according to visual rating (Scheltens score, 18 range 0-8) and reached a consensus.
Covariates assessed at age 50 included exact age, sex, ethnicity (white, non-white), marital status (married/cohabiting, other), and socioeconomic status according to occupational position (high, intermediate, and low, representing income and status at work) and education (less than primary school (up to age 11), lower secondary school (up to age 16), higher secondary school (up to age 18), university, and higher university degree). In sensitivity analysis, we also used data on apolipoprotein E ε4.
Coronary heart disease was identified by study specific assessments (12 lead resting electrocardiogram recording, coded using the Minnesota system), self reported coronary heart disease (verified in medical records), and linkage to HES (ICD-9 codes 410-414, ICD-10 codes I20-I25, or procedures K40–K49, K50, K75, U19). Stroke was determined using linkage to HES (ICD-9 430, 431, 434, 436; ICD-10 I60-I64).
All residents in England, Scotland, and Wales have a unique National Health Service (NHS) identification number, which we used to link all participants to electronic health records. We used three registers (the national hospital episode statistics (HES) database, the Mental Health Services Data Set, and the mortality register) for ascertainment of dementia using ICD-10 (international classification of disease, 10th revision) codes F00-F03, F05.1, G30, and G31. Record linkage was available until 31 March 2017. The NHS provides most of the healthcare, including outpatient and inpatient care. The sensitivity of dementia in the HES data is 78.0%, and the specificity is 92.0%. 15 In addition, we used the Mental Health Services Data Set, a national database containing information on dementia for people in contact with mental health services in hospitals, outpatient clinics, and the community. Cause specific mortality data came from the British national mortality register (National Health Services Central Registry). Date of dementia was set at the first record of diagnosis of dementia in any of the three databases used for ascertainment.
We calculated a behavioural score as the sum of the behavioural metrics (smoking, physical activity, diet, body mass index) ranging from 0 (worst) to 8 (best) and a biological score as the sum of the biological metrics (glucose, cholesterol, blood pressure) ranging from 0 (worst) to 6 (best), as recommended by the AHA. 4
We used the sum of each metric to calculate the cardiovascular health score, ranging from 0 to 14 with higher scores corresponding to better cardiovascular health. We categorised this score as poor for scores ranging from 0 to 6 (corresponding to less than one standard deviation from the mean), intermediate for scores ranging from 7 to 11 (+/−1 SD from the mean), and optimal for scores between 12 and 14 (>1 SD from the mean). We also derived the number of cardiovascular health metrics at optimal level, ranging from zero (none) to seven (all metrics at optimal level).
We categorised all metrics into three levels (coded as poor=0, intermediate=1, and optimal=2), following the AHA’s recommendations, 4 apart from smoking and diet, for which we adapted the categorisation to reflect data available in the study ( table 1 ). For smoking, we split ex-smokers into optimal and intermediate levels depending on whether they had stopped smoking before or after the previous wave of data collection (corresponding to a four to five year gap, instead of one year). For the diet metric, we used information on consumption of fruit and vegetables and type of bread, as this information was available from all waves of data collection.
Smoking status (current, past, never), physical activity (hours of moderate and vigorous physical activity per week), and diet (fruit and vegetable consumption, types of bread) were assessed using questionnaires. A trained nurse used standard protocols to collect data on body mass index (weight/height 2 in kg/m 2 ), fasting glucose concentration, blood cholesterol concentration, and blood pressure during the clinical examination. Blood pressure was taken as the mean of two measurements using a Hawksley random zero sphygmomanometer (1985, 1991, and 1997) and OMRON HEM 907 (2002) with the participant in a sitting position after five minutes of rest. Weight was measured in underwear to the nearest 0.1 kg on Soehnle electronic scales with digital readout (Leifheit, Nassau, Germany), and height was measured in bare feet to the nearest 1 mm by using a stadiometer with the participant standing erect with the head in the Frankfurt plane. Venous blood samples were taken after at least five hours of fasting, and serum obtained after centrifugation was refrigerated at 4°C and assayed within 72 hours of the blood draw. Total cholesterol was measured using a Cobas Fara centrifugal analyzer (Roche Diagnostics, Nutley, NJ).
We used data collected at the first four clinical examinations of the study (1985 (age range 35-55 years), 1991 (40-64 years), 1997 (45-69 years), and 2002 (50-74 years)) to extract information on the seven cardiovascular health metrics at age 50 for every participant, allowing a five year margin either way.
The Whitehall II study is an ongoing cohort study of 10 308 people (6895 men and 3413 women, aged 35-55) recruited from the British civil service in 1985-88. 14 Baseline assessment consisted of a questionnaire and a structured clinical evaluation composed of measures of anthropometric, cardiovascular, and metabolic risk factors and diseases. Subsequent follow-up clinical examinations have taken place approximately every four to five years (1991, 1997, 2002, 2007, 2012, and 2015), with each wave taking two years to complete. Written informed consent from participants was renewed at each contact.
Among 771 participants who had magnetic resonance imaging assessment, data on cardiovascular health at age 50 were available for 708 participants (569 (80.4%) men, mean age at assessment 69.9 (SD 5.1) years). One year higher age was associated with 0.33% (95% confidence interval 0.30% to 0.36%) lower whole brain volume, 0.25% (0.22% to 0.28%) lower grey matter volume, 0.08% (0.06% to 0.10%) lower white matter volume, 0.09 (0.07 to 0.10) points higher white matter hyperintensities on the Fazekas scale, and 0.11 (0.09 to 0.13) points greater hippocampal atrophy on the Scheltens score. Higher cardiovascular health score (per 1 point increment in the cardiovascular health score) was associated with 0.14% (0.06% to 0.22%) higher total brain and 0.12% (0.06% to 0.19%) higher grey matter volumes ( table 4 ), corresponding to an age effect of 5.1 months on whole brain volume and 5.8 months on grey matter volume. Higher cardiovascular health score was associated with lower hippocampal atrophy, but the results did not reach statistical significance (P=0.07).
Multi-state models for role of cardiovascular health (CVH) score in transitions between start of follow-up, cardiovascular disease, and dementia. Top: hazard ratio (HR) per 1 point increment in CVH score. Bottom: HR per each additional CVH metric at optimal level (range 0-7). HRs and 95% CIs were estimated using inverse probability weighted multi-state models with age as timescale and adjusted for sex, ethnicity, education, occupational position, and marital status. No of cardiovascular disease (CVD; coronary heart disease or stroke) cases among healthy participants=1570/7899 (transition A); No of dementia cases among healthy participants=222/7899 (transition B); No of dementia cases among participants with CVD over follow-up=125/1570 (transition C)
Before use of multi-state modelling transitions between health states, we examined the association between cardiovascular disease and incidence of dementia. As expected, cardiovascular disease was associated with a higher risk of incident dementia (hazard ratio 1.96, 1.56 to 2.48) in a Cox regression with cardiovascular disease treated as a time dependent variable (data not tabulated). Figure 3 shows results from multi-state models in participants free of dementia and cardiovascular disease at age 50 (n=7899). A 1 point increment in the cardiovascular health score was associated with a reduced risk of incident cardiovascular disease over the follow-up (transition A: hazard ratio 0.87, 0.85 to 0.89). Among people free of cardiovascular disease before diagnosis of dementia, a 1 point increment in cardiovascular health score was associated with a lower risk of dementia (transition B: hazard ratio 0.89, 0.84 to 0.95), suggesting that the association between cardiovascular health and dementia is not fully explained by clinically manifest cardiovascular disease. In those with cardiovascular disease over the follow-up, cardiovascular health score at age 50 was not associated with risk of dementia following diagnosis of cardiovascular disease (transition C: hazard ratio 0.98, 0.91 to 1.06).
In an analysis using the seven cardiovascular health metrics at optimal levels, and adjusted for sociodemographic factors, the hazard ratio for dementia for each additional metric at optimal level was 0.88 (0.79 to 0.97). Both the behavioural and biological subscale scores were associated with incidence of dementia (hazard ratio per 1 point increment 0.87 (0.81 to 0.93) and 0.91 (0.83 to 1.00), respectively), and we found no evidence of an interaction between the two (P=0.32). On further analysis in 4996 participants with relevant data available, results remained similar after additional adjustment for apolipoprotein E ε4 (supplementary table B).
Association between continuous 14 point cardiovascular health score and incidence of dementia. Hazard ratio (95% CI) was estimated using inverse probability weighted Cox regression model with age as timescale and adjusted for sex, ethnicity, education, occupational position, and marital status, with a score of 9 (mean) as reference (hazard ratio=1)
As we found no evidence of effect modification by sex (P for interaction=0.42), we did analyses in men and women combined, with adjustment for sex. We verified the proportional hazard assumption by using Schoenfeld residuals and Kaplan-Meier curves (supplementary figure A). Figure 2 shows the association between the 14 point cardiovascular health score and risk of dementia to be linear (P for non-linearity=0.26). Further analyses using cardiovascular health score categorised in three groups showed the incidence rate of dementia to be lower in the intermediate and optimal cardiovascular health groups than in the poor cardiovascular health group ( table 3 ). Compared with an incidence rate of dementia of 3.2 (95% confidence interval 2.5 to 4.0) per 1000 person years among the group with poor cardiovascular health (scores 0-6), the absolute rate differences per 1000 person years were −1.5 (95% confidence interval −2.3 to −0.7) for the group with intermediate (7-11) and −1.9 (−2.8 to −1.1) for the group with optimal (12-14) cardiovascular health. In an analysis adjusted for sociodemographic factors, compared with the poor cardiovascular health category, intermediate and optimal categories of cardiovascular health were associated with lower risk of dementia (hazard ratio 0.61 (0.47 to 0.80) and 0.57 (0.36 to 0.90), respectively; table 3 ). The hazard ratio for dementia for an increment of 1 point in the cardiovascular health score was 0.89 (0.85 to 0.95). Additional adjustment for cardiovascular disease as a time varying variable slightly attenuated this association (hazard ratio 0.91 (0.86 to 0.97) per 1 point increment in the cardiovascular health score).
Among the 7899 study participants, a total of 347 cases of dementia were recorded over a median follow-up of 24.7 (interquartile range 19.1-29.3) years. Mean age at diagnosis of dementia was 75.3 (SD 5.3; interquartile range 72.3-79.4) years. Table 2 shows characteristics of the study sample at age 50. The proportion of women, non-white participants, and participants in the lower socioeconomic group was higher in the group of dementia cases compared with participants who did not develop dementia during follow-up. Participants with higher cardiovascular health score, denoting better health, were more likely to be male, white, married/cohabiting, and from the higher educational and occupational groups. Further distribution of the cardiovascular health metrics and by categories of the cardiovascular health score are shown in supplementary table A.
Among the 9740 participants free of cardiovascular disease and dementia at age 50 (target population), data on all cardiovascular health metrics at age 50 (mean age at assessment 50.4 (SD 2.3) years) were available for 7899 participants ( fig 1 ). Compared with those not included in the analysis (n=1841), study participants were older at baseline (45.3 v 41.6 years) and were more likely to be men (67.6% (n=5337) v 64.2% (n=1182)) and to develop dementia over the follow-up period (4.4% (n=347) v 3.3% (n=61)) (all P<0.05), leading us to use inverse probability weighting to take these differences into account in the analyses.
Discussion
This longitudinal study based on 7899 men and women has three key findings. Firstly, the American Heart Association’s cardiovascular health score assessed at age 50 was associated with subsequent risk of dementia over a 24.7 year median follow-up period, with lower risk observed for both intermediate and optimal scores compared with poor scores. The associations were evident for the continuous cardiovascular health score as well as the behavioural and biological scores, suggesting that both these subscales contribute to dementia risk. Secondly, the association between cardiovascular health at age 50 and subsequent dementia was also observed among people without coronary heart disease or stroke during the follow-up period. Thus, cardiovascular disease events do not fully account for the association between cardiovascular health and dementia. Thirdly, findings were corroborated in results using magnetic resonance imaging data for a subcohort. Higher cardiovascular health score at age 50 was associated with higher whole brain and grey matter volumes 20 years later.
Strengths and limitations of study We assessed cardiovascular health close to age 50 (mean age 50.4 (SD 2.3) years, age range 45-55). Much of the previous evidence on “midlife” risk factors has used a wide age range, sometimes as large as 20 years, from a baseline assessment to draw conclusions on the importance of midlife factors. This is particularly problematic for research on dementia, as risk factor levels change during the long preclinical period of dementia,1 which can lead to findings that are affected by reverse causation.121322 Key strengths of this study include use of a study design that allowed us to assess cardiovascular health metrics at age 50, a long follow-up for incidence of dementia, the use of multiple statistical methods to control for bias and confounding,21 and inclusion of data from the Whitehall II magnetic resonance imaging substudy. A key limitation, as in any observational study, is the self reported measure of behavioural factors and drug use. The Whitehall II study is an occupational cohort at recruitment, and participants are healthier than the general population in terms of risk factors levels and incidence of disease. However, this does not necessarily affect risk factor-disease associations.23 For example, the association between cardiovascular risk factors and incidence of cardiovascular disease in the Whitehall II study is similar to that in general population studies.24 Use of linkage to electronic health records for ascertainment of dementia may not be the “gold standard” method but has the advantage of allowing analysis on everyone recruited to the study rather than only those who continue to participate over the course of the study and are available for an in-person clinical ascertainment of dementia. In the UK, HES records on dementia have been shown to have high specificity but modest sensitivity (78%) due to missing of milder cases of dementia,15 as also reported in the Mayo Clinic Study of Ageing and the Adult Changes study.25 We additionally used the UK mental health database to improve the sensitivity of dementia diagnosis.26
Comparison with previous studies Few previous studies have examined the association between cardiovascular health and cognitive outcomes, and most were based on older adults who were followed for cognitive outcomes for less than 10 years. These studies reported better cardiovascular health to be associated with lower risk of cognitive impairment,27 cognitive decline,89 and dementia.810 In the Atherosclerosis Risk in Community (ARIC) cohort, higher cardiovascular health scores assessed at mean age 54 (SD 6) years were associated with slower cognitive decline over a 20 year follow-up period.28 In participants from the Framingham Heart Study Offspring cohort, the association with risk of dementia was observed when risk factors were assessed at a mean age of 62 (SD 6) years but not when assessed at a mean age of 69 (6) years.10 In a study on people with a mean age of 67 (8) years at cardiovascular health assessment, no association was found with incidence of dementia over a seven year mean follow-up.11 One explanation for this inconsistency is that studies that assess risk factors at older ages are more likely to be affected by reverse causation bias than are those with this assessment in midlife, a possible explanation for null findings in recent studies on cardiovascular health and dementia.1011 Evidence shows that the associations of body mass index, blood pressure, and cholesterol with dementia are attenuated or even reversed at older ages.111213293031 Few studies, mostly cross sectional, have examined the association between cardiovascular health and brain imaging.10263233 Cardiovascular health has been shown to be associated with whole brain volume,1032 although findings on specific markers are less consistent.10263233 White matter hyperintensities, particularly in the deep white matter, are usually interpreted as “microvascular changes” that are associated with vascular risk in general.34 We found no association with cardiovascular health, which is consistent with some but not all previous studies.10323335 The large heterogeneity in population settings (mean age ranged from young adulthood to older age), as well as the type of brain imaging analysis, might explain inconsistent findings. Further investigations are thus needed to confirm specific brain correlates of cardiovascular health.
Meaning of study The AHA’s recently defined concept of “ideal cardiovascular health” by presence of all seven metrics at an ideal level is useful for the primordial prevention of cardiovascular disease, as shown in several studies.5 In our data, each additional cardiovascular health metric at optimal level was more strongly associated with a lower risk of cardiovascular diseases than was a 1 point increment in the more refined 14 point cardiovascular health score (fig 3, transition A). As a similar tool does not exist for dementia, we used the cardiovascular health metrics at an optimal level and the 14 point cardiovascular health score. Our results showed reductions in the risk of dementia across the continuum of the 14 point cardiovascular health score, highlighting the importance of clustering of cardiovascular risk factors in midlife for risk of dementia at older ages. Each 1 point increment in the 14 point cardiovascular health score was associated with a similar reduction in the risk of dementia to each additional cardiovascular health metric at an optimal level (seven metrics). Use of a finely graded 14 point scale, which also considers each metric at an intermediate level, suggests that even small improvements in cardiovascular health metrics, without necessarily reaching the optimal level for each metric, are likely to be beneficial in reducing the risk of dementia. From a public health perspective, moving from a poor to an intermediate level in cardiovascular health metrics is perhaps more achievable and sustainable in the long term than moving from a poor to an optimal level. In addition, both the behavioural and biological subscales of the cardiovascular health score were associated with incidence of dementia, and the absence of an interaction between the two subscales highlights the importance of the behavioural score at all levels of the biological subscale, including among people without biological risk factors at age 50. Dementia has a multifactorial aetiology, and accordingly multidomain interventions targeting several risk factors simultaneously have been recommended for prevention.36 Although the cardiovascular health metrics were not originally developed for the prevention of dementia, results from this observational study suggest that their assessment in midlife could be used for identification of groups at increased risk of dementia and that interventions targeting cardiovascular risk factors in midlife might additionally decrease the risk of dementia.37 Use of multi-state models in this study showed a robust association between cardiovascular health and incidence of dementia in participants free of major cardiovascular disease over the follow-up. Possible mechanisms by which cardiovascular health is associated with risk of dementia therefore include mechanisms beyond occlusion of major arteries, such as cerebral small vessel lesions, hypoxia, microinfarctions, inflammation, oxidative stress, and advanced glycation end products.37 The precise pathway through which vascular and degenerative processes determine risk of Alzheimer’s disease and dementia is likely to be complex. Our results showing cardiovascular health assessed at age 50 to be associated with dementia and brain volume 20 years later are in agreement with previous studies based on shorter follow-up.1033 These results highlight the importance of the cardiovascular health score in promoting brain health at older ages.

Story 76
Access Denied - Sucuri Website Firewall
If you are the site owner (or you manage this site), please whitelist your IP or if you think this block is an error please open a support ticket and make sure to include the block details (displayed in the box below), so we can assist you in troubleshooting the issue.
Block details:

Story 77
PITTSBURGH — It's been quite the night already here in PPG Paints Arena, and, against a two-time national champion, Virginia Tech's Mekhi Lewis decided it was time to write some history of his own.
The redshirt freshman had never been to the NCAA tournament, never mind an NCAA final, before this year. He worked his way through the 165-pound bracket, pinning Cam Coy of Virginia and beating Cael McCormick of Army before pulling off one of the biggest upsets of the quarterfinals and taking down No. 1-seeded Alex Marinelli. That win made headlines and sent the 2019 Big Ten champion down to the consoles where he would ultimately finish seventh. Lewis, however, was still alive on the championship side, and he was just getting started.
NCAA TOURNAMENT: Relive all of the best moments so far from the 2019 NCAA wrestling tournament
SHOP OFFICIAL 2019 CHAMPIONSHIP GEAR
In the semifinals, the first-time All-American Hokie took on Evan Wick of Wisconsin, last year's third-place finisher, and pulled off a 5-2 upset win. The No. 8 seed was heading to the finals.
Mekhi Lewis vs. Vicenzo Joseph. The names rolled off the announcers tongue as the finals started in the exact dramatic way they should to start a championship final. It was time for Lewis to test himself again.
Lewis came out a mission and took the defending champ to task. An early cradle nearly put Joseph on his back, but the Nittany Lion survived, only to be taken down again. A physical battle and a relentless spirit from the true freshman overpowered the Penn State junior, and Lewis, to the delight of his fan base in the stands, became a national champion.
HIGHLIGHT REEL: These are the most insane moves we've seen so far at the 2019 wrestling tournament
"It means a lot, because Virginia Tech wrestling has been really good," Lewis said after his match. "It's just that we never really had good Finals, good end results. So to be the first one is really special. It means a lot to me. Just so happy that I'm a part of the program."
Knowing that he was going down in the Hokie history books forever, Lewis showed pure elation standing on the podium, almost as if he couldn't believe what had just really happened.
"Everybody, other than my teammate's, family and coaches and fans, thought I was the underdog. I didn't think I was the underdog. I just thought people didn't get the chance to see me wrestle at a big stage, like, folkstyle, because they only saw freestyle," Lewis said. "And I just felt like I was like I was prepared and ready to win a national title. So I felt equal to everybody I wrestled."
Turns out, he wasn't equal, he was better. Go ahead and add Virginia Tech to the list of schools with national champions. The Hokies have Lewis to thank for that.

Story 78
A July 1859 edition of the Amherst Express reports on the first intercollegiate baseball game (and accompanying chess match), played between Williams and Amherst.
Any fan of baseball knows there’s plenty of controversy surrounding the origin of the game.
The sport’s hall of fame resides in Cooperstown, New York, where legend has it that Abner Doubleday invented America’s pastime in 1839. But there is very little evidence for that story. The game likely dates back to the 18th century, though the modern format set forth by the Knickerbocker rules didn’t arrive until 1845.
So naturally, there’s some debate as to how college baseball got started as well.
Regardless of which side of the debate you fall on, there’s no questioning that the first ever college baseball game took place in 1859 — 44 years before the first World Series.
MORE HISTORY: What we know about the first college basketball game ever played
On July 1 of that year, Amherst College and Williams College met in Pittsfield, Massachusetts, for the first-ever game of baseball between to colleges.
But the game was played under Massachusetts rules, which look wildly different than the baseball we know today.
Under Massachusetts rules, the playing field was a square with no foul territory, with the “striker” setting up on a line halfway between first base and home base. The bases were wooden stakes, projecting four feet from the ground, 60 feet apart from each other.
There were no balls in pitching. If a striker swung at a pitch and missed, he received a strike. But if he repeatedly decided not to swing at good pitches in an attempt to delay the game, the referee would give a warning, and then start awarding strikes if he continues.
One of the most significant differences under Massachusetts rules was the ability to get a runner out by throwing the ball at him and hitting him. Seems just slightly dangerous.
Williams and Amherst agreed that the game would be played to 65 “tallies” (or runs), and that each team would consist of 13 players. And since each inning lasted for only one out, the game went for 25 innings before the 65-run mark was met.
Williams took an early 9-2 lead in the game, but Amherst was the first to 65. Yet they didn’t stop there. Due to a lack of a mercy rule, they piled on eight more runs before the final out, going on to win 73-32.
And for good measure, the two teams played a chess match afterwards, which Amherst also won.
Here are a couple fun excerpts from the Amherst Express' article about the game:
"At the commencement of this term, it was privately proposed among the Amherst students to challenge Williams College to a game of Ball.
"The challenge was readily accepted, and in turn Williams challenged to a game at Chess, that there might be 'a trial of mind as well as muscle.'
"26th (inning): Gridley ticked out, caught by Anderson, (W) out by player unknown. The last inning. The Amherst boys ran around, entirely regardless of danger or appearances. They made their bases as if they were thinking of 75 tallies, which was the number proposed by them for the game. However they only reached 73 in the inning, which was 8 more than the limit of the score. The game closed at 2 1/2; o'clock, having lasted 3 1/2; hours."
Now, there's little doubt that the Williams vs. Amherst game was the first intercollegiate baseball game. But there was another game in 1859 that can make an argument for the first true college baseball game.
On November 3, 1859, the St. John’s College Fordham Rose Hill Baseball Club (now known as Fordham University) played against St. Francis Xavier College.
MORE BASEBALL: The 9 winningest college baseball teams in NCAA history
This was the first college game played under more modern rules, with only nine players to a side, foul territory, three outs per inning, and just six innings. Oh, and no throwing at a runner to get him out.
Fordham would win the game 33-11, starting a tradition for the Rams, who would go on to become the winningest program in college baseball history, sitting at 4,479 wins through the 2018 season (almost 1,000 more than the next-best team, Texas).


Story 79
Liverpool summer signing, Dutch wonderkid Sepp van den Berg, will make his first start tonight since joining from PEC Zwolle.
Jurgen Klopp beat several other top European clubs to his signature, knowing the centre-back has plenty of potential.
instagram 4 Van den Berg is the latest Dutch defensive wonderkid to make a name for himself
The 17-year-old made 15 appearances in the Eredivise last season for Zwolle, who finished in a respectable 13th place.
Nicknamed Ed Sheeran by his team-mates thanks to his shock of red hair, he comes from sporting stock with his father playing tennis to a decent level and his mother playing volleyball for the Dutch youth team, while his sister plays hockey and his younger brother, Rav, is also a talented member of the Zwolle academy.
Van den Berg is starting Liverpool’s Carabao Cup tie against Arsenal this evening and below talkSPORT.com gives an in-depth insight into all you need to know about him…
LATEST FOOTBALL STORIES off the mark Chris Smalling scores first goal for Roma since joining from Man United disgraceful Fan rages at ‘clueless’ Emery after ‘shambolic’ Arsenal lose to Liverpool teens VERDICT Mourinho is 'exactly what Spurs need' and can take them to 'elite level' - Durham ALMOST HAPPENED Origi to blame for denying Emery the chance to win by 'preferred' scoreline unexpected Mustafi shows Xhaka how to address Arsenal fans following a bad performance CLASSY Tierney 'already gets it' as Arsenal man is praised for actions after Liverpool loss selfless Barca players offered to alter contracts so club could sign Neymar, says Pique Homecoming 'It would be amazing' - Milner discusses Leeds return before retiring SPYGATE II? FA demands Man City 'Spygate' answers from Liverpool GOSSIP Liverpool to sign Werner, Man United eye £45m striker, Pochettino wanted by Bayern Play him Unai Emery told by Jamie Carragher he must put Mesut Ozil in his Arsenal XI Praise Solskjaer hails Rashford’s ‘Cristiano Ronaldo-like’ free-kick against Chelsea
Sepp van den Berg - 2018/19 Minutes played: 906
Pass completion rate: 88.4%
Tackles per game: 1.3
Clearances per game: 2.7
Passes per game: 36.2
Interceptions per game: 0.8
Could Van den Berg be the next Joe Gomez?
Klopp’s goal is to repeat the success story of Joe Gomez, who played a major role in Liverpool’s success during last year’s campaign.
The young Englishman signed for the Reds in 2015, for a fee £3.5million but it was not until the 2017/18 season that the 22-year-old’s career really took off.
Were it not for a succession of injuries, Gomez could already be one of the Premier League’s best centre-backs; his partnership with player of the season Virgil van Dijk was one that excited Liverpool fans.
getty 4 Van Dijk and Gomez formed a great partnership last season
The Van Dijk and Gomez combination in defence conceded only six goals in 1,373 minutes of football – a record that brings them close to that of the best ever defensive partnership in Premier League history, according to statistics – Jamie Carragher and Daniel Agger.
Reds fans will hope history will repeat itself with the arrival of Van den Berg, who would be a welcome addition to the already proven backline that kept an impressive 21 clean sheets in the Premier League last time out.
Liverpool fan Dan reckons the Premier League is rigged against the Reds
Career so far?
In early 2018, the teenager was named Zwolle’s youth player of the month for December and a professional contract was offered to him in February.
Zwolle technical director Gerard Nijkamp committed to a ‘step-by-step plan’ set up to ‘connect the player to the club so he can develop further’.
The defender’s debut came in a defeat against FC Groningen in March and he went on to start five of the final seven games of the season.
In September, Van den Berg broke the record previously held by Clarence Seedorf to become the youngest player to play at least ten games in the Eredivise.
getty 4 Joe Gomez’s Liverpool career has been beset by multiple injuries
In the following season the 17-year-old’s first team opportunities dried up considerably with the appointment of Jaap Stam as manager, but the composed centre-back still managed to record Zwolle’s second highest pass completion rate of 88.4%.
Football writers from the Netherlands have marked out the youngster’s pace as defining feature of his game.
Once a winger, the now centre-half has the unique ability to make defensive recovery challenges due to his lightning pace.
Getty Images 4 Jurgen Klopp may have found another gem
The youngster readily admits he’s not the finished article, and he’s currently on a nutritional plan to try and help him bulk up a little, which he conceded meant his mother was doing a little more cooking than usual.
Team-mate Dirk Marcellis said of Van den Berg: “What I have known is a smart player, who knows how to read situations in advance, as well as being very fast. He is an already reliable defender, with great consistency of performance.”
Meanwhile, fellow Dutch wonderkid Matthijs de Ligt has offered advice to Van den Berg, saying: “I think Sepp is a great talent and I hope he continues to grow.
“The advice I can give him is to keep his feet on the ground and surround himself with the right people.”

Story 80
Here's 5 FBS games to watch in week one
Here's 5 FBS games to watch in week one
Since Clemson beat Alabama in January, we’ve all been wondering the same thing: When does the 2019 college football season start?
The wait is over. College football returned on Aug. 24.
WHAT TO KNOW FOR NEXT SEASON: Preseason Top 25 rankings for 2019
The first FBS game on Aug. 24 was Florida vs. Miami (Fla.) in Orlando. The No. 8 Gators, who finished 10-3 last year, topped the rival Hurricanes 24-20 in a back-and-forth affair.
Following that, we saw some Pac-12 vs. Mountain West action as Hawaii defeated Arizona 45-38. Rainbow Warriors wide receiver Cedric Byrd caught four touchdowns in addition to racking up a career-high 14 catches and 224 yards.
But "Week 0" really began with FCS games earlier on Aug. 24. College football season officially started when Villanova topped Colgate 34-14 and Youngstown State ran past Samford 45-22.
Week 1 of the college football season features games Thursday through Monday, Aug. 29-Sept. 2.
COLLEGE FOOTBALL PLAYOFF: College Football Week 1 TV schedule
Here’s a look at some notable Week 1 matchups.
Thursday, Aug. 29
Friday, Aug. 30
Saturday, Aug. 31
Sunday, Sept. 1
Houston at Oklahoma, 7:30 p.m. EST, ABC | Box score
Monday, Sept. 2

Story 81
MSC Gülsün arriving in Germany. Its owner says that larger container ships help to lower exporters’ carbon footprint Mohssen Assanimoghaddam/Alamy
The world’s largest container ship has arrived in Europe after its maiden voyage from China.
MSC Gülsün, owned by Mediterranean Shipping Company, is longer than 36 London buses and can carry up to 23,756 containers — enough to hold some 223 million bananas or 8.35 million microwave ovens. It called at Bremerhaven in Germany yesterday.
At 400 metres long and more than 60 metres wide the vessel is designed to stimulate the trade of chilled and frozen goods, including food, drink and medicines, between Asia and Europe. It has more than 2,000 refrigerated containers on board.
The company is planning to introduce a further ten ships with capacity to hold at least 23,000 standard 20ft-equivalent unit containers. It argues that large ships “generally emit less…

Story 82
Conclusion The developed model accurately predicted levels of fat mass in children aged 4-15 years. The prediction model is based on simple anthropometric measures without the need for more complex forms of assessment and could improve the accuracy of assessments for body fatness in children (compared with those provided by body mass index) for effective surveillance, prevention, and management of clinical and public health obesity.
Results Model derivation was based on a multi-ethnic population of 2375 children (47.8% boys, n=1136) aged 4-15 years. The final model containing predictor variables of height, weight, age, sex, and ethnicity had extremely high predictive ability (optimism adjusted R 2 : 94.8%, 95% confidence interval 94.4% to 95.2%) with excellent calibration of observed and predicted values. The internal validation showed minimal overfitting and good model generalisability, with excellent calibration and predictive performance. External validation in 176 children aged 11-12 years showed promising generalisability of the model (R 2 : 90.0%, 95% confidence interval 87.2% to 92.8%) with good calibration of observed and predicted fat mass (slope: 1.02, 95% confidence interval 0.97 to 1.07). The mean difference between observed and predicted fat mass was −1.29 kg (95% confidence interval −1.62 to −0.96 kg).
Main outcome measure Multivariable linear regression analysis, using backwards selection for inclusion of predictor variables and allowing non-linear relations, was used to develop a prediction model for fat-free mass (and subsequently fat mass by subtracting resulting estimates from weight) based on the four studies. Internal validation and then internal-external cross validation were used to examine overfitting and generalisability of the model’s predictive performance within the four development studies; external validation followed using the fifth dataset.
Objectives To develop and validate a prediction model for fat mass in children aged 4-15 years using routinely available risk factors of height, weight, and demographic information without the need for more complex forms of assessment.
We report on the development and validation of a prediction model to estimate fat mass accurately in UK children aged 4-15 years of different ethnic origins, based on weight, height, and routinely available basic demographic information.
We examined whether weight and height as opposed to BMI could provide more accurate assessments of fat mass, particularly using prediction methods that have shown promise in estimating disease risks. 22 23 24
Although imaging (by dual energy x ray absorptiometry or magnetic resonance imaging), densitometric, and isotope dilution methods are available and accurate, they are unsuitable for routine clinical or public health assessment of body fatness. 11 21 Simple methods for body fatness assessment, based on routinely available measurements (particularly weight and height) and valid in a range of populations would be of considerable value.
Accurate and practical methods for quantifying body fatness in children are essential for effective monitoring, prevention, and management of high body fatness, overweight, and obesity in childhood. 8 9 Body mass index (BMI), the most widely used marker of childhood body fatness in clinical and public health practice, has serious limitations as a marker of body fatness in children. 9 10 11 Firstly, as a weight based measure, it does not discriminate between lean (fat-free mass) and fat mass, which can vary substantially in those with a given BMI. 10 Secondly, height squared provides poor height standardisation of weight in children—a higher power is needed to obtain height standardisation. 12 13 14 Finally, BMI in childhood is not a consistent marker of body fatness across different ethnic groups. In the UK and the United States, BMI has been shown to overestimate body fatness in black African children and underestimate body fatness in children of Asian origin. 15 16 17 18 19 Similar problems have been reported in other settings; BMI under estimates body fatness in South Asian girls and over estimates body fatness in Pacific Island girls in New Zealand. 20
With the increasing prevalence of obesity in children globally, 1 such as in the United Kingdom, where about one third of children aged 2-15 years are overweight or obese, 2 high body fatness in childhood represents a serious public health problem. High levels of body fatness in childhood have been associated with both overweight and obesity and increased risks of non-communicable diseases in adulthood—notably type 2 diabetes and cardiovascular diseases. 3 4 5 6 7
Methods
Data sources and study population For this investigation we pooled data from four cross sectional studies for the development of a prediction model, with a fifth study (not available at the time of model derivation) for external validation. All studies included data on weight, height, and reference standard body fatness assessments based on the deuterium dilution method.
Derivation data Data from four separate cross sectional studies17252627 (supplementary table 1), identified as the four available UK population based studies, which contained deuterium dilution measurements together with weight and height measurements in more than 200 children aged 4-15 years, were obtained and pooled for analysis (n=2375). Each of these studies used a similar protocol when conducting the deuterium dilution method to measure total body water (and indirectly fat mass), as described elsewhere.15 Three of the four studies included multi-ethnic populations; assessment of ethnicity was based on a combination of self reported parental information on parental ethnicity17 and child ethnicity,172627 with self reported participant information on ethnicity for older children.2526 Ethnic group categories were based on the 2001 UK census (supplementary table 1).
External validation data Data from a smaller separate UK cross sectional study at the 11 year follow-up visit within the Avon Longitudinal Study of Parents and Children (ALSPAC)28 were obtained for external validation. ALSPAC is a birth cohort study containing detailed assessments from predominantly white children born in the Bristol area between April 1991 and December 1992, including information on height, weight, sex, ethnicity, and age. At the 11 year follow-up visit, a subsample of the cohort (stratified by sex and BMI to represent the whole cohort) was recruited to participate in a further study that involved assessment of fat mass using the deuterium dilution method alongside measures of height and weight taken simultaneously.29 Ethnicity was based on a combination of self reported parental information on parental ethnicity.
Defining the outcome of prediction models Our primary aim was to develop a model for predicting fat mass in childhood, which could be estimated directly or indirectly (by predicting fat-free mass from models and then subtracting resulting estimates from known weight) based on deuterium dilution measurements. Firstly, we investigated the potential for modelling fat mass directly or indirectly by examining the distributions of fat mass and fat-free mass in relation to height (one of the strongest predictors of body composition) in boys and girls separately. This showed that a regression model for fat-free mass better met the assumptions of linear regression (more details in Appendix 1). The distribution of fat-free mass (both in boys and girls separately and combined) was positively skewed (supplementary figure 1) and showed increased heterogeneity with increases in height and weight. Fat-free mass, transformed using natural logarithms, was therefore the outcome in the main analyses.
Candidate predictors In the model development stage, we considered weight, height, age, sex, and ethnic group as candidate predictors (variables). Our derivation data, once restricted to those with fat-free mass or fat mass assessment, had no missing data on any of the candidate predictors. The sample size of 2375 participants meant that the number of candidate predictors being considered (along with non-linear terms) far exceeded both the minimum 10 people per candidate predictor rule of thumb30 and the minimum sample size requirements for prediction models proposed elsewhere.31 Ethnicity was based on self reported parental information on parental ethnicity. For the present analyses, we categorised child ethnicity as white (European origin), black (black children of African and Caribbean descent), South Asian (children of Indian, Pakistani, Bangladeshi, and Sri Lankan descent), other Asian (predominantly East Asian origins), and other (predominantly mixed ethnicity) groups.
Statistical analysis for model development Stata v14 was used for all analyses. We followed the TRIPOD (transparent reporting of a multivariable model for individual prognosis or diagnosis) guidance for development and reporting of multivariable prediction models.32 To avoid data splitting we used all four available studies for model development.33 A linear regression was used with the natural logarithm of fat-free mass as the outcome, and weight, height, age, sex, and ethnic group as candidate predictors (variables). Using a stepwise approach through backwards elimination, beginning with a model that included all predictors, we excluded candidate predictors from the saturated model based on their statistical significance (Wald test P>0.05). Non-linear relations between outcome and continuous predictors were considered by identifying, at each iterative step of the stepwise process, the best fitting fractional polynomial terms3435 (using Stata command mfp36). This model development process led to a final model for the prediction of natural logarithm of fat-free mass (and subsequently for fat mass=weight−exp(prediction of natural logarithm of fat-free mass)) based on the selected predictors along with their corresponding estimated β coefficients and the associated intercept term. Although heterogeneity and clustering of patients across or within studies was not considered for model development, we checked the impact of this using an internal-external validation approach.
Model performance and internal validation The performance of the final model was assessed using several approaches: • R2—proportion of the variance in natural logarithm of fat-free mass explained by the included predictors • Root mean square error (RMSE)—the average difference between the predicted and observed values. The RMSE of fat mass predictions was also assessed overall and within subgroups for age, ethnicity, and sex • Calibration slope—based on model regressing observed on predicted values of natural logarithm of fat-free mass (with a slope of 1 being ideal) • Calibration-in-the-large—intercept term from the model regressing observed on predicted values of natural logarithm of fat-free mass (with an intercept of 0 being ideal) • Comparing mean observed with mean predicted values of natural logarithm of fat-free mass. Calibration was also assessed graphically by displaying fat-free mass and fat mass on a calibration plot with a local regression (loess) smoother fitted across all children We carried out internal validation to estimate optimism (the level of model overfitting)32 and correct measures of predictive performance (R2, calibration slope, and calibration-in-the-large) for model overfitting by bootstrapping32 1000 samples of the derivation data (with replacement). The entire variable selection process, including the choosing of the fractional polynomial terms, was repeated within the model development for each of the 1000 bootstrap samples. This led to a set of 1000 bootstrap models that were derived using the same methods as in our original model development. We then applied each of these bootstrap sample models within the original dataset to estimate optimism in the performance statistics (difference in test performance and apparent bootstrap performance) of R2, calibration slope, and calibration-in-the-large (see Appendix 2 for further details), referred to as adjusted R2, adjusted calibration slope, and adjusted calibration-in-the-large, respectively. To adjust for optimism after model development, we obtained estimates of a uniform shrinkage factor (the average calibration slope from each of the bootstrap samples) and multiplied these by the original β coefficients to obtain optimism adjusted coefficients.3237 At this stage, we re-estimated the intercept of the model based on the adjusted coefficients to maintain overall model calibration,32 producing a final model.
Internal-external validation It is important to examine the generalisability of a prediction model developed using the process discussed. Owing to the limited availability of appropriate external datasets, we conducted internal-external validation3839 to further assess the performance of the derived model. This internal-external approach3839 involved cross validation, omitting one of each of the four studies in turn from the development dataset, and developing a model within the remaining three datasets. The following three steps were undertaken: (1) using the same model development strategy, we developed a model on three of the four studies and obtained the β coefficients from the model predicting natural logarithm of fat-free mass; (2) the predictive performance of the model from the first step was then assessed (overall and within sex and ethnic groups) within the fourth external validation study data in terms of accuracy of predicted fat mass (the primary outcome) by means of the calibration slope, calibration-in-the-large, and the R2 measures; and (3) we repeated the first two steps until we had assessed external validation for each of the four studies. We assessed overfitting in each round of the cross validation and obtained a uniform shrinkage factor,37 which was applied to the β coefficients from step 1. Calibration slope, calibration-in-the-large, and R2 measures derived from this procedure for each of the studies were then pooled and estimated via a random effects meta-analysis to assess the heterogeneity across studies (with the τ2 statistic estimated using the Mantel-Haenszel method). The variance of R2 was estimated using the Wald type method outlined previously40 and used to pool the values.
External validation We applied our final prediction model to each participant in the external validation dataset based on his or her respective predictor values. In a small number of children with missing ethnicity, we reclassified missing ethnicity data as white to produce an estimate of fat mass. The performance of the model for predicting fat mass, by sex and overall, was assessed using the calibration slope, calibration-in-the-large, R2, and RMSE and by comparing mean observed values with mean predicted values. We also assessed the overall calibration of the model graphically in terms of fat mass by plotting agreement between predicted and observed values across 10ths of predicted values. Finally, we re-estimated the intercept term from the final model for the external data to maintain the calibration of the model and reassessed the performance statistics.

Story 83
- FDA sets eptinezumab PDUFA date of February 21, 2020; launch expected in first quarter of 2020 -
- Acute study planned for potential eptinezumab label expansion -
- Conference call today at 5:00 p.m. ET -
BOTHELL, Wash., May 02, 2019 (GLOBE NEWSWIRE) -- Alder BioPharmaceuticals, Inc. (NASDAQ: ALDR), a biopharmaceutical company focused on developing novel therapeutic antibodies for the treatment of migraine, today provided a corporate update and reported its financial results for the first quarter ended March 31, 2019.
“The recent acceptance by the U.S. Food and Drug Administration (FDA) of our Biologics License Application (BLA) for eptinezumab was another major milestone for Alder and moves us one step closer to making the first quarterly infusion prevention therapy available to the millions of patients debilitated by episodic and chronic migraine,” said Bob Azelby, Alder’s president and chief executive officer. “We are in a strong position as we continue to prepare to commercialize eptinezumab in the first quarter of 2020, by building commercial inventory and expanding our commercial infrastructure. Additionally, in pursuit of Alder’s mission to forever change migraine treatment, we are excited to announce today that we plan to initiate a Phase 3 clinical trial of eptinezumab for the acute treatment of migraine in the second half of 2019.”
First Quarter 2019 Highlights
On April 22, 2019, Alder announced its BLA submission for eptinezumab, the company’s investigational monoclonal antibody (mAb) for migraine prevention targeting the calcitonin gene-related peptide (CGRP) and lead commercial candidate, was accepted by the FDA. The FDA has set the Prescription Drug User Fee Act (PDUFA) target action date of February 21, 2020. The BLA includes, and is supported by, positive data from Alder’s PROMISE 1 and PROMISE 2 Phase 3 clinical trials, open-label safety study, pharmacokinetic (PK) comparability study and chemistry, manufacturing, and controls (CMC) data packages.
In April, Alder announced the appointment of Nadia Dac as chief commercial officer. Ms. Dac brings more than two decades of U.S. and global commercial experience in neurology with both large and small publicly traded biopharmaceutical companies, with extensive expertise across all commercial functions including marketing, market access and promotion, sales, pipeline management, business development and partnerships. She joins Alder from AbbVie, where she served as vice president of global specialty commercial development.
In March, Alder closed an underwritten public offering and concurrent private placement in which the company received net proceeds of $159.3 million (which included the exercise of an over-allotment option granted to the underwriters in the public offering).
In January, Alder announced the appointment of Dr. Paul Streck, M.D. as chief medical officer. He brings more than 25 years of experience in drug development, regulatory and medical affairs leadership across both large and small publicly traded biopharmaceutical companies. Dr. Streck previously served as chief medical officer at Insmed Incorporated, where he played an instrumental role as a member of the executive leadership team and successfully led the Arikayce® regulatory filing, approval and launch.
In January, an amendment to Alder’s contract manufacturing agreement with Sandoz GmbH for the production of eptinezumab became effective. Pursuant to this amendment, Sandoz will manufacture and supply guaranteed quantities of eptinezumab drug substance for a five year term, running through 2023. Alder anticipates the guaranteed quantities will be sufficient to supply U.S. and ex-U.S. markets beyond 2023, if eptinezumab is approved.
Upcoming Anticipated Milestones
Alder plans to initiate a Phase 3 clinical trial evaluating eptinezumab as a treatment for acute migraine in the second half of 2019. The trial will seek to leverage eptinezumab’s 100% bioavailability and rapid onset of prevention demonstrated in clinical testing, with the objective of securing an indication for the acute treatment of migraine and positioning eptinezumab as the only anti-CGRP monoclonal antibody for the treatment and prevention of migraine, if approved for these indications.
Alder remains on track for the potential commercial launch of eptinezumab in the first quarter of 2020, and continues to advance its manufacturing and commercial readiness activities in anticipation of launch. Currently, Alder is advancing its supply chain, building commercial inventory, continuing to build out its commercial and operational infrastructure, and executing against other key pre-launch initiatives.
Alder continues to advance its pre-clinical candidate, ALD1910, a monoclonal antibody targeting PACAP-38 (pituitary adenylate cyclase-activating peptide-38). ALD1910 is currently undergoing Investigational New Drug (IND)-enabling preclinical studies and Alder expects to initiate a first in-human clinical study by the end of 2019.
First Quarter 2019 Financial Results
As of March 31, 2019, Alder had $498.5 million in cash, cash equivalents, investments and restricted cash, compared to $412.4 million as of December 31, 2018.
Research and development expenses for the first quarter ended March 31, 2019 totaled $69.6 million, compared to $74.0 million for the same period in 2018. The year-over-year decrease was primarily due to lower clinical trial costs, partially offset by expenses related to securing manufacturing capacity and the initial build of commercial inventory in preparation for the launch of eptinezumab.
General and administrative expenses for the first quarter ended March 31, 2019 totaled $44.5 million, compared to $11.6 million for the same period in 2018. The year-over-year increase reflects a $26 million loss contingency provision relating to a dispute over a contract we terminated for breach by the other party, as well as Alder’s continued ramp-up of the commercial organization and infrastructure required for the anticipated commercialization of eptinezumab.
Net loss applicable to common stockholders for the first quarter ended March 31, 2019 totaled $119.2 million, or $1.63 per share, compared to net loss of $117.6 million, or $1.73 per share on a fully-diluted basis, for the same period in 2018.
Financial Outlook
Alder continues to expect that full-year 2019 net cash used in operating activities and purchases of property and equipment will be in the range of $285 to $315 million. The majority of the spend is focused on ensuring that Alder is prepared for the potential launch of eptinezumab in the first quarter of 2020, including advancing eptinezumab’s supply chain, building commercial inventory, continuing to build out Alder’s commercial footprint and other pre-launch market readiness activities.
Alder believes its available cash, cash equivalents, investments and restricted cash will be sufficient to meet its projected operating requirements through the anticipated launch of eptinezumab and into the latter part of 2020.
Conference Call and Webcast
Alder will host a conference call today at 5:00 p.m. ET to discuss these financial results and recent corporate highlights. The live call may be accessed by dialing (877) 430-4657 for domestic callers or (484) 756-4339 for international callers, and providing conference ID number 8162289. The webcast will be broadcast live and can be accessed from the Events & Presentations page in the Investors section of Alder’s website at www.alderbio.com. The accompanying slides are available now at the Events & Presentations page in the Investors section of Alder’s website at www.alderbio.com. The webcast will be available for replay following the call for at least 30 days.
About Alder BioPharmaceuticals, Inc.
Alder BioPharmaceuticals is a clinical-stage biopharmaceutical company focused on transforming the migraine treatment paradigm through the discovery, development and commercialization of novel therapeutic antibodies. Alder’s lead product candidate, eptinezumab, is an investigational monoclonal antibody (mAb) that inhibits calcitonin gene-related peptide (CGRP) and is currently in late-stage clinical development for the prevention of migraine. If approved by the U.S. Food and Drug Administration, eptinezumab will be the first infusion therapy for migraine prevention. Alder is also developing ALD1910, a preclinical mAb that inhibits pituitary adenylate cyclase-activating polypeptide-38 (PACAP-38), as a potential new therapeutic option for migraine. For more information, please visit www.alderbio.com.
Forward-Looking Statements
This press release contains forward-looking statements, including, without limitation, statements relating to: the potential approval by the FDA of the BLA for eptinezumab; the anticipated commercial launch of eptinezumab and Alder’s progress with advancing manufacturing, commercial readiness and other activities and initiatives to prepare for such launch; Alder’s mission to forever change migraine treatment; the planned Phase 3 clinical trial of eptinezumab for the acute treatment of migraine and Alder’s objective relating thereto; Alder’s contract manufacturing agreement with Sandoz GmbH, including the sufficiency and duration of the supply produced thereunder; the clinical, therapeutic and commercial potential of eptinezumab and ALD1910; the development of ALD1910, including the planned initiation of a first in human clinical trial; and Alder’s financial outlook, including the expected range of full-year 2019 net cash used in operating activities and purchases of property and equipment and Alder’s belief that its available cash, cash equivalents, investments and restricted cash will be sufficient to meet the company’s projected operating requirements through the anticipated launch of eptinezumab and into the latter part of 2020. Words such as “expected,” “planned,” “potential,” “moves,” “available,” “continue,” “prepare,” “mission,” “initiate,” “will,” “anticipates,” “sufficient,” “objective,” “on track,” “advance,” “outlook,” “believes,” “projected,” or other similar expressions, identify forward-looking statements, but the absence of these words does not necessarily mean that a statement is not forward-looking. In addition, any statements that refer to expectations, projections or other characterizations of future events or circumstances are forward-looking statements. The forward-looking statements in this press release are based upon Alder's current plans, assumptions, beliefs, expectations, estimates and projections, and involve substantial risks and uncertainties. Actual results and the timing of events could differ materially from those anticipated in the forward-looking statements due to these risks and uncertainties as well as other factors, which include, without limitation: the clinical, therapeutic and commercial value of eptinezumab and ALD1910; risks and uncertainties related to regulatory application, review and approval processes and Alder's compliance with applicable legal and regulatory requirements; risks and uncertainties relating the build of Alder’s commercialization infrastructure; risks and uncertainties relating to the manufacture and supply of eptinezumab; risks related to the potential failure of eptinezumab and ALD1910 to demonstrate safety and efficacy in clinical testing; Alder's ability to conduct clinical trials and studies of eptinezumab and ALD1910 sufficient to achieve a positive completion; the availability of data at the expected times; Alder's ability to obtain and protect intellectual property rights, and operate without infringing on the intellectual property rights of others; risks and uncertainties relating to ongoing and potential future legal proceedings; the uncertain timing and level of expenses associated with Alder's development and commercialization activities; the sufficiency of Alder's capital and other resources; market competition; changes in economic and business conditions; and other factors discussed under the caption "Risk Factors" in Alder's Quarterly Report on Form 10-Q for the quarterly period ended March 31, 2019, which was filed with the Securities and Exchange Commission (SEC) on May 2, 2019, and is available on the SEC's website at www.sec.gov. Additional information will also be set forth in Alder's other reports and filings it will make with the SEC from time to time. The forward-looking statements made in this press release speak only as of the date of this press release. Alder expressly disclaims any duty, obligation or undertaking to release publicly any updates or revisions to any forward-looking statements contained herein to reflect any change in Alder's expectations with regard thereto or any change in events, conditions or circumstances on which any such statements are based.
Condensed Consolidated Balance Sheets (Unaudited) (Amounts in thousands) March 31, December 31, 2019 2018 Cash, cash equivalents, investments and restricted cash $ 498,508 $ 412,369 Prepaid expenses and other assets 14,660 13,870 Total assets $ 513,168 $ 426,239 Convertible notes, net of discount $ 185,146 $ 182,104 Other liabilities 67,214 30,404 Convertible preferred stock 103,755 103,755 Total stockholders’ equity 157,053 109,976 Total liabilities, convertible preferred stock and stockholders’ equity $ 513,168 $ 426,239


Condensed Consolidated Statements of Operations (Unaudited) (Amounts in thousands, except share and per share data) Three Months Ended March 31,
2019 2018 Revenues Collaboration and license agreements $ — $ — Operating expenses Research and development 69,589 74,048 General and administrative 44,498 11,553 Total operating expenses 114,087 85,601 Loss from operations (114,087 ) (85,601 ) Other income (expense), net (3,847 ) (1,430 ) Net loss $ (117,934 ) $ (87,031 ) Dividends on convertible preferred stock (1,311 ) (1,083 ) Deemed dividend on convertible preferred stock related to accretion of beneficial conversion feature — (29,460 ) Net loss applicable to common stockholders $ (119,245 ) $ (117,574 ) Net loss per share applicable to common stockholders - basic and diluted $ (1.63 ) $ (1.73 ) Weighted average number of common shares used in net loss per share - basic and diluted 73,056,907 67,844,872
Investor Relations Contact:
Michael Schaffzin
Stern Investor Relations, Inc.
212-362-1200
michael@sternir.com
Media Contact:
Ashley Cadle
TogoRun
310-463-0143
a.cadle@togorun.com
All trademarks, trade names or service marks appearing in this press release are the property of their respective owners.

Story 84
Careers
BMJ
2019
365
Cite this as: BMJ 2019;365:l1489

Story 85
Cordelia Dewey and Matt Harwood, of Surfers against Sewage, in Sandown on the Isle of Wight. The beach is just one of those plagued by sewage overflows PHIL YEOMANS
Southern Water has polluted some of Britain’s most popular beaches with raw sewage and storm water more than 150 times in six weeks.
Herne Bay in Kent, Brighton in East Sussex and Sandown on the Isle of Wight are among those affected. Southern has had the most sewage spills of any water supplier in England and Wales since the bathing season started on May 15.
In 2016 the company reported 26 spills in bathing water, although it was covering up pollution incidents at the time. In the first six weeks of this season it has already reported 157.
Ofwat, the water services regulator, imposed a £126m penalty on Southern last month for dumping untreated effluent into beaches, rivers and streams and not reporting the pollution.

Story 86
Cannabis regulation in the EU remains a patchwork of local and national regulations. In some respects the marijuana market is already mature. In Austria, for example, it is legal to grow marijuana so long as the THC-containing buds are not sold, so the country has a relatively developed retail and wholesale cannabis nursery industry that supplies legal growers across the EU. In Germany, medical marijuana was only legalised in 2017, and the market is just starting to take off (with a few budding startups listed below), while the UK just received its first batch of medical cannabis last Thursday. In Spain, marijuana is basically decriminalised (though enforcement depends on the province, and smoking in public could land you a fine), and the country is also home to hundreds of cannabis clubs, though many are under threat of shutdown. And in Portugal, all drugs are decriminalised. We could go on, but it would be easier for you to check out this map for a very basic breakdown of world cannabis laws.
The EU still generally lags behind the US in terms of medical and retail cannabis deregulation, but as more and more countries trend toward legalisation, a plethora of startups are forming in niches specific to local regulations. Some startups are developing highly-engineered products for the pharmaceutical market, while other startups are focusing on products with little to no cannabidiol (CBD) or tetrahydrocannabinol (THC), the medicinal and psychoactive components of cannabis, respectively.
Banks and financiers are often reluctant to back these startups for fear of getting caught up in a web of international drug-trafficking laws, so they often operate on low-budgets, around the edges of existing law – but this is changing as the laws do, and we are starting to see some cannabis startups receive some serious funding.
So without further ado, here are 10 dope startups innovating in the marijuana industry, that will help get you high, informed, or just plain healthy:
Based in Barcelona, Harmony is exploring the frontiers of cannabinoid science, with the objective of creating the most efficient, affordable hemp-powered products on the market to bring wellness and harmony to people’s lives. Harmony uses certified, legal hemp as a source of cannabidiol (CBD) and terpenes, two legal components of hemp that have a range of applications. CBD is said to be useful in treating epilepsy, Alzheimer’s disease, Parkinson’s, anxiety, depression, and even schizophrenia. Unlike THC, CBD has no psychotropic or hallucinogenic effects, making it legal in most countries. Founded in 2014, Harmony creates products including CBD vape pens and CBD e-liquids in a variety of flavors, which are distributed by more than 2,000 retailers worldwide.
If you want to know what’s going on in the world of cannabis, read Newsweed. Founded in 2016 in Paris, the online publication is France’s leading media source on global cannabis news, discussing topics including the state of legalisation and its evolution, research on medical cannabis, biology, business, trends, health, celebrities, art, movies on the subject, and more. Recent articles on the site include titles such as “Will hemp save bees?”, “UK receives first batch of medical cannabis”, “Edelgreen: first European farm to obtain a permaculture label for its cannabis”, and “Hawaii and New Hampshire set out to legalize cannabis”. Marijuana is going through exciting times, and Newsweed will keep you up to date about all things weed. Still working on your French? Don’t forget to use your Google translate extension.
MedPayRx is an insurtech and medtech startup aiming to take “the pain and the paperwork out of prescriptions”. With one simple app, MedPayRx connects medical cannabis patients, doctors, insurers, and pharmacies in Germany. MedPayRx not only serves cannabis patients, but anyone in need of a prescription, especially those that need special approvals. Through its platform, patients can find prescribing doctors and friendly pharmacies, as well as manage their prescriptions and insurance payments. Founded in 2017 and based in Frankfurt, MedPayRx also uses blockchain technology to create smart contracts for anonymous and secure transaction management.
Based in London and founded in 2017, Prohibition Partners aspires to be the world’s foremost source of independent data, intelligence and strategy for the cannabis industry, expecting that their data, insights and education efforts will unlock the societal and commercial potential of cannabis. Prohibition Partners’ consultancy team works with investors, operators and regulators to identify and execute opportunities across multiple jurisdictions. The startup advises private clients on licensing, regulatory and business opportunities, while its research and content teams routinely share the latest legislative developments and key trends in the industry – information that is regularly cited by political leaders, investment banks and Fortune 500 companies. Prohibition Partners publishes a weekly newsletter and longer-format regular reports on the industry, and claims and names some 30 partner corporations worldwide, including major pharmaceutical firms.
Looking for cannabis products? Look no further. Founded in 2015, Hanfgarten is an Austrian online retailer of CBD products, and one of the biggest distributors of hemp products in Europe. The online shop sells CBD oil, hemp seeds, plants, “grass”, cannabis-based wines and teas, and even lots of fun accessories to go with them, like growing kits, fertilizers, LED lights, vaporizers, soap, incense, and room sprays. The startup ships across Europe, as long as the product is legal in your country. The website also features its own magazine with cannabis-related articles including delicious recipes and tips and tricks. Based in Graz, Hanfgarten closed a seed round of funding of €300k in April 2016.
Cologne-based medical marijuana startup Cannamedical Pharma GmbH is one of Germany and the EU’s leading cannabis wholesalers. Its products include high quality cannabis varieties, cannabinoid oil, medical marijuana grinders, and patient ID cards to treat medical conditions including cancer and chronic pain. Currently around 60,000 patients in Germany have a license to use medical cannabis, and independent research shows that up to three percent of the population could benefit from treatment, equating to approximately 2.5 million people in Germany. For the EU as a whole, the patient population could eventually be around 15 million patients. Founded in 2016, Cannamedical just raised €15 million in a Series A round in January – the largest equity investment in a European cannabis startup to date.
Since the 1920s, research and development of cannabis-based products has been largely restricted or banned. Frankfurt-based pharmaceutical startup Farmako plans to catch up on this research backlog of almost 100 years. Medical cannabis has many therapeutic applications, including treating chronic pain and improving the lives of cancer and AIDS patients. Farmako is active in all European markets that have so far created a legal basis for cannabinoid therapies, conducting research and developing cannabis-based products. Just founded in 2018, the pharmaceutical startup received a seven-digit seed funding round in December 2018 from the German health tech platform Heartbeat Labs. The company plans to release information about its first patent in early 2019.
Based in Copenhagen, Growbud markets Bud, an iOS app that maintains a visual journal of growers’ crops. Incorporating photos allows the grower to monitor every phase of a crop’s growth cycle. Growers can also share their journals amongst other growers, botanists, or with corporate headquarters, to get feedback on their crop’s health. Recognising that privacy is important to growers, all images are stripped of metadata before being stored and shared.
Founded in London in 2017, Growth Mavericks bills itself “the world’s first cannabis growth hacking agency”, helping marijuana startups grow through digital marketing. It offers different “growth” packages, for instance its Facebook Growth Package, Instagram Growth Package, Twitter Growth Package, Digital Optimization Package, and the ultimate Dispensary Package. Packages start from $299 to $999, including services such as content creation, content strategy, conversion optimisation, customer acquisition optimisation, SEO optimisation, a brand ambassador program, and overall social media optimisation, to newsletter creation and website creation and optimisation.
As more and more governments legalise marijuana, the Duillier-based Swiss company Hempfy expects comestible cannabis to replace smoking and alcohol as the world’s preferred social drug. However cannabis is a plant not widely prized for its flavor. To address this problem, Hempfy has developed and is marketing cannabis infusions that “bring out the best flavours and aromas from the cannabis plant, by perfectly balancing the gentle herbal bitterness, a rich taste and light carbonation”. For the present, Hempfy products are made from low-CBD strains of cannabis that have no known psychoactive effects (though this could change as the law does). Hempfy also produces a Cannabis Essential Oil via steam distillation of natural hemp from Switzerland. According to its CEO Constantin Marakhov, Hempfy received Swiss government clearance to develop its THC-free beverages and essential oils in 2017, along with the blessing, if not the public participation, of Switzerland’s powerful pharmaceutical industry. Founded in 2016, Hempfy was the first project posted on the Swiss Beedoo crowdfunding platform in December of 2017.
By the way: If you’re a corporate or investor looking for exciting startups in a specific market for a potential investment or acquisition, check out our Startup Sourcing Service!

Story 87
Jacinda Ardern in Beijing with President Xi last month. She said that the Belt and Road initiative has evolved and her government wants to help it expand RAO AIMIN/XINHUA/ALAMY
New Zealand has broken away from its western intelligence allies with an offer to support China’s contentious global infrastructure and investment project.
The Belt and Road initiative involves Chinese state banks offering funds to develop transport schemes around the world to facilitate trade.
Supporters present it as a development initiative but critics say it is primarily to advance Beijing’s strategic interests, and even a form of “debt colonialisation”. Beijing has recently tried to recast the programme, promising to improve standards and transparency.
Jacinda Ardern, the New Zealand prime minister, said she believed the scheme had “really evolved” and her government was prepared to offer Beijing advice on expanding it. Her trade minister, David Parker, said that New Zealand believed that it could “find a win-win…

Story 88
A former television executive is to become the first black head of an Oxbridge college, after she was elected as master of Jesus College, Cambridge.
Sonita Alleyne, 51, is the chairwoman of the British Board of Film Classification’s management council and before that served as a BBC trustee. She will take up her new role in October.
She may be the first black Oxbridge college master, but she is in good company as a BBC alumna.
The corporation has become something of a breeding ground for Cambridge heads, including Alan Bookbinder, former head of religion, master at Downing; Dame Fiona Reynolds, former executive, master at Emmanuel; Bridget Kendall, former diplomatic correspondent, master at Peterhouse; and Roger Mosey, former head of news, master at Selwyn.
The…

Story 89
The nicknames Ursula von der Leyen has acquired over the course of her 29-year career in German politics tell their own story about the new president of the European commission.
During her time in charge of the family ministry, she was first called Krippen-Ursel (“crèche Ursel”), a conservative closet feminist set on expanding nursery places, and then Zensursula, a control freak who wanted to shield German youth from the dark sides of the internet.
When she became Germany’s first female defence minister in 2013, her (mostly male) detractors referred to her as Flinten-Uschi (“shotgun Uschi”), a caricature of the bossy career woman.
A liberal in conservative clothing or a pious authoritarian matriarch? If there is one quality the European commission’s first female president shares with her mentor Angela Merkel, it is that her political persuasions can be difficult to classify. Unlike Germany’s consensus-seeking chancellor, however, she is not afraid to raise hackles and divide opinion to drive through the policies she believes are right.
Born in October 1958, Ursula Gertrud von der Leyen spent her first 13 years in Brussels, where her father was one of the first pan-European civil servants. She attended the European School in Uccle, graduating two years before a certain Alexander Boris de Pfeffel Johnson joined the same establishment.
One of seven children, she was raised in a Christian household that adhered to the traditional model of the West German nuclear family. As state premier of Lower Saxony, her father, Ernst Albrecht, became a leading figure of the Christian Democratic Union (CDU) and a bete noire for the burgeoning Green movement, with whom he clashed over the opening of a nuclear waste depository.
Her mother, Heidi, took a supporting role, at times leading a family choir that serenaded its patriarch on German TV shows, and stating: “The best way for me to gain the respect of the public is through the role of motherliness.”
But if her father’s career enabled her international upbringing, it also allowed Von der Leyen to step out from his shadow.
When she was studying economics at the University of Göttingen in the late 1970s, her father was informed that his family could be a potential target for the Red Army Faction, a terrorist group also known as the Baader-Meinhof gang, and that his daughter should consider moving to another university.
Von der Leyen adopted the pseudonym Rose Ladson – a combination of her family nickname and the surname of her American great-grandmother – and enrolled at the London School of Economics.
“I lived much more than I studied,” she told the weekly Zeit. “No details, please. Only this: in 1978 I immersed myself for one year in this seething, international, colourful city. For me, coming from the rather monotonous, white Germany, that was fascinating.
“For me, London was the epitome of modernity: freedom, the joy of life, trying everything. This gave me an inner freedom that I have kept until today. And another thing I have kept: the realisation that different cultures can get on together very well.”
EU top jobs explained: who is coming in and what is their role? Read more
Switching to study medicine, she later worked as an assistant physician at a women’s clinic in Hanover and graduated as a doctor of medicine in 1991.
After she joined the CDU in 1990, on the same day her father stepped down from his job as state premier, her inner freedom made its mark on the posts she held, first as a regional and national delegate and then at the family, work and defence ministries.
“She has an incredible amount of energy”, said Daniel Goffart, a political correspondent for the news magazine Focus who co-wrote her biography in 2015. “You especially saw that in her bitter and protracted battle to modernise her party’s view on the role of the family.”
Under her watch, Germany introduced a law guaranteeing every child over 12 months of age a place at a daycare facility, and a paid parental leave scheme that includes at least two months of paid leave for fathers. She forced Merkel to drop her opposition to boardroom quotas for women, even though the policy was later defeated in the Bundestag.
Facebook Twitter Pinterest Ursula von der Leyen baking cookies with her seven children in 2003. Photograph: Jochen Luebke/AFP
Married since 1986 to a physician, Heiko, and mother to seven children, Von der Leyen has juggled a prolific career with family life – at the cost of popularity within her own party, some say. Instead of attending CDU summer fetes in rural Lower Saxony, said her biographer Goffart, she preferred to spend weekends at the family home in Beinhorn near Hanover when her children were still young.
Among her critics, the 60-year-old Von der Leyen has a reputation as an Einzelgängerin, a lone wolf with an instinct for front page-grabbing interviews and photo ops, but lacking the gift to pass the inner freedom driving her career down to the teams she works with.
If Von der Leyen’s approval ratings have recently plummeted, making her the least popular minister in Merkel’s cabinet, it is because her handling of Germany’s notoriously under-funded military at times displayed those same deficiencies.
When she diagnosed the troops with an “attitude problem” after the emergence of stories about rightwing extremist activities and hazing of new recruits, she was accused – and not only by members of the Bundeswehr – of choosing a good write-up over loyalty to her staff. “If she has a weakness, it is her tendency to excessive stage management,” said Goffart.
More recently, Von der Leyen grabbed negative headlines over the accusation that her defence ministry had allocated over-inflated contracts worth hundreds of millions of euros to external consultants. A parliamentary committee is investigating the ministry for accusations of nepotism, and Von der Leyen is expected to be invited as a witness in December. In Brussels and Berlin, she will have two stages to manage.
• This article was amended on 17 July 2019. An earlier version said Ursula von der Leyen is not afraid to raise heckles, rather than hackles.

Story 90
Conclusions Declines in case fatality, probably driven by improvements in stroke care, contributed more than declines in event rates to the overall reduction in stroke mortality. Mortality reduction in men and women younger than 55 was solely a result of a decrease in case fatality, whereas stroke event rates increased in the age group 35 to 54 years. The increase in stroke event rates in young adults is a concern. This suggests that stroke prevention needs to be strengthened to reduce the occurrence of stroke in people younger than 55 years.
Results Between 2001 and 2010 stroke mortality rates decreased by 55%, stroke event rates by 20%, and case fatality by 40%. The study population included 358 599 (45%) men and 437 270 (55%) women. Average annual change in mortality rate was −6.0% (95% confidence interval −6.2% to −5.8%) in men and −6.1% (−6.3% to −6.0%) in women, in stroke event rate was −1.3% (−1.4% to −1.2%) in men and −2.1% (−2.2 to −2.0) in women, and in case fatality was −4.7% (−4.9% to −4.5%) in men and −4.4% (−4.5% to −4.2%) in women. Mortality and case fatality but not event rate declined in all age groups: the stroke event rate decreased in older people but increased by 2% each year in adults aged 35 to 54 years. Of the total decline in mortality rates, 71% was attributed to the decline in case fatality (78% in men and 66% in women) and the remainder to the reduction in stroke event rates. The contribution of the two factors varied between age groups. Whereas the reduction in mortality rates in people younger than 55 years was due to the reduction in case fatality, in the oldest age group (≥85 years) reductions in case fatality and event rates contributed nearly equally.
Objectives To study trends in stroke mortality rates, event rates, and case fatality, and to explain the extent to which the reduction in stroke mortality rates was influenced by changes in stroke event rates or case fatality.
We quantified the contribution of changes in stroke event rates and case fatality to the reduction in stroke mortality using methods developed by the World Health Organization’s MONICA (monitoring of trends and determinants in cardiovascular disease) study, 6 7 as was used in a similar study of myocardial infarction. 5 We report on temporal changes in age specific stroke mortality rates, event rates, and case fatality.
Within existing evidence, it is not completely understood which of the two factors—declining event rates or declining case fatality—has a more important role in the observed reduction in mortality rates from stroke in England. A study of acute myocardial infarction reported that a decline in event rates contributed just over a half and improved survival at 30 days just under a half to the decline in mortality. 5 No studies analysed the factors that contributed to the decline in mortality from acute stroke. Data from clinical trials or biobank studies alone cannot be used to find the answer because they do not cover whole, representative populations. England, however, has a large national linked dataset of electronic hospital records and mortality statistics, which is well suited for such studies.
Stroke mortality rates have been declining in almost every country. 1 Reduction in mortality could result from a decline in disease occurrence or a decline in case fatality, or both. A reduction in stroke event rates could result from better management of risk factors, achieved through lifestyle modification and prevention. From a public health perspective, decline in disease is preferable to decline in case fatality, because people who survive a stroke have high rates of disability and an increased risk of developing vascular dementia. 2 For patients after stroke and their families, however, quality of care is paramount to increase the chance of survival. Improved case fatality at 30 days after stroke is almost certainly a result of improvements in treatment and management, and perhaps in prevention, which could reduce the severity of strokes. 3 4
The investigation did not conduct any interaction or intervention with participants on whom data were obtained. Patients and the public were not involved in the design, analysis, or interpretation of this study. The analysis was done on anonymised data, and therefore we are not able to consult with or disseminate our findings to participants.
Using this formula, we separated the contribution of percentage change in stroke event rates and case fatality to the percentage change in mortality rates. The relative contribution of each of the two parameters in the formula is calculated as the percentage of total mortality, which is set to 100%.
The equation is derived: if M is the mortality rate, E is the event rate, and C is the case fatality, then at any moment M=E×C, since the mortality rate is just the event rate multiplied by the case fatality. To estimate the change in mortality rates by time (t), differentiation (d) is used, whereby it follows that dM/dt=E×dC/dt+C×dE/dt, or M’=E×C’+C×E’ where M’=dM/dt and similar for E and C. The annual percentage change in rates is simply the annual change divided by the rate, so that ΔM=M’/M, ΔE=E’/E and ΔC=C’/C. From this, ΔM=M’/M=(E×C’+C×E’)/(E×C)=C’/C+E’/E=ΔC+ΔE.
We estimated the relative contribution of changes in event rates and case fatality to changes in stroke mortality over years using an equation from the WHO MONICA study, which states that ∆M=∆C+∆E, where ∆M is the annual percentage change in mortality rate, ∆C is the annual percentage change in case fatality, and ∆E is the annual percentage change in event rate. 6
Two methods were used to calculate average annual changes in case fatality. Using the dataset, we calculated the annual changes in case fatality in a generalised linear model with binominal distribution, with death within 30 days after stroke as the dependent variable. We also calculated the annual change in case fatality as a difference in annual change in mortality rates and stroke event rates using the WHO MONICA formula by subtracting the event rate from the mortality rate.
We used a Poisson regression model to calculate the average annual percentage change in mortality rates and event rates. In the analysis of changes in stroke mortality rates, the dependent variable was stroke deaths. In the analysis of changes in stroke event rates, the dependent variable was stroke events. In both analyses the calendar year of admission was an independent variable and, because we did Poisson regression analysis for rates, we used the corresponding age specific mid-year population as the exposure variable.
The estimate of change in rates was the average annual percentage change. For each measure—mortality rate, stroke event rate, and case fatality—we ran a separate regression model for all ages combined and for specified age groups. Age specific analysis was performed in six age groups: 20-34, 35-54, 55-64, 65-74, 75-84, and 85 years and older. To allow comparison with the MONICA results, we repeated the same analysis restricting the study cohort to people younger than 65 years.
We calculated stroke mortality rates, event rates, and 30 day case fatality in men and women in individual calendar years. The corresponding 95% confidence intervals were calculated assuming a Poisson distribution. Mortality rates were calculated by dividing the number of stroke deaths in a calendar year by mid-year resident populations; the population counts were obtained from the Office for National Statistics website. Our measure of stroke occurrence was a stroke event, and to calculate annual rates we divided the number of stroke events—both hospital admissions and deaths—by mid-year populations and expressed these per 100 000 population. Mortality and event rates in men and women as population based rates were directly age standardised to the 2013 European standard population. Case fatality was calculated by dividing the total number of deaths that occurred within 30 days after hospital admission for stroke, and included out-of-hospital deaths, by the total number of stroke events, multiplied by 100 and expressed as a percentage. Case fatality was directly age standardised in five year age groups using the combined 10 year study population as the standard population. In addition, we standardised case fatality to the 2013 European standard population to enable comparison with other studies.
Strokes were selected using the ICD-10 (international classification of diseases, 10th revision) codes I61-I64 as the primary diagnosis on a hospital record or as the certified underlying cause of death. We restricted analysis to emergency admissions and hospital transfers and excluded elective admissions. Only patients who spent more than a day in hospital and who were discharged alive were included in the analysis. The length of stay criterion was not applied to patients who had a stroke recorded as the principal diagnosis and who died in hospital: these cases were included. In patients who were discharged home when the diagnosis was not confirmed, we used the one day criterion to exclude cases of suspected acute stroke, which likely were transient ischaemic attacks or similar.
Following the terminology used by the MONICA study, we defined the occurrence of stroke as events, 7 defined as hospital admission for stroke, or a death with stroke as the underlying cause without a corresponding hospital admission for stroke in the preceding 30 days. If patients had more than one stroke, we included multiple events in the analysis if these events were more than 30 days apart. Event rates were expressed per 100 000 resident population of England. Case fatality was defined as the proportion of events that were fatal within 30 days after stroke, and this was expressed as a percentage.
In the analysis we included all residents of England aged 20 and older who were admitted to hospital with stroke or died from stroke between 1 January 2001 and 31 December 2010. We defined population based mortality for stroke as a death with stroke as the certified underlying cause of death, and this was expressed per 100 000 population of England.
Data were obtained from two national datasets of routine data, hospital episode statistics (HES) and national mortality statistics. The HES data were supplied by Health and Social Care Information Centre (renamed as NHS Digital). The Office for National Statistics supplied the mortality data. The linkage of records between the datasets was based on encrypted personal identifiers, including National Health Service number, date of birth, and postcode, sent in encrypted form by the data providers to the Unit of Health-Care Epidemiology, University of Oxford, where the linkage was done. The database covers the whole of England and contains information on every stroke that resulted in hospital admission to an NHS hospital or in a death without hospital admission. The NHS funds most of the hospital care in England. HES also receives information on private patients (although a minority of emergency admissions in England) managed in NHS hospitals. Thus, the database provides nearly complete coverage, except for private hospitals, of all patients admitted to hospital for stroke events in England. From national mortality data held by NHS Digital at https://digital.nhs.uk/data-and-information we obtained information on all deaths certified as death from stroke, including those that occurred out of hospital or in an emergency department, before a patient was admitted to a ward.
Table 2 and figure 3 show the contribution to reduction in mortality rates of changes in event rates and case fatality for men and women of all ages and in specific age groups. Seventy one per cent of the reduction in mortality from stroke overall was attributable to the reduction in case fatality and 29% to the reduction in stroke event rates. In men and women, the equivalent percentage contributions were, respectively, 78% and 66% and 22% and 34%. The contribution of these two factors varied between the age groups. In the two youngest age groups, 20-34 and 35-54 years, the decline in stroke mortality was attributable to a reduction in case fatality. A gradual increase occurred in the relative contribution of changes in stroke event rates to mortality reduction with increasing age, from 10% in men and 14% in women aged 55-64 years, to 48% in men and 43% in women aged 85 years and older.
Analysis of age specific case fatality showed a substantial reduction in 30 day mortality after stroke in all age groups. Case fatality after stroke was the highest in older age groups. In 2001 more than half of all patients with stroke aged 85 years and older died within 30 days; within 10 years it decreased to 34% (33% to 36%) in men and 38% (37% to 39%) in women ( table 2 ). Average annual changes in case fatality were calculated using the WHO MONICA formula and regression analysis. Each method produced similar results. On average the annual reduction in case fatality was 4.7% in men and 4.0% in women calculated using the WHO MONICA formula, and 4.7% (4.9% to 4.5%) in men and 4.4% (4.5% to 4.2%) in women calculated in regression analysis. When trends were analysed by age group, the largest average annual reduction in case fatality was observed in men and women aged 35-54 years, at 6.0% and 7.5% each year, respectively.
Case fatality at 30 days decreased by about 40% between 2001 and 2010 ( fig 2 ). A choice of the standard population made a noticeable difference to the absolute values of age standardised case fatality; for example, in 2001 case fatality in men was 42% when age standardised to the study population and 22% when age standardised to the 2013 European standard population. Given the large difference in case fatality introduced by using the standard population, figure 2 presents the two sets of results alongside each other.
Between 2001 and 2010 stroke event rates in men decreased from 345 (342 to 349) per 100 000 population to 285 (282 to 287) per 100 000, and in women from 280 (278 to 283) per 100 000 to 234 (232 to 236) per 100 000 ( fig 1 ), with an average annual reduction in men of –1.3% (–1.4% to –1.2%) and in women of –2.1% (–2.2% to –2.0%). The reduction in stroke event rate was larger in older age groups: in men and women aged 85 and older, for example, it was –3.4% (–3.6% to –3.1%) and –2.7% (–2.8% to –2.5%), respectively ( table 2 ). In contrast, stroke event rates among people aged 35-54 years increased by 2% each year. No statistically significant change was observed in men and women younger than 35 years.
The age standardised mortality rates decreased by 55% during the study period, and a reduction was observed in all age groups. Age standardised mortality rates in men decreased from 140 (95% confidence interval 137 to 142) per 100 000 population in 2001 to 74 (73 to 75) per 100 000 in 2010 and in women from 128 (126 to 130) per 100 000 in 2001 to 72 (71 to 73) per 100 000 in 2010 ( fig 1 ). The annual change in mortality rates in men was –6.0% (95% confidence interval –6.2% to –5.8%) and in women was –6.1% (–6.3% to –6.0%). The largest reduction in mortality rates was in men and women aged 65 to 74, with an annual change in men of –8.1% (–8.6% to –7.7%) and in women of –8.3% (–8.7% to –7.8%). The lowest average annual reduction in mortality rates was in the youngest age group, 20-34 years: –4.1% (–7.8% to –0.4%) in men and –4.5% (–8.8% to 0.0%) in women.
The linked hospital episode and mortality dataset comprised data on 947 497 stroke events, including 337 085 stroke deaths, in 795 869 people. Of these events, 521 788 (55.1%) of strokes and 207 198 (61.5%) of stroke deaths occurred in women ( table 1 ). Although between 2001 and 2010 there was no change in the total number of stroke events in men and a modest reduction in women, the total number of stroke deaths decreased in men, from 15 904 in 2001 to 10 481 in 2010, and in women from 25 947 to 16 117. The mean age at the onset of stroke was 72 years (SD 13 years) in men and 76 (SD 14) years in women. The mean age of those who died from stroke was 79 (SD 11) years in men and 83 (SD 9) years in women.
Discussion
During the first decade of the 21st century stroke mortality rates in England halved, stroke event rates decreased by about 20%, and case fatality decreased by about 40%. Most of the decline in stroke mortality rates—78% in men and 66% in women—resulted from a reduction in case fatality, and the remaining 22% and 34%, respectively, from a reduction in event rates. Important variations existed between young and old people: in those younger than 55 years, the reduction in mortality from stroke was attributed to improved survival, and in those aged 85 years or older, improved survival and reduction in event rates were equally important for mortality reduction. Stroke event rates increased in people aged 35-54 years, on average by 2% each year, which contrasts with the downward trend observed in the other age groups. In this age group, however, the increase in event rates did not translate into an increase in mortality rates, as it was offset by the reduction in case fatality.
The burden of stroke in England is decreasing, when 2010 is compared with 2001, as reflected by the reduction in absolute numbers of stroke deaths and in the stable absolute numbers of stroke events in men and the reduction in women.
Strengths and limitations of this study This large study of stroke events and mortality in England includes all patients admitted to an NHS hospital and all deaths in England, and it covers a continuous period of 10 calendar years. The findings are applicable to the whole of England. However, epidemiological and medical care factors vary from place to place, and a challenge for local investigators and those in other countries is to determine how these compare with profiles of mortality, event rates, and case fatality in their settings. The study is free from selection biases that might arise when data collected by stroke registries are analysed, which are limited in terms of populations and period covered, or clinical trials in which participants are selected and therefore might not be representative of all patients with stroke. The large size of the study population provided the statistical power to undertake age specific analyses. Unlike other studies such as MONICA, our study cohort did not have an upper age limit, and we reported trends in old as well as young adults.67 We relied on the quality of stroke diagnoses in routine hospital statistics and mortality statistics. Validation studies have consistently reported more than 90% accuracy of stroke codes in linked HES datasets.8910 For this study we combined all strokes with ICD-10 codes I61 to I64. We did not analyse haemorrhagic and ischaemic stroke separately, because additional analyses (not shown) showed that the reporting of stroke type in linked HES has been inconsistent through the study period.11 For example, in 2001 the type of stroke was not recorded for about half of all hospital admissions for stroke, and this decreased to less than 20% in 2010. Therefore, examining trends in rates reported for stroke types, as distinct from stroke overall, could be misleading as they are likely to be affected by improved recording of stroke type rather than true changes. Changes in stroke event rates could be subject to improved sensitivity of stroke diagnostics, including better quality of brain imaging, as well as increasing public awareness of the signs of stroke. Although these might have resulted in an increase in hospital admissions, particularly for milder strokes, we report a decrease in stroke event rates. In calculating event rates, we only included people who were admitted to hospital with acute stroke or those who died from stroke. Our study would not capture any silent infarcts or small strokes that did not result in a hospital admission or death, and therefore this study might have missed cases of stroke that were treated wholly without hospital admission, such as patients managed in nursing homes. Information on stroke severity is not recorded in routine hospital statistics. Some of the decline in case fatality reported here could be a result of a reduction in stroke severity and an increase in hospital admissions for less severe or suspected strokes, rather than advances in acute stroke care. To avoid counting suspected strokes that were not confirmed, we excluded all patients who spent one day or less in hospital and were discharged alive. If hospital admission criteria for patients with stroke changed over time, with an increasing threshold for admission, this might have artificially lowered the event rates. However, we found no evidence that any such clinical recommendations were introduced during the study years. We could not extend our analysis to include data from more recent years, because NHS Digital, which now owns and distributes data that were in the custodianship of the Office for National Statistics, stopped supplying the full date of death and the month and year of birth from April 2012 onwards. Without a full date of death it is not possible to calculate 30 day case fatality; and the absence of information on date of birth meant that it is not possible to calculate age specific rates in more recent years than those covered by this study.
Comparison with other studies The Global Burden of Disease (GBD) study reported a stroke mortality rate for high income countries of 60.54 (95% confidence interval 57.21 to 67.00) per 100 000 in 2010, a close estimate to the rates reported in this study at 74 per 100 000 population in men and 72 per 100 000 population in women.1 The marginal difference in rates is a result of methodological differences between the two studies. For age standardisation, the GBD study used the WHO world standard population as their standard population, which results in about 20% lower estimates of the standardised rates than when using the European population, which was used in this study.12 The GBD study, studies comparing mortality trends in Europe, and researchers in England have produced consistent evidence on the reduction in stroke mortality rates between the 1990s and the early 2010s.131415 The scale of reduction is similar to that reported in this study. The stroke incidence rate in 2010 reported in the GBD study was 217 per 100 000, and as with the mortality rate, it is about 20-30% lower than our estimates of stroke event rates: 284 per 100 000 population in men and 234 per 100 000 in women. Choice of the standard population, and counting of multiple stroke events in our study, could explain the difference in results between the two studies. In line with studies on trends in stroke incidence rates, we reported a reduction in stroke event rates over the study period.1314 However, our findings on age specific rates showed that the reduction was not universal: stroke rates declined in older people, no changes were observed in adults aged 20-34 years, and an increase of about 2% each year occurred in the age group 35-54 years. A stroke registry in south London reported similar findings on age specific rates.16 An increase in stroke incidence rates in young adults has been reported in France and America.1718 Published studies suggested that improvements in management of vascular risk factors have contributed to the observed reduction in overall stroke event rates.19 Others have emphasised the contribution of several stroke prevention strategies: hypertension control, use of statins, improved management of atrial fibrillation, reduction in smoking, decrease in salt consumption, and the introduction of nationwide clinics specialising in transient ischaemic attacks in England.20212223 In contrast, stable or increasing stroke rates in younger age groups are likely to result from increasing rates of obesity and diabetes in younger people.2425 Substance misuse, including cocaine, has also been linked to increasing rates of stroke in young people.2627 We report on national trends in 30 day case fatality after stroke in specific age groups, as well as overall rates, over several individual calendar years. Our findings of a 40% reduction in case fatality between 2001 and 2010 are encouraging, and they are consistent with results of a study of primary care data, which analysed mortality at 56 days after stroke.14 Our estimates of age standardised case fatality of 44% in women and 42% in men in 2001, are higher than the case fatality reported in the MONICA study in the late 1980s.7 The higher rates in our study are mainly due to particularly high case fatality in older people; for example, 53% in men aged 85 years and older and 21% in men aged 55-64 years. In the MONICA study, which only included people younger than 65 years, case fatality in different centres ranged from 15% to 49% in men and 18% to 57% in women. After we restricted our analysis to people younger than 65 years, the case fatality decreased to 22% in men and 23% in women, comparable to rates reported in MONICA. Our estimates of case fatality in 2001 at 22% in men and 23% in women, when age standardised to the 2013 European standard population, are comparable to the 20% case fatality reported for high income countries in a published review.28 The Oxford Vascular Study (OXVASC), conducted in Oxfordshire, overlaps with the early years of our study.29 The investigators reported case fatality of 17% in 2004, which is only moderately lower than the roughly 20% reported here. Our estimates are higher because they are combined estimates for the entire country, including the north of England, which historically has had higher stroke mortality than the southeast, where the data for OXVASC were collected.29 The contribution of specific aspects of the organisation of stroke care, medical and surgical interventions, and rehabilitation, to the observed reduction in case fatality needs to be further studied. However, the study period overlapped with a time of major changes to provision of stroke care nationally. These include unrestricted access to brain imaging; organisation of stroke units in all hospitals receiving patients with stroke; aspirin and thrombolysis for acute stroke; early supported discharge; and rehabilitation at home.30313233
Explaining factors behind observed reductions in stroke mortality Our findings are consistent with the original MONICA study, for which data were collected between 1982 and 1995, and reported that two thirds of the decline in stroke mortality was attributable to a decline in case fatality and one third to a decline in event rates.7 Findings of the two studies are similar, despite being conducted in different times and in different populations—the MONICA study was undertaken years ago, did not cover England, and did not include people older than 64 years. Although no studies have reported on determinants of reduction in stroke mortality rates in England, a study of myocardial infarction applied the WHO MONICA equation and used the same datasets and covered the same period as our study.5 It is well known that stroke and myocardial infarction share many common risk factors.3435 In contrast to our findings on stroke, the study of myocardial infarction reported that more than a half of the decline in mortality rates was due to a reduction in event rates and less than a half due to a reduction in case fatality. Thus, differences in the findings of the two studies, covering the same period and country, might suggest that prevention strategies were more effective in reducing the rates of myocardial infarction than of stroke. In contrast, acute care was more effective in improving short term survival of patients with stroke than of patients with myocardial infarction. The observed variations in age specific trends in event rates between young and older people might reflect effective preventive strategies and policies, but ones with different levels of impact in different population subgroups. During the study years, prevention at the individual level was focused on reducing a 10 year risk of vascular disease.36 The implication of this approach was that middle aged and older people have been recognised as a high risk group, and therefore they are offered treatment to control their vascular risk factors. In contrast, younger people were categorised into an intermediate risk group and received no treatment, despite having higher life long risks of cardiovascular events. In 2014, the updated British consensus recommendations for the prevention of vascular diseases were published, which shifted the focus of prevention from short term risk to life time risk.36
Implications for clinicians, policy makers, and researchers Findings of the study showed that most of the reduction in stroke mortality is a result of improved survival of patients with stroke. However, acute and long term management of such patients is expensive, and the NHS is already spending about 5% of its budget on stroke care.37 By focusing on prevention and reducing the occurrence of stroke, major resources can be conserved. The reported age specific trends provide important insights that can inform stroke prevention strategies. In 2009 the NHS started the Health Check programme aimed at reducing vascular disease risks and events in people aged 40-79 years. The evaluation of the first years of the programme showed suboptimal coverage, with only 10% of eligible people aged 40-59 attending clinics, but higher attendance rates among older people.38 The lack of interest in the NHS Health Check among younger adults, the group which, as found in this study, experienced an increase in stroke rates, highlights the importance of reviewing existing programmes or developing specific targeted interventions that appeal to this age group. This study covered only one year after the NHS Health Check was introduced, and therefore rates reported here can be used as a point of reference against which to compare future studies of the population level impact of the programme. An updated analysis of the age specific rates of stroke events and case fatality, perhaps looking separately at intracerebral haemorrhage and cerebral ischaemia, as well as total stroke, might assess the impact of the NHS Health Check in different population groups. Younger adults need to be the focus of research to build the evidence base for effective and tailored interventions. Clinicians and policy makers should consider targeting risk factors for vascular disease in those aged 55 and younger, without compromising on achievements with prevention in older age groups. Understanding trends in rates is necessary to compare changes in disease burden over time, but for clinicians, policy makers, and researchers, to plan resource allocation it is important to know if there are changes in absolute numbers of patients who require treatment. Our findings on no increase in the absolute numbers of stroke events and a reduction in stroke deaths are reassuring, and they are indicative of the reduction in stroke burden at population level.
Unanswered questions and future research Given that information on treatment and management of patients with stroke is limited in linked HES, further research using other data sources should explore the contribution of specific treatments and interventions to reduction in case fatality after stroke. Studies of changes in stroke severity over time could help to understand whether these had an impact on reduction in case fatality. A study of predictors of survival after stroke, including the impact of hyperacute care, centralised stroke care, and early rehabilitation on case fatality rates, would help in developing the optimal care path for patients with stroke. Analysis of data collected by the Sentinel Stroke National Audit Programme could provide answers. The increase in stroke events in younger people needs further exploration and monitoring. The risk factors that are contributing to the increase in stroke rates in people younger than 55 years need to be further investigated. We did not report trends separately for haemorrhagic stroke and ischaemic stroke; other researchers might be able to do that if they have reliable diagnostic data on the types of stroke.

Story 91
News Corp is a network of leading companies in the worlds of diversified media, news, education, and information services.

Story 92
We’re a step closer to the 2019/20 Premier League season after the fixtures were announced.
The opening clashes have got us excited too with Manchester United and Chelsea squaring off in the first Super Sunday of the campaign.
Getty Images 7 Manchester United vs Chelsea should give us an outstanding start to the new year
Liverpool get the season under way on Friday, August 9 against promoted club Norwich City in a match which will see two German managers – Jurgen Klopp and Daniel Farke – go head-to-head.
Meanwhile, in the first five games of the campaigns we also get a north London derby at the Emirates, a match between Liverpool and Arsenal, along with many other intriguing clashes.
Premier League 2019/20 fixtures in FULL: Dates and kick-off times for every game this season
But just how will it all play out? It’s two months until it starts but we couldn’t wait that long so we booted up the talkSPORT Super Computer to find out just what is going to happen in the first five games. You can see the results and the predicted table below…
Darren Gough discusses if it matters in what order you play your fixtures
LATEST FOOTBALL STORIES NEW THREADS Ronaldo scores controversial winner as Juventus sport 'unique' new Palace kit AWKWARD Owen and Shearer could face awkward reunion as Amazon announce pundits BOOKED When the real Pele had no clue about Arsenal legend Ray 'Romford Pele' Parlour off the mark Chris Smalling scores first goal for Roma since joining from Man United disgraceful Fan rages at ‘clueless’ Emery after ‘shambolic’ Arsenal lose to Liverpool teens VERDICT Mourinho is 'exactly what Spurs need' and can take them to 'elite level' - Durham ALMOST HAPPENED Origi to blame for denying Emery the chance to win by 'preferred' scoreline unexpected Mustafi shows Xhaka how to address Arsenal fans following a bad performance CLASSY Tierney 'already gets it' as Arsenal man is praised for actions after Liverpool loss selfless Barca players offered to alter contracts so club could sign Neymar, says Pique Homecoming 'It would be amazing' - Milner discusses Leeds return before retiring SPYGATE II? FA demands Man City 'Spygate' answers from Liverpool
Gameweek 1 predictions
Bournemouth 2-1 Sheffield United
Burnley 1–1 Southampton
Crystal Palace 0-2 Everton
Leicester City 2-2 Wolverhampton Wanderers
Liverpool 4–1 Norwich City
Manchester United 1-1 Chelsea
Newcastle United 1–2 Arsenal
Tottenham Hotspur 3–1 Aston Villa
Watford 1-1 Brighton & Hove Albion
West Ham United 0–3 Manchester City
Getty Images 7 Will Arsenal kick off the season with a win?
Gameweek 2 predictions
Arsenal 3-1 Burnley
Aston Villa 1-1 Bournemouth
Brighton & Hove Albion 0–3 West Ham United
Chelsea 1–2 Leicester City
Everton 2–1 Watford
Manchester City 3–2 Tottenham Hotspur
Norwich City 1–1 Newcastle United
Sheffield United 0–2 Crystal Palace
Southampton 0–2 Liverpool
Wolverhampton Wanderers 1–2 Manchester United
Getty Images 7 Tottenham fans have fond memories of playing Manchester City last season
Gameweek 3 predictions
Aston Villa 1–2 Everton
Bournemouth 0–4 Manchester City
Brighton & Hove Albion 0–1 Southampton
Liverpool 4-2 Arsenal
Manchester United 3–1 Crystal Palace
Norwich City 0–3 Chelsea
Sheffield United 1–2 Leicester City
Tottenham Hotspur 2–0 Newcastle United
Watford 1–2 West Ham United
Wolverhampton Wanderers 2–1 Burnley
Getty Images 7 Liverpool came from behind to beat Arsenal 5-1 last December
Gameweek 4 predictions
Arsenal 2–2 Tottenham Hotspur
Burnley 1-2 Liverpool
Chelsea 2–0 Sheffield United
Crystal Palace 2–1 Aston Villa
Everton 2–1 Wolverhampton Wanderers
Leicester City 3–0 Bournemouth
Manchester City 4–1 Brighton & Hove Albion
Newcastle United 1-1 Watford
Southampton 1–2 Manchester United
West Ham United 3–2 Norwich City
7 Arsenal and Spurs players clash in the north London derby on December 2 last season
Gameweek 5 predictions
Aston Villa 1–1 West Ham United
Bournemouth 2-2 Everton
Brighton & Hove Albion 0-1 Burnley
Liverpool 5–1 Newcastle United
Manchester United 0–1 Leicester City
Norwich City 1–3 Manchester City
Sheffield United 1-1 Southampton
Tottenham Hotspur 2–0 Crystal Palace
Watford 1–3 Arsenal
Wolverhampton Wanderers 1-2 Chelsea
Getty Images 7 Chelsea star N’Golo Kante battles for the ball against Wolves last season
How we predict the 2019/20 Premier League table will look like after five games
7 Will the Premier League table look like this after five games?
talkSPORT is the home of live football as we bring you over 100 Premier League commentaries in 2019/20! Make sure you stay tuned in for 24/7 coverage of the biggest and best league in the world.

Story 93
IT'S the day Ballum fans have been waiting for in EastEnders as Ben Mitchell and Callum Highway go on their first official date.
But don’t get too excited as it turns out to be something of a nightmare as Ben – Max Bowden - starts to have doubts about the potential relationship.
2 EastEnders fans have been rooting for Ben Mitchell and Callum Highway's romance
The EastEnders favourite is made to question a future with Callum after both his half-brother, Ian Beale, and best mate, Jay Brown, comment on his not-exactly-successful history with men.
And Callum – Tony Clay - should probably sleep with one eye open if he gets involved with the Mitchell bad boy considering two of Ben’s former lovers are now dead.
Ben’s doubts are made even worse when Callum’s overprotective big brother, Stuart, arrives at The Arches and pleads with Ben not to hurt Callum.
However, despite the doubts which are creeping in, Ben meets Callum for their date later.
But Callum is confused and disappointed when Jay and Lola arrive too.
2 Doubts develop for Ben in EastEnders
And things go from disappointing to down-right terrible for Callum when Ben makes no effort at all during the date.
A crest-fallen Callum gets set to leave and go home when Ben does something that leaves him – and Jay and Lola – totally floored.
But what does he do?
Tomorrow’s episode will see Stuart secretly pleased that his brother’s date didn’t go well. But Callum is less than impressed when he discovers that Stuart meddled in his love life.
Callum tries to explain things to Ben but is gutted when he doesn’t get the response he was hoping for.
Lola steps in and offers a conflicted Callum some advice which leads him to seek out Ben at The Vic.
LATEST IN EASTENDERS UP THE DUFF-DUFF When is Louise's baby due in EastEnders? SQUARE FOOTAGE EastEnders set pictures show builders working on new houses on the square Waltzford EastEnders star Maisie Smith shares first look at soap Strictly special BEN-DED KNEE EastEnders fans convinced Ben will PROPOSE to Callum after 'grand gesture' PAN-SAVIOUR EastEnders fans predict newbie Jags might save Chantelle from abuser Gray Spoiler Revenge hell EastEnders' Sharon breaks down in tears after Mel’s revenge threats
He declares that he wants he and Ben to go on another date and this time Ben’s response leaves Callum surprised. Will they just get together already?
Meanwhile, Callum gets another shock when his homophobic dad, Jonno, arrives on the Square.
When he finds out that Callum’s wedding to Whitney was cancelled, he wants to know why.
Everyone tries to cover but Callum decides to make a stand against his dad. Does he tell him that he’s gay? And how will Jonno react?

Story 94
Austria’s capital city of Vienna is creating a new district in which the buildings, electrical grid and energy market will be monitored continuously in a world-class living laboratory that incorporates new distribution grid solutions and energy-saving technologies. The Aspern Urban Lakeside project is being developed on the site of a former airport that has an area of 2.4 sq km (0.927 sq miles) some 25 minutes by subway from downtown Vienna. This long-term project will include 10,500 residential apartments, offices, shops, training establishments and industry, ultimately creating 20,000 job opportunities. With an investment totaling €5.5 billion (US$6.06 billion), the construction period will continue until 2028.
Reduction of carbon dioxide emissions and per-capita energy consumption as well as ensuring a failure-free supply of energy are the fundamental goals of the energy transition, which is characterized by increasingly decentralized energy generation, prosumers and new storage technologies. The research project is managed by Aspern Smart City Research GmbH & Co. KG (ASCR), a joint venture formed in 2013 among distribution system operator Wiener Netze GmbH, Vienna’s electricity, gas and district heating network operator; energy service provider Wien Energie GmbH, Vienna’s energy supplier; technology company Siemens AG; and the City of Vienna.
Overview of Aspern Smart City Research fields.
Challenges as well as technology and innovation that are part of this smart building initiative.
This cooperative partnership was established to develop some of the technical solutions required for the future energy environment, especially in a new real-life urban district with active consumers. This involves innovative approaches to building automation systems and using the energy flexibilities of buildings and the energy market in ways that enable residents to cooperate and accept the new systems. Furthermore, optimal methods are being developed to capture detailed network-status data for use in network planning. All these solutions are based on comprehensive information and communications technology (ICT) as well as testing and developing convenient big-data models and suitable analytics.
Smart Buildings
ASCR is implementing one of the most innovative and sustainable energy-efficiency showcase projects in Europe. Real data is used for research on complex correlations as well as integrated elements and components. Based on national and international experience, ASCR is exploring not only individual aspects in the Aspern Urban Lakeside but also the entire system. Buildings, the electricity grid, communications and information technologies, and user behavior all are captured in the large-scale energy research program.
Interaction with the smart user.
The smart building research objectives of ASCR include three building types:
1. Residential building with 213 apartments, seven heat pumps (800 kW), hybrid panels for solar-thermal generation (65 kW) and power generation (16 kW), photovoltaics (20 kW), electric heating cartridges (4 kW hot water), geothermal heat (60 kW) and hot water accumulators, a battery (2 kWh) and apartment automation.
2. Student home for 300 students with photovoltaics (220 kW), a battery (120 kWh) and electric heating cartridges (two quantity of 8 kW hot water).
3. School campus comprising kindergarten and primary school equipped with two heat pumps (510 kW), photovoltaics (29 kW), solar-thermal generation (90 kW) and electrical cartridges (two quantity of 35 kW).
Complex ICT systems facilitate the optimal management of generation, distribution, consumption, storage and transmission of energy. Two buildings equipped with conventional technology will be used as benchmarks for the research project.
One of the priority areas for ASCR is optimizing a building’s own use of energy, as current building optimization systems cannot predict the future. However, this is about to change as intelligent building management systems focus on calculating estimated energy requirements with due consideration given to weather forecasts and other data. Additionally, they can provide information about the condition of individual building units and, thus, support the forward planning of maintenance.
In addition to optimizing energy consumption, the research company is primarily interested in the potential of buildings to make energy flexibility available outside their walls. Consequently, one of the most important questions is how buildings can use their flexibility in the future to support local medium- and low-voltage networks or, alternatively, participate as an active player in the electricity market.
To master these challenges, aggregation levels must be created within a few buildings and, in the future, even with up to several thousand buildings. At least two systems are used for this purpose. One is a building energy management system (BEMS), which is in the building itself and calculates the electricity consumption of the building and any flexibility at regular intervals. The other is the energy pool manager (in our case Decentralized Energy Management - DEMS) that acts as an interface between the individual building and the electricity market.
To participate in balancing energy markets, intelligent electricity networks are required to determine and forecast the network status at all times.
Smart grid migration path.
Smart Grid
The ASCR smart grid consists of 20/0.4-kV secondary substations equipped with 24 transformers. Transformers with different technologies are being used, including amorphous core, ester midel, aluminum and on-load tap changers as well as five grid storage systems. Many sensors—including grid monitoring devices and smart meters in three building blocks, designed to deliver consumption and grid data to the low-voltage grid control center—constitute the basic infrastructure of the ASCR smart grid test bed.
Green house on a residential block.
The approach adopted here is based on the optimal use of existing copper reserves and integrated smart ancillary technologies continuously along the smart grid migration path. This serves as a guideline for the transition from a passive distribution network to a smart grid, with its bidirectional load and communication flows. This can be thought of as a smart grid migration path:
• The status of the electricity network, that is the usage down to the low-voltage level, must be transparent. The low-voltage networks constitute the largest part of the electricity network and are the most active areas in terms of grid dynamics and fluctuating voltages. Data collection is recorded by smart meters and self-configuration field sensors, including power-quality measuring devices or grid monitoring devices. This is all part of the grid monitoring aspect of the project.
• Smart meters already have been tested, but they only provide rough data. Additional measurements and sensors increase the project costs, but they also provide a more accurate overview of the network status. A core objective of the ASCR research program is to determine the minimum required coverage with sensors to provide a sufficiently detailed picture of the network status for optimal network operation and network planning, with due consideration given to economic efficiency.
Ground water heat pumps are part of monitored equipment.
Grid monitoring devices installed on low-voltage fuseboard.
High-voltage and low-voltage transformer connections.
Siemens SICAM monitoring equipment.
• For planning and low-voltage management further down the smart grid migration path, the data can be used to make management decisions that do not require any physical network expansion. They represent an efficient alternative to vague worst-case planning. Without active network intervention, specific network data enables the infrastructure to be operated closer to its physical limits, providing early warnings when thresholds or established key performance indicators (KPIs) are threatened to be exceeded.
• Active grid intervention can help to increase the efficiency of electricity network infrastructure. However, this requires all components to be as fault-tolerant as possible. Furthermore, they should not generate any significant additional costs during the rollout or in operation. This can be ensured by means of system solutions with component-support functions such as zero touch, plug and play, and plug and automate.
Smart User
Users represent a particularly important part of the ASCR research activities, because it ultimately depends on how much energy the building requires and to what extent it can offer flexibilities. However, the research program only includes apartment residents (50%) who have given written approval permitting their energy consumption and ambient air control system (electricity, heat, hot and cold water, room temperature and room air quality) usage data to be used for research purposes. The aim is to find out how the buildings, occupied by a diverse population, can work in an optimal way. This requires information on current use habits and future needs. Consequently, the cooperation with users was supported continuously by social scientists.
As a basis for home automation, smart measuring and control technology (smart MCT) is installed in participating households to control the air quality and temperature of the residence to optimize the building energy consumption. Residents can intervene with the smart MCT and change the air-quality and temperature levels themselves, even remotely from a tablet or smartphone. Additionally, they can test innovative products and services to control their individual energy consumption (for example, time-variable tariff models), which in turn helps the research team to develop innovations.
Rooftop solar panel installations are for electric generation and water heating.
However, the aim is to promote sustainable cost- and energy-efficient usage by means of incentives and raising awareness. The paradigm of today is this: Generation follows consumption, meaning the generation is adapted to the consumption. In the future, it must be possible to adapt consumption more toward fluctuating renewable energy generation.
Smart ICT
With due consideration given to data protection guidelines, smart ICT uses all data obtained from the buildings and network (temperature, room air quality, electricity consumption, voltage, etc.) as well as external data (for example, weather or other related events) to analyze the interaction and interdependencies between the network and buildings. The essential factor is the integrated view of data from various domains.
Using real data from the test field, the ASCR research team creates a digital twin of reality to simulate any energy concepts as well as optimization measures. The objective here is to develop scalable and feasible solutions for urban energy balance. Because building occupancy and network capacity utilization constantly changes, the models on which the simulations run must be adjusted on a continuous basis. The models, and thus the internal building and network control mechanisms, are refined by means of adaptive self-learning algorithms.
Big-data methods are used to cope with the enormous data volumes from the various domains. Numerous different data models can be used depending on the area of application. As a part of the ASCR research program, both large centralized and decentralized data models in the style of the Hadoop software framework are tested. Some of the data analytics scenarios are as follows:
• Low-voltage grid anomaly detection — In this scenario, a huge volume of fine-grained grid measurements (voltage, power, etc.) are analyzed to detect outliers and unusual patterns. The goal is to identify the relevant grid segments and time frames for further investigation, simulation and planning. This descriptive analytics task, basically retrieved from the grid operator, only considers aggregated data from many individuals. Consequently, only the building operators (as legal entities) need to agree on the usage of the total building energy measurements.
• Identification of building energy patterns — This scenario focuses on the analysis of building performance data, which includes time series from heterogeneous measurement devices (power, heating, water, ventilation, etc.). The purpose of this diagnostic analytics task is classification and comparison of energy profiles for entire buildings or building parts. The valuable derived information can be used for energy consumption planning or pricing. Also, data from individuals can be used if consent has been granted, but generally only overall building data is used. Consequently, only the building operators are required to provide permission for the data dissemination.
• Building prognosis — A potential succeeding task of the identification of building energy patterns is the prognosis of the future behavior of buildings or building parts. This predictive analytics task uses historical information and the derived patterns to estimate an energy schedule for the near future. This offers crucial information that can be used to develop a more flexible energy market or to stabilize the grid, if necessary. From a data perspective, mainly building data and derived data is being used. In addition, external factors like weather are considered for the estimation of solar power generation or consumption.
• Grid prognosis — The improved prognosis of the state and demand of the low-voltage grid in the near future is a challenging predictive task with large financial potential for the grid operators when it comes to balancing unscheduled power flows. The grid prognosis is based on historical measurements from the grid and external data such as weather or mass events. Similar to the first scenario, the data analyzed is retrieved from the grid operator and only consent from the building operators is required.
• Data availability for future applications — One of the goals of the project is to enable new business opportunities based on cross domain and cross vendor integration of data. This integration builds the foundation for new smart applications, where new revenues can be generated through data collected in the city. Clearly, all applications and business models must respect users’ privacy, which imposes several challenges for data governance and monitoring.
Observations to Date
The first data analytics already provide some illuminating results on asymmetric loads and the detection of faulty installation. The ASCR also has observed, in residential areas, certain unbalanced building loading of the three-phase distribution network. This is a result of the consumer’s white goods and television sets, all of which have been connected to the same phase to minimize the cost of internal wiring installation.
Also, as a result of analysing all available data, ASCR has been able to detect current sensors that have been installed incorrectly. These analytics offer an opportunity to check for this more quickly in future installations to avoid repetition.
ASCR has just started analysing all the available data, but the initial results underline the decision taken by the three partners, Wien Energie, Wiener Netze and Siemens, to cooperate in the form of a joint venture in Vienna.
Wiener Netze
Wiener Netze GmbH is a subsidiary of Wiener Stadtwerke Holding AG (Vienna Municipal Utilities) and is Austria’s largest distribution system operator for supplying electricity, gas and district heating to 1.2 million customers. To be able to safeguard a high degree of supply reliability and quality of supply, the utility has embarked on a programme of high capital investment in the infrastructure. The electrical power mission of Wiener Netze is responsible for customer services, network strategy and planning as well as construction, operation and maintenance of the gas, primary district heating and electricity grid. Furthermore, Wiener Netze is responsible for meter management, data and regulatory management.
Wien Energie
Wien Energie GmbH is a subsidiary of Wiener Stadtwerke Holding AG (Vienna Municipal Utilities) and is responsible for ensuring the reliable supply of electricity, natural gas and heating to a population of some 2 million customers, 230,000 businesses and industrial facilities as well as 4500 farms in the greater Vienna metropolitan area. The utility also is responsible for waste recycling, providing energy–related advice and services, facility management and telecommunications. Moreover, Wien Energie is active in a number of projects at a European level.
Wien Energie offers heating, cooling and decentralized products directly, such as citizen investment models. Electricity and gas are sold by a subsidiary, Wien Energie Vertrieb GmbH & Co.KG.
With an annual turnover of €1,820.8 million ($US 2,041 million) in 2015, Wien Energie is among Austria’s top 30 companies in terms of turnover. In the 2015 Business Report, employees totaled 2680, making Wien Energie Group one of the largest employers in the Austrian capital.
Acknowledgement
The authors wish to express their thanks for the technical support and assistance given by staff at Siemens in the preparation of this article.

Story 95
The 2019 SEC football season is through Week 9. Check out the full schedule, including game times and TV channels below.
At the end of the regular season, action then turns to Atlanta for the 2019 SEC Championship Game on Dec. 7.
2019 SEC football schedule: Game times, TV channels for every week
Saturday, Nov. 2 — Week 10
UTSA at Texas A&M | 12 p.m. | SEC Network
No. 8 Georgia vs. No. 6 Florida (Jacksonville, FL) | 3:30 p.m. | CBS
Mississippi State at Arkansas | 4 p.m. | SEC Network
Ole Miss at No. 11 Auburn | 7 p.m. | ESPN
UAB at Tennessee | 7 p.m. | ESPNU
Vanderbilt at South Carolina | 7:30 p.m. | SEC Network
COLLEGE FOOTBALL: Schedule, scores
Saturday, Nov. 9 — Week 11
Western Kentucky at Arkansas | 12 p.m. | SEC Network
Vanderbilt at Florida | 12 p.m. | ESPN
LSU at Alabama | 3:30 p.m. | CBS
New Mexico State at Ole Miss | 4 p.m. | SEC Network
Missouri at Georgia | 7 p.m. | ESPN
Appalachian State at South Carolina | 7 p.m. | ESPN2
Tennessee at Kentucky | 7:30 p.m. | SEC Network
COLLEGE FOOTBALL HISTORY: National Champion going back to 1869
Saturday, Nov. 16 — Week 12
Georgia at Auburn
LSU at Ole Miss
Alabama at Mississippi State
Florida at Missouri
South Carolina at Texas A&M
Kentucky at Vanderbilt
Saturday, Nov. 23 — Week 13
Western Carolina at Alabama
Samford at Auburn
Texas A&M at Georgia
UT Martin at Kentucky
Arkansas at LSU
Abilene Christian at Mississippi State
Tennessee at Missouri
East Tennessee State at Vanderbilt
Thursday, Nov. 28 — Week 14
Ole Miss at Mississippi State | 7:30 p.m. | ESPN
Friday, Nov. 29 — Week 14
Missouri at Arkansas (War Memorial Stadium in Little Rock, AR) | 2:30 p.m. | CBS
Saturday, Nov. 30 — Week 14
Alabama at Auburn
Florida State at Florida
Georgia at Georgia Tech
Louisville at Kentucky
Texas A&M at LSU
Clemson at South Carolina
Vanderbilt at Tennessee
Saturday, Dec. 7
SEC Championship Game (Mercedes-Benz Stadium in Atlanta, GA)
Saturday, Aug. 24 — Week 1
No. 8 Florida 24, Miami (FL) 20
Thursday, Aug. 29 — Week 1
No. 12 Texas A&M 41, Texas State 7
Saturday, Aug. 31 — Week 1
No. 2 Alabama 42, Duke 3
No. 3 Georgia 30, Vanderbilt 6
No. 6 LSU 55, Georgia Southern 3
No. 16 Auburn 27, No. 11 Oregon 21
Kentucky 38, Toledo 24
Memphis 15, Ole Miss 10
Mississippi State 38, Louisiana 28
North Carolina 24, South Carolina 20
Georgia State 38, Tennessee 30
Arkansas 20, Portland State 13
Wyoming 37, Missouri 31
Saturday, Sept. 7 — Week 2
No. 1 Clemson 24, No. 12 Texas A&M 10
No. 2 Alabama 62, New Mexico State 10
No. 3 Georgia 63, Murray State 17
No. 6 LSU 45, No. 9 Texas 38
No. 10 Auburn 24, Tulane 6
No. 11 Florida 45, UT Martin 0
Missouri 38, West Virginia 7
South Carolina 72, Charleston Southern 10
Purdue 42, Vanderbilt 24
Mississippi State 38, Southern Miss 15
BYU 29, Tennessee 26 (2OT)
Kentucky 38, East Tennessee State 17
Ole Miss 31, Arkansas 17
Saturday, Sept. 14 — Week 3
No. 2 Alabama 47, South Carolina 23
No. 3 Georgia 55, Arkansas State 0
No. 4 LSU 65, Northwestern State 14
No. 8 Auburn 55, Kent State 16
No. 9 Florida 29, Kentucky 21
No. 16 Texas A&M 62, Lamar 3
Kansas State 31, Mississippi State 24
Tennessee 45, Chattanooga 0
Ole Miss 40, Southeastern Louisiana 29
Arkansas 55, Colorado State 34
Missouri 50, Southeast Missouri State 0
Saturday, Sept. 21 — Week 4
No. 2 Alabama 49, Southern Miss 7
No. 3 Georgia 23, No. 7 Notre Dame 17
No. 4 LSU 66, Vanderbilt 38
No. 8 Auburn 28, No. 17 Texas A&M 20
No. 9 Florida 34, Tennessee 3
No. 23 California 28, Ole Miss 20
Mississippi State 28, Kentucky 13
Missouri 34, South Carolina 14
San Jose State 31, Arkansas 24
Saturday, Sept. 28 — Week 5
No. 2 Alabama 59, Ole Miss 31
No. 7 Auburn 56, Mississippi State 23
No. 9 Florida 38, Towson 0
No. 23 Texas A&M 31, Arkansas 27
Vanderbilt 24, Northern Illinois 18
South Carolina 24, Kentucky 7
Saturday, Oct. 5 — Week 6
No. 3 Georgia 43, Tennessee 14
No. 5 LSU 42, Utah State 6
No. 10 Florida 24, No. 7 Auburn 13
Missouri 42, Troy 10
Ole Miss 31, Vanderbilt 6
Saturday, Oct. 12 — Week 7
No. 1 Alabama 47, Texas A&M 28
South Carolina 20, No. 3 Georgia 17 (2OT)
No. 5 LSU 42, No. 7 Florida 28
Tennessee 20, Mississippi State 10
UNLV 34, Vanderbilt 10
Missouri 38, Ole Mis 27
Kentucky 24, Arkansas 20
Saturday, Oct. 19 — Week 8
No. 1 Alabama 35, Tennessee 13
No. 2 LSU 36, Mississippi State 13
No. 9 Florida 38, South Carolina 27
No. 10 Georgia 21, Kentucky 0
No. 11 Auburn 51, Arkansas 10
Vanderbilt 21, No. 22 Missouri 14
Texas A&M 24, Ole Miss 17
Saturday, Oct. 26 — Week 9
No. 1 Alabama 48, Arkansas 7
No. 2 LSU 23, No. 9 Auburn 20
Texas A&M 49, Mississippi State 30
Tennessee 41, South Carolina 21
Kentucky 29, Missouri 7

Story 96
Solskjaer has been the popular choice to become boss on a full-time basis having excelled in the position of caretaker manager
Ole Gunnar Solskjaer has finally fulfilled his dream having been confirmed as Manchester United manager on a permanent basis.
Solskjaer, the clear favourite for the position having overseen a remarkable turnaround of the club’s fortunes while caretaker, has put pen to paper on a three-year deal to succeed Jose Mourinho, the Premier League club confirmed on Thursday morning.
3 Club hero Solskjaer becomes United’s fourth permanent manager since Sir Alex Ferguson’s retirement in 2013
“Manchester United announces that current caretaker manager and former striker, Ole Gunnar Solskjær, has been appointed as the club’s full-time manager on a three-year contract,” a statement read.
Solskjaer was appointed to the interim role last December following the club’s decision to dismiss Jose Mourinho, and he won his first eight matches in charge and claimed a total 14 victories and two draws in just 19 games.
LATEST FOOTBALL NEWS NEW THREADS Ronaldo scores controversial winner as Juventus sport 'unique' new Palace kit AWKWARD Owen and Shearer could face awkward reunion as Amazon announce pundits BOOKED When the real Pele had no clue about Arsenal legend Ray 'Romford Pele' Parlour off the mark Chris Smalling scores first goal for Roma since joining from Man United disgraceful Fan rages at ‘clueless’ Emery after ‘shambolic’ Arsenal lose to Liverpool teens VERDICT Mourinho is 'exactly what Spurs need' and can take them to 'elite level' - Durham ALMOST HAPPENED Origi to blame for denying Emery the chance to win by 'preferred' scoreline unexpected Mustafi shows Xhaka how to address Arsenal fans following a bad performance CLASSY Tierney 'already gets it' as Arsenal man is praised for actions after Liverpool loss selfless Barca players offered to alter contracts so club could sign Neymar, says Pique Homecoming 'It would be amazing' - Milner discusses Leeds return before retiring SPYGATE II? FA demands Man City 'Spygate' answers from Liverpool
He has guided the Red Devils back into a battle for a top four finish – something that seemed remarkably unlikely during Mourinho’s tenure – while United also booked their place in the Champions League quarter-finals for the first time in five years with a stunning comeback defeat of Paris Saint-Germain.
Solskjaer said: “From the first day I arrived, I felt at home at this special club.
“It was an honour to be a Manchester United player, and then to start my coaching career here.
3 Solskjaer spent 11 years playing for United and also managed the club’s reserve team
“The last few months have been a fantastic experience and I want to thank all of the coaches, players and staff for the work we’ve done so far.
“This is the job that I always dreamed of doing and I’m beyond excited to have the chance to lead the club long-term and hopefully deliver the continued success that our amazing fans deserve.”
Ed Woodward, the club’s executive vice-chairman, added: “Since coming in as caretaker manager in December, the results Ole has delivered speak for themselves.
LIVE on talkSPORT talkSPORT is your home of live football! Here's what's coming up on talkSPORT and talkSPORT 2... West Brom vs Birmingham (Friday, 7:45pm) – talkSPORT 2
Brighton vs Southampton (Saturday, 3pm) – talkSPORT 2
West Ham vs Everton (Saturday, 5:30pm) – talkSPORT
Middlesbrough vs Norwich (Saturday, 5:30pm) – talkSPORT 2
Portsmouth vs Sunderland (Sunday, 2:30pm) – talkSPORT 2
“More than just performances and results, Ole brings a wealth of experience, both as a player and as a coach, coupled with a desire to give young players their chance and a deep understanding of the culture of the club. This all means that he is the right person to take Manchester United forward.
“I want to thank Ole and the coaching team for everything they have done so far and congratulate him on this richly deserved appointment. The fans and everyone at the club are behind him as he looks to take us where we need to be and build the next stage of our history.”
Solskjaer spent 11 years playing for United, scoring 126 goals in 266 appearances, and helping the club win 12 trophies – including the historic Treble of 1998/99.
The 46-year-old scored the all-important injury time winner against Bayern Munich to complete the Treble, after Teddy Sheringham’s equaliser, having only been introduced as a substitute in the final 10 minutes.
3 Solskjaer scored perhaps the most famous goal in Manchester United’s illustrious history
He first moved to Old Trafford from Molde in 1996, having previously played for Clausenengen, and retired in 2007, aged 34, following a long-running battle with knee injuries.
Solskjaer began his coaching career with United’s reserves, before taking charge of former club Molde.
He endured an ill-fated spell as Cardiff City boss in 2014, and returned to Molde the following year.
After just over three years in charge at the Aker Stadion, the ‘Baby-faced Assassin’ was brought back to Old Trafford to take the reins after the dismissal of Jose Mourinho.
Though originally expected to only see out the remainder of the 2018/19 season before returning to Molde, Solskjaer has been rewarded with a three-year contract following his fine work in the dug out.

Story 97
Motorsport-Magazin.com - Juan Manuel Correa befindet sich auch zweieinhalb Wochen nach dem furchtbaren Unfall im Formel-2-Rennen in Spa-Francorchamps, dem Anthoine Hubert auf tragische Weise zum Opfer fiel, weiterhin im künstlichen Koma in der intensivmedizinischen Einrichtung in Großbritannien.
Das gab das Presseteam des amerikanisch-ecuadorianischen Fahrers nun in einem Statement bekannt. Demnach hat sich die Lunge des 19-jährigen Fahrers des Sauber Junior Teams allerdings leicht erholt. Correas Atemfunktionen werden dennoch weiterhin künstlich unterstützt.
Correa hatte sich bei dem Unfall in Spa zudem leichte Wirbelverletzungen und Beinbrüche zugezogen. Letztere bereiten aktuell die größten Sorgen. "Juan Manuels Beinverletzungen bleiben ein wichtiges Bedenken und werden sofort operiert, sobald seine Lungen stark genug sind, diesen Prozess zu überstehen", heißt es in dem Statement weiter.
Der Entwicklungsfahrer von Alfa Romeo Racing ist aktuell also noch nicht OP-fähig. Sobald sich daran etwas ändert oder es anderweitige Updates gibt, will das das Presseteam weiterhin mit Statements melden.
Ein anderes Statement kam unterdessen bereits vom Sauber Junior Team by Charouz. Für die beiden letzten Events der Saison hat man nun mit Matevos Isaakyan einen Ersatzfahrer für Correa verkündet. In Russland und Abu Dhabi wird der Russe aus dem bekannten SMP-Programm neuer Teamkollege von Ferrari-Junior Callum Ilott.
Das bedeutet gleichzeitig, dass der Bolide Correas inzwischen nicht mehr für kriminaltechnische Untersuchungen eingezogen ist. In Monza war das Team zuletzt deshalb nur mit einem Auto an den Start gegangen.

Story 98
Sinéad M Langan , associate professor 1, Sigrún AJ Schmidt , registrar 2, Kevin Wing , assistant professor 1, Vera Ehrenstein , professor 2, Stuart G Nicholls , postdoctoral fellow 3 4, Kristian B Filion , assistant professor 5 6, Olaf Klungel , professor 7, Irene Petersen , professor 2 8, Henrik T Sorensen , professor 2, William G Dixon , professor 9, Astrid Guttmann , senior scientist 10 11, Katie Harron , associate professor 12, Lars G Hemkens , senior scientist 13, David Moher , professor 3, Sebastian Schneeweiss , professor 14, Liam Smeeth , professor 1, Miriam Sturkenboom , associate professor 15, Erik von Elm , codirector 16, Shirley V Wang , assistant professor 14, Eric I Benchimol , associate professor and senior scientist 10 17 18 1Faculty of Epidemiology and Population Health, London School of Hygiene and Tropical Medicine, London WC1E 7HT, UK 2Department of Clinical Epidemiology, Aarhus University, Aarhus, Denmark 3Ottawa Hospital Research Institute, Ottawa, ON, Canada; 4School of Epidemiology and Public Health, University of Ottawa, Ottawa, ON, Canada 5Departments of Medicine and of Epidemiology, Biostatistics, and Occupational Health, McGill University, Montreal, QC, Canada 6Centre for Clinical Epidemiology, Lady Davis Institute, Jewish General Hospital, Montreal, QC, Canada 7Division of Pharmacoepidemiology and Clinical Pharmacology, Utrecht Institute for Pharmaceutical Sciences, Utrecht University, Utrecht, Netherlands 8Department of Primary Care and Population Health, University College London, London, UK 9Arthritis Research UK Centre for Epidemiology, Division of Musculoskeletal and Dermatological Sciences, School of Biological Sciences, Manchester Academic Health Science Centre, University of Manchester, Manchester, UK 10Institute for Clinical Evaluative Sciences, Toronto, ON, Canada 11Hospital for Sick Children, Department of Paediatrics, University of Toronto, Toronto, ON, Canada 12ICH Population, Policy, and Practice Programme, University College London, Great Ormond Street Institute of Child Health, London, UK 13Basel Institute for Clinical Epidemiology and Biostatistics, Department of Clinical Research, University Hospital Basel, University of Basel, Basel, Switzerland 14Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, Brigham and Women’s Hospital and Harvard Medical School, Boston, MA, USA 15Julius Global Health, University Medical Center Utrecht, Utrecht, Netherlands 16Cochrane Switzerland, Institute of Social and Preventive Medicine, University of Lausanne, Lausanne, Switzerland 17Department of Pediatrics and School of Epidemiology and Public Health, University of Ottawa, Ottawa, ON, Canada 18Children’s Hospital of Eastern Ontario Research Institute, Ottawa, ON, Canada Correspondence to: S M Langan sinead.langan{at}lshtm.ac.uk Accepted 30 July 2018
In pharmacoepidemiology, routinely collected data from electronic health records (including primary care databases, registries, and administrative healthcare claims) are a resource for research evaluating the real world effectiveness and safety of medicines. Currently available guidelines for the reporting of research using non-randomised, routinely collected data—specifically the REporting of studies Conducted using Observational Routinely collected health Data (RECORD) and the Strengthening the Reporting of OBservational studies in Epidemiology (STROBE) statements—do not capture the complexity of pharmacoepidemiological research. We have therefore extended the RECORD statement to include reporting guidelines specific to pharmacoepidemiological research (RECORD-PE). This article includes the RECORD-PE checklist (also available on www.record-statement.org) and explains each checklist item with examples of good reporting. We anticipate that increasing use of the RECORD-PE guidelines by researchers and endorsement and adherence by journal editors will improve the standards of reporting of pharmacoepidemiological research undertaken using routinely collected data. This improved transparency will benefit the research community, patient care, and ultimately improve public health.
Routinely collected health data are a by-product of the daily operations of healthcare systems, collected independently of specific a priori research questions.12 A broad range of sources (eg, disease registries, health administrative data, quality/safety surveillance databases, electronic health records, and pharmacy data) contain routinely collected data and have both drug exposure and clinical outcomes that are of potential use in pharmacoepidemiology.34
In pharmacoepidemiology, routinely collected health data are a broadly accepted, necessary, and cost effective resource widely used for evaluating the real world effectiveness and safety of medicines. Studies conducted with routinely collected data are necessary for many reasons. Clinical trials might not be available, or ethical, and could have limitations owing to restrictive inclusion and exclusion criteria. Primary data collection could be costly or infeasible, have limited statistical power to detect safety events, or have durations that prevent the assessment of long term safety outcomes. In many cases, routinely collected health data can be used to provide timely answers and reduce waste in biomedical research when analysing important and novel healthcare issues. The use of routinely collected health data not only leverages existing investment but also could reduce the need for additional investment in de novo data collection.56 Research based on real world evidence, such as routinely collected data, has been conducted on health system planning and evaluation, drug utilisation, comparative drug effectiveness, epidemiological surveillance, and postmarketing drug surveillance (phase IV studies).789
Although routinely collected health data are commonly used in pharmacoepidemiological research, these studies are often suboptimally reported.101112 Reporting guidelines have been developed for a range of study designs, and represent a minimum standard or items that should be reported in academic manuscripts.1314 The main purposes of reporting guidelines are to ensure that readers can easily determine the research question, the methodology used, and the study findings; facilitate understanding of study strengths and limitations, specifically providing insight regarding possible biases; and facilitate replication. Reporting guidelines can also indirectly improve the quality of research by indicating which items to address during study design.1516
The RECORD (REporting of studies Conducted using Observational Routinely collected Data) guideline represents the current best practice standard for the reporting of research using non-randomised routinely collected health data. The guideline was the product of an international collaboration focused on improving the reporting of observational studies using routinely collected data.117 RECORD consists of a checklist of 13 items that supplement or modify the earlier best practice guideline, STROBE (STrengthening the Reporting of OBservational studies in Epidemiology), which focused on the reporting of observational studies.118 The RECORD statement was informed by a systematic review that highlighted major deficiencies in the reporting of studies using routinely collected health data.11 Since its publication, RECORD has been endorsed by more than 20 major journals (for more information, see www.record-statement.org).
However, the methodological complexity of pharmacoepidemiological research means that certain reporting requirements are beyond the scope of either RECORD or STROBE. Here, we aimed to extend the RECORD statement to include reporting guidelines specific to pharmacoepidemiological research—that is, the reporting of research focusing on the uses and effects of drugs.19 This initiative is complementary to existing guidance in the field that mainly focuses on methods for doing (instead of reporting) pharmacoepidemiological research and evaluating the quality of published papers.2021 We welcome global community engagement in this endeavour and comments from interested parties by email as these guidelines will be updated periodically.
Summary points The RECORD reporting guidelines represent the current best practice standard to ensure the clarity and completeness of reporting of non-interventional research using routinely collected health data
The RECORD-PE statement was derived by use of rigorous methodology and endorsed by the International Society for Pharmacoepidemiology. It is intended to act as a guideline to improve the reporting of pharmacoepidemiological research undertaken using routinely collected health data
The 15 item checklist should be used in parallel with the RECORD and STROBE guidelines to ensure transparent reporting of pharmacoepidemiology studies using routinely collected health data
The RECORD for Pharmacoepidemiology (RECORD-PE) checklist Creation and development of the checklist We convened a group of international experts in pharmacoepidemiology, routinely collected health data research, reporting guidelines, journalology (that is, the science of publication practices), the joint International Society for Pharmacoepidemiology/International Society for Pharmacoeconomics and Outcomes Research consensus paper on reporting requirements to make database studies reproducible,22 and knowledge users to adapt RECORD for non-interventional pharmacoepidemiological research (RECORD-PE), as presented below. Draft items to be considered in a RECORD-PE checklist were proposed by authors and considered during regular teleconferences and electronic communication, resulting in a draft checklist. A face-to-face meeting was then held in Montreal, Canada, on 25 August 2017. At this meeting, attendees voted on the inclusion of proposed statements and the appropriate wording of these statements, using the approach previously described for the creation of the RECORD statement.17 Items were included in the checklist if more than 80% of participants agreed on the concept, wording, and message of the item. The draft manuscript and checklist were subsequently revised and circulated to all authors and the RECORD steering committee for comment and approval. It was also circulated to the members of the International Society for Pharmacoepidemiology for comment after completion of the draft and revised accordingly. RECORD-PE checklist items Table 1 shows the complete RECORD-PE checklist, which is organised according to standard manuscript sections and follows the conventions set out in STROBE (and subsequently RECORD).118 The checklist consists of 15 additional items, of which 13 focus on the methods section. Because this checklist is an extension of RECORD, which in turn is an extension of available STROBE items, the statements specific to pharmacoepidemiology are presented next to corresponding STROBE and RECORD checklist items. STROBE additionally has specific checklists for study designs including cohort, cross sectional, and case-control studies. For RECORD and RECORD-PE, we have extended the general STROBE checklist.1018 Authors will be expected to consider each checklist item when drafting their manuscript and include items in their manuscript submissions. Below, we provide explanatory text for each RECORD-PE checklist item, organised by manuscript section, and provide a glossary in supplementary table 1. Table 1 The RECORD statement for pharmacoepidemiology (RECORD-PE) checklist of items, extended from the STROBE and RECORD statements,118 which should be reported in non-interventional pharmacoepidemiological studies using routinely collected health data View this table: For content sufficiently covered under STROBE or RECORD, no additional items are provided, although explanatory text regarding particular aspects that might be more pertinent to pharmacoepidemiological studies is provided. All relevant explanations are presented under the respective RECORD-PE item or article section. The RECORD-PE statement is intended for use only in reporting on pharmacoepidemiology studies conducted with routinely collected health data, and represents a minimum standard of reporting for such research in published papers. Such studies include investigation of the use, effectiveness, and safety of drugs or drug eluting devices (eg, drug eluting stents) used in clinical practice. In addition to the widely accepted uses of routinely collected health data for pharmacoepidemiology, in recent years, the concept has emerged that cohort studies of interventions using such data could also be considered attempts to emulate a target trial of the intervention of interest. This concept has been considered helpful within epidemiology and pharmacoepidemiology.2324 Routinely collected health data can also help studies with baseline randomisation or pragmatic trials, because the data are frequently collected as part of routine care or health system administration; however, guidance for the reporting of pragmatic trials or trials using these data is beyond the scope of RECORD-PE.
Keywords and medical subject headings terms The STROBE and RECORD statements do not address the use of specific keywords or medical subject headings (MeSH) terms to identify studies using routinely collected health data.125 There are currently no specific MeSH terms to identify these studies, and researchers use a range of search terms to identify these studies, which is a clear limitation in terms of undertaking systematic reviews and meta-epidemiological research and highlights a need for future research focus.11
Title and abstract No items specific to the RECORD-PE guidelines are needed in addition to the STROBE and RECORD items for the title and abstract. STROBE guidelines advise that an abstract should provide “an informative and balanced summary of what was done and found.”18 Providing such a summary in the abstract highlights that the study is a pharmacoepidemiological study, and details the research question, the approach taken, and the study findings. Because screening of titles and abstracts is a key step in knowledge syntheses (eg, scoping reviews, systematic reviews), clarity in wording the title and abstract will facilitate appropriate reuse of research findings, thus reducing the waste of research resources. In describing the conduct of a study using routinely collected health data, the RECORD guideline items recommend reporting the type of data used and the name of the database(s), including highlighting whether linked data were used; these specifications are also directly relevant to pharmacoepidemiological studies.1
Introduction No items specific to the RECORD-PE guidelines are needed in addition to the STROBE and RECORD items for the introduction section. The STROBE guidelines advise authors to detail “specific objectives, including any prespecified hypotheses.”18 The RECORD explanatory paper further recommends that authors be explicit about whether analyses were exploratory or confirmatory, post hoc or prespecified, or a mixture of these characteristics. Authors should highlight how interested readers can access the study protocol. These recommendations are needed to enable stakeholders to interpret pharmacoepidemiological studies.
Methods (study design) RECORD-PE item 4.a Include details of the specific study design (and its features) and report the use of multiple designs if used. Explanation STROBE recommends that researchers present key elements of the study design early in the paper.18 Because routinely collected health data are typically collected in advance of undertaking a study, researchers can theoretically use a range of study designs (eg, self controlled case-series, cohort or case-control studies) or design features (eg, new user designs) depending on the research question. Use of a range of study designs within papers was not directly considered by RECORD. Two aspects of pharmacoepidemiological research warrant an extension to the STROBE statement. Firstly, researchers in the field often use specific study design features (eg, the active comparator new user design) not covered by existing STROBE guidance. Secondly, it is common to use more than one such design or design feature in one publication. Readers should be able to determine which study designs or design features were used. This information will facilitate those readers interested in replicating the methods used. Study authors should describe such study designs or design features with as much detail as is necessary to make clear to readers what the design involved. If using multiple study designs or design features, authors should comment on which was used for the primary analysis. Authors also should comment on and justify deviations from any study protocol or explicitly state that there was no changes from the protocol. Examples Specific design feature (active comparator new user design)—“A new-user cohort design was used to compare patients initiating dabigatran or rivaroxaban at standard doses for treatment of non valvular AF [atrial fibrillation]. We identified all patients with any inpatient or outpatient diagnoses of AF or atrial flutter, based on International Classification of Diseases, Ninth Revision (ICD-9), coding, who filled their first prescription for either drug from November 4, 2011, when rivaroxaban was approved for AF in the United States, through June 30, 2014. Patients were excluded if they had less than 6 months of enrolment in Medicare Parts A, B, and D, were younger than 65 years, had received prior treatment with warfarin or any NOAC [novel oral anticoagulant], resided in a skilled nursing facility or nursing home, or were receiving hospice care on the date of their cohort-qualifying prescription (index date) . . . Because our purpose was to directly compare dabigatran and rivaroxaban, we did not include a warfarin-treated cohort.”26 Specific design feature (interrupted time series analysis)—“To estimate trend changes in antibiotic prescribing over time, we used segmented linear regression analysis of interrupted time series data, a common quasi-experimental method to assess trend changes after clearly defined events. Separately for each birth week cohort, we estimated the 1-year risk of redeeming at least 1 prescription for an antibiotic, with subanalysis for amoxicillin and penicillin V.”27 Specific design feature (drug utilisation/evaluation of the effectiveness of risk minimisation interventions)—“Following a centralised authorisation within the European Union, on 1 August 2011, dabigatran was marketed in two doses (either 150 or 110 mg bid) for stroke prevention in patients with NVAF [non-valvular atrial fibrillation] and having one or more stroke risk factors. . . . Following early post-marketing reports of bleedings, cautionary recommendations were issued by regulatory authorities. In the safety update from the European Medicines Agency (EMA) (18 November 2011), it was recommended that low doses should be prescribed to elderly patients. Also, this update emphasised the importance of monitoring of renal function, in particular in patients over 75 years. The impact of this safety update, as well as the features of the framework previously described, is assessed in the case study described below.”28 RECORD-PE item 4.b The use of a diagram(s) is recommended to illustrate key aspects of the study design(s), including exposure, washout, lag and observation periods, and covariate definitions as relevant. Explanation We recommend the inclusion of a diagram or figure that illustrates the overall study design or timeline for patient inclusion (including key study aspects such as prescription start and end, risk periods, exposed periods, unexposed periods, grace periods, induction periods, and washout periods). Exposure periods are complex in pharmacoepidemiology and are often difficult for readers to follow; this item was not specifically recommended by RECORD. If more than one type of design or analysis is included in the study, a diagram for each is recommended. This allows potentially complex analysis designs, including multiple at-risk periods between or within patients, to be visually summarised in a way that can prevent misinterpretation of paragraphs of text describing the design and implementation. Examples Illustration of exposure assessment periods in self controlled case series studies—a paper by Douglas and colleagues29 relates to the use of orlistat and risk of acute liver injury and contains a figure describing a typical timeline for a patient in the study (fig 1). The study used a self controlled case series design, and the diagram provides an example of the distribution of unexposed and exposed periods for one patient (baseline, pretreatment, and multiple time periods of orlistat exposure) and highlights the liver injury risk periods. Fig 1 Example of a diagram showing a typical timeline for a patient. *Liver injury could occur at any point during observation period. Adapted from Douglas et al29 with permission Illustration of exposure assessment periods in cohort studies—this study by Kim and colleagues30 on tolciluzimab use and the risk for cardiovascular events describes an active comparator new user comparing two biological medicines to treat rheumatoid arthritis (fig 2). The figure shows two key inclusion criteria (use of ≥1 biological medicine and a diagnosis of rheumatoid arthritis without prior exposure to the specific drug), and the follow-up periods for the two exposure groups, including washout windows. Time periods are clearly marked and censoring events described. Fig 2 Example of a diagram illustrating cohort entry criteria, exposure assessment, and censoring events including time periods. RA=rheumatoid arthritis; TCZ=tocilizumab; TNFi=tumour necrosis factor inhibitors; Dx=diagnosis; Rx=prescription. Adapted from Kim et al30 with permission
Methods (setting) RECORD-PE items No additional RECORD-PE items are needed to broaden the existing STROBE items. Explanation As discussed in the RECORD explanatory document, readers need to understand both the reasons and context of data collection to be able assess the potential for information bias, for example, were the data collected for clinical care or billing purposes. Readers also should be able to determine whether the population in the database represents the source population in order to evaluate the generalisability of findings.
Methods (participants) RECORD-PE item 6.1.a Describe the study entry criteria and the order in which these criteria were applied to identify the study population. Specify whether only users with a specific indication were included and whether patients were allowed to enter the study population once or if multiple entries were permitted. See below for guidance related to matched designs. Explanation When patients are included in a study on the basis of their exposure status to one (or more) drugs, there are likely to be several ways of defining the entry criteria; hence an extension to RECORD is required. We refer here to three levels of population hierarchy described in detail in the RECORD explanatory text—namely, the source population, database population, and study population. In many Scandinavian databases, the source population and database population might represent the same individuals because they comprise the entire population of the specific country.1 The database population is derived from the study population and contains people who meet eligibility criteria (eg, in the case of primary care databases, they are in primary care practices and have not opted out of inclusion in the database). It is important to provide details of the inclusion and exclusion criteria applied to identify the study population, which includes clearly specification of how exposure status and other eligibility criteria are defined. Authors should also be clear whether the exclusion criteria are applied before or after selection of study entry dates. Reporting these details would greatly enhance study reproducibility and ability to evaluate the relevance and validity of findings. A detailed description of matching procedures should be provided. For control sampling, the time axis on which the risk set or incidence density sampling was conducted should also be reported. The procedure for handling cases without eligible controls should be explained (eg, loosening of matching criteria, exclusion). A description should further include whether frequency or individual matching was used, whether matching was done with or without replacement, and the algorithm used (eg, greedy v nearest neighbour matching). Examples of selection of the population A study by van Staa and colleagues included users of oral corticosteroids who were defined as “permanently registered patients aged 18 years or older who received one or more prescriptions for oral corticosteroids during the period of time from the enrolment date in their practice in GPRD up to the end of the study (December 1997).”31 Shin and colleagues report: “The index date for cases was defined by the day of follow-up on which hospital admission occurred. For each case, up to 10 controls were randomly selected using risk set sampling, with controls matched on sex, age (±1 year), cohort entry date (±90 days), and follow-up duration; for one case, the age caliper was widened to 2 years to identify an eligible control.”32
Methods (variables) RECORD-PE item 7.1.a Describe how the drug exposure definition was developed. Explanation Authors should specify clearly how drug exposure code lists were obtained. This information could include which dictionary was searched (eg, the Anatomical Therapeutic Chemical (ATC) classification, or database or country specific codes such as the National Drug Codes in the US)33 and how these dictionaries or data sources were searched (eg, automated or manual), as well as which drug substance name(s) and what route of administration was used for the search and which ATC classification level was applied. This level of detail allows readers to interpret the completeness and veracity of the exposure definition and permits replication of study findings, and goes beyond the detail of RECORD. Example Defining the drug exposure definition—“The main exposures evaluated were first-trimester exposure to any antidepressants (medications with Anatomical Therapeutic Chemical Classification [ATC] codes beginning with N06A) and selective serotonin reuptake inhibitors (SSRIs; medications with ATC codes beginning with N06AB). Exposure was defined according to two sources of information: maternal self-reports (available for offspring born between 1996 and 2012) and dispensation records (available for both parents of offspring born between 2006 and 2012). Information about maternal self-reported medication use during the first trimester of pregnancy came from the Medical Birth Register . . . Information about medication use based on dispensation records came from the Prescribed Drug Register, which covers all medication dispensations and accompanying prescriptions written in Sweden since July 2005.”34 RECORD-PE item 7.1.b Specify the data sources from which drug exposure information for individuals was obtained. Explanation Authors should make clear what the data source is and whether the electronic records represent issued prescriptions from electronic health records or redeemed prescriptions. Readers also need to understand whether a database contains information on reimbursed prescriptions, out-of-network dispensations, drugs directly dispensed by healthcare providers (samples), or over-the-counter drug use and the completeness of these variables. Example Specifying the data sources for drug exposure identification—“In Denmark, the study population included users of OHAs [oral hypoglycaemic agents] identified in the Aarhus University Prescription Database (AUPD). The database’s catchment area covers the North and Central Regions of Denmark (hereafter referred to as ‘northern Denmark’), with a combined population in mid-2010 of 1.8 million persons, which is about one-third of the Danish population. AUPD captures reimbursed prescriptions redeemed in the regions’ outpatient pharmacies since 1998. In the UK, OHA users were identified from the General Practice Research Database (GPRD), currently also known as the Clinical Practice Research Datalink.”35 RECORD-PE item 7.1.c Describe the time window(s) during which an individual is considered exposed to the drug(s). The rationale for selecting a particular time window should be provided. The extent of potential left truncation or left censoring should be specified. Explanation The time of exposure can be, for instance, the number of days after the start of a first prescription (see also recommendation for figure in RECORD-PE item 4). The number of days may be derived from the number of tablets prescribed, the number of recorded refills, or the number of tablets taken per day for the stated or assumed indication. Frequently, for researchers using routinely collected health data, there might be no access to data regarding the instructions for taking the medicine. Readers should be able to know whether duration was assumed, based on usual prescribing or directly ascertained from instructions. A description of specific variables generated in association with drug exposure also should be provided. These could include variables capturing information related to dosage information or the total number of prescriptions redeemed within a defined period. Examples include duration, cumulative dose, and recency (that is, current, new, recent, former use). Authors should specify whether only initiators or both initiators and prevalent users are included. They should clearly outline whether they included new users and treatment naive new users by defining the required washout period before a patient is categorised as new user (eg, a new user, by contrast to a treatment naive new user, could be a re-initiator). Authors should detail assumptions about the prescribed daily dose (if not recorded), the duration of prescription coverage, and the length of grace periods used in defining characteristics such as switching, discontinuation, persistence, and adherence.36 To account for variation in refill behaviour, refills that are sufficiently close together usually are considered to represent continuous use. A drug is often considered discontinued, in the absence of a new refill, if a prespecified time interval goes past the assumed expiration date supplied in a given prescription (based on the estimated number of days prescribed). This issue could be important in systems such as electronic health records, which have variable coding dates. Readers may want to consult recently published recommendations on how to compute such durations of exposure and how to report methodology.37 The definition of the exposed period also can be used to assess the outcome of discontinuation. Because prescription or redemption records are an imperfect measure of true drug intake, the algorithms and assumptions used by authors to define exposed time should be reported. Different definitions of the exposed period can be examined by researchers in sensitivity analyses, which should be reported in the manuscript or appendices. In routinely collected health data, issues of left or right truncation and censoring might also affect the definition of drug exposure and outcome data, and might result in important misclassification and bias—hence, these issues should be reported in publications of routinely collected health data.38 For example, right truncation could exist in an electronic health records setting because patients transfer between practices or within administrative systems if they become ineligible for insurance coverage; decisions around these aspects should be made clear to the reader. Examples of defining exposure time windows Patorno and colleagues report: “Exposure was defined as at least one filled prescription for lithium during the first trimester (first 90 days after the date of the last menstrual period). The primary reference group included women with no lithium or lamotrigine dispensings during the 3 months before the start of pregnancy or during the first trimester. The criterion of no dispensing during the 3 months before the start of pregnancy was imposed to avoid misclassifying as unexposed women who still had medications from an earlier filling available at the start of pregnancy.”39 Larivée and colleagues report: “As is true with most healthcare databases, data are left truncated, resulting in the incomplete capture of medical history and previous use of medications. This issue is particularly important in insurance databases, where no information is available outside of the coverage period, and databases such as US Medicare, which only cover patients aged 65 years or older. This truncation is partially mitigated in the CPRD [Clinical Practice Research Datalink] by the transfer of patient records from one practice to another when patients change practices, but such transfers are only feasible between practices that use the same software and it is not possible to link patient records across practices.”40 RECORD-PE item 7.1.d Justify how events are attributed to current, prior, ever, or cumulative drug exposure. Explanation In pharmacoepidemiological studies, it is common to compare rates of adverse events between two drug groups or two or more periods. The adverse event rate is defined as the number of adverse events divided by the total time at risk for a given exposure. It is important to consider and report transparently how the time at risk is defined. The definition of time at risk depends on the pharmacokinetic properties of the drug, the nature of the endpoint of interest, patient related factors, and the plausible hypothesis about the induction period linking the drug and the endpoint. Outcomes can be attributed to drug exposure anywhere along the spectrum from “currently exposed” to “ever exposed” when a binary exposure variable is considered. Another risk attribution model within this spectrum is “on drug plus a lag window.” In this model, an event can be attributed to treatment for a given time period beyond drug discontinuation, thereby allowing time for the drug to continue having a residual effect within the body, or for delayed presentation of the outcome. Different risk attribution models can lead to different conclusions based on the same data. This issue has led to guidelines for rheumatology biological medicine registers, suggesting that research groups use similar risk attribution models when addressing the same research question, to increase comparability of findings.41 When defining the risk attribution model, researchers may also consider the possibility of protopathic bias, for example, starting a drug to treat early symptoms of the undiagnosed outcome.42 If protopathic bias is possible, authors should describe it in their manuscript. Example Describing how events are attributed to drug exposure—[In the] “statistical analysis TB [tuberculosis] cases were attributed to anti-TNF [tumour necrosis factor] therapy using two different models: “on drug” (if the patient was actively receiving that drug at the time of diagnosis) and “most recent drug.”43 RECORD-PE item 7.1.e When examining drug dose and risk attribution, describe how current treatment, historical treatment, or time on treatment are considered. Explanation The risk of an adverse event could be influenced by current or historical treatment. Therefore, researchers should look at how current and past drug exposure are considered in analyses. Modelling only current use, either as a binary variable or as current dose, assumes that previous use has no effect on the outcome of interest. Recent use, such as exposure in the past 30 days, allows historical exposure to be considered, but assumes that exposure 29 days ago was important but exposure 31 days ago was not. Selection of an appropriate risk window varies according to the research question and the biological mechanism through which the exposure might lead to the outcome. For example, historical drug exposure is unlikely to influence a hypersensitivity reaction today, while drug exposure months or years ago could contribute to current risk of malignancy.44 Complex models, such as the weighted cumulative exposure model, allow history of drug use to be modelled flexibly up to the time point when risk is assessed.45 Although no model is perfect, researchers should consider and report how past exposure was taken into consideration. The approach for handling individuals who were exposed to more than one of the drug exposures of interest during the study period also should be outlined and authors will want to report their approach to time varying confounding. Authors might also want to directly address the issue of depletion of susceptible people or healthy adherer bias.4647 Examples describing how current and historical exposures are considered Movahedi and colleagues report: “Because of uncertainty about mechanisms linking glucocorticoid (GC) exposure and diabetes mellitus (DM), we fitted 7 conventional models, each using a different representation of time-varying GC exposure . . . Models 5 and 6 used continuous time-varying measures of cumulative dose until a given time point, either in the last year or since study entry, respectively. Model 7 categorized cumulative dose since cohort entry, with cutoff points (based on quartiles) at 0, 960, 3,055, and 7,300 mg PED [prednisolone equivalent dose].”48 Larivée and colleagues report: “The aim of this study was to describe the challenge of studying the risk of VTE [venous thromboembolism] among first-time users of drospirenone-containing COCs [combined oral contraceptives] in a healthcare database and assess the risk among first-time users and restarters . . . The first-time user cohort included all women aged 16-45 years who received a first ever prescription of drospirenone- or levonorgestrel-containing COCs between May 2002 and March 2015. The restarter cohort included those who were restarting a COC after a period of non-use of ≥6 months.”40 RECORD-PE item 7.1.f Use of any comparator groups should be outlined and justified. Explanation Confounding by indication has also been called an “intractable” bias in epidemiology,49 because the choice of treatment is guided foremost by the risk of a particular outcome; hence this item has particular relevance to pharmacoepidemiology. This bias might lead to strong confounding, perhaps greater than that arising from associations due to underlying common causes. Moreover, the degree of confounding by indication is difficult to assess, because it is based on an expected prognosis, and that expectation is formed in the mind of an individual health professional dealing with an individual patient. An appropriate choice of a comparator treatment is key to reducing confounding by indication or severity (see RECORD-PE item 4.a). If there is no comparator group or cohort, authors should state why. Clear description of the use and justification of comparator groups is needed for the assessment of the potential for confounding by indication or severity. Comparators might include alternative drug exposures for the same indication, differing time windows for the same drug exposures, use of historical comparators, unexposed periods, or unexposed individuals. In the absence of randomisation, confounding (by indication) deserves close attention. Therefore, researchers can use more than one comparison group and make inferences based on whether the estimate of association changes in response to better control of confounding (eg, whether an odds ratio based on an active comparator differs with or without adjustment for confounders), and these analyses should be reported in the published paper. Historical active comparator groups can be assembled from routinely collected health data for single arm studies or when a contemporaneous active comparator is not available; any of these approaches should be clearly reported. Examples of consideration of comparator drugs In a study examining the association between use of antidepressants and pregnancy/offspring outcomes, Sujan and colleagues dealt with confounding by indication by using exposures during non-relevant gestational periods: “To explore whether intrauterine exposure was specifically associated with outcomes over and above maternal depression treatment around the time of pregnancy, associations for maternal first-trimester antidepressant dispensations were compared with associations for dispensations before pregnancy, while adjusting for measured pregnancy covariates, maternal covariates, and paternal covariates . . . Additionally, the fit of models that included separate parameters for before-pregnancy dispensations and first trimester dispensations were compared with models that included 1 parameter for both dispensation windows. Paternal first trimester antidepressant dispensations were used as a negative control to further explore the role of familial confounding.”34 Filion and colleagues report: “Our primary reference group was patients receiving treatment with combinations of oral antidiabetic drugs. With guidelines recommending that incretin-based drugs be used as second-line or third-line therapy, the use of this reference group both reduced potential confounding by indication and provided a clinically relevant treatment comparison.”50 RECORD-PE item 7.1.g Outline the approach used to handle individuals with more than one relevant drug exposure during the study period. Explanation In a cohort study comparing the incidence of an adverse reaction between two or more drug exposures, the method of handling individuals who receive multiple drugs at the start of their exposure period (or drug 1 initially, followed by drug 2) should be described to enable readers to interpret findings (see also RECORD-PE items 7.1.d and 7.1.e). Some studies exclude patients who, according to the prescription or dispensing record, receive more than one treatment at the same time at cohort entry, since attribution of risk is difficult. Censoring is used most often if more than one treatment is experienced during follow-up (see below). Alternatively, exposure to more than one treatment (eg, while switching from an old treatment to a novel treatment) can be handled through time varying exposure, whereby each patient’s person time is segmented, based on the dispensing record, with appropriate methods for handling time dependent confounding (eg, marginal structural models, g estimation). The approach taken by authors should be reported transparently, including defining risk attribution models and lag periods. Examples of handling multiple drug exposures Use of time varying exposures was reported clearly by Xue and colleagues in an international pharmacovigilance study of women with postmenopausal osteoporosis treated with denosumab: “because a large proportion of new Prolia users may have been previously treated with a bisphosphonate, a new-user designwhich mitigates biases associated with previous treatments, if adopted, will be based on a very small number of patients. Also, patients with osteoporosis tend to switch treatments over time, so an open-cohort design combined with an ‘as treated’ analysis was selected to account for time-varying medication exposure.”51 Wong and colleagues report: “Based on age within five years, sex, and calendar year at use, we matched one clarithromycin user with one or two amoxicillin users. In both groups we excluded patients who had been prescribed clarithromycin up to four years before the date of first antibiotic prescription during the observation period. However, amoxicillin users could be classified as using clarithromycin at a later date. The observation period commenced from the date of the first antibiotic prescription (index date) and ended at the earliest occurrence of the outcome, death, subsequent use of clarithromycin or amoxicillin, or end of study (31 December 2012).”52
Methods (data sources) RECORD-PE item 8.a Describe the healthcare system and mechanisms for generating the drug exposure records. Specify the care setting in which the drug(s) of interest was prescribed. Explanation The type of healthcare system, the characteristics of patients for whom drug data are available, and the extent to which patients are reimbursed for prescription drugs could affect the likelihood of drug use, and the likelihood of a record of drug use being included in the study data—for example, formulary restrictions could preclude the use of drugs. Understanding this context will be important for interpretation of generalisability or understanding the limitations in availability of drugs in different settings. For example, although Canada has a government funded, universal healthcare system, some provinces reimburse all prescription drug costs, whereas other provinces only cover drug costs in specific age groups or in people with low incomes who are receiving social assistance. In this second group of provinces, supplemental private insurance might be common among non-covered groups, and therefore drug records could be incomplete in provincial health administrative data. This missing information could result in partial ascertainment, because complete prescription records are available only for certain patients. Left truncation also could create bias if public insurance coverage is available only for older patients. Therefore, characteristics of the health system and context of drug data collection should be provided. Examples describing the healthcare system within which drugs were prescribed Larivée and colleagues report: “Restarters of COCs [drospirenone-containing combined oral contraceptives] can also be misclassified as first-time users in UK databases as oral contraceptives are commonly prescribed at family planning clinics (i.e., community contraception clinics, genitourinary medicine clinics, sexual health clinics). In England, approximately 7.9% of women aged under 16 attended a family planning clinic from 2009 to 2010 and 21.5% of women aged 16–19 years visited a family planning clinic from 2008 to 2009. The CPRD [Clinical Practice Research Datalink] only captures prescriptions issued by the general practitioner, and the availability of oral contraceptives at family planning clinics makes the identification of first-time users difficult. To attempt to overcome this issue, we applied several exclusion criteria, such as the exclusion of all women with previous prescriptions for hormonal contraception issued by the general practitioner and those with diagnostic codes indicating previous use of hormonal contraception. In addition, we excluded all women with a diagnostic or referral code indicating previous visits to a family planning clinic any time before cohort entry.”40 Khan and colleagues report: “Using unique patient identifiers, stroke patients identified in the registry were linked to the Ontario Drug Benefits Database, which contains information on antihypertensive drug prescriptions, including the quantity and dates of drugs dispensed as well as the number of days supplied from each prescription, for patients ≥65 years of age. Residents may fill prescriptions at any outpatient pharmacy in Ontario with a maximum copayment of $6.11 (Canadian) for each prescription after a yearly $100 (Canadian) deductible. Low income seniors have a $2 (Canadian) maximum copayment with no yearly deductible. Using postal codes, patients in the registry are also linked to data from the 2006 Canada Census to determine median neighborhood income.”53
Methods (bias) RECORD-PE items No items specific to the RECORD-PE guidelines are needed in addition to the RECORD and STROBE items. Explanation Biased studies are characterised by systematic error in observed associations, and readers need to understand the approaches taken to manage bias in order for them to judge whether the results are biased. Several potential biases are likely to arise within pharmacoepidemiological studies, and could be more prominent when routinely collected data are used. Recent papers describing use of triangulation could be helpful in discussions about bias.54 The ROBINS-I (risk of bias in non-randomised studies of interventions) tool might also help to focus discussions of bias.55 We list below some potential sources of bias in pharmacoepidemiological studies that should be reported. Confounding in pharmacoepidemiological analyses might be addressed by design or analytical approaches.56 Examples of designs or design features include the use of self controlled case series, instrumental variables, regression discontinuity design, and active comparators. Examples of analytical approaches include the use of multivariable regression analysis or propensity scores, although these approaches will not guarantee absence of confounding. The study design or analytical approach used to address confounding should be reported, and the authors should note in the discussion the extent to which these methods potentially addressed or failed to address the risk of confounding. If more than one method was used, authors should make clear which approach was the main analysis and which were sensitivity analyses. For example, in studies applying the propensity score methodology to handle baseline confounding, the method of propensity score estimation should be reported (eg, logistic regression). These scores can be used to adjust for baseline confounding by several methods: propensity score matching, propensity score stratification, covariate adjustment, and inverse probability of treatment weighting.57 The specific approach (or approaches) used should be clearly described, together with any attempts to assess the similarities of the resulting treated and untreated groups for each baseline variable.5859 If investigators have used trimming approaches, they should discuss the resulting number of excluded participants. In particular, high dimensional proxy adjustment based on propensity score methods has been reported to reduce residual confounding in studies using claims data and if this approach is used, it should be described.60 Lists of empirically identified potential confounders should be reported in online appendices.39 If other approaches (such as instrumental variables) were used, these should be clearly described in the publication with similar detail to those outlined for propensity scores.61 Of particular relevance when considering confounding in studies of drug treatment is the type of treatment effect that the non-interventional study is attempting to measure. Types include the intention-to-treat effect (the comparative effect of being assigned to treatment strategies at baseline carried forward, regardless of whether study individuals adhere to the specific treatment) and the as-treated effect (the comparative effect of a drug while it is actually used). In cases in which observational studies based on routinely collected data are designed to emulate a hypothetical or real trial, authors should clearly specify any relevant existing or hypothetical trial that is being emulated. For studies that allow individuals to switch drug treatments as part of the analysis, the role of potential time varying confounders should be considered and reported in the text, along with details of any complex statistical methods applied (such as inverse probability weighting of marginal structural models). For example, in their study of the effect of aspirin on cardiovascular mortality,62 Cook and colleagues include a directed acyclical graph of the hypothetical relation between aspirin use, cardiovascular death, and intervening cardiovascular events to show the role of non-fatal cardiovascular events as potential time varying confounders or intermediate steps in the association between aspirin use and cardiovascular mortality.
Confounding by health status (healthy initiator bias or depletion of susceptibles) can be dealt with at the design stage by aligning the start of observation with treatment initiation (the active comparator new user design; see RECORD-PE item 4.a). The reasoning behind the decision to use such a design feature as well as the extent to which selection bias was or was not addressed should be discussed.
Information and selection bias due to potential misclassification of drug exposure by prescription or redemption records can be dealt with in a sensitivity analysis that includes different definitions of exposures (eg, when different algorithms are used to define duration of prescribing episodes63). An alternative approach is to include only people with more than one prescription or redemption over a given period (eg, within six months), because those individuals with just one prescription or redemption might never have used the treatment. Use of different washout periods to define new episodes of treatment could also affect the interpretation of data. Each issue should be clearly described and discussed in reports of pharmacoepidemiological studies based on routinely collected health data.
Methods (statistical methods) RECORD-PE item 12a Describe the methods used to evaluate whether the assumptions have been met. Explanation In reporting all study designs, authors should discuss whether the underlying study assumptions have been met. A failure of the assumptions being met could undermine the methods used. Determining whether the methods used were appropriate, given the data, is important for readers to understand whether the resulting analysis requires further consideration. A pharmacoepidemiological example is the use of self controlled studies, in which participants act as their own controls, and include the case crossover design and self controlled case series studies.64 When applying the self controlled case series method, several assumptions must be met to obtain valid and unbiased estimates,65 for instance, exposure to the drug of interest must not be influenced by a previous outcome event.6667 Authors should specify clearly how the assumptions of self controlled or other study designs were evaluated. Detailed guidance on the conduct and reporting of self controlled case series are beyond the scope of these guidelines, but are currently being developed by the SCOPE (self controlled crossover observational pharmacoepidemiology) initiative.68 All reports should explain any assumptions that were not evaluated or not met. Discussions should also address the possibility of time related bias (eg, immortal time bias),69 if these are likely to be a problem. Example on testing study assumptions Wilson and colleagues report: “We graphed the number of combined endpoint events in the days before and after vaccination. In the self-controlled case series model, the date of vaccination serves as the index date for exposure for each patient. Previous studies have identified that children are at increased risk for systemic reactions at different times from 5–14 days after vaccination . . . Because a priori we did not know with certainty the time period following vaccination for which there would be an increased risk of our combined endpoint, we modified the standard self-controlled case series approach by looking for an elevation in risk during each post-vaccination day up to day 17 . . . We then classified days 20–28 as unexposed, establishing a washout period in between the exposed and unexposed periods . . . When multiple events occurred to a given individual, the first occurrence of the composite outcome in the post-vaccination period was used (e.g., someone attending the ER [emergency department] who was then admitted would have one event counted in that period). The relative incidence rate of the composite endpoint during the exposed period compared with the unexposed period was analyzed using a fixed effects Poisson regression model. This model included a term for exposure period and a term for patient, thereby allowing each individual to serve as his or her own control and accounting for intra-individual correlation. An offset term was also included to account for the differing durations of the exposed and unexposed periods.”70 RECORD-PE item 12.b Describe and justify the use of multiple designs, design features, or analytical approaches. Explanation As discussed in RECORD-PE item 4.a, the use of multiple designs or design features in the same report is a commonly used strategy in pharmacoepidemiological studies to assess the potential for bias and residual confounding. If authors have used multiple approaches to analysis, these should be clearly outlined for readers to assess strengths and limitations. The authors also should state clearly how they approached reproducibility across different databases, including issues such as variability in coding and healthcare systems. If authors used a common data model71 (see the second example72 below) to analyse data across different data sources, they should describe this and specify which common data model they used. If any data pooling across data sources was done, the approaches used should be described. Examples describing each design, design feature, or analytical approach Wong and colleagues report: “We used Poisson regression to estimate the rate ratios for clarithromycin users compared with amoxicillin users during current, recent, and past use . . . For the self-controlled case series analysis, we estimated incidence rate ratios using conditional Poisson regression, comparing the rate of events during risk windows with the rate during baseline periods . . . we also performed a post hoc case crossover analysis, which is not vulnerable to this limitation of the self controlled case series. The case crossover design is applied for studies investigating the association between transient drug use and outcome with abrupt time of onset. We estimated odds ratios using conditional logistic regression, comparing drug use before the event (current period) with that at other earlier control periods within patients.”52 But and colleagues report: “The individual-level data from the five cohorts were standardised by each research partner locally using the common data model. We then conducted centralised analyses by uploading the unified data to a server at Statistics Denmark, where for each cohort we constructed the individual-level dataset to assess insulin exposure and other variables in exactly the same way. We employed a semi-aggregate level approach to combine the datasets, which were tabulated by cancer site as the number of cancer cases and person-years aggregated by categorical variables.”72
Methods (data access and cleaning methods) RECORD-PE items No items specific to the RECORD-PE guidelines are needed in addition to the RECORD items. Explanation RECORD states that “authors should provide information on the data cleaning methods used in the study.”1 This information is particularly important for pharmacoepidemiological studies, because the preparation of drug exposure data is complex and reflects serial assumptions that are typically not disclosed. Therefore, data cleaning extends substantially beyond the removal of outlying values. When data require preparation for analysis (eg, conversion of raw prescription data to exposed and unexposed episodes of person time), authors should be transparent about the steps undertaken in cleaning the data. These steps might include decisions on deriving start and stop dates; and assumptions made when instructions on administration instructions provide for flexibility (eg, prescriptions as needed), when prescriptions are overlapping, and when clinically implausible values are encountered.
Results RECORD-PE items For the results section, no items specific to RECORD-PE are needed in addition to the earlier STROBE and RECORD recommendations. Explanation STROBE guidelines recommend that researchers report the number of individuals included at each stage of the study, including reasons for exclusion.18 The RECORD guidelines further underscore the importance of reporting how results were filtered based on data quality, availability, and linkage.1 Use of a flow diagram to illustrate the selection of the study population is encouraged by both STROBE and RECORD—note that this diagram is distinct from the study design diagram discussed in RECORD-PE item 4.b. A high level of transparency is equally important in pharmacoepidemiological studies in which additional eligibility criteria are often used (eg, based on indications for use, washout periods, and lag periods), adding further complexity to the selection process. Researchers should report the number of participants included at all stages of the study, including the analysis stage and for analyses performed to assess different objectives (eg, subgroup and sensitivity analyses). Pharmacoepidemiological studies that examine adverse drug events or reactions should report whether and how researchers assessed or validated the outcome on the individual case level (eg, through record review by a specialist blinded to the exposure(s) under study, in order to try and rule out other more likely causes of the event). This process should be clear from the text, a table, or a flowchart describing how many events were considered to be caused by the study drug(s) after record review. Presenting numbers of potential cases that lacked sufficient data to be classified as non-cases or definite cases (and were assigned a final status such as possible or uncertain) is also encouraged. In an article by Kaye and colleagues on the risk of liver injury associated with use of oral antimicrobials, figure 1 provides a good example.73 Clear delineation of the selection process facilitates critical appraisal, applicability, and reproducibility of the study findings. Regarding results from descriptive analyses, STROBE recommends that authors present detailed data on the distribution of demographic, clinical, and social variables, including the number of participants with missing data. Missing data are frequently encountered in pharmacoepidemiological studies based on routinely collected data. In studies using routinely collected data, we might not know whether there is non-recorded or unmeasured information on diagnoses, symptoms, and management. Cohort studies also should provide summary measures of follow-up time. For studies based on routinely collected data, RECORD does not include additional items.1 However, in terms of clinical variables, pharmacoepidemiological studies should report the distribution of indications for the drug of interest. It is also advised that authors summarise person time on and off drug exposure, including the sensitivity of “at risk” periods to different definitions of risk attribution if appropriate. Furthermore, in the case of time varying variables, which are increasingly used in pharmacoepidemiology, authors should consider reporting the number and characteristics of individuals with time varying data. RECORD-PE supports the STROBE recommendations for presentation of outcome data, main results, and other analyses.18 Thus, researchers should report the number of events or summary measures of outcomes (or exposures in case-control studies), unadjusted and adjusted estimates and their precision, confounder variables adjusted for, category boundaries when continuous variables are categorised, absolute measures of risk for a meaningful time period (if relevant), and other analyses performed (including subgroup, interaction, and sensitivity analyses). Authors should present the results determined using the different approaches, which could include conventional methods and more complex approaches. If multiple approaches have been used in an attempt to account for confounding (eg, matching and adjustment), the results of all methods should be presented and any differences discussed. It is advisable to present descriptive results showing covariate distribution (number and percentages) in exposure groups before propensity score matching, as well as the distribution after propensity score matching if appropriate. Authors should explicitly state whether an analysis was prespecified or post hoc. Researchers also are advised to report in detail the results of analyses used to explore and handle missing data, which are frequently encountered in pharmacoepidemiological studies based on routinely collected data.
Discussion (limitations) RECORD-PE item 19.1.a Describe the degree to which the chosen database(s) adequately captures the drug exposure(s) of interest. Explanation Authors should report whether the drug exposure in question could be ascertained by an alternative source, if not fully captured in the database used for the study. Some of the explanation outlined in RECORD-PE item 8.a is also relevant here. An additional issue relates is whether a drug exposure of interest could have been obtained over the counter, and whether such use is captured by the data source.74 If not, authors may want to discuss the likely extent of misclassification. A similar issue is that if patients are admitted to hospital for extended periods and the database does not capture inhospital dispensing of drug treatments, misclassification also might occur.6975 Authors should also discuss whether the database is likely to have had information on diagnoses, symptoms, and management, and discuss the implications for study findings. Examples on adequacy of capture of drug exposure in database Weinstein and colleagues report: “This analysis was restricted to prescription use of paracetamol and ibuprofen, and it is unknown whether these results would generalize to non-prescription exposures. There are several reasons for a GP [general practitioner] to prescribe these medications in the CPRD [Clinical Practice Research Datalink], including record keeping and giving the patient access to the medication at a lower cost because the patient qualifies for free filling of prescriptions. In addition, those using these medications chronically may need larger quantities than typically available over the counter. Thus, it is likely that, by relying on prescriptions, we skewed our study population toward elderly subjects with chronic conditions who may also be at the low end of the economic spectrum.”76 Suissa reports: “In our illustration, the naive approach that does not account for the immeasurable hospitalized time during the 30-day period prior to the index date estimated a significant 40 percent reduction in mortality associated with a prescription of inhaled corticosteroids during this period. However, there were 806 cases (deaths) that had been hospitalized during this same 30-day period and that were considered unexposed by this analysis since they did not receive a prescription. These cases had spent 16.2 out of the 30 days in the hospital, time during which they could not receive outpatient prescriptions, compared with 8.8 days for the corresponding 253 such controls. In fact, 190 of these 806 cases (24 percent) had spent the entire 30-day period in the hospital, compared with seven of the 253 controls (3 percent), and could not possibly have received any prescription at all.”69
Discussion (interpretation) RECORD-PE item 20.a Discuss the potential for confounding by indication, contraindication, or disease severity or for selection bias (healthy adherer or sick stopper) as alternative explanations for the study findings when relevant. Explanation As discussed in the methods section, confounding by indication is a major issue in interpreting the findings of pharmacoepidemiological studies, beyond studies of routinely collected data in general. Particularly in the case of insurance or billing data (such as health administrative data), identification of study participants, drug exposures, confounders, and outcomes are based on coded data. Little or no information might be available to describe the indication for drug treatment, personal preferences and values of the patient and prescriber, any potential contraindications to use, or disease severity, all of which could confound the association between the drug and the outcome of interest. Even in clinical data (such as data from electronic health records), the indication or contraindication for drugs might not be recorded or might be contained in free text fields, and not accessible to investigators using these data for pharmacoepidemiological research. Important confounding variables thus might not be available for investigators or readers of the research report. Therefore, to the best of their ability, authors should report such potential confounding in the routinely collected health data and how the confounding was managed overall. We recommend the inclusion of a clear statement in the conclusions (or other discussion section) to explain whether the results could be explained by confounding by indication. Such a statement would help reduce misguided decision making and increase the trustworthiness of the evidence and its interpretation. This statement could report any post hoc analyses designed to evaluate the robustness of the finding and alternative explanations—for instance, to evaluate whether patients in different exposure groups were likely to have been prescribed the drugs for similar conditions. If moving of an individual to another practice or insurance database cannot be tracked, authors should clearly outline whether that individual’s person time is unique (that is, only considered from the new registration date) and discuss the effect of missing past exposures or events on the study findings. A histogram of people leaving for reasons other than death by year of age also might be useful, as well as the age distribution of people entering the population. Further, as per RECORD-PE item 12.1.b, authors should include explicit consideration of results from different approaches when they have used multiple designs, design features, or analytical approaches. This information is especially pertinent if such efforts yield inconsistent results and thus guidance on interpretation is needed. Examples on alternative explanation for findings Sujan and colleagues report: “The findings from the present study should be considered in light of several limitations. First, and most important, observational designs such as these cannot fully rule out all sources of confounding. In particular, like other register-based approaches, this study could not comprehensively assess maternal depression or its severity, nor could it compare different antidepressant treatment regimens. Thus, associations could have been influenced by confounding by antidepressant indication . . . the study used multiple designs to address this limitation, each of which could help rule out some but not all sources of confounding, to provide complementary evidence. For example, sibling comparisons ruled out all stable confounders (e.g., chronic maternal depression), but that design may not have been able to account for confounding from maternal depression that varied across pregnancies. Thus, the within-family associations with preterm birth may plausibly be driven by unmeasured time-varying maternal depression rather than by antidepressant use.”34 Filion and colleagues report: “Our study was designed to examine the impact of drug formulary restrictions on the validity of pharmacoepidemiologic studies using the example of fluticasone/salmeterol combination therapy. We found that the implementation of these restrictions had a profound effect on drug utilization, with the policy resulting in an important decrease in the rates of prescription and of new use of fluticasone/salmeterol. These prescription changes resulted in channeling and confounding by indication, with new users of fluticasone/salmeterol having a significantly higher crude rate of hospitalization for respiratory causes during the restricted period (crude HR [hazard ratio] = 1.41, 95%CI [confidence interval] = 1.32, 1.51) because of the presence of more severe underlying respiratory disease. Adjustment for potential confounders attenuated and reversed the association, with new users during the restricted period having a significantly lower rate of hospitalization for respiratory causes compared with those during the liberal period (fully adjusted HR = 0.78, 95%CI = 0.73, 0.83). These results suggest that drug formulary restrictions can result in substantial and unexpected confounding by indication that threatens the validity of study results. These results also suggest that adjusting for patient demographic and clinical characteristics is insufficient to account for channeling because of formulary restrictions. Consequently, such restrictions must be considered in the design and analysis of pharmacoepidemiologic studies.”77 Schneeweiss and colleagues report: “Aprotinin rather than aminocaproic acid was used in sicker patients, and the modest reduction in the relative mortality estimates after the control of confounding by covariates is consistent with the hypothesis of confounding on the basis of indication. Multivariate analyses resulted in weaker associations between aprotinin and death than those reported in unadjusted analyses (unadjusted relative risk, 1.83; adjusted relative risk, 1.64). Matching according to propensity score permitted us to control for an additional 10 covariates in a highly selected cohort, which further reduced the relative-risk estimate. “Our analyses were adjusted for some, but not all, covariates typically included in risk-prediction scores for patients undergoing CABG [coronary artery bypass grafting]. However, we adjusted for many covariates not typically included, and controlling for proxies of confounders results in control of the confounders themselves if the proxies capture the relations with the true confounding variable, exposure, and outcomes. Our joint adjustment for 41 characteristics before CABG was performed resulted in the prediction of in-hospital death that is as good as that from widely accepted clinical risk-prediction models for patients undergoing CABG. Prediction was almost identical for patients receiving aprotinin and for those receiving aminocaproic acid.”78
Discussion of the RECORD-PE checklist The complete and accurate reporting of research is an ethical requirement endorsed by leading declarations and recommendations internationally.7980 The RECORD-PE guidelines have been developed to meet an identified need and are designed to improve the reporting of pharmacoepidemiological studies undertaken using routinely collected data. They are an extension of the STROBE and RECORD statements and should be used in conjunction with the existing guidelines.11881 RECORD-PE represents a minimum standard of reporting and complements a recent set of comprehensive methodological and reporting items created with the aim of making pharmacoepidemiological research more reproducible.22 Better reporting is a prerequisite of replication, but replication requires much more detail. However, RECORD-PE also guides authors on the transparency of reporting and helps readers to understand strengths and potential limitations of the work. Therefore, RECORD-PE represents a minimum standard of reporting for pharmacoepidemiological studies undertaken using routinely collected health data. Limitations We consulted widely in the creation of these guidelines, including international experts in pharmacoepidemiology, journalology, editors, and policy makers. Despite wide consultation, we may have missed some key points. In addition, members of our guideline development working committee were primarily from western Europe and North America. Pharmacoepidemiology is a rapidly changing field with frequent new methodological developments, reflecting the growth of big data, the development of integrated or distributed data systems, and the innovative approaches being developed to reduce bias associated with the use of non-randomised data to assess drug effects. Increasing collaborative approaches across traditional geographical and data source boundaries are leading to new discoveries for patient benefit in pharmacovigilance and pharmacoepidemiology to overcome problems such as sample sizes insufficient to detect less common safety signals. We have included some recent developments briefly in this article, for example, the use of common data models. We recognise that these guidelines will need to be updated to encompass new developments. The RECORD-PE guidelines are an extension of the STROBE guidelines for non-interventional research, hence the focus of these guidelines is largely on non-interventional research in pharmacoepidemiology. There is much discussion in the literature about whether the term “observational” should be used as opposed to the term “non-interventional studies,” because all studies involve observation. For RECORD-PE, we have continued with the term “observational” in the title because RECORD-PE is an extension of RECORD which, in turn, is an extension of the STROBE guidance.118 We have briefly mentioned the use of pragmatic trials using routinely collected health data in the RECORD-PE guidelines; however, the increasing use of pragmatic randomised controlled trials (and particularly the development of registry based trials and trials within cohorts8283) will likely necessitate expansion of the currently available guidance with both RECORD and CONSORT as guiding documents. Conclusions of the RECORD-PE checklist The RECORD-PE statement aims to extend existing STROBE and RECORD guidelines providing guidance for the reporting of pharmacoepidemiological studies using routinely collected data. It aims to enable readers to understand what was planned, what was done, and what was found in the research. This essential information is critical for users of research to optimally interpret the findings, including their strengths and limitations. Poor research reporting hampers the use of research findings and is an important component of research waste.84 We anticipate that with increasing use of the RECORD-PE guidelines by researchers and endorsement and adherence by journal editors, the reporting of pharmacoepidemiological research undertaken using routinely collected health data will improve. The improved transparency and accuracy will benefit the research community, and ultimately improve patient care.
Footnotes Contributors: SML and EIB conceived and designed the study, carried out the statistical analysis, had full access to all the data in the study, take responsibility for the integrity of the data and the accuracy of the data analysis, and are guarantors. All authors acquired data, analysed and interpreted data, drafted the manuscript, and critically revised the manuscript for important intellectual content. The corresponding author attests that all listed authors meet authorship criteria and that no others meeting the criteria have been omitted.
Funding: We gratefully acknowledge funding from the International Society for Pharmacoepidemiology as well as comments received from its membership. SML is supported by a Wellcome Senior Clinical fellowship in Science (205039/Z/16/Z); EIB is supported by a New Investigator Award from the Canadian Institutes of Health Research, Canadian Association of Gastroenterology, and Crohn’s and Colitis Canada; EIB is also supported by the career enhancement programme of the Canadian Child Health Clinician Scientist Programme; KBF is supported by a salary support award from the Fonds de recherche du Québec—Santé (FRQS; Quebec Foundation for Health Research); HTS is supported by the Programme for Clinical Research Infrastructure (PROCRIN) Programme.
Competing interests: All authors have completed the ICMJE uniform disclosure form at www.icmje.org/coi_disclosure.pdf and declare: main support from the International Society for Pharmacoepidemiology for the submitted work; no financial relationships with any organisations that might have an interest in the submitted work in the previous three years; no other relationships or activities that could appear to have influenced the submitted work.
Provenance and peer review: Not commissioned; externally peer reviewed.

Story 99
A 24-HOUR bus service is set to be introduced in Dublin on some routes by the end of the year.
The first route to be trialled on the new service will be the 41 between Swords and Dublin city centre, a route that also services Dublin Airport, it's understood.
1 Dublin Bus is set to trial a 24-hour service on the route 41 to start Credit: PA:Press Association
The decision was made following a pilot scheme in Cork by the National Transport Authority that was shown to benefit late-night businesses.
NTA CEO Anne Graham said it would be useful for members of the public working irregular hours as well as pubs and restaurants in the city.
While the 41 will be first route trialled, other Dublin Bus routes are set to see a 24-hour service rolled out later.
Anne Graham told the Sunday Independent: "We know there is a demand for 24-hour services within Dublin city so we're hoping to commence at least one service this year in Dublin Bus.
"We haven't got the routes worked out yet, but we are planning that we would extend these on the key routes around the city."
CORK TRIAL SUCCESS
The success of the scheme in Cork, where a 24-hour service operates on Bus Eireann route 220 between Ballincollig and Carrigaline, has led to suggestions that the National Transport Authority may have to increase the frequency of night buses as they only come every hour.
It's hoped that the service in Dublin will begin by the end of the year.
Fine Gael TD Noel Rock welcomed the move.
MOST READ IN NEWS DEATH PROBE DPP considering criminal charges after woman found dead at Dublin home in 2017 ‘HORRIFIC’ END Brit, 27, dies from blood infection after being bitten by insect on holiday BUG BEAR NHS warns of killer superbugs rise with 61,000 drug-resistant infections last year klll probe Murder inquiry launched after man, 47, stabbed to death outside property in Down Breaking 'substantial damage' Two men arrested after JD Sports store robbed on Mary Street, Dublin MISSING TEEN Gardai launch public appeal to find teen, 14, missing from Athlone
He said: "It makes sense for shift workers, for airport workers, for people coming to and from the airport, and for people who need to get to or from town late at night or early in the morning.
"I hope that the NTA move to introduce this as soon as possible and that Dublin Bus confirm timetables and frequencies as soon as possible.
"This is a positive move, and means our transport system gets closer to reflecting the needs of the city."

Story 100
OMAHA — The pairings and game times for the first two days of the 2019 NCAA Men’s College World Series (MCWS) have been announced. The 73rd MCWS will take place at TD Ameritrade Park Omaha in Omaha, Nebraska, June 15-25/26.
CWS 2019: Full tournament bracket | Printable CWS bracket | CWS info & tickets | Shop latest CWS gear
The first game this Saturday, June 15 is scheduled to begin at 1 p.m. (CT), and will feature No. 8 national seed Texas Tech (44-18) against Michigan (46-20) on ESPN. Saturday’s second game features No. 5 national seed Arkansas (46-18) against Florida State (41-21) and is scheduled to begin at 6 p.m. (CT) on ESPN.
On Sunday, June 16 action features No. 2 national seed Vanderbilt (54-11) vs. No. 7 national seed Louisville (49-16) at 1 p.m. (CT) on ESPN. In the evening game starting at 6:30 p.m. (CT), No. 6 national seed Mississippi State (51-13) will be squaring off against Auburn (38-26) on ESPN2.
BRACKET: Click or tap here for a printable bracket | Interactive bracket
The losers of Saturday’s two games will play at 1 p.m. (CT) Monday, June 17 on ESPN, while Saturday’s winners face off at 6 p.m. (CT) Monday, June 17 on ESPN. The losers of Sunday’s games will play each other at 1 p.m. (CT) Tuesday, June 18 on ESPN. Sunday’s winners will meet Tuesday, June 18 at 6 p.m. (CT) on ESPN.
The winners of the two brackets will play a best-of-three Men’s College World Series Finals, with the first game set for 6 p.m. (CT) Monday, June 24. The second game is scheduled for 6 p.m. (CT) Tuesday, June 25 with game three (if necessary) scheduled for 6 p.m. (CT) Wednesday, June 26. All three of the finals games will air on ESPN.

Story 101
Iran seized two oil tankers – one registered in the UK, the other in Liberia – in the strait of Hormuz on Friday, marking a dramatic escalation in the worsening standoff in the Gulf.
Iran’s Revolutionary Guards claimed to have taken the British-flagged Stena Impero into port with its 23-strong crew, and Iranian officials claimed it had infringed maritime regulations.
On Saturday, the semi-official Iranian news agency, Fars, said the ship had been taken to Bandar Abbas port and that the crew remained on the vessel. Meanwhile, Iran’s state-run news agency, IRNA, reported that the tanker was seized due to a collision with an Iranian fishing boat. It said the fishing boat informed Iran’s Ports and Maritime Organisation, which notified the Revolutionary Guards.

The Stena Impero’s owners however, said the ship had been “approached by unidentified small crafts and a helicopter during transit of the strait of Hormuz while the vessel was in international waters”.
A second tanker, the Mesdar, which is Liberian-flagged but British operated, also made a sudden diversion from its course towards the Saudi port of Ras Tanura on Friday, and tracking data showed it moving northwards towards the Iranian coast before apparently turning off its tracking signal.
Less than two hours later, the Mesdar’s tracking signal was turned back on. Fars, the semi-official Iranian news agency, reported that it was briefly detained in the strait of Hormuz and given a notice to comply with environmental regulations before being allowed to continue on its way.
The Mesdar’s Glasgow-based operator, Norbulk Shipping UK, confirmed that the vessel had been boarded by armed guards but had then been allowed to continue its voyage. “All crew are safe and well,” it said.
Stena Bulk and Northern Marine Management confirmed in a statement on Friday that the ship remained uncontactable.
Stena Impero was in “full compliance with all navigation and international regulations” when it was intercepted, the company said.
Stena Bulk chief executive Erik Hanell said: “There are 23 seafarers onboard of Indian, Russian, Latvian and Filipino nationality. There have been no reported injuries and the safety and welfare of our crew remains our primary focus.”
Jeremy Hunt, the UK foreign secretary, told Sky News: “We are absolutely clear that, if this situation is not resolved quickly, there will be serious consequences.”
Play Video 1:02 Jeremy Hunt warns Iran of 'serious consequences' over tanker seizure - video
But he added: “We are not looking at military options, we are looking at a diplomatic way to resolve the situation but we are very clear that it must be resolved.”
He said that Stena Impero had been surrounded by four Iranian vessels with a helicopter hovering overhead, while 10 Iranian speedboats had converged on the Mesdar.
“These seizures are unacceptable. It is essential that freedom of navigation is maintained and that all ships can move safely and freely in the region,” Hunt said.
Late on Friday night, the British government advised UK ships to stay out of the area “for an interim period”.
“We remain deeply concerned about Iran’s unacceptable actions which represent a clear challenge to international freedom of navigation,” a government statement said following a meeting of ministers to discuss the incident in the strait of Hormuz.
“As the foreign secretary has said, our response will be considered and robust and there will be serious consequences if the situation is not resolved.
“We remain in close contact with our international partners and there will be further meetings over the weekend.”
Donald Trump, the US president, said on Friday night that the US would talk to Britain about the incidents.
The Revolutionary Guards said they had seized the Stena Impero, citing international maritime law for their actions. Iran Front Page quoted an unnamed military source as saying the tanker had been “crossing a route other than the shipping lane in the strait of Hormuz, had switched off its transponders and did not pay any attention to Iran’s warnings when it was seized by the [Revolutionary Guards] forces”.
The seizure of the tankers came hours after authorities in Gibraltar announced that they were extending their custody of the Iranian tanker, seized by Royal Marines on 4 July, on suspicion of shipping oil to Syria, in violation of an EU embargo. Tehran has denounced the detention of the Grace 1 as piracy carried out on orders from Washington.
Iranian politicians have been calling for reprisals and the country’s forces, led by the Revolutionary Guards, are being increasingly aggressive in disrupting shipping lanes in the Gulf.
The Stena Impero, a 30,000-tonne British-flagged and Swedish-owned ship, was heading for Saudi Arabia when it abruptly left international sea lanes, and tracking data showed it heading north towards the Iranian island of Qeshm, where the Iran’s Revolutionary Guards have a substantial base.
Iran’s Revolutionary Guards previously attempted to capture a British tanker six days after the Grace 1 was seized. On 10 July, a British warship, the HMS Montrose, intervened to drive off three Iranian military vessels that were attempting to divert a UK tanker, the British Heritage, towards Iranian territory.
The incidents come amid a battle of nerves along the oil export routes of the Gulf, which has involved close encounters between Iranian, UK and US military forces.
Earlier on Friday, Tehran denied Trump’s claim that US forces had downed a Iranian drone over the Gulf. Iran’s top military spokesman said all drones had returned safely to base, but Trump was adamant. “No doubt about it ... we shot it down,” the US president said.
Trump said on Thursday that the USS Boxer took defensive action after the unmanned vehicle came within 1,000 metres of the warship and ignored multiple calls to stand down.
The prospect of negotiations that might defuse the standoff appeared more distant than ever on Friday as a senior US official dismissed a nuclear offer proposed the previous day by Iran’s foreign minister, Javad Zarif, during a visit to New York. The official suggested the offer was not serious and called for “an actual decision-maker” to enter talks to “end Iran’s malign nuclear ambitions”.
Trump has vacillated on what he wants Iran to do in return for a lifting of the oil and banking embargo that the US has imposed since walking out of an international nuclear deal with Tehran (the Joint Comprehensive Plan of Action, or JCPOA) in May last year. The sharp response to Zarif’s offer suggests that administration hardliners, led by the national security adviser, John Bolton, are currently running Iran policy.
Q&A What is the Iran nuclear deal? Show Hide In July 2015, Iran and a six-nation negotiating group reached a landmark agreement known as the Joint Comprehensive Plan of Action that ended a 12-year deadlock over Tehran’s nuclear programme. The deal, struck in Vienna after nearly two years of intensive talks, limited the Iranian programme, to reassure the rest of the world that it cannot develop nuclear weapons, in return for sanctions relief.
At its core, the JCPOA is a straightforward bargain: Iran’s acceptance of strict limits on its nuclear programme in return for an escape from the sanctions that grew up around its economy over a decade prior to the accord. Under the deal, Iran unplugged two-thirds of its centrifuges, shipped out 98% of its enriched uranium and filled its plutonium production reactor with concrete. Tehran also accepted extensive monitoring by the International Atomic Energy Agency (IAEA), which has verified 10 times since the agreement, and as recently as February, that Tehran has complied with its terms. In return, all nuclear-related sanctions were lifted in January 2016, reconnecting Iran to global markets. The six major powers involved in the nuclear talks with Iran were in a group known as the P5+1: the UN security council’s five permanent members – China, France, Russia, the UK and the US – and Germany. The nuclear deal is also enshrined in a UN security council resolution that incorporated it into international law. The 15 members of the council at the time unanimously endorsed the agreement. On 8 May 2018, US president Donald Trump pulled his country out of the deal. Iran announced its partial withdrawal from the nuclear deal a year later. Saeed Kamali Dehghan, Iran correspondent
Zarif proposed that Iran’s parliament immediately ratify acceptance of a permanent regime of intrusive international inspections, known as the Additional Protocol, designed to ensure that Iran was not building nuclear weapons covertly. Iran is currently observing the protocol under the terms of the JCPOA, and was due to ratify it, cementing it into law, in October 2023.
Zarif offered to bring that arrangement forward by more than four years in return for immediate sanctions relief. The offer was never likely to be accepted – the US has an expansive list of demands concerning Iran’s activities – but it did signal a willingness to do a deal with Washington outside the framework of the JCPOA. The US reaction, however, was scathing.
“If Iran wants to make a serious gesture, it should start by ending uranium enrichment immediately and having an actual decision-maker attempt to negotiate a deal that includes a permanent end to Iran’s malign nuclear ambitions, including its development of nuclear-capable missiles,” a senior administration official said.
Iran has consistently refused to give up uranium enrichment, which can be for both civilian and military purposes. Efforts by previous US administrations to stop it led to an exponential expansion of Iran’s enrichment capacity. The JCPOA accepted Iran’s right to enrich uranium, but imposed strict upper limits on its purity and other elements of the nuclear programme in return for sanction relief.
With the negotiating gap between Washington and Tehran as wide as ever, the contest between the two countries has shifted increasingly to the Gulf.
The Gibraltar supreme court’s extended the detention of the Grace 1 at a hearing on Friday after Gibraltar’s chief minister, Fabian Picardo, held talks with Iranian officials at the Foreign Office. Picardo also held talks with Theresa May and Jeremy Hunt, the foreign secretary.
The UK has been seeking legal assurances that the tanker would not travel to Syria to unload 2.1m barrels of oil if released, as it was suspected of attempting when detained.
Tehran says it is not party to an EU embargo and insists that the ship was not bound for Syria.
Bob Sanguinetti, the chief executive of the UK Chamber of Shipping, said: “We condemn unreservedly the capture of Stena Impero … Our priority is for the safety and welfare of the crew. We call on the UK government to do whatever is necessary to ensure their safe and swift return.
“This incident represents an escalation. While we call for measured response, it is also clear that further protection for merchant vessels must be forthcoming to ensure enhanced security to guarantee free flow of trade in the region.”
Labour leader Jeremy Corbyn said: “Escalation risks a slide into an even deeper conflict. President Trump’s decision to tear up the Iran nuclear deal fuelled the risk of full-scale conflict. A negotiated reinstatement of the nuclear deal through the UN is essential to wind down tensions and defuse the threat of war in the Gulf.”

Story 102
Cleverciti Systems, a leader in comprehensive, high-tech solutions for smart parking, today announced the addition of the ClevercitiCard, the first system to seamlessly combine outdoor and indoor parking guidance, including single-space occupancy detection, into a credit card-sized smart card.
ClevercitiCard is designed to provide integrated, frictionless permit payment and parking guidance for drivers, and offers a complete management solution for parking operators in a variety of industries. An active card that sits on the windshield or the dashboard of a vehicle, ClevercitiCard eases the complexity of the parking process. It activates automatically when a car is parked and transmits the position of the vehicle with a precision of 10 inches. It then instantly communicates the appropriate permit, reservation, and payment status. With the Cleverciti app, drivers can identify open spaces upon approach to an outdoor parking area or indoor garage. The technology can also be used to provide access to gated or secure areas.
“With the ClevercitiCard, we can now offer a new level of parking guidance through the integration of permit and payment features for outdoor and indoor parking, without the need to install expensive infrastructure, such as single space sensors. We have placed the sensor, permit and payment functions into a single application, providing a truly seamless and comfortable parking experience for drivers,” said Thomas Hohenacker, CEO and Founder, Cleverciti System. “Companies can now manage corporate parking in a highly efficient way, and organizations with the desire to manage multiple users, including valet parking, have now complete control over their parking assets.”
ClevercitiCard offers a unique platform for managing permits for corporate campuses, VIP parking areas, train stations, stadiums, and many others. Employees gain instant guidance of where to park, without losing valuable time. Spaces or defined parking areas can be reserved for specific users according to their permit status, while managers can see in real-time who is parking where and manage parking assets with unmatched precision, data analytics, and insights.
Campuses can provide their students and faculty members with instant guidance on available parking and quickly view permit status and payment method. The Cleverciti platform gives the parking operator real-time insight of the exact position, length of stay, as well as the permit and payment status of each car. There are also numerous applications in the logistics market, such as for car dealers, car rental, and fleet management companies, where it is essential to locate the exact position of a car.
The Cleverciti dashboard aggregates all real-time data to allow organizations to monitor each car as well as any associated user data. Parking operators gain valuable insight into real-time occupancy statistics while drivers benefit from having instantaneous directions to available parking spaces. Furthermore, individuals save time by automatically paying, without the need to visit a meter or ticket machine.
Cleverciti currently has over 56 installations in 20 countries around the world. Its comprehensive suite of smart parking solutions is an ideal choice for organizations focused on a forward-thinking approach to customer service that also seeks to streamline parking and increase the revenue potential of their parking assets.
For more information about the ClevercitiCard, visit www.cleverciti.com/cleverciti-card.
About Cleverciti Systems
Cleverciti Systems is the leader in comprehensive, high-tech solutions for outdoor and on-street parking detection, monitoring, and guidance. Cleverciti provides organizations with a robust and highly reliable solution that enhances convenience, builds loyalty and boosts engagement, allowing our customers to maximize ROI, and streamline the parking experience. Its end-to-end solutions are designed to strengthen parking detection, improve guidance, and enhance communication. With more than 54 installations in 18 countries across the world, Cleverciti seeks to help organizations reduce traffic and emissions, and increase revenue while allowing drivers to enjoy a smooth, stress-free parking experience. The company is headquartered in Munich, Germany, with offices in Chicago. To learn more, visit www.cleverciti.com.

Story 103
Motorsport-Magazin.com - Sauber-Junior Juan Manuel Correa, der am Samstag im Formel-2-Rennen von Spa-Francorchamps in den schweren Unfall verwickelt war, an dessen Folgen Anthoine Hubert verstarb, wurde noch am Samstagabend operiert und befindet sich nach wie vor in stabilem Zustand. Das hat Correas Presse-Team in der Nacht auf Sonntag noch bestätigt.
Correa habe Brüche in beiden Beinen und eine geringfügige Verletzung der Wirbelsäule erlitten, wird im offiziellen Statement beschrieben. Nach dem Unfall wurde Correa per Hubschrauber ins Krankenhaus geflogen. Er sei aber die ganze Zeit bei Bewusstsein geblieben. Nach der Operation befindet sich Correa vorläufig auf der Intensiv-Station.
Correa hatte Huberts Auto beim Unfall in Raidillon frontal gerammt, als er versucht hatte, dem Zwischenfall, in den auch andere Fahrzeuge verwickelt waren, auszuweichen. "Ein Opfer des Unfalles vor ihm, hatte Correa keinen Patz auszuweichen und kollidierte mit dem Fahrzeug eines Mitbewerbers", heißt es im Statement seines Teams.
Update, 02.09.2019: Nach einer langen Operation am Sonntag, in deren Rahmen die Brüche in Correas Beinen stabilisiert wurden, befindet er sich weiterhin im Beisein seiner Eltern auf der Intensiv-Station, allerdings nur mehr zur Überwachung durch die verantwortlichen Ärzte.
Sobald diese ihn freigeben, soll Correa in sein Heimatland, in die USA, geflogen werden, um dort mit einem "sehr langen Rehabilitations-Programm" zu beginnen, wie sein PR-Team im letzten offiziellen Statement schreibt.

Story 104
Die Causa Bankomatgebühren ist vor dem Verfassungsgerichtshof gelandet. Die Geldinstitute wollen nicht die Gebühren von Fremdanbietern für ihre Kunden bezahlen.
Zwei Stunden lang wurde am Verfassungsgerichtshof (VfGH) in Wien zum Thema Bankomatgebühren verhandelt. Seit Jänner 2018 sind neue Bestimmungen in Kraft, die es Banken grundsätzlich verbieten, ihren Kunden für Bargeldabhebungen an Geldautomaten ein Entgelt zu verrechnen - außer es wurde im Einzelnen ausgehandelt. Dieses Gesetz gilt allerdings auch für Abhebungen bei Bankomaten von unabhängigen Betreibern wie First Data oder Euronet. Letzterer verrechnet als bisher einziger Anbieter in Österreich bei Bargeldbehebungen an den eigenen Geräten einen Fixbetrag von 1,95 Euro pro Behebung.
>>> Mehr dazu: Bankomatgebühren – darf es sie noch geben?
495 Kreditinstitute haben sich in der Folge an den VfGH gewandt und die Aufhebung des § 4 Abs. 2 und § 4a Verbraucherzahlungskontogesetz (VZKG) verlangt.
Jurist Raimund Bollenberger führte als Rechtsvertreter der Banken aus, dass der Anteil der von österreichischen Banken betriebenen Geldausgabeautomaten seit Jahren rückläufig sei (siehe Grafik). 1140 der 8.769 aufgestellten Bankomaten betreibt First Data betrieben. Die Anzahl der von Euronet betriebenen Geldausgabeautomaten sei von 120 im Jahr 2016 auf deutlich über 200 gestiegen, sagte Bollenberger.
Ein Verbot von Bankomatgebühren werde zu einer Verschlechterung und Verteuerung der Bargeldversorgung führen, argumentieren die Banken: "Die Entgelte für die Euronet-Kunden werden am Ende von den österreichischen Konsumenten zu bezahlen sein", warnte der Bollenberger.
"Markt wartet Verfassungsgerichtshof ab"
Bollenberger geht davon aus, dass die Zahl der Drittanbieter, die Entgelte verlangen, steigen wird. Auch First Data könnte jederzeit Standortentgelte einheben. "Der Markt wartet den Verfassungsgerichtshof ab", so Bollenberger. Es dürften deutlich mehr Anbieter auf den österreichischen Markt drängen. Durch das Gesetz gebe dann auch keinen Wettbewerb zwischen den unabhängigen Anbieter mehr und diese könnten verlangen, was sie wollten.
Ob die Banken mit den Geldausgabegeräten einen Gewinn oder Verlust machen, sagte Bollenberg nicht - Banken dürften die Kosten dafür nicht offenlegen. Laut Bundeswettbewerbsbehörde (BWB) sei das aber ein Verlustgeschäft, während das Geschäft mit POS-Terminals positiv sei.
"Werde solche Bankomaten in Zukunft meiden"
"Werde solche Bankomaten in Zukunft meiden"



(APA)

Story 105
In the autumn of 2010, Mei Mei Hu, a management consultant for McKinsey in New York, received an unexpected invitation from her mother, Chang Yi Wang, asking her to join her for Christmas in Shanghai.
Mei Mei always had a complicated relationship with her mother. “Chang Yi is very particular and exacting – which is part of her genius,” Mei Mei explains, sitting in a restaurant in Cold Spring Harbor, a former whaling community on Long Island’s North Shore. She’s tall and slim, with long dark hair pulled back in an unruly pony tail. She was born in Great Neck, a suburb of New York, in 1983. A few years later, her family moved to a large colonial house in Cold Spring Harbor. “I remember coming back from school with a test score of 98 per cent and all she said was – next time, kill those last two points,” she grins, exasperated. “So, much to her surprise, I avoided science in school. I spent the rest of my life trying not to work with my parents.” Instead, she studied economics at the University of Pennsylvania, where she met her husband, then trained to be a lawyer, and has spent most of her career as a management consultant.
Chang Yi, on the other hand, is something of a legend in the fields of immunology and biochemistry: she has two PhDs, developed tests for HIV and Hepatitis C, and conducted pioneering research into an HIV vaccine. She is also the co-founder of United Biomedical, a sprawling drug development company with offices and labs in the US, Taiwan and mainland China. Mei Mei hadn’t really talked to her mother about United Biomedical for some time, and she was keen to remain ignorant about the company’s affairs. “Ever since I’ve been small my parents have worked together with very little boundary between personal life and work life,” she says. “If they’re stressed at work, you know about it. It’s one of the reasons I always promised I would never work with my mother.”
Advertisement
Over that Christmas in 2010, however, Mei Mei gradually realised, during long conversations with her mother at the dinner table, that the company was facing serious legal issues. “I just listened and talked to her and discovered there were shareholder disputes and legal actions that were taking up her time and money,” she explains. “If they went badly, the company would be in trouble.”
Mei Mei began poring over the company’s documents and what she found amazed her. United Biomedical was a company with only a few hundred employees and yet it was involved in animal and human healthcare: making generic drugs, monoclonal antibodies, blood tests for HIV and vaccines for foot-and-mouth disease. Chang Yi was trying to do everything.
Read next A mysterious death, a genetic clue and the lifelong quest for answers A mysterious death, a genetic clue and the lifelong quest for answers
To Mei Mei, it was clear this wide range of operations wasn’t sustainable. United Biomedical had to be restructured. “Perhaps it was my legal background combined with consulting experience but sometimes it just takes different ways of looking at something to solve it, so I decided to give it a shot,” she shrugs.
She drew up a large organogram on a whiteboard – separating out the generic drugs, animal healthcare and monoclonal antibodies businesses to be spun off into third-party joint ventures. On the diagram she made up names for each offshoot, just for illustration: United Biopharma, UBI Asia, and United Neuroscience. “I was explaining to my mother how we're going to re-organise things, and just put in placeholder names until we thought up proper names,” she recalls. But Chang Yi loved United Neuroscience, and "just kept saying it. After that, we couldn’t name it anything else.”
Advertisement
A few days before she was due to return to the US, Mei Mei offered to stay for six months to deal with legal issues and help find joint venture shareholders. She took a sabbatical from McKinsey, and soon realised her future was with her mother's company. “When you grow up and you see your parents work their butts off to try to do good and now they're about to maybe get screwed, you want to defend them,” she shrugs. She partnered off non-core assets, spun out some departments, and focused on the part of the business that had the most potential. “Chang Yi thinks all of her products are great, and they are, but it didn’t take a genius to see that her vaccine business had the most promise,” Mei Mei smiles.
The vaccine research involved a new field in immunology called endobody vaccines. Most vaccines prepare our body’s immune system to fight off so-called exogenous disease, such as measles or flu, caused by bacteria or viruses entering our blood. Endobody vaccines, on the other hand, prime our immune system to deal with malfunctioning internal parts of the body that it would otherwise ignore.
Endobody vaccines are very rare, with only four approved for the market, two for cancer and two for animal healthcare – one of which was developed by Chang Yi in 2003. This particular drug can completely block the production of testosterone in the body and is currently used as a method of pig castration. “It’s like a teenager’s worst nightmare,” Mei Mei says with a dry smile. “Most men find their partner’s parents intimidating. My mother literally developed a drug that can cause men’s testicles to shrivel up and disappear.”
Read next Apple Watch Series 5 review: still the best, but where’s the rest? Apple Watch Series 5 review: still the best, but where’s the rest?
United Biomedical had other endobody vaccine candidates in development, the most interesting a vaccine for Alzheimer's. This vaccine had already been successfully tested on small mammals and monkeys (baboons and macaques). Mei Mei wasn't versed in the intricacies of the biochemistry so decided to get an outside opinion, approaching prominent vaccine researchers. They were blown away by her mother’s work. One investor suggested that she should search for other endobody vaccines that worked in the same way. Mei Mei couldn’t find any. Her mother had created something unique.
Advertisement
Upon this realisation, Mei Mei urged her mother to focus all her efforts on the Alzheimer's vaccine through the spinoff company United Neuroscience. This was the chance of a lifetime, the opportunity to change the lives of millions. Chang Yi reflected for a few days before agreeing. She asked her daughter to be the CEO of the new company. She would return to the lab and finish the work she had started, she told her daughter. She was going to find a defence against Alzheimer’s disease.
Chang Yi Wang Benedict Evans
United Neuroscience’s laboratory sits on an industrial estate at the edge of Hauppauge, a sprawling Long Island town. It’s a low building, divided up into small rooms where machines gently shake organic liquids to create peptide chains for vaccines. On a quiet morning in early March, the only sound is the hum of the machines. The family’s clapboard house is some 20 minutes' drive away, and it’s there the team hold meetings and throw staff parties. Today there’s a management meeting, with senior people cloistered in the living room. Other staff members sit in the kitchen, picking their way through a vast Chinese banquet prepared by a cook who keeps adding new dishes to the groaning table.
Chang Yi sits at the table, every now and then rotating the Lazy Susan to ensure everyone tries each dish as it arrives. Her short, dark hair is neatly cut and combed, she is wearing a traditional Chinese suit, and she speaks rapidly, peppering her conversation with stories of inventions and inspiring researchers.
Read next Japan is hoarding viruses to fight bioterrorism at the 2020 Olympics Japan is hoarding viruses to fight bioterrorism at the 2020 Olympics
Chang Yi has, she explains, wanted to be a scientist for as long as she can remember. She was five in 1957 and living in Taipei, the capital of Taiwan, when her mother showed her a picture of the Chinese-American physicist Chien-Shiung Wu — who Chang Yi calls “Madame Wu” — on the front page of the New York Times. Wu had just overturned a fundamental quantum physics law called conservation of parity. Columbia University physicists Tsung-Dao Lee and Chen Ning Yang had suggested that conservation theory was flawed two years earlier, but it was Wu who confirmed that hypothesis experimentally. “Then and there,” Chang Yi says, “I decided that I wanted to be a scientist.”
She went to the prestigious Taipei First Girls’ High School, and studied chemistry at the National Taiwan University. In 1973, she became the first Asian woman accepted on the graduate programme at the prestigious Rockefeller University in New York. This private medical research centre sits at the centre of New York’s medical science. Weill Cornell Medicine, the New York-Presbyterian Hospital and the Memorial Sloan Kettering Cancer Center are all clustered nearby.
At Rockefeller University, Chang Yi studied with four academics she still calls her mentors: Bruce Merrifield, the 1984 Nobel laureate for his work on the development of solid-phase peptide synthesis and its potential applications; Henry Kunkel, her thesis professor and a pioneer in clinical immunology; Gerald Edelman, who deciphered the structure of antibodies; and cellular immunology expert Ralph Steinman, who won a Nobel prize (the first to be awarded posthumously, in 2011) for his discovery of dendritic cells, a critical element in the generation of an immune response.
In 1979, Chang Yi joined Memorial Sloan-Kettering, the largest private cancer hospital and research centre in the world, as head of the molecular immunology laboratory. She was 27 years old, making her the youngest faculty member. There she began developing clinical uses for her theoretical work. In particular, she was interested in the role of epitopes – fragments of proteins, five to six amino acids long, that play a critical role in the body’s defence against external diseases.
The human immune system relies on a collection of cells and proteins to identify, neutralise and destroy invaders.
The body’s first two lines of defence are inflammation and the so-called neutrophil cells. Inflammation is caused by damaged cells releasing chemicals that cause blood vessels in the area to leak, swelling the tissue with fluid and isolating the foreign substance. Neutrophils are white blood cells that then ingest invaders and break down their protein chains. The next wave of defence – white cells called microphages - "eat" the neutrophils, extracting fractions of the invading proteins and attaching them to the surface of their cell wall. These fractions are the so-called epitopes.
Read next Snotty children are the key to the UK's biggest ever flu vaccine push Snotty children are the key to the UK's biggest ever flu vaccine push
The presence of foreign epitopes on microphage cell walls indirectly triggers a type of white cell called a B cell. These are produced in the bone marrow and, when triggered, start producing antibodies that clump the invaders together, making them easy targets for T cells, another type of white cell.
After the body has defeated the invasion, it stores a blueprint of the successful B cells and T cells. This makes it much faster at fighting another bout of the same disease, swamping the threat before it has time to spread. Most immunisation against disease involves mimicking an infection by injecting an inactivated or attenuated form of the invader to trigger the immune system – should an infection occur, the immune system will then respond before the person becomes ill.
In 1985, Chang Yi had co-founded United Biomedical with Nean Hu, Mei Mei’s father. Her work initially involved detecting epitopes. The body uses epitopes as a short cut. If you can detect a particular epitope, you know there is a particular pathogen present. Chang Yi was hoping to develop a quick, simple test for HIV using that same mechanism. If you could inject harmless synthetic versions of HIV’s signature epitopes, you could measure the body’s immune response to see if it had already encountered the virus.
“I was working on the HIV virus in 1985 just as a huge argument was breaking out between the French Pasteur Institute and the American National Cancer Institute over who had developed the first test to detect antibodies to the virus back in 1983,” she explains. “They were arguing over tests for the whole virus. I looked at where the antigenic epitopes were. We could synthesise these epitopes and use them to detect HIV antibodies in the blood.”
When her HIV and Hepatitis C tests reached the market, large pharmaceutical companies – which had spent years and fortunes testing for the full virus – claimed patent infringement. The US company Chiron forced her Hep C test out of the UK, but its claim was thrown out in the House of Lords in 1996. By then Chang Yi had shifted her focus to vaccines.
Read next The UK's messy CBD oil industry is finally starting to clean up its act The UK's messy CBD oil industry is finally starting to clean up its act
In 1991, she first attempted to develop an HIV vaccine. “The problem is that HIV mutates so constantly and so rapidly,” she explains. “We could devise a vaccine for the strain of HIV we had in the lab, but out in the field it had already changed and the vaccine couldn’t protect people.”
In 1993 she began working on her first endovaccine – partly because no one else was working in the field, and partly because she thought that her work with epitopes was well suited to this type of vaccine. She created synthetic versions of the tiny chains of amino acids that trigger the production of antibodies. In the case of her Alzheimer’s vaccine, this allowed her to develop a mechanism that triggers antibodies to the Alzheimer’s protein in the blood. These then attract T cells that attack any protein with an antibody attached.
But that was to come later. The first endovaccine was directed at prostate cancer – targeting the hormones that prompt production of testosterone, because prostate cancer grows aggressively in the presence of testosterone. And to prove her idea could work, she began working on pig castration.
It took ten years to develop her first proof of concept – a vaccine that tricked the immune defence system of boars into attacking the building blocks of its own testosterone. Without a steady flow of testosterone, the tissues in the penis, scrotum and testicles atrophy and wither away, in effect castrating the animal.
“Drug development is a long and evolving process,” Mei Mei explains. “The immunocastration vaccine started as a human therapeutic, then became a model for testing and building a library of molecules that could work in different conditions, and ended up commercialised as an animal health application. The entire journey was just over two decades.”
Read next This startup's map will accelerate our hunt for a Parkinson's cure This startup's map will accelerate our hunt for a Parkinson's cure
In 2003, over 10 years into that journey, Chang Yi read reports that a promising anti-Alzheimer’s vaccine developed by Irish pharmaceutical company Elan had failed in clinical trials. Despite some success in treating the condition, its side effects included inflammation in the brain. The human trials were launched after tests on genetically modified mice had removed clumps of beta-amyloid – one of the key proteins damaging the brain. But during the trials four patients in France developed inflammation in the brain and central nervous system. Further checks revealed eight more cases.
Chang Yi believed her new endobody vaccines could overcome this problem. “The Elan vaccine stimulated the immune system too broadly,” Mei Mei explains. “Your body has two tools to deal with infection – inflammation to trap the invader, and cells that attack and destroy them. The Elan vaccine triggered both those responses. Chang Yi’s vaccines use molecules that are so small, they don’t trigger inflammation.”
Because Chang Yi was introducing small chains of amino acids synthetically created for a specific role in the immune process – essentially just triggering B cells to make antibodies – and because they were attached to a synthetic version of a disease the body already had, they don’t trigger inflammation.
Alzheimer’s also offered an attractive target for her vaccines because the beta-amyloid protein has a very small, very simple epitope that she could mimic. “I could see how easy it would be to do a vaccine better,” she recalls. “Alzheimer’s is such low-hanging fruit.”
Mei Mei with her mother, Chang YiWang, in the family home in Cold Spring Harbor, Long Island Benedict Evans
Read next The vaping deaths backlash is in danger of doing more harm than good The vaping deaths backlash is in danger of doing more harm than good
Very few people consider Alzheimer’s to be low-hanging fruit. The condition was first recorded by the German psychiatrist Alois Alzheimer in 1906 after he noticed changes in the brain tissue of a patient who had died from an unusual mental illness, with symptoms including memory loss, language problems, and unpredictable behaviour.
Since then the disease has risen to become the leading cause of death for women and the second leading cause for men in the UK: combating Alzheimer’s would be a dramatic medical achievement. Half the deaths in the US in 1900 were from infectious disease. By 2010, mortality related to infectious disease had been all but wiped out, leaving the two biggest killers as cancer and heart disease. Over the last 15 years, UK mortality statistics have shown a steady decline in deaths from heart disease, strokes and most major cancers – for men and women.
Over the same period the death rate from dementia – of which Alzheimer’s is the most common cause – has doubled: in part because lifespans have increased, and the effects of the disease increase with age. In the UK, there are currently 850,000 people living with dementia, and 500,000 – perhaps as many as two-thirds – have Alzheimer’s. In the UK, the Alzheimer’s Society expects dementia sufferers to exceed a million by 2025, with an unknown quantity of carers and family members affected.
A total of five drugs are available to relieve symptoms, but they cannot slow or stop the progression of the disease.
In the last ten years, over 100 anti-Alzheimer’s drugs have been abandoned in development or during clinical trials. “We’ve known about Alzheimer’s for over 100 years,” explains James Pickett, head of research at the Alzheimer’s Society. “Forty years ago every form of cancer was incurable – now people are surviving. HIV was almost unknown until 1981, and now it looks like it can be cured. In all that time, we’ve found nothing for Alzheimer’s. It’s a difficult disease, and we’re not even sure if we fully understand its mechanism. What we do know is that it’s a killer and we have no cure.”
Although we don’t know much about Alzheimer’s, researchers believe its effects are caused by two rogue proteins, beta-amyloid and tau – high amounts of both are found in the brains of people with Alzheimer’s. Beta-amyloid was discovered in 1984, with tau identified two years later.
Read next What happens when vaccine scepticism takes over? Look to the Philippines What happens when vaccine scepticism takes over? Look to the Philippines
Healthy versions of these proteins are important in supplying food to brain cells and ensuring that key chemicals move freely between them. The blueprint for every protein in your body is held in your DNA, which unwinds to allow long chains of amino acids to line up in the correct sequence for each protein needed. When first created, these are long, straight chains, which then fold into compact blobs to function properly.
For reasons that are unclear, damaged beta-amyloid can misfold into a “sticky” form that clumps together in a tangle of fibres – called plaques – that accumulate around nerve cells and disrupt cell communication, metabolism and repair. Tau can also misfold into an abnormal shape and clump with other tau molecules, forming threads that eventually join to form tangles inside neurons, blocking the flow of food.
Both proteins may cause brain cell damage, although researchers aren’t sure if high levels of beta-amyloid and tau cause Alzheimer’s or are symptoms of the condition. Both damaged versions of the proteins can cause neighbouring beta-amyloid and tau molecules to misfold as well – spreading the damaging tangles to other cells, breaking nerve cell connections with other neurons and slowly starving neurons to death.
The risks generally increase with age, but an inheritable form of the disease – early-onset Alzheimer’s – can affect people as young as 30. Symptoms begin with difficulty remembering recent events, progressing to problems with language, mood, motivation and orientation. Patients become isolated and confused as the disease progresses, shutting down physical functions. Some medications can reduce memory loss and aid concentration, but these just boost the performance of unaffected neurons, doing nothing to stop the kill-off of brain cells. There is no known cure. Following diagnosis, life expectancy is typically between three and nine years.
Chang Yi’s vaccine – UB-311 – couples a synthetic imitation of a common disease with a specific sequence of amino acids that are present only in the damaged beta-amyloid protein, and absent in the healthy form. This provokes an antibody response, clearing the tangled proteins away without provoking potentially damaging inflammation.
Read next The extreme tech that will help people live forever The extreme tech that will help people live forever
In January 2019, the company announced the first results from a phase IIa clinical trial in 42 human patients. “We were able to generate some antibodies in all patients, which is unusual for vaccines,” Chang Yi explains with a huge grin. “We’re talking about almost a 100 per cent response rate. So far, we have seen an improvement in three out of three measurements of cognitive performance for patients with mild Alzheimer’s disease.”
Because phase II trials are so small, there’s no statistically valid evidence yet that UB-311 has an impact on cognition and memory, but the lack of serious side-effects is a big step forward. “You’d want to see larger numbers, but this looks like a beneficial treatment,” says James Brown, director of the Aston University Research Centre for Healthy Ageing, in Birmingham. “This looks like a silver bullet that can arrest or improve symptoms and, if it passes the next phase, it could be the best chance we’ve got.”
Mei Mei, co-founder of United Neuroscience Benedict Evans
In March 2019, the US Department of Defense invited Mei Mei and her husband, Lou Reese, to explain the vaccine at a conference in Telluride, Colorado. Currently, United Neuroscience is proceeding with phase III trials for its Alzheimer’s vaccine, and has adapted the synthetic peptide technology to create vaccines for the hallmark protein in Parkinson's disease. Known as UB-312, the Parkinson’s vaccine is just about to enter phase I testing. A third vaccine, targeting Tau, is in the pre-clinical phase. Tangled Tau proteins aren’t just a feature of Alzheimer’s – they’re also found in soldiers and athletes who face repeated or significant head injuries, hence the interest from the military.
Reese, a co-founder of United Neuroscience, was on his way to the airport as WIRED arrived at the door of the Cold Spring Harbor house. He’s got a mop of tousled hair and a contagious energy. “If you’re going after the concept of democratising medicine, that involves new methods of getting the disruptive treatments to patients,” he argues. “We have one vaccine for Alzheimer’s, another for Parkinson’s, another for migraine coming out of the pipeline based on Chang Yi’s building blocks. We have a 50-year vision – to immuno-sculpt people against chronic illness and chronic ageing with vaccines as prolific as vaccines for infectious diseases.” Reese believes that the endobody vaccines are the first steps in democratising medicine. He imagines a future where drones will fly directly to patients, allowing carers or family members to administer the vaccine.
Read next Is vaping actually bad for your health? It's complicated Is vaping actually bad for your health? It's complicated
He’s hoping the DoD will be interested in new forms of distribution – including a form of high-altitude delivery vehicle originally developed by the German military in the Second World War. This would use rocket-powered aircraft to fly as high as possible, right to the edge of the atmosphere, so that by the time they come back down the Earth has rotated beneath them. They could travel from London to Sydney in around six hours, carrying the vaccine.
After he’s gone, Mei Mei offers a more grounded — and perhaps realistic — perspective. “What if you went to the doctor and they took a measurement that could record protein levels in your brain?” she begins. “If it’s too high, we give you a vaccine and keep toxic proteins at bay. You could do it in a kiosk in a mall or with an iPad at home, if this could be monitored through affordable blood tests or retinal scans. We’re starting work on an anti-migraine vaccine at the end of this year and the technology can be applied to anything.”
Back in the kitchen, Chang Yi sips tea and avoids discussing Reese’s ambitions. For her, the goal is simply to take what she’s learned with Alzheimer’s and use it to treat everything from cancer to HIV. “If we can do that, I would feel my life’s purpose has been satisfied,” she nods. “My parents gave me the name Chang Yi which, in English, means Always Happy. If we cured Alzheimer’s I would be very happy.”
More great stories from WIRED
💰 Facebook's Libra cryptocurrency, explained
🔍 The disturbing return of scientific racism
🚕 Uber has a new London rival and it's much cheaper
🤵🏻 The NHS has a plan to get more men donating blood
Advertisement
💻 The 10 iPadOS features that will transform your iPad
🐄 How our addiction to big beef ended up ruining the planet
📧 Never miss an awesome story again with our weekly WIRED Weekender newsletter

Story 106
After taking down Salisbury — the winner of two of the past three national titles — in the semifinal of the DIII men's lacrosse tournament, Cabrini knocked off Amherst 16-12 to win the program's first national title in its first championship-game appearance.
The tournament began with 36 teams. Heading into the semifinals on May 19, only Salisbury, Cabrini, Amherst and Williams were left to compete for the title. Amherst beat Williams in the first semifinal, and Cabrini beat Salisbury in the second semifinal to set up an Amherst-Salisbury championship.
2019 CHAMPIONSHIP: View the 2019 interactive bracket | Shop Cabrini national champ gear
Semifinals were played at the home field of the higher seeds. The winners met in Philadelphia, Pennsylvania, on Lincoln Financial Field Sunday afternoon to crown the champion.
Below, you can find information on the semifinals and finals, including stats, live updates, how to watch and where the games will be played.
ROUND LOCATION MATCH-UP RESULTS WATCH TIME Semifinals Salisbury, MD Salisbury vs. Cabrini Cabrini, 16-13 Stream May 19 - 5 p.m. EST Semifinals Williamstown, MA Williams vs. Amherst Amherst, 12-8 Stream May 19 - 1 p.m. EST Final Philadelphia, PA Amherst vs. Cabrini Cabrini, 16-12 Stream May 26 - 4 p.m. EST
Follow below for live updates from the championship game.
This is the 27th time that Salisbury has appeared in the Division III semifinals. The Sea Gulls have won 12 national championships in the sport, most recently in 2017. In 2018, they fell to Wesleyan (CT). Salisbury's Jim Berkman is the all-time winningest coach in NCAA men's lacrosse history, among all divisions, with a 553-62 career record.
Cabrini and Amherst have never appeared in the national championship game until this year.
NCAA.COM CHAMPIONSHIP CENTRAL | SPRING SELECTION SHOW SCHEDULE

Story 107
Cat O'Neil
On a drizzly Saturday morning in rural Henan, a province in northern China, Mr Liu, 68, is in high spirits. The ruddy-skinned farmer has come to his village clinic for his second health examination of the year; he’s had his blood pressure checked, had an ECG, completed a urine test and given a blood sample.
“[With these check-ups] I know more about my health, and I feel more secure,” he says ”It’s very good.” Despite suffering from high blood pressure and chronic leg pain, he has never been to the bigger town hospital, which is a 30 minute drive away and at which he would have to pay a fee. The village check-ups, which started last year, are free.
Advertisement
What Mr Liu doesn’t know is that the mobile clinic that has driven up to his village this morning is provided by WeDoctor, a private healthcare company that is part of Tencent, the Chinese technology conglomerate. Mr Liu has never heard of WeDoctor, but WeDoctor knows a lot about him.
In April 2017, the company signed a co-operation agreement with the local government to provide medical services, health insurance, pharmaceuticals and healthcare education in the city, starting with a pilot in Jia County, which includes Mr Liu’s village. None of the equipment or staff that Mr Liu has interacted with mentioned WeDoctor, but all the data collected, which is linked to personal identification numbers, is being uploaded straight to the WeDoctor cloud.
Read next Blizzard and esports can't win the battle against Chinese censors Blizzard and esports can't win the battle against Chinese censors
This data is used to feed WeDoctor’s artificial intelligence products, including the “auxiliary treatment system for general practice” that village doctors in Jia County can now use. Doctors simply have to input a patient’s symptoms and the system provides them with suggested diagnoses and treatments, calculated from a database of over 5,000 symptoms and 2,000 diseases. WeDoctor claims that the system has an accuracy rate of 90 per cent.
Dr Zhang Qiaofen, in nearby Ren Zhuang village, says the system it has made her life easier. “Since WeDoctor came to my clinic, I feel more comfortable and have more confidence,” she says. “I’m thankful to the device for helping me make decisions.” The system is part of a dual-pronged effort to connect rural doctors with greater levels of expertise, and to integrate patient data. China’s laws offers few protections on personal data, which has allowed AI to advance rapidly, and the government to build an even more comprehensive picture of each of its citizens.
Advertisement
“As per local requirements,” WeDoctor says in a report, “the data of WeDoctor is now integrated into the regional government platform.” At the local headquarters, a giant screen shows the breakdown of patient data in Jia County: village, gender, age, ailment and whether or not a person has registered with a village health check are all detailed. “The government doesn’t have access to personalised [patient] data,” a WeDoctor spokesperson says. “Just their phone number [which is linked to a personal identification number], address and details of their sickness.” A second spokesperson says that it is obligatory for villagers to attend these checks, whether or not they are unwell.
The WeDoctor pilot is one of many similar initiatives in China. Over 130 companies are working on applying AI in China’s healthcare sector, as part of the government’s “Made in China 2025” plan.
According to PereDoc, a Beijing-based startup that has developed software that can parse CT scans and identify lung nodules, “[The volume of] China’s medical data almost doubles every two years”, while “the [annual] growth rate of radiologists in China is only four per cent’.” China has a serious shortage of doctors: there are only 1.5 doctors per 1,000 people (compared to 2.8 in the UK). As life expectancy increases, so do chronic illnesses such as diabetes and high blood pressure, but the already strained medical system is struggling to keep up.
Read next China's social credit system is coming for businesses too China's social credit system is coming for businesses too
It is not just rural areas that are benefitting from and having their data mined by AI companies. At Beijing Shijitan Hospital, one of the largest cancer hospitals in the country, doctors have been using PereDoc software since May. Dr Xue Xinying, a chest specialist, says that the technology is “amazing”. “It now only takes five seconds to process a scan, rather than ten to 20 minutes.”
Advertisement
The AI flags potential nodules in red, and a doctor checks for false positives. The company claims that the accuracy rate is 94.9 per cent for nodules under 5mm, and 99.7 per cent for larger ones, compared to a human accuracy rate that ranges from 77.6 percent to 95.3 per cent. As with WeDoctor, the patient data provides further fuel for the AI software, although the data is stored by the hospital rather than by PereDoc.
The Chinese government’s grip on private companies gives it free rein over what information it collects about its citizens, and how it is used. If China does pull ahead in the global AI race, it will also be thanks to people like Mr Liu.
5 Chinese startups innovating in healthcare technology WeDoctor Founded in 2010, WeDoctor was originally an app to help people book hospital appointments. This later expanded into a more comprehensive, AI-driven project. It is part of the technology giant Tencent, China’s second-most valuable company. PereDoc A Beijing startup that launched in 2017 with a trial at the People’s Liberation Army General Hospital, one of the best hospitals in the country. PereDoc now provides imaging software to over 200 hospitals around the country, focusing on lung cancer detection. Driver A US-based app funded by Hong Kong’s richest man, Li Ka-shing. The app connects cancer sufferers with their nearest treatment centres, and offers remote consultations and treatment plans. Ping An Good Doctor Unstaffed AI clinics, the size of telephone booths, that collect data through health and voice interactions. The AI software can suggest a treatment plan and a list of medication that can be bought from in-clinic vending machines. The first clinic was unveiled in November 2018 in Shanghai. Alihealth The healthcare subsidiary of the e-commerce giant, Alibaba, it Alihealth has partnered with three major hospitals to launch China’s first AI medical laboratory, which includes a “smart diagnostics” system able to remotely assist doctors in clinical decisions.
More great stories from WIRED
– The Play Store is packed with nasty, violent games for kids
– Why does the London Tube still not have Wi-Fi in tunnels?
– Netflix's Love, Death & Robots is just tedious sexist sci-fi
Advertisement
– The grim reality of life under London's Gangs Matrix
– Care about online privacy? Then change your phone number

Story 108
02.03.2019 - Motorsport
David Schumacher steigt mit US Racing in neue Formel-Serie auf Nach dem Rookie-Titel in der ADAC Formel 4 steigt David Schumacher weiter auf. Mit US Racing startet er in der neuen Formula Regional European Championship. mehr

Story 109
16.05.2019 - 09:38 UTC
Great Dane Airlines (DW, Aalborg) has acquired two E195s from Stobart Air (RE, Dublin Int'l) ahead of the launch of flights operations next month. The first of the pair, EI-GGC (msn 19000213), is currently at Dublin Int'l awaiting delivery to the start-up's Aalborg base.
Operationally, Great Dane Airlines has secured a contract from Danish tour operator Bravo Tours to run charter flights from Aalborg to Chania, Palma de Mallorca, Varna, and Rhodes initially with Dublin Int'l, Edinburgh, and Nice to follow.
“Our mission is to provide much-needed connectivity, so far denied, to Northern Jutland as these popular routes are too thin to support large narrowbody operations profitably," Thomas Møller, Founder and CEO of Great Dane Airlines said in a statement.
Great Dane Airlines is currently in the process of completing its certification drive with the Danish authorities.

Story 110
Relive some of the best college football moments of week 9
Relive some of the best college football moments of week 9
Notre Dame managed a perfect record through 12 games last year, before falling in the Cotton Bowl to eventual national champion Clemson, 30-3.
They picked up their second loss of the 2019 campaign in Week 9 against Michigan, but there's still plenty of time left for the Irish.
Notre Dame Fighting Irish 2019 full football schedule
Here is the full, detailed schedule for Notre Dame’s 2019 football season, with past games and results first, then the TV schedule for future games below.
PAST GAMES OPPONENT DATE TIME (ET) LOCATION RESULT Louisville Monday, Sept. 2 8:00 p.m. Louisville, KY W, 35-17 New Mexico Saturday, Sept. 14 2:30 p.m. Notre Dame, IN W, 66-14 Georgia Saturday, Sept. 21 8:00 p.m. Athens, GA L, 23-17 Virginia Saturday, Sept. 28 3:30 p.m. Notre Dame, IN W, 35-20 Bowling Green Saturday, Oct. 5 3:30 p.m. Notre Dame, IN W, 52-0 USC Saturday, Oct. 12 7:30 p.m. Notre Dame, IN W, 30-27 Michigan Saturday, Oct. 26 7:30 p.m. Ann Arbor, MI L, 45-14
UPCOMING GAMES OPPONENT DATE TIME (ET) LOCATION TV Virginia Tech Saturday, Nov. 2 2:30 p.m. Notre Dame, IN NBC Duke Saturday, Nov. 9 TBD Durham, NC ACCN Navy Saturday, Nov. 16 2:30 p.m. Notre Dame, IN NBC Boston College Saturday, Nov. 23 2:30 p.m. Notre Dame, IN NBC Stanford Saturday, Nov. 30 TBD Stanford, CA TBD
2019 SEASON PREVIEW: 15 games that will impact the CFP race this season
Tickets
You can find tickets to each of Notre Dame’s home games here.
2018’s results
The Irish went 12-1 last year, losing to Clemson 30-3 in the Cotton Bowl.
Here’s what happened in every game of Notre Dame’s 2018 schedule:
OPPONENT DATE LOCATION RESULT SCORE Michigan Saturday, September 1 Notre Dame, IN W 24-17 Ball State Saturday, September 8 Notre Dame, IN W 24-16 Vanderbilt Saturday, September 15 Notre Dame, IN W 22-17 Wake Forest Saturday, September 22 Winston-Salem, NC W 56-27 Stanford Saturday, September 29 Notre Dame, IN W 38-17 Virginia Tech Saturday, October 6 Blacksburg, VA W 45-23 Pittsburgh Saturday, October 13 Notre Dame, IN W 19-14 Navy Saturday, October 27 San Diego, CA W 44-22 Northwestern Saturday, November 3 Evanston, IL W 31-21 Florida State Saturday, November 10 Notre Dame, IN W 42-13 Syracuse Saturday, November 17 Bronx, NY W 36-3 USC Saturday, November 24 Los Angeles, Cali W 24-17 Clemson Saturday, Dec. 29 Arlington, TX L 30-3
MORE: Programs with the most national championships
Top returning players
Quarterback Ian Book didn’t take over the starting job until week three of 2018, but still managed to pass for 2,628 yards, 19 touchdowns, and 7 interceptions (a 154.0 rating) in just 10 games. With Brandon Wimbush gone to UCF, Book enters 2019 as the obvious starter under center, which should allow for a breakout season for the junior.
Jafar Armstrong was playing second fiddle to Dexter Williams, but emerged as the top aerial threat out of Notre Dame’s backfield last season, catching 14 passes for 159 yards (an average of 11.4 yards per reception).
But where Notre Dame will shine next year will obviously be the defense, led in part by lineman Julian Okwara. Last year, Okwara had 26 solo tackles, including 12.5 for a loss, and eight sacks, and he also picked up an interception and a forced fumble.
Preseason ranking
We have Notre Dame sitting at No. 10 in our preseason Top 25. Here’s that breakdown:
10. Notre Dame
Get ready for a slightly down year for the Irish. That trip to Georgia seems destined to end in a loss. And then there are brutal games at Michigan, Duke and Stanford. Seems like 9-3 is the end result. But there won't be a collapse.
PRESEASON RANKING: The full college football preseason Top 25
The 2020 College Football Playoff
The College Football Playoff era is entering its sixth season in the 2019-20 season. Will it be the first season since the inaugural playoff that Clemson and Alabama are left out of either the CFP semifinal or national championship?
Whether the Tigers and Tide play each other or not, here are the dates and sites for the 2019 College Football Playoff semifinals and CFP national championship.
MORE: Clemson dominates Alabama to win 2018 College Football Playoff title
When are the 2019 College Football Playoff semifinals?
The CFP semifinals are set for Dec. 28, 2019. One semifinal is the Peach Bowl at Mercedes-Benz Stadium in Atlanta. The other semifinal is the Fiesta Bowl in Glendale, Arizona.
When is the 2020 College Football Playoff national championship?
The CFP national championship is a bit later in 2020. The two winners of the semifinals will meet on the second Monday of January in New Orleans on Jan. 13, 2020 at the Mercedes-Benz Superdome.
Below is a complete history of the College Football Playoff national championship game.
YEAR GAME 2015 No. 4 Ohio State 42, No. 2 Oregon 20 2016 No. 2 Alabama 45, No. 1 Clemson 40 2017 No. 2 Clemson 35, No. 1 Alabama 31 2018 No. 4 Alabama 26, No. 3 Georgia 23 (OT) 2019 No. 2 Clemson 44, No. 1 Alabama 16
2021-2024 CFP national championship locations and dates
2021: Miami-South Florida (Hard Rock Stadium, Miami Gardens, Florida) - Jan. 11
2022: Indianapolis (Lucas Oil Stadium, Indianapolis, Indiana) - Jan. 10
2023: Los Angeles (Los Angeles Stadium at Hollywood Park, Inglewood, California) - Jan. 9
2024: Houston (NRG Stadium, Houston, Texas) - Jan. 8

Story 111
What is Libra?
On June 18, 2019, Facebook announced Libra. It is a virtual currency, or cryptocurrency, though some people don’t agree with that definition. We'll get into why later.
In Facebook’s vision, it should become a global currency for billions of people, especially those in developing countries who have no access to banks or financial services. In other words, Digital money which you can transfer to other people or simply use to buy stuff.
Advertisement
Facebook CEO Mark Zuckerberg is not doing this alone – a bunch of Silicon Valley hotshots are also on-board with the plan.
Libra will be governed by the Libra Association, a Swiss group including 28 members – among which Facebook subsidiary Calibra, Uber, PayPal, Mastercard, Visa, Spotify, and many other household names in technology and finance.
Read next Facebook's new Portal is a last-ditch attempt at hardware success Facebook's new Portal is a last-ditch attempt at hardware success
How will Libra work?
Libra’s white paper – a sort of technical manifesto – says that it will run on a "blockchain". Again, that is a controversial definition in some quarters, so here's a quick and rough explainer.
A blockchain is the infrastructure on which cryptocurrency payments take place. It is a digital, unchangeable record of all the payments ever happened in a given cryptocurrency.
Advertisement
Here’s a crucial thing: a Blockchain is decentralised. The transactions are processed and verified by a swarm of independent computers rather than by a single referee or central bank. Those independent computers are called nodes.
That decentralised structure is intended to enhance security – as there is no single entity to be hacked – and also, to guarantee that governments can’t block transactions simply by browbeating a central authority.
It is a pretty libertarian, anti-state, anti-bank tool. The first blockchain ever is, of course, the one underpinning Bitcoin, the original cryptocurrency.
Read next A huge new Russian propaganda effort is attacking much more than Facebook A huge new Russian propaganda effort is attacking much more than Facebook
So Libra is a cryptocurrency?
Yes, but also no. This is where the disagreements start. The Libra blockchain is not decentralised the way the Bitcoin is. With the Bitcoin blockchain, anyone can theoretically run a node, even if that’s expensive. In contrast, Libra’s nodes will be only run from the servers of the Libra Association’s members – that is: Facebook, Uber, Paypal and the others.
Advertisement
Now, none of these companies will individually have much of a say on how transactions are processed and verified – it will be a collective effort – which is good, according to the blockchain ethos.
Still, the more libertarian cryptocurrency fans resent that Libra will be controlled by a club of mega-corporations. They also fear that the Libra Association could buckle under pressure if, for instance, a government ordered it to block a transaction.
Facebook’s official reason for this make-up is that a fully decentralised model would not be powerful or fast enough to deliver the “global financial infrastructure” Libra aspires to become.
Why does Libra need to be centralised?
Because of scale and speed.
Read next Facebook's Libra currency won't replace your money Facebook's Libra currency won't replace your money
Decentralisation makes the system less vulnerable to hacks or shutdowns, but takes time: the Bitcoin blockchain, for instance, can only process about seven payments per second. By comparison, the centralised Visa payment network can support up to 24,000 payments per second. Initially, Libra should be able to handle about 1,000 transactions per second.
The white paper says that, over the next five years, Libra will shift from the current proposed model – also called “permissioned” blockchain – to a totally decentralised – or “permissionless” blockchain. Of course, there is no guarantee that will ever happen.
Bitcoin is really volatile, isn't that a problem?
Absolutely. Over the course of 2017, the price of Bitcoin swung between £920 and $20,000. That is great news if you are a speculator, but it’s not ideal if you want to launch a global payment network for Facebook’s 2.4 billion users. That’s why Libra has been designed as a so-called “stablecoin”.
That means the value of Libra will be tied to the value of real-world assets. Essentially, the Libra Association will store a basket of currencies (like dollars, euros and pounds) and low-risk government securities. The value of this basket will determine the value of all the Libra units in circulation. Every time a user trades cash for Libra through an exchange, that cash will be added to the Libra Association’s reserves.
At this stage, there is not much else we know about Libra. We do know that Facebook Calibra will launch a Libra wallet allowing users to exchange Libra through Messenger, WhatsApp or a standalone app. But we don’t know which businesses will accept Libra yet, thought it's probable that both Uber and Ebay will because they are both members of the Libra Association.
Read next Friday briefing: Facebook is preparing to launch its own cryptocurrency Friday briefing: Facebook is preparing to launch its own cryptocurrency
What do central banks think about Libra?
Libra doesn’t launch until 2020 but that doesn’t mean that people aren’t already fretting about the whole affair. Facebook has promised that it won’t use payment data in order to target adverts – but people don’t trust Facebook, for notorious reasons.
And regulators are also frowning upon the move. France has underlined that only governments can mint money, and has warned against Libra’s potentially nefarious uses. The bank of England said that Libra will have to meet very high financial standards to be allowed in the UK.
And, of course, lawmakers in both the US and the EU are concerned about Facebook’s expansion to the financial domain. For a company which is increasingly depicted as an oversized, unaccountable, arrogant monopoly, is launching a currency really the best way to avoid scrutiny?
We’ll find out in 2020.
More great stories from WIRED
💸 How the hell did Uber lose $5bn in three months?
Read next Why does Facebook recommend friends I've never even met? Why does Facebook recommend friends I've never even met?
♻️ The truth behind the UK's biggest recycling myths
🤷🏼 How is the internet still obsessed with Myers-Briggs?
🚬 England has an ambitious plan to eradicate smoking by 2030
Advertisement
🕵🏿 It's time you ditched Chrome for a privacy-first web browser
📧 Get the best tech deals and gadget news in your inbox

Story 112
Janne Ilvonen
Once, to see a movie, you had to go to a cinema, head to your local video shop, or hope that a broadcaster was screening something you might want to watch. Nowadays, whether you like Hitchcock, docu-dramas or binge-watching House of Cards, Netflix has you covered. As the TV critic James Poniewozik wrote in the New York Times, Netflix is “breathtakingly broad and microscopically niche at the same time”.
In 2019, financial services will reach a similar tipping point. What used to be a clunky, one-size-fits-all approach to things such as borrowing, insurance and investing will become simpler, cheaper, more personal and within reach of a wider range of consumers. Many of the fintech businesses that have blossomed in the past decade will come of age next year. That means they won’t just be mimicking and improving on what the banks did – in the same way Netflix didn’t simply build a better movie rental company. Rather, we’ll start to see proof of the fact fintech is changing every aspect of our financial lives, just as Netflix fundamentally reshaped what and how we watch.
Advertisement
There are plenty of signs that this transformation is already taking place. Several fintech businesses have recently gone public, with some approaching the valuations of the biggest banks. The new crop of companies that sprung up in the wake of the 2008 financial crisis were built from scratch by talented twenty-somethings, and have already earned the trust of millions of customers.
They’re making a real impact in areas people care about: giving small businesses access to crucial loans, as well as helping consumers save, invest more wisely and get better value from their health and motor insurance. By 2019, control over their personal financial future will be within reach of more people than ever before.
Read next A new-wave of challenger banks is taking on Monzo and Starling A new-wave of challenger banks is taking on Monzo and Starling
In the US, for example, companies such as Robinhood, Acorns, Wealthfront and Fundrise have all made it cheaper and easier for ordinary people to invest in areas such as real-estate, currencies and shares. That’s particularly important for millennials, who came of age at a time when faith in the financial sector was at a low ebb. In 2013, only one in three millennials in the US said they owned stocks – a skittishness that’s not surprising, given their exposure to global finance was overshadowed by the biggest crash since the Depression of the 1930s.
This is how Netflix's secret recommendation system works Netflix This is how Netflix's secret recommendation system works
Advertisement
But these numbers are finally starting to rise, with a recent Gallup survey putting the proportion of people under 35 in the US with money in the stock market at closer to 40 per cent. In 2019, we think that the growing awareness of fintech offerings could see up to half of US millennials investing in stocks, and participating in the wealth which that creates.
Meanwhile, we can also expect to see old, staid banks desperately trying to attract our attention with new initiatives. In 2019, the legacy players will start to make serious investments, instead of just setting up incubators and hubs, where they merely tinker with innovation at the fringes. Take JP Morgan, which recently launched “Finn”, a smartphone-only bank account for young adults; or “Canvas”, a platform created by Citi that lets customers beta-test and co-create new products and services.
You can expect to see the old guard close more and more physical branches, and compensate with shiny new digital offerings. But all this is likely to do is bring more people online, where the more nimble, newer players can out-compete.
Read next Starling Bank review: the grownup challenger card Starling Bank review: the grownup challenger card
2019 will also experience finance achieving an ever-wider global footprint while becoming more and more tailored. In the past, companies had to offer a wide range of services in a single geography, similar to the way broadcasters would select shows to appeal to the widest possible audience.
Advertisement
More and more, though, fintech businesses will endeavour to win over customers by doing one thing really well, in as many places as possible – just as streamed content can now cater to extraordinarily specific preferences. Fintech is often talked about as a revolution. But actually it is more a democratisation and personalisation of financial services that will raise standards across the board. And in 2019 that will spell good news for everybody.
Samir Desai is a co-founder and CEO of Funding Circle. Neil Rimer is a partner at Index Ventures
More great stories from WIRED
– Inside the dark web's biggest hitman-for-hire website
– How BMW's new electric powertrain torpedos Tesla
Advertisement
– Google is no longer the best company to work for in the UK
– How to make sense of bitcoin's unrelenting death spiral
Get the best of WIRED in your inbox every Saturday with the WIRED Weekender newsletter

Story 113
Summary Background Suboptimal diet is an important preventable risk factor for non-communicable diseases (NCDs); however, its impact on the burden of NCDs has not been systematically evaluated. This study aimed to evaluate the consumption of major foods and nutrients across 195 countries and to quantify the impact of their suboptimal intake on NCD mortality and morbidity. Methods By use of a comparative risk assessment approach, we estimated the proportion of disease-specific burden attributable to each dietary risk factor (also referred to as population attributable fraction) among adults aged 25 years or older. The main inputs to this analysis included the intake of each dietary factor, the effect size of the dietary factor on disease endpoint, and the level of intake associated with the lowest risk of mortality. Then, by use of disease-specific population attributable fractions, mortality, and disability-adjusted life-years (DALYs), we calculated the number of deaths and DALYs attributable to diet for each disease outcome. Findings In 2017, 11 million (95% uncertainty interval [UI] 10–12) deaths and 255 million (234–274) DALYs were attributable to dietary risk factors. High intake of sodium (3 million [1–5] deaths and 70 million [34–118] DALYs), low intake of whole grains (3 million [2–4] deaths and 82 million [59–109] DALYs), and low intake of fruits (2 million [1–4] deaths and 65 million [41–92] DALYs) were the leading dietary risk factors for deaths and DALYs globally and in many countries. Dietary data were from mixed sources and were not available for all countries, increasing the statistical uncertainty of our estimates. Interpretation This study provides a comprehensive picture of the potential impact of suboptimal diet on NCD mortality and morbidity, highlighting the need for improving diet across nations. Our findings will inform implementation of evidence-based dietary interventions and provide a platform for evaluation of their impact on human health annually. Funding Bill & Melinda Gates Foundation.
Introduction 1 Willett WC
Stampfer MJ Current evidence on healthy eating. , 2 Norat T
Chan D
Lau R
Aune D
Vieira R
Corpet D The associations between food, nutrition and physical activity and the risk of colorectal cancer. , 3 World Cancer Research Fund/American Institute for Cancer Research
Diet, nutrition, physical activity and cancer: a global perspective. Continuous Update Project Expert Report. , 4 Micha R
Shulkin ML
Peñalvo JL
et al. Etiologic effects and optimal intakes of foods and nutrients for risk of cardiovascular diseases and diabetes: systematic reviews and meta-analyses from the Nutrition and Chronic Diseases Expert Group (NutriCoDE). , 5 Micha R
Kalantarian S
Wirojratana P
et al. Estimating the global and regional burden of suboptimal nutrition on chronic disease: methods and inputs to the analysis. 2 Norat T
Chan D
Lau R
Aune D
Vieira R
Corpet D The associations between food, nutrition and physical activity and the risk of colorectal cancer. , 3 World Cancer Research Fund/American Institute for Cancer Research
Diet, nutrition, physical activity and cancer: a global perspective. Continuous Update Project Expert Report. , 4 Micha R
Shulkin ML
Peñalvo JL
et al. Etiologic effects and optimal intakes of foods and nutrients for risk of cardiovascular diseases and diabetes: systematic reviews and meta-analyses from the Nutrition and Chronic Diseases Expert Group (NutriCoDE). , 5 Micha R
Kalantarian S
Wirojratana P
et al. Estimating the global and regional burden of suboptimal nutrition on chronic disease: methods and inputs to the analysis. , 6 Colditz GA Overview of the epidemiology methods and applications: strengths and limitations of observational study designs. , 7 Nishida C
Uauy R
Kumanyika S
Shetty P The joint WHO/FAO expert consultation on diet, nutrition and the prevention of chronic diseases: process, product and policy implications. 8 Lloyd-Jones DM
Hong Y
Labarthe D
et al. Defining and setting national goals for cardiovascular health promotion and disease reduction: the American Heart Association's strategic Impact Goal through 2020 and beyond. , 9 McGuire S U.S. Department of Agriculture and U.S. Department of Health and Human Services, Dietary Guidelines for Americans, 2010. The relationship between dietary habits and chronic non-communicable diseases (NCDs) has been extensively investigated.Long-term randomised trials with NCD endpoints have not been feasible for most dietary factors, but synthesis of other lines of epidemiological evidence, including long-term prospective observational studies and short-term trials of intermediate outcomes, have provided supporting evidence for potential causal relationships between specific dietary factors (eg, fruits, vegetables, processed meat, and trans fat intake) and NCDs (ischaemic heart disease, diabetes, and colorectal cancer).These findings have been widely used to inform national and international dietary guidelines aimed at preventing NCDs.However, because of the complexities of characterising dietary consumption across different nations, assessment of the health effects of suboptimal diet at the population level has not been possible. 10 Lim SS
Vos T
Flaxman AD
et al. A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010. , 11 Forouzanfar MH
Alexander L
et al. GBD 2013 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks in 188 countries, 1990–2013: a systematic analysis for the Global Burden of Disease Study 2013. , 12 GBD 2015 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2015: a systematic analysis for the Global Burden of Disease Study 2015. , 13 GBD 2016 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. , 14 Mozaffarian D
Fahimi S
Singh GM
et al. Global sodium consumption and death from cardiovascular causes. , 15 Singh GM
Micha R
Khatibzadeh S
et al. Estimated global, regional, and national disease burdens related to sugar-sweetened beverage consumption in 2010. , 16 Singh GM
Micha R
Khatibzadeh S
et al. Global, regional, and national consumption of sugar-sweetened beverages, fruit juices, and milk: a systematic assessment of beverage intake in 187 countries. , 17 Micha R
Khatibzadeh S
Shi P
et al. Global, regional and national consumption of major food groups in 1990 and 2010: a systematic analysis including 266 country-specific nutrition surveys worldwide. , 18 Micha R
Khatibzadeh S
Shi P
et al. Global, regional, and national consumption levels of dietary fats and oils in 1990 and 2010: a systematic analysis including 266 country-specific nutrition surveys. , 19 Wang Q
Afshin A
Yakoob MY
et al. Impact of nonoptimal intakes of saturated, polyunsaturated, and trans fat on global burdens of coronary heart disease. In the past decade, efforts have been made to quantify the burden of disease attributable to specific dietary factors.These efforts, although useful, had several important limitations, including insufficient geographically representative data on dietary consumption, inaccurate characterisation of population distribution of dietary intake, insufficient accounting for biases of different sources of dietary assessment, standardisation of the intake to 2000 kcal per day, and insufficient accounting for within-person variation of intake of dietary factors. To address these limitations, as part of the Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) 2017, we systematically collected geographically representative dietary data from multiple sources, characterised the population distribution of intake for 15 foods and nutrients among adults aged 25 years or older across 195 countries, estimated the effect of each individual dietary factor on NCD mortality, and quantified the overall impact of poor dietary habits on NCD mortality. We also evaluated the relationship between diet and socioeconomic development, and assessed the trends in disease burden of diet over time. This analysis supersedes all previous results from GBD with respect to dietary risks by comprehensively reanalysing all data from 1990 to 2017, using consistent methods and definitions. Research in context Evidence before this study We systematically searched MEDLINE and the Global Health Data Exchange (GHDx) to identify studies providing nationally or subnationally representative estimates of consumption of 15 foods and nutrients. We included only studies reporting data collected between Jan 1, 1980, and Dec 31, 2016, in one of the 195 countries included in this analysis. Studies were excluded if done with non-random samples or among specific subpopulations. We estimated the potential health effects of each dietary risk by use of the Global Burden of Diseases, Injuries, and Risk Factors Study comparative risk assessment approach. Added value of this study This study provides a comprehensive picture of consumption of 15 dietary factors across nations and quantifies the potential impact of suboptimal intake of each diet component on chronic disease mortality and morbidity among 195 countries. Additionally, this study characterises the relationship between diet and development and evaluates the trends in the burden of disease attributable to diet from 1990 to 2017. High intake of sodium, low intake of whole grains, and low intake of fruits were the leading dietary risk factors for deaths and DALYs globally and in many countries. Implications of all the available evidence This study highlights the need for improving diet at the global, regional, and national level. The findings inform priorities for population-level interventions to improve diet.
Methods Selection of dietary risk factors 10 Lim SS
Vos T
Flaxman AD
et al. A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010. , 11 Forouzanfar MH
Alexander L
et al. GBD 2013 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks in 188 countries, 1990–2013: a systematic analysis for the Global Burden of Disease Study 2013. , 12 GBD 2015 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2015: a systematic analysis for the Global Burden of Disease Study 2015. , 13 GBD 2016 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. 10 Lim SS
Vos T
Flaxman AD
et al. A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010. , 11 Forouzanfar MH
Alexander L
et al. GBD 2013 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks in 188 countries, 1990–2013: a systematic analysis for the Global Burden of Disease Study 2013. , 12 GBD 2015 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2015: a systematic analysis for the Global Burden of Disease Study 2015. , 13 GBD 2016 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. We selected 15 dietary risk factors ( table ) that met GBD selection criteria for risk factors.These criteria include the importance of the risk factor to either disease burden or policy; the availability of sufficient data to estimate risk factor exposure; the strength of the epidemiological evidence supporting a causal relationship between risk factor exposure and disease endpoints, and availability of data to quantify the magnitude of this relationship per unit of change in the exposure; and evidence supporting the generalisability of the effects to all populations. The process of evaluation of the strength of epidemiological evidence for the causal relationship of each diet–disease pair is described elsewhereand summarised in the appendix Table Dietary risk factor exposure definitions, optimal level, and data representativeness index, 1990–2017 Exposure definition Optimal level of intake (optimal range of intake) Data representativeness index (%) Diet low in fruits Mean daily consumption of fruits (fresh, frozen, cooked, canned, or dried fruits, excluding fruit juices and salted or pickled fruits) 250 g (200–300) per day 94·9 Diet low in vegetables Mean daily consumption of vegetables (fresh, frozen, cooked, canned, or dried vegetables, excluding legumes and salted or pickled vegetables, juices, nuts, seeds, and starchy vegetables such as potatoes or corn) 360 g (290–430) per day 94·9 Diet low in legumes Mean daily consumption of legumes (fresh, frozen, cooked, canned, or dried legumes) 60 g (50–70) per day 94·9 Diet low in whole grains Mean daily consumption of whole grains (bran, germ, and endosperm in their natural proportion) from breakfast cereals, bread, rice, pasta, biscuits, muffins, tortillas, pancakes, and other sources 125 g (100–150) per day 94·9 Diet low in nuts and seeds Mean daily consumption of nut and seed foods 21 g (16–25) per day 94·9 Diet low in milk Mean daily consumption of milk including non-fat, low-fat, and full-fat milk, excluding soy milk and other plant derivatives 435 g (350–520) per day 94·9 Diet high in red meat Mean daily consumption of red meat (beef, pork, lamb, and goat, but excluding poultry, fish, eggs, and all processed meats) 23 g (18–27) per day 94·9 Diet high in processed meat Mean daily consumption of meat preserved by smoking, curing, salting, or addition of chemical preservatives 2 g (0–4) per day 36·9 Diet high in sugar-sweetened beverages Mean daily consumption of beverages with ≥50 kcal per 226·8 serving, including carbonated beverages, sodas, energy drinks, fruit drinks, but excluding 100% fruit and vegetable juices 3 g (0–5) per day 36·9 Diet low in fibre Mean daily intake of fibre from all sources including fruits, vegetables, grains, legumes, and pulses 24 g (19–28) per day 94·9 Diet low in calcium Mean daily intake of calcium from all sources, including milk, yogurt, and cheese 1·25 g (1·00–1·50) per day 94·9 Diet low in seafood omega-3 fatty acids Mean daily intake of eicosapentaenoic acid and docosahexaenoic acid 250 mg (200–300) per day 94·9 Diet low in polyunsaturated fatty acids Mean daily intake of omega-6 fatty acids from all sources, mainly liquid vegetable oils, including soybean oil, corn oil, and safflower oil 11% (9–13) of total daily energy 94·9 Diet high in trans fatty acids Mean daily intake of trans fat from all sources, mainly partially hydrogenated vegetable oils and ruminant products 0·5% (0·0–1·0) of total daily energy 36·9 Diet high in sodium 24 h urinary sodium measured in g per day 3 g (1–5) per day * * To reflect the uncertainty in existing evidence on optimal level of intake for sodium, 1–5 g per day was considered as the uncertainty range for the optimal level of sodium where less than 2·3 g per day is the intake level of sodium associated with the lowest level of blood pressure in randomised controlled trials and 4–5 g per day is the level of sodium intake associated with the lowest risk of cardiovascular disease in observational studies. 26·2 Dietary intake at the population level 20 Schmidhuber J
Sur P
Fay K
et al. The Global Nutrient Database: availability of macronutrients and micronutrients in 195 countries from 1980 to 2013. We did a systematic review of the scientific literature to identify nationally or subnationally representative nutrition surveys providing data on consumption of each dietary factor ( appendix ). We also searched the Global Health Data Exchange website for nationally or subnationally representative nutrition surveys and household budget surveys. Additionally, for food groups, we used national sales data from Euromonitor and national availability data from United Nations Food and Agriculture Organization food balance sheets. For nutrients, we used data on their national availability from the Global Nutrient Database.For sodium, we collected data on 24 h urinary sodium, where available. For trans fat, we used sales data from Euromonitor on hydrogenated vegetable oil. The list of all dietary data sources used in GBD 2017 is publicly available at the Global Health Data Exchange website. For each dietary factor, we computed a data representativeness index as the fraction of countries for which we identified any data on the risk factor exposure ( table ). Our dietary data were from multiple sources and were affected by different types of biases. We considered 24 h diet recall as the gold standard method for assessing mean intake at the population level and adjusted dietary data from other sources accordingly ( appendix ). Some types of dietary data (ie, availability, sales, and household data) were only available for all-age groups and both sexes. To split these data into standard age-specific and sex-specific groups, we first estimated the global age and sex patterns of intake using data from nutrition surveys and then used those patterns to split the availability, sales, and household data. We used the spatiotemporal Gaussian process regression method to estimate the mean intake of each dietary risk factor by age, sex, country, and year ( appendix ). To improve our estimates in data-sparse models, we tested a wide range of covariates with plausible relationships with intake and included the covariates with best fit and coefficients in the expected direction ( appendix ). Effect size of dietary risks on disease endpoints 21 Gakidou E
Afshin A
Abajobir AA
et al. Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. 22 Singh GM
Danaei G
Farzadfar F
et al. The age-specific quantitative effects of metabolic risk factors on cardiovascular diseases and diabetes: a pooled analysis. 14 Mozaffarian D
Fahimi S
Singh GM
et al. Global sodium consumption and death from cardiovascular causes. For each diet–disease pair, we used data from published meta-analyses of prospective observational studies to estimate the relative risk of mortality and morbidity.For diet–disease pairs for which evidence was only available on morbidity, we assumed that the estimated relative risks were also applied to mortality ( appendix ). Considering the relationship of diet and metabolic risk factors and the well established age trend of the relative risks of metabolic risks for cardiovascular disease and type 2 diabetes, we used the age trend of the relative risks of metabolic risk factorsto estimate the age-specific relative risk of dietary risks for cardiovascular disease and type 2 diabetes ( appendix ). To estimate the impact of sodium on outcomes, we first estimated the relationship between urinary sodium and change in systolic blood pressure, and then estimated the relationship between change in systolic blood pressure and disease outcomes. Optimal level of intake 13 GBD 2016 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. 23 Mente A
O'Donnell M
Rangarajan S
et al. Associations of urinary sodium excretion with cardiovascular events in individuals with and without hypertension: a pooled analysis of data from four studies. , 24 Trinquart L
Johns DM
Galea S Why do we think we know what we know? A metaknowledge analysis of the salt controversy. We defined the optimal level of intake as the level of risk exposure that minimises the risk from all causes of death. To estimate the optimal intake for each dietary factor, we first calculated the level of intake associated with the lowest risk of mortality from each disease endpoint based on the studies included in the meta-analyses of the dietary relative risks. Then, we calculated the optimal level of intake as the weighted mean of these numbers using the global proportion of deaths from each disease as the weight. To reflect the uncertainty of optimal level of intake, we assumed a uniform uncertainty distribution of 20% above and below the mean.For sodium, the evidence supporting the selection of the optimal level of intake was uncertain.Therefore, we included a uniform distribution of different optimal levels of intake in the uncertainty estimation sampling. Disease-specific deaths and disability-adjusted life-years 25 GBD 2016 Causes of Death Collaborators
Global, regional, and national age-sex specific mortality for 264 causes of death, 1980–2016: a systematic analysis for the Global Burden of Disease Study 2016. , 26 Djalalinia S
Saeedi Moghaddam S
Moradi-Lakeh M
et al. Prevalence and years lived with disability of 310 diseases and injuries in Iran and its neighboring countries, 1990–2015: findings from Global Burden of Disease Study 2015. Data on disease-specific deaths and disability-adjusted life-years (DALYs) by age, sex, country, and year were obtained from GBD 2017. The GBD approach to estimating cause-specific mortality and DALYs has been described in detail elsewhere. Disease burden of dietary risks 10 Lim SS
Vos T
Flaxman AD
et al. A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010. , 11 Forouzanfar MH
Alexander L
et al. GBD 2013 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks in 188 countries, 1990–2013: a systematic analysis for the Global Burden of Disease Study 2013. , 12 GBD 2015 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2015: a systematic analysis for the Global Burden of Disease Study 2015. , 13 GBD 2016 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. We used the GBD comparative risk assessment approach to estimate the population attributable fraction for each diet–disease pair by age, sex, country, and year.Then, we estimated the number of deaths and DALYs attributable to each dietary risk factor by multiplying the population attributable fraction by the total number of disease-specific deaths and DALYs. 12 GBD 2015 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2015: a systematic analysis for the Global Burden of Disease Study 2015. , 13 GBD 2016 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 84 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016. To position countries on the development continuum, we used the Socio-demographic Index (SDI), which is a summary measure calculated on the basis of lag-distributed income per capita, mean educational attainment of individuals aged 15 years or older, and total fertility rate among women younger than 25 years.To estimate gaps in intake or excess of intake of individual components of diet, we compared the current intake of each dietary factor with the midpoint of its optimal range of intake ( table ). High intake of a dietary component refers to an intake level higher than the midpoint of the optimal range of intake, and low intake refers to an intake level lower than the midpoint of the optimal range of intake. To incorporate the uncertainty of parameters (exposure, relative risk, optimal level of intake, and mortality) as well as modelling uncertainty, we followed a Monte Carlo approach. We repeated all calculations 1000 times using one draw of each parameter at each iteration. Using these 1000 draws, we calculated the mean and 95% uncertainty interval (UI) for the final estimates. All statistical analyses were done in Python, version 3.5. Role of the funding source The funder of the study had no role in study design, data collection, data analysis, data interpretation, or writing of the report. The first author and the corresponding author had full access to all the data in the study and had final responsibility for the decision to submit for publication.
Results Consumption of major foods and nutrients Globally, consumption of nearly all healthy foods and nutrients was suboptimal in 2017 ( figure 1 ). The largest gaps between current and optimal intake were observed for nuts and seeds, milk, and whole grains, with mean consumption at 12% (95% UI 12–13; 3 g [2–3] of nuts and seeds per day), 16% (16–17; 71 g [70–72] of milk per day), and 23% (23–23; 29 g [29–29] of whole grains per day) of the optimal levels (percentages calculated on the basis of data before rounding). In parallel with suboptimal healthy food consumption, daily intake of all unhealthy foods and nutrients exceeded the optimal level globally ( figure 1 ). The consumption of sugar-sweetened beverages (49 g per day) was far higher than the optimal intake. Similarly, global consumption of processed meat (4 g [4–4] per day, 90% greater than the optimal amount) and sodium (6 g [5–6] per day, 86% greater than the optimal amount) were far above the optimal levels. The global intake of red meat (27 g [26–28] per day) was 18% greater than the optimal intake. Men generally had a higher intake of both healthy and unhealthy foods than did women. Intake of both healthy and unhealthy foods was generally higher among middle-aged adults (50–69 years) and lowest among young adults (25–49 years) with a few exceptions. The highest intake of sugar-sweetened beverages and legumes were observed among young adults and showed a decreasing trend with age. Figure 1 Age-standardised intake of dietary factors among adults aged 25 years or older at the global and regional level in 2017 At the regional level, in 2017, the intake of all healthy foods was lower than the optimal level in all 21 GBD regions ( figure 1 ). The only exceptions were the intake of vegetables in central Asia, seafood omega-3 fatty acids in high-income Asia Pacific, and legumes in the Caribbean, tropical Latin America, south Asia, western sub-Saharan Africa, and eastern sub-Saharan Africa. Among unhealthy food groups, consumption of sodium and sugar-sweetened beverages were higher than the optimal level in nearly every region. Red meat consumption was highest in Australasia, southern Latin America, and tropical Latin America. High-income North America had the highest processed meat intake followed by high-income Asia Pacific and western Europe. The highest intake of trans fats was observed in high-income North America, central Latin America, and Andean Latin America. Overall impact of diet on mortality Globally, in 2017, dietary risks were responsible for 11 million [95% UI 10–12] deaths (22% [95% UI 21–24] of all deaths among adults) and 255 million (234–274) DALYs (15% [14–17] of all DALYs among adults; appendix ). Cardiovascular disease was the leading cause of diet-related deaths (10 million [9–10] deaths) and DALYs (207 million [192–222] DALYs), followed by cancers (913 090 [743 345–1 098 432] deaths and 20 million [17–24] DALYs) and type 2 diabetes (338 714 deaths [244 995–447 003] and 24 million [16–33] DALYs). More than 5 million (95% UI 5–5) diet-related deaths (45% [43–46] of total diet-related deaths) and 177 million (163–192) diet-related DALYs (70% [68–71] of total diet-related DALYs) occurred among adults aged younger than 70 years. Across the 21 GBD regions, in 2017, the highest age-standardised rates of all diet-related deaths and DALYs among adults aged 25 years or older were observed in Oceania (678 [95% UI 616–746] deaths per 100 000 population and 17 804 [16 041–19 907] DALYs per 100 000 population; appendix ). The lowest rates of all diet-related deaths among adults (aged 25 years or older) were observed in high-income Asia Pacific (97 [89–106] deaths per 100 000 population) and the lowest rates of all diet-related DALYs were observed in Australasia (2182 [1955–2444] DALYs per 100 000 population). The regions with the highest rates of diet-related cardiovascular disease deaths and DALYs were central Asia (613 [566–658] deaths per 100 000 population) and Oceania (14 755 [13 212–16 512] DALYs per 100 000 population), whereas the lowest rate of cardiovascular disease deaths and DALYs were observed in high-income Asia Pacific (68 [63–75] deaths per 100 000 population and 1443 [1329–1573] DALYs per 100 000 population). Diet-related cancer death and DALY rates were highest in east Asia (41 [34–49] deaths per 100 000 population and 878 [736–1023] DALYs per 100 000 population) and lowest in north Africa and the Middle East (nine [8–11] deaths per 100 000 population and 203 [169–243] DALYs per 100 000 population). Oceania (60 [44–78] deaths per 100 000 population and 2426 [1737–3198] DALYs per 100 000 population) had the highest age-standardised rate of diet-related diabetes deaths and DALYs, and high-income Asia Pacific had the lowest rates (two [2–3] deaths per 100 000 population and 290 [202–395] DALYs per 100 000 population). In 2017, the highest age-standardised proportions of diet-related deaths and DALYs from cardiovascular disease were observed in Oceania (60% [95% UI 56–63] of deaths) and east Asia (64% [60–68] of DALYs), those from cancer in east Asia (15% [13–18] of deaths and 15% [12–17] of DALYs), and those from type 2 diabetes in high-income North America (41% [34–48] of deaths and 50% [42–58] of DALYs; appendix ). The lowest age-standardised proportions of deaths and DALYs from these causes were in western Europe (42% [38–45] of deaths and 44% [41–47] of DALYs), western sub-Saharan Africa (5% [4–6] of deaths and 4% [4–5] DALYs), and southeast Asia (29% [20–38] of deaths and 35% [25–46] of DALYs). In 2017, among the world's 20 most populous countries, Egypt had the highest age-standardised rate of all diet-related deaths (552 [95% UI 490–620] deaths per 100 000 population) and DALYs (11 837 [10 525–13 268] DALYs per 100 000 population) and Japan had the lowest rate of all diet-related deaths (97 [89–106)] deaths per 100 000 population) and DALYs (2300 [2099–2513] DALYs per 100 000 population; figure 2 ). China had the highest age-standardised rates of diet-related cardiovascular disease deaths (299 [275–324] deaths per 100 000 population) and Egypt had the highest DALY rates (10 811 [9577–12 209] DALYs per 100 000 population). China had highest rates of diet-related cancer deaths and DALYs (42 [34–49] deaths per 100 000 population and 889 [744–1036] DALYs per 100 000 population), and Mexico had the highest rates of diet-related type 2 diabetes deaths and DALYs (35 [28–44] deaths per 100 000 population and 1605 [1231–2034] DALYs per 100 000 population). Japan had the lowest rate of diet-related cardiovascular disease deaths and DALYs (69 [63–75] deaths per 100 000 population and 1507 [1389–1639] DALYs per 100 000 population) and diabetes deaths and DALYs (one [1–1] death per 100 000 population and 234 [161–321] DALYs per 100 000 population). Egypt had the lowest rate of diet-related cancer deaths and DALYs (five [4–6] deaths per 100 000 population and 120 [96–146] DALYs per 100 000 population; appendix ). The highest age-standardised proportion of all diet-related deaths (30% [27–33]) and DALYs (23% [21–25]) in adults aged 25 years or older were observed in Egypt, and the lowest proportion of all diet-related deaths (11% [9–12]) and DALYs (7% [6–8]) in the same age group were observed in Nigeria ( appendix ). The highest proportions of diet-related cardiovascular disease deaths and DALYs in 2017 were observed in Pakistan (60% [95% UI 57–64] of deaths and 66% [62–69] of DALYs), cancer deaths and DALYs in China (16% [13–18] of deaths and 15% [13–17] of DALYs), and type 2 diabetes deaths and DALYs in the USA (41% [34–49] of deaths and 50% [43–58] of DALYs). The lowest proportions of cardiovascular disease deaths and DALYs were seen in Turkey (42% [38–47] of deaths and 44% [40–49] of DALYs), cancer deaths and DALYs in Egypt (4% [3–4] of deaths and 3% [3–4] of DALYs), and type 2 diabetes deaths and DALYs in Bangladesh (25% [17–34] of deaths and 34% [23–45] of DALYs). Figure 2 Age-standardised mortality rate per 100 000 population (A) and DALY rate per 100 000 population (B) attributable to diet in 2017 Show full caption ATG=Antigua and Barbuda. Isl=Islands. FSM=Federated States of Micronesia. LCA=Saint Lucia. TLS=Timor-Leste. TTO=Trinidad and Tobago. VCT=Saint Vincent and the Grenadines. Impact of individual components of diet on mortality A small number of dietary risks had a large impact on health outcomes. In 2017, more than half of diet-related deaths and two-thirds of diet-related DALYs were attributable to high intake of sodium (3 million [95% UI 1–5] deaths and 70 million [34–118] DALYs), low intake of whole grains (3 million [2–4] deaths and 82 million [59–109] DALYs), and low intake of fruits (2 million [1–4] deaths and 65 million [41–92] DALYs; figure 3 ). Low intake of whole grains was the leading dietary risk factor for DALYs among men and women and the leading dietary risk factor for mortality among women. Sodium ranked first for mortality among men followed by whole grains and fruit. Low intake of whole grains was the leading risk for deaths and DALYs among young adults (aged 25–50 years) and sodium ranked first among older adults (≥70 years). Figure 3 Number of deaths and DALYs and age-standardised mortality rate and DALY rate (per 100 000 population) attributable to individual dietary risks at the global and SDI level in 2017 Show full caption DALY=disability-adjusted life-year. SDI=Socio-demographic Index. In 2017, across the 21 GBD regions, a diet low in whole grains was the most common leading dietary risk factor for deaths (in 16 regions) and DALYs (in 17 regions; figure 4 ). A diet high in sodium was the leading dietary risk factor for deaths and DALYs in east Asia and high-income Asia Pacific regions ( appendix ). In southern sub-Saharan Africa, a diet low in fruits and in central Latin America a diet low in nuts and seeds were the dietary risk factors responsible for the greatest proportion of deaths and DALYs in 2017. Figure 4 Age-standardised proportions of deaths and DALYs attributable to individual dietary risks at the global and regional level in 2017 Show full caption DALYs=disability-adjusted life-years. High intake of sodium was the leading dietary risk for deaths and DALYs in China, Japan, and Thailand. Low intake of whole grains was the leading dietary risk factor for deaths and DALYs in the USA, India, Brazil, Pakistan, Nigeria, Russia, Egypt, Germany, Iran, and Turkey. In Bangladesh, low intake of fruits was the leading dietary risk associated with deaths and DALYs. In Mexico, low intake of nuts and seeds ranked first for diet-related deaths and DALYs. High consumption of red meat, processed meat, trans fat, and sugar-sweetened beverages were towards the bottom in ranking of dietary risks for deaths and DALYs for most high-population countries ( appendix ). Relationship between diet and SDI Overall, in 2017, the highest age-standardised rates of all diet-related deaths and DALYs were observed in low-middle SDI countries (344 [95% UI 319–369] deaths per 100 000 population and 7797 [7265–8386] DALYs per 100 000 population) and high-middle SDI countries (347 [324–369] deaths per 100 000 population and 6998 [6534–7454] DALYs per 100 000 population; appendix ). The lowest burden of exposure to dietary risk was observed in high SDI countries (139 [129–148] deaths per 100 000 population and 3032 [2802–3265] DALYs per 100 000 population). Low-middle SDI had the highest age-standardised rates of diet-related deaths and DALYs for cardiovascular disease (311 [288–335] deaths per 100 000 population and 6685 [6228–7161] DALYs per 100 000 population) and diabetes (14 [10–18] deaths per 100 000 population and 681 [477–914] DALYs per 100 000 population). High-middle SDI had the highest age-standardised rates of diet-related mortality for cancer (29 [24–34] deaths per 100 000 population and 630 [529–731] DALYs per 100 000 population). The lowest age-standardised rate of diet-related deaths and DALYs for cardiovascular disease (113 [104–122] deaths per 100 000 population and 2156 [2005–2306] DALYs per 100 000 population) and diabetes (five [4–6] deaths per 100 000 population and 444 [324–587] DALYs per 100 000 population) was observed in high SDI countries and lowest mortality rate for cancer was observed in low SDI countries (15 [12–17] deaths per 100 000 population and 324 [268–376] DALYs per 100 000 population). The highest proportions of diet-related deaths and DALYs for all causes were observed in high-middle SDI countries (29% [95% UI 27–31] of deaths and 19% [17–21] of DALYs), the lowest proportion of diet-related deaths was observed in low SDI countries (16% [15–17] of deaths), and the lowest proportion of DALYs was observed in high SDI countries (10% [9–11] of DALYs; appendix ). Dietary risks were responsible for 55% [51–59] of cardiovascular disease deaths and 60% [56–63] of DALYs in middle SDI countries, and 46% [42–49] of cardiovascular disease deaths and 49% [46–52] of cardiovascular disease DALYs in high SDI countries. Middle SDI countries had the highest proportion of cancer deaths (12% [10–14]) and DALYs (11% [9–13]) and high SDI countries had the lowest proportion of attributable cancer deaths (8% [7–9]) and DALYs (7% [6–9]). The highest burden of diabetes attributable to diet was observed in high SDI countries (35% [28–43] of deaths and 46% [38–55) of DALYs) and lowest attributable burden was observed in the low SDI countries (31% [22–39] of deaths and 39% [29–50] of DALYs). High-middle and middle SDI countries were at the greatest risk of deaths and DALYs from high consumption of sodium, whereas high and low-middle SDI countries had the greatest risk caused by a diet low in whole grains ( figure 3 ). In low SDI countries, low intake of fruit was the leading dietary risk for deaths and low intake of whole grains was the leading dietary risk for DALYs. Countries at all levels of SDI other than low SDI had the same four leading dietary risks: high sodium, low whole grains, low fruit, and low nuts and seeds. The four leading dietary risks for low SDI countries were a diet in low whole grains, low in fruit, low in nuts and seeds, and low in vegetables. Impact of nutrition transition on exposure to dietary risks Since 1990, the number of deaths (8 million [95% UI 7–8] deaths) and DALYs (184 [172–197] DALYs) attributable to dietary risks significantly increased to 11 million (10–12) deaths and 255 million (234–274) DALYs in 2017 ( appendix ). The main contributors to this increase were population growth and population ageing. After removing the effect of population growth and population ageing, the age-standardised attributable death and DALY rates showed a significant decrease between 1990 and 2017; from 406 (381–430) deaths per 100 000 population to 275 (258–292) deaths per 100 000 population, and from 8536 (8063–9013) DALYs per 100 000 population to 6080 (5685–6472) DALYs per 100 000 population. This decrease seemed to be driven mostly by decreases in the background mortality rate because, during the same period, the proportion of deaths and DALYs related to dietary risk remained relatively stable.
Discussion Our systematic evaluation of dietary consumption patterns across 195 countries provides a comprehensive picture of the health effects of poor dietary habits at the population level. We found that improvement of diet could potentially prevent one in every five deaths globally. Our findings show that, unlike many other risk factors, dietary risks affected people regardless of age, sex, and sociodemographic development of their place of residence. Although the impact of individual dietary factors varied across countries, non-optimal intake of three dietary factors (whole grains, fruits, and sodium) accounted for more than 50% of deaths and 66% of DALYs attributable to diet. 11 Forouzanfar MH
Alexander L
et al. GBD 2013 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks in 188 countries, 1990–2013: a systematic analysis for the Global Burden of Disease Study 2013. , 12 GBD 2015 Risk Factors Collaborators
Global, regional, and national comparative risk assessment of 79 behavioural, environmental and occupational, and metabolic risks or clusters of risks, 1990–2015: a systematic analysis for the Global Burden of Disease Study 2015. 27 WHO
Global action plan for the prevention and control of noncommunicable diseases: 2013–2020. , 28 WHO
2008–2013 action plan for the global strategy for the prevention and control of noncommunicable diseases: prevent and control cardiovascular diseases, cancers, chronic respiratory diseases and diabetes. Our findings show that suboptimal diet is responsible for more deaths than any other risks globally, including tobacco smoking,highlighting the urgent need for improving human diet across nations. Although sodium, sugar, and fat have been the main focus of diet policy debate in the past two decades,our assessment shows that the leading dietary risk factors for mortality are diets high in sodium, low in whole grains, low in fruit, low in nuts and seeds, low in vegetables, and low in omega-3 fatty acids; each accounting for more than 2% of global deaths. This finding suggests that dietary policies focusing on promoting the intake of components of diet for which current intake is less than the optimal level might have a greater effect than policies only targeting sugar and fat, highlighting the need for a comprehensive food system interventions to promote the production, distribution, and consumption of these foods across nations. 29 Afshin A
Penalvo J
Del Gobbo L
et al. CVD prevention through policy: a review of mass media, food/menu labeling, taxation/subsidies, built environment, school procurement, worksite wellness, and marketing standards to improve diet. , 30 Mozaffarian D
Afshin A
Benowitz NL
et al. Population approaches to improve diet, physical activity, and smoking habits: a scientific statement from the American Heart Association. , 31 WHO
Interventions on diet and physical activity: what works. Summary report. 32 Cobiac LJ
Veerman L
Vos T The role of cost-effectiveness analysis in developing nutrition policy. , 33 Bibbins-Domingo K
Chertow GM
Coxson PG
et al. Projected effect of dietary salt reductions on future cardiovascular disease. , 34 Smith-Spangler CM
Juusola JL
Enns EA
Owens DK
Garber AM Population strategies to decrease sodium intake and the burden of cardiovascular disease: a cost-effectiveness analysis. , 35 Owen L
Morgan A
Fischer A
Ellis S
Hoy A
Kelly MP The cost-effectiveness of public health interventions. 29 Afshin A
Penalvo J
Del Gobbo L
et al. CVD prevention through policy: a review of mass media, food/menu labeling, taxation/subsidies, built environment, school procurement, worksite wellness, and marketing standards to improve diet. , 30 Mozaffarian D
Afshin A
Benowitz NL
et al. Population approaches to improve diet, physical activity, and smoking habits: a scientific statement from the American Heart Association. 32 Cobiac LJ
Veerman L
Vos T The role of cost-effectiveness analysis in developing nutrition policy. , 33 Bibbins-Domingo K
Chertow GM
Coxson PG
et al. Projected effect of dietary salt reductions on future cardiovascular disease. , 34 Smith-Spangler CM
Juusola JL
Enns EA
Owens DK
Garber AM Population strategies to decrease sodium intake and the burden of cardiovascular disease: a cost-effectiveness analysis. , 35 Owen L
Morgan A
Fischer A
Ellis S
Hoy A
Kelly MP The cost-effectiveness of public health interventions. 36 Lachat C
Otchere S
Roberfroid D
et al. Diet and physical activity for the prevention of noncommunicable diseases in low- and middle-income countries: a systematic policy review. , 37 Downs SM
Thow AM
Leeder SR The effectiveness of policies for reducing dietary trans fat: a systematic review of the evidence. 38 Anand SS
Hawkes C
de Souza RJ
et al. Food consumption and its impact on cardiovascular disease: importance of solutions focused on the globalized food system: a report from the workshop convened by the World Heart Federation. , 39 Over the past decade, the effectiveness of a range of population-level dietary interventions has been systematically evaluated and several promising interventions have been identified.These include mass media campaigns, food and menu labeling, food pricing strategies (subsidies and taxation), school procurement policies, and worksite wellness programmes. Cost-effectiveness analyses of these interventions have shown that targeting specific dietary factors (eg, sodium) might not only be cost-effective but cost-saving.However, improvement of diet through population-level interventions faces several major challenges. First, the observed effects for most of these dietary interventions are far below the level required to achieve optimal diet globally.Second, there is almost no evidence on the effectiveness of these interventions on several important dietary factors (ie, nuts, whole grains, seafood, red meat, and processed meat). Third, cost-effectiveness analyses of dietary interventions are generally based on a range of simplifying assumptions and do not take into account the reactions of consumers (eg, substitution effect), the food industry (eg, food reformulations and pricing strategies), and other stakeholders in the real world.Fourth, despite the growing public and political will for the implementation of some of these policies (eg, trans fat bans), few countries have successfully adopted and implemented them.Fifth, many of these policies only target consumers but not the wide range of interconnected factors, such as food production, processing, and distribution, that exist throughout the food system. Indeed, these factors might affect dietary consumption, and it is important to include them to improve diet.Therefore, in view of the magnitude of the disease burden attributable to diet and the limitations of the existing interventions, development of novel food system interventions is urgently needed. 40 Tilman D
Clark M Global diets link environmental sustainability and human health. , 41 Auestad N
Fulgoni VL What current literature tells us about sustainable diets: emerging research linking dietary patterns, environmental sustainability, and economics. , 42 Heller MC
Keoleian GA
Willett WC Toward a life cycle-based, diet-level framework for food environmental impact and nutritional quality assessment: a critical review. , 43 Sabaté J
Soret S Sustainability of plant-based diets: back to the future. 40 Tilman D
Clark M Global diets link environmental sustainability and human health. , 41 Auestad N
Fulgoni VL What current literature tells us about sustainable diets: emerging research linking dietary patterns, environmental sustainability, and economics. , 42 Heller MC
Keoleian GA
Willett WC Toward a life cycle-based, diet-level framework for food environmental impact and nutritional quality assessment: a critical review. , 43 Sabaté J
Soret S Sustainability of plant-based diets: back to the future. 41 Auestad N
Fulgoni VL What current literature tells us about sustainable diets: emerging research linking dietary patterns, environmental sustainability, and economics. 42 Heller MC
Keoleian GA
Willett WC Toward a life cycle-based, diet-level framework for food environmental impact and nutritional quality assessment: a critical review. Our results show a need for extensive changes in various sectors of the food system at the global, regional, and national levels to improve diet. Changes in agricultural practices, if not done properly, might raise concerns over potential environmental effects on climate change, biodiversity loss, degradation of land and soil, and freshwater depletion.A growing body of evidence has emerged in the past decade showing that shifting diet from unhealthy animal-based foods (eg, red meat and processed meat) to healthy plant-based foods (eg, fruits, vegetables, and whole grains) might be associated with lower emission of greenhouse gases and thus might be more environmentally sustainable.The few studies evaluating other environmental effects of the shift from animal-based to plant-based diet have also demonstrated that this shift might be associated with lower land use and water footprint.However, because of the variations in the methods and research questions across these studies and scarcity of reliable estimates on dietary consumption patterns across nations, a comprehensive assessment of environmental effects of achieving optimal diet globally has not been possible to date. GBD estimates the dietary consumption of key foods and nutrients across 195 nations annually. These data provide a unique opportunity to quantify the environmental burden of current dietary consumption patterns at global, regional, and national levels in a consistent and comparable way. Additionally, these data could potentially be used to evaluate the effect of various food system interventions on human health and environment. 17 Micha R
Khatibzadeh S
Shi P
et al. Global, regional and national consumption of major food groups in 1990 and 2010: a systematic analysis including 266 country-specific nutrition surveys worldwide. , 18 Micha R
Khatibzadeh S
Shi P
et al. Global, regional, and national consumption levels of dietary fats and oils in 1990 and 2010: a systematic analysis including 266 country-specific nutrition surveys. 44 Food and Agriculture Organization of the United Nations
Food consumption database. 45 Hill RJ
Davies PS The validity of self-reported energy intake as determined using the doubly labelled water technique. , 46 McLean RM Measuring population sodium intake: a review of methods. 47 Illner A-K
Freisling H
Boeing H
Huybrechts I
Crispim SP
Slimani N Review and evaluation of innovative technologies for measuring diet in nutritional epidemiology. Our study also demonstrates the gaps in nationally representative individual-level data on intake of key foods and nutrients in different regions of the world, highlighting the importance of establishing national surveillance and monitoring systems for key dietary risk factors.For example, although many countries collect data on fruit and vegetable intake, data on intake of specific nutrients such as sodium are scarce. The FAO/WHO Global Individual Food consumption data Toolaims to address this problem, but several important gaps will remain. In the absence of reliable biomarkers or more accurate methods of dietary assessment, the 24 h diet recall or diet record remains the gold standard method of dietary assessment. However, evidence from validation studies suggests that it is not highly reliable for assessment of foods and nutrients due to recall bias or potential social desirability.This evidence highlights the need for development and validation of innovative dietary assessment methods. In the past decade, new methods have been developed; however, they have not been widely used and their validity has not been systematically evaluated.Furthermore, accurate estimation of nutrients (eg, fibre, calcium, and polyunsaturated fatty acids), remains a major challenge. Many countries do not have local food composition tables and rely on data from food composition tables from other countries (eg, US Department of Agriculture food composition tables). Additionally, the recipes of mixed dishes as well as formulation of the food products, particularly their content of fat, sugar, and sodium, varies across countries and over time, which makes estimation of the true intake of nutrient more challenging. Our systematic evaluation of epidemiological evidence shows several important limitations in existing dietary relative risks. The effect sizes of the dietary risk factors on disease endpoints were mostly obtained from meta-analyses of prospective observational studies. Although many of these dietary relative risks have been adjusted for the major confounders (eg, age, sex, smoking, and physical activity), the possibility of residual confounding cannot be excluded. To remove the effect of energy intake as a potential confounder and address measurement error in dietary assessment tools, most cohorts have adjusted for total energy intake in their statistical models. This energy adjustment means that diet components are defined as risks in terms of the share of diet and not as absolute levels of exposure. In other words, an increase in intake of foods and macronutrients should be compensated by a decrease in intake of other dietary factors to hold total energy intake constant. Thus, the relative risk of change in each component of diet depends on the other components for which it is substituted. However, the relative risks estimated from meta-analyses of cohort studies do not generally specify the type of substitution. The definition of dietary factors (eg, whole grains) also varies across studies. Additionally, given the intake of healthy dietary factors are generally positively correlated with each other and inversely correlated with harmful dietary factors, the effect size of the individual dietary factors might be overestimated. Many of the observational studies used for estimation of the relative risks have not corrected risk estimates for dietary measurement error, and some have adjusted for factors along the causal pathways. Although many cohort studies have collected dietary data, only a few of them have published results of their assessment, which increases the possibility of publication bias. These limitations highlight the need for a collaborative effort to collect and harmonise all available dietary data from cohort studies and to do a pooled analysis for each diet–disease pair and quantify the effect size after adjusting for the same set of confounders. Other potential limitations should also be considered in interpreting and using the findings of our study. We did not evaluate the effect of other forms of malnutrition (ie, undernutrition and obesity). The epidemiological evidence supporting a causal relationship between dietary risks and disease endpoints were mostly from observational studies, and the strength of evidence was generally weaker than the strength of evidence supporting a causal relationship between other established risks factors (eg, tobacco use and high systolic blood pressure) and chronic diseases. Additionally, the strength of evidence varied across foods and nutrients. Dietary data were from mixed sources and were not available for all countries. These factors increase the statistical uncertainty of our estimates for exposure to dietary risks. For sodium, we did not include data from spot urine sample, which resulted in a lower data representativeness index for sodium than that of other dietary risks. In estimation of the NCD burden of diet, we assumed that the distribution of dietary factors is independent within each unit of analysis (ie, country, age, and sex group), which might have resulted in underestimation or overestimation of the combined effect of dietary factors. To quantify the effect of correlation of dietary factors, we used individual-level data from the US National Health and Nutrition Examination Survey and estimated the overall burden of dietary risks (ie, joint population attributable fractions) with and without taking into account their correlation. The absolute difference in the joint population attributable fractions, on average, was less than 2%. Additionally, deaths due to some dietary risk factors might not be mutually exclusive, which could result in overestimation of the burden of disease attributable to diet. In summary, we found that poor dietary habits are associated with a range of chronic diseases and can potentially be a major contributor to NCD mortality in all countries worldwide. This finding highlights the urgent need for coordinated global efforts to improve the quality of human diet. Given the complexity of dietary behaviours and the wide range of influences on diet, improving diet requires active collaboration of a variety of actors throughout the food system, along with policies targeting multiple sectors of the food system. Global Health Data Exchange see For more on thesee http://ghdx.healthdata.org Euromonitor see For more onsee https://www.euromonitor.com/ food balance sheets see For more onsee http://www.fao.org/economic/ess/fbs/en/ Global Nutrient Database see For thesee https://nutrition.healthdata.org/global-nutrient-database dietary data sources see For the list of allsee http://ghdx.healthdata.org/gbd-2017/data-input-sources
GBD 2017 Diet Collaborators
Ashkan Afshin, Patrick John Sur, Kairsten A Fay, Leslie Cornaby, Giannina Ferrara, Joseph S Salama, Erin C Mullany, Kalkidan Hassen Abate, Cristiana Abbafati, Zegeye Abebe, Mohsen Afarideh, Anju Aggarwal, Sutapa Agrawal, Tomi Akinyemiju, Fares Alahdab, Umar Bacha, Victoria F Bachman, Hamid Badali, Alaa Badawi, Isabela M Bensenor, Eduardo Bernabe, Stan H Biryukov, Sibhatu Kassa K Biadgilign, Leah E Cahill, Juan J Carrero, Kelly M Cercy, Lalit Dandona, Rakhi Dandona, Anh Kim Dang, Meaza Girma Degefa, Maysaa El Sayed Zaki, Alireza Esteghamati, Sadaf Esteghamati, Jessica Fanzo, Carla Sofia E Sá Farinha, Maryam S Farvid, Farshad Farzadfar, Valery L Feigin, Joao C Fernandes, Luisa Sorio Flor, Nataliya A Foigt, Mohammad H Forouzanfar, Morsaleh Ganji, Johanna M Geleijnse, Richard F Gillum, Alessandra C Goulart, Giuseppe Grosso, Idris Guessous, Samer Hamidi, Graeme J Hankey, Sivadasanpillai Harikrishnan, Hamid Yimam Hassen, Simon I Hay, Chi Linh Hoang, Masako Horino, Farhad Islami, Maria D Jackson, Spencer L James, Lars Johansson, Jost B Jonas, Amir Kasaeian, Yousef Saleh Khader, Ibrahim A Khalil, Young-Ho Khang, Ruth W Kimokoti, Yoshihiro Kokubo, G Anil Kumar, Tea Lallukka, Alan D Lopez, Stefan Lorkowski, Paulo A Lotufo, Rafael Lozano, Reza Malekzadeh, Winfried März, Toni Meier, Yohannes A Melaku, Walter Mendoza, Gert B M Mensink, Renata Micha, Ted R Miller, Mojde Mirarefin, Viswanathan Mohan, Ali H Mokdad, Dariush Mozaffarian, Gabriele Nagel, Mohsen Naghavi, Cuong Tat Nguyen, Molly R Nixon, Kanyin L Ong, David M Pereira, Hossein Poustchi, Mostafa Qorbani, Rajesh Kumar Rai, Christian Razo-García, Colin D Rehm, Juan A Rivera, Sonia Rodríguez-Ramírez, Gholamreza Roshandel, Gregory A Roth, Juan Sanabria, Tania G Sánchez-Pimienta, Benn Sartorius, Josef Schmidhuber, Aletta Elisabeth Schutte, Sadaf G Sepanlou, Min-Jeong Shin, Reed J D Sorensen, Marco Springmann, Lucjan Szponar, Andrew L Thorne-Lyman, Amanda G Thrift, Mathilde Touvier, Bach Xuan Tran, Stefanos Tyrovolas, Kingsley Nnanna Ukwaja, Irfan Ullah, Olalekan A Uthman, Masoud Vaezghasemi, Tommi Juhani Vasankari, Stein Emil Vollset, Theo Vos, Giang Thu Vu, Linh Gia Vu, Elisabete Weiderpass, Andrea Werdecker, Tissa Wijeratne, Walter C Willett, Jason H Wu, Gelin Xu, Naohiro Yonemoto, Chuanhua Yu, and Christopher J L Murray.
Affiliations
Department of Health Metrics Sciences (A Afshin MD, Prof S I Hay FMedSci, I A Khalil MD, Prof A H Mokdad PhD, Prof M Naghavi MD, Prof S E Vollset DrPH, Prof T Vos PhD, Prof C J L Murray DPhil), Institute for Health Metrics and Evaluation (A Afshin MD, P J Sur MPH, K A Fay BS, L Cornaby BS, G Ferrara BA, J S Salama MSc, E C Mullany BA, S H Biryukov BS, K M Cercy BS, Prof L Dandona MD, Prof R Dandona PhD, Prof V L Feigin PhD, M H Forouzanfar MD, Prof S I Hay FMedSci, S L James MD, I A Khalil MD, Prof A D Lopez PhD, Prof R Lozano MD, Prof A H Mokdad PhD, Prof M Naghavi MD, M R Nixon PhD, K L Ong PhD, G A Roth MD, R J D Sorensen MPH, Prof S E Vollset DrPH, Prof T Vos PhD, Prof C J L Murray DPhil), Department of Epidemiology (A Aggarwal PhD), School of Medicine (V F Bachman BA), Division of Cardiology (G A Roth), Department of Global Health (R J D Sorensen), University of Washington, Seattle, WA, USA; School of Medicine, University of California Riverside, Riverside, CA, USA (P J Sur); Department of Population and Family Health, Jimma University, Jimma, Ethiopia (K H Abate PhD); Department of Law, Philosophy and Economic Studies, La Sapienza University, Rome, Italy (C Abbafati PhD); Human Nutrition Department (Z Abebe MSc), Institute of Public Health (Y A Melaku MPH), University of Gondar, Gondar, Ethiopia; Endocrinology and Metabolism Research Center (M Afarideh MD, Prof A Esteghamati MD, M Ganji MD), Endocrine Research Center (S Esteghamati MD), Non-communicable Diseases Research Center (F Farzadfar MD), Hematologic Malignancies Research Center (A Kasaeian PhD), Digestive Diseases Research Institute (Prof R Malekzadeh MD, H Poustchi PhD, G Roshandel PhD, S G Sepanlou MD), Hematology-Oncology and Stem Cell Transplantation Research Center (A Kasaeian), Tehran University of Medical Sciences, Tehran, Iran; Vital Strategies, Gurugram, India (S Agrawal PhD); Department of Epidemiology, University of Kentucky, Lexington, KY, USA (T Akinyemiju PhD); Evidence Based Practice Center, Mayo Clinic Foundation for Medical Education and Research, Rochester, MN, USA (F Alahdab MD); School of Health Sciences, University of Management and Technology, Lahore, Pakistan (U Bacha MPhil); Department of Medical Mycology, Mazandaran University of Medical Sciences, Sari, Iran (H Badali PhD); Public Health Risk Sciences Division, Public Health Agency of Canada, Toronto, ON, Canada (A Badawi PhD); Department of Nutritional Sciences, University of Toronto, Toronto, ON, Canada (A Badawi); Department of Internal Medicine (I M Bensenor PhD, A C Goulart PhD), Department of Medicine (Prof P A Lotufo DrPH), Center for Clinical and Epidemiological Research (A C Goulart), University of São Paulo, São Paulo, Brazil; Dental Institute, King's College London, London, UK (E Bernabe PhD); Independent Consultant, Addis Ababa, Ethiopia (S K K Biadgilign MPH); Department of Medicine, Dalhousie University, Halifax, NS, Canada (L E Cahill PhD); Department of Nutrition (L E Cahill, M S Farvid PhD, Prof W C Willett MD), T.H. Chan School of Public Health, Harvard University, Boston, MA, USA (A L Thorne-Lyman ScD); Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden (J J Carrero PhD, Prof E Weiderpass PhD); Public Health Foundation of India, Gurugram, India (S Agrawal, Prof L Dandona, Prof R Dandona, G A Kumar PhD); Institute for Global Health Innovations, Duy Tan University, Hanoi, Vietnam (A K Dang MD, C T Nguyen MPH); Department of Nutrition and Dietetics, Mekelle University, Mekelle, Ethiopia (M G Degefa BSc); Department of Clinical Pathology, Mansoura University, Mansoura, Egypt (Prof M El Sayed Zaki PhD); Berman Institute of Bioethics (Prof J Fanzo PhD), Bloomberg School of Public Health (A L Thorne-Lyman), Johns Hopkins University, Baltimore, MD, USA; National Statistical Office, Lisbon, Portugal (C S E S Farinha MSc); Nutrition and Food Systems Division (Prof J Fanzo), Trade and Markets Division (J Schmidhuber PhD), Food and Agriculture Organization of the United Nations, Rome, Italy; National Institute for Stroke and Applied Neurosciences, Auckland University of Technology, Auckland, New Zealand (Prof V L Feigin); Center for Biotechnology and Fine Chemistry, Catholic University of Portugal, Porto, Portugal (J C Fernandes PhD); Sergio Arouca National School of Public Health, Rio De Janeiro, Brazil (L S Flor MPH); Federal University of Espírito Santo, Vitoria, Brazil (L S Flor); Institute of Gerontology, National Academy of Medical Sciences of Ukraine, Kyiv, Ukraine (N A Foigt PhD); Division of Human Nutrition and Health, Wageningen University and Research, Wageningen, Netherlands (Prof J M Geleijnse PhD); Department of Community and Family Medicine, Division of General Internal Medicine, Howard University, Washington, DC, USA (R F Gillum MD); Registro Tumori Integrato, Vittorio Emanuele University Hospital Polyclinic, Catania, Italy (G Grosso PhD); Unit of Population Epidemiology, Department of Community Medicine, Primary Care and Emergency Medicine, Geneva University Hospitals, Geneva, Switzerland (I Guessous PhD); Department of Ambulatory Care and Community Medicine, University of Lausanne, Lausanne, Switzerland (I Guessous); School of Health and Environmental Studies, Hamdan Bin Mohammed Smart University, Dubai, United Arab Emirates (Prof S Hamidi DrPH); School of Medicine, University of Western Australia, Perth, WA, Australia (Prof G J Hankey MD); Neurology Department, Sir Charles Gairdner Hospital, Perth, WA, Australia (Prof G J Hankey); Cardiology Department, Sree Chitra Tirunal Institute for Medical Sciences and Technology, Trivandrum, India (Prof S Harikrishnan MD); Public Health Department, Mizan-Tepi University, Teppi, Ethiopia (H Y Hassen MPH); Unit of Epidemiology and Social Medicine, University Hospital Antwerp, Wilrijk, Belgium (H Y Hassen); Center of Excellence in Behavioral Medicine, Nguyen Tat Thanh University, Ho Chi Minh, Vietnam (C L Hoang BSc, G T Vu BA, L G Vu BSc); Nevada Division of Public and Behavioral Health, Carson City, NV, USA (M Horino MPH, M Mirarefin MPH); Surveillance and Health Services Research, American Cancer Society, Atlanta, GA, USA (F Islami PhD); Department of Community Health and Psychiatry, University of the West Indies, Mona, Jamaica (Prof M D Jackson PhD); Independent Consultant, Eiksmarka, Norway (L Johansson DrPH); Department of Ophthalmology (Prof J B Jonas MD), Medical Clinic V (Prof W März MD), Heidelberg University, Mannheim, Germany; Beijing Institute of Ophthalmology, Beijing Tongren Hospital, Beijing, China (Prof J B Jonas); Department of Public Health and Community Medicine, Jordan University of Science and Technology, Ramtha, Jordan (Prof Y S Khader PhD); Institute of Health Policy and Management, Department of Health Policy and Management, Seoul National University, Seoul, South Korea (Prof Y-H Khang MD); Department of Nutrition, Simmons College, Boston, MA, USA (R W Kimokoti MD); Department of Preventive Cardiology, National Cerebral and Cardiovascular Center, Suita, Japan (Prof Y Kokubo PhD); Population and Work Ability Program, Finnish Institute of Occupational Health, Helsinki, Finland (T Lallukka PhD); Department of Public Health, University of Helsinki, Helsinki, Finland (T Lallukka); Department of Medicine (Prof T Wijeratne MD), University of Melbourne, Melbourne, VIC, Australia (Prof A D Lopez PhD); Institute of Nutrition, Friedrich Schiller University Jena, Jena, Germany (Prof S Lorkowski PhD); Innovation Office (T Meier PhD), Competence Cluster for Nutrition and Cardiovascular Health (NUTRICARD), Jena, Germany (Prof S Lorkowski); Non-Communicable Diseases Research Center, Shiraz University of Medical Sciences, Shiraz, Iran (Prof R Malekzadeh, S G Sepanlou); Clinical Institute of Medical and Chemical Laboratory Diagnostics, Medical University of Graz, Graz, Austria (Prof W März); Institute for Agricultural and Nutritional Sciences, Martin Luther University Halle-Wittenberg, Halle, Germany (T Meier); Adelaide Medical School, University of Adelaide, Adelaide, SA, Australia (Y A Melaku); Peru Country Office, United Nations Population Fund (UNFPA), Lima, Peru (W Mendoza MD); Department of Epidemiology and Health Monitoring, Robert Koch Institute, Berlin, Germany (G B M Mensink PhD); Friedman School of Nutrition Science and Policy, Tufts University, Boston, MA, USA (R Micha PhD, D Mozaffarian MD); Pacific Institute for Research and Evaluation, Calverton, MD, USA (T R Miller PhD); School of Public Health, Curtin University, Perth, WA, Australia (T R Miller); Department of Diabetology, Madras Diabetes Research Foundation, Chennai, India (V Mohan DSc); Institute of Epidemiology and Medical Biometry, Ulm University, Ulm, Germany (Prof G Nagel PhD); REQUIMTE/LAQV, University of Porto, Oporto, Portugal (Prof D M Pereira PhD); Cartagena University, Cartagena, Colombia (Prof D M Pereira); Non-Communicable Diseases Research Center, Alborz University of Medical Sciences, Karaj, Iran (M Qorbani PhD); Society for Health and Demographic Surveillance, Suri, India (R K Rai MPH); Department of Economics, University of Goettingen, Göttingen, Germany (R K Rai); Center for Population Health Research (C Razo-García PhD), Center for Nutrition and Health Research (Prof J A Rivera PhD, S Rodríguez-Ramírez DSc), National Institute of Public Health, Cuernavaca, Mexico (T G Sánchez-Pimienta MSc); Department of Epidemiology & Population Health, Montefiore Medical Center, Bronx, NY, USA (C D Rehm PhD); Golestan Research Center of Gastroenterology and Hepatology, Golestan University of Medical Sciences, Gorgan, Iran (G Roshandel); Department of Surgery, Marshall University, Huntington, WV, USA (Prof J Sanabria MD); Department of Nutrition and Preventive Medicine, Case Western Reserve University, Cleveland, OH, USA (Prof J Sanabria); Department of Public Health Medicine, University of Kwazulu-Natal, Durban, South Africa (Prof B Sartorius PhD); Hypertension in Africa Research Team (HART), North-West University, Potchefstroom, South Africa (Prof A E Schutte PhD); Unit for Hypertension and Cardiovascular Disease, South African Medical Research Council, Cape Town, South Africa (Prof A E Schutte); Korea University, Seoul, South Korea (Prof M-J Shin PhD); Oxford Martin Programme on the Future of Food and Centre on Population Approaches for Non-Communicable Disease Prevention, Nuffield Department of Population Health, University of Oxford, Oxford, UK (M Springmann PhD); National Food and Nutrition Institute, Warsaw, Poland (L Szponar MD); Monash University, Melbourne, VIC, Australia (Prof A G Thrift PhD); Nutritional Epidemiology Research Team, National Institute of Health and Medical Research, Paris, France (M Touvier PhD); Department of Health Economics, Hanoi Medical University, Hanoi, Vietnam (B X Tran PhD); Research and Development Unit, San Juan de Dios Sanitary Park, Sant Boi De Llobregat, Spain (S Tyrovolas PhD); Carlos III Health Institute, Biomedical Research Networking Center for Mental Health Network (CIBERSAM), Madrid, Spain (S Tyrovolas); Department of Internal Medicine, Federal Teaching Hospital, Abakaliki, Nigeria (K N Ukwaja MD); Gomal Center of Biochemistry and Biotechnology, Gomal University, Dera Ismail Khan, Pakistan (I Ullah PhD); TB Culture Laboratory, Mufti Mehmood Memorial Teaching Hospital, Dera Ismail Khan, Pakistan (I Ullah); Division of Health Sciences, University of Warwick, Coventry, UK (O A Uthman PhD); Department of Social Work, Department of Public Health and Clinical Medicine, Umeå University, Umeå, Sweden (M Vaezghasemi PhD); UKK Institute, Tampere, Finland (Prof T J Vasankari MD); Department of Research, Cancer Registry of Norway, Oslo, Norway (Prof E Weiderpass); Demographic Change and Ageing Research Area, Federal Institute for Population Research, Wiesbaden, Germany (A Werdecker PhD); Independent Consultant, Staufenberg, Germany (A Werdecker); Department of Psychology, La Trobe University, Melbourne, VIC, Australia (Prof T Wijeratne); Channing Division of Network Medicine, Department of Medicine, Brigham and Women's Hospital, Boston, MA, USA (Prof W C Willett); The George Institute for Global Health, University of New South Wales, Newtown, NSW, Australia (J H Wu PhD); School of Medicine, Nanjing University, Nanjing, China (Prof G Xu MD); Department of Psychopharmacology, National Center of Neurology and Psychiatry, Tokyo, Japan (N Yonemoto MPH); and Global Health Institute, Department of Epidemiology and Biostatistics, Wuhan University, Wuhan, China (Prof C Yu PhD).
Contributors
AAf prepared the first draft. KAF and KMC constructed the figures and tables. AAf and PJS developed models for dietary risks. CJLM provided overall guidance. JSS managed the project. AAf and ECM finalised the manuscript on the basis of comments from other authors and reviewer feedback. All other authors provided data, reviewed results, or reviewed and contributed to the paper.
Declaration of interests
JMG reports grants from Unilever. LJ reports personal fees from Mills Scientific Council. SL reports personal fees from Amgen, Berlin-Chemie, Merck Sharp & Dohme (MSD), Novo Nordisk, Sanofi-Aventis, Synlab, Unilever, and Upfield, and non-financial support from Preventicus. SL is also a member of the Scientific Board of the German Nutrition Society and a coauthor of the evidence-based guideline Fat Intake and Prevention of Nutrition-Related Diseases of the German Nutrition Society. WMä reports grants and personal fees from Siemens Diagnostics, Aegerion Pharmaceuticals, Amgen, AstraZeneca, Danone Research, Pfizer, BASF, Numares AG, and Berlin-Chemie; personal fees from Hoffmann LaRoche, MSD, Sanofi, and Synageva; grants from Abbott Diagnostics; and employment with Synlab Holding Deutschland GmbH. WMe is currently a program analyst for Population and Development at the Peru Country Office of the United Nations Population Fund-UNFPA, an institution that does not necessarily endorse this study. RMi reports grants from the US National Institutes of Health, Bill & Melinda Gates Foundation, and Unilever; and personal fees from World Bank and Bunge. DM reports research funding from the US National Institutes of Health and the, Bill & Melinda Gates Foundation; personal fees from GOED, DSM, Nutrition Impact, Pollock Communications, Bunge, Indigo Agriculture, Amarin, Acasti Pharma, and America's Test Kitchen; scientific advisory board roles with Elysium Health (with stock options), Omada Health, and DayTwo; and chapter royalties from UpToDate. In addition, DM is listed as a co-inventor on patents US8889739 and US9987243 issued to Tufts University (Somerville, MA, USA; unlicensed) for use of trans-palmitoleic acid to prevent and treat insulin resistance, type 2 diabetes, and related conditions, as well as reduce metabolic risk factors. CDR reports personal fees from Dairy Management Institute. AES reports personal fees from IEM, Novartis, Servier, and Abbott. AGT reports grants from National Health and Medical Research Council, Australia. All other authors declare no competing interests.
Acknowledgments The work of HB was financially supported by Mazandaran University of Medical Sciences, Sari, Iran. AB is supported by the Public Health Agency of Canada. JCF acknowledges funding support from Fundação para a Ciência e a Tecnologia, through project UID/Multi/50016/2013. TL is supported by the Academy of Finland ( grants number 287488 and number 319200 ). The work of SL is funded by the German Federal Ministry of Education and Research (nutriCARD; grant agreement number 01EA1411A ). TM acknowledges additional institutional support from the Competence Cluster for Nutrition and Cardiovascular Health (nutriCARD), in Jena, Halle, and Leipzig, Germany. AES is supported by the South African Medical Research Council and the South African Research Chair Initiative by the National Research Foundation. AGT acknowledges fellowship funding from the National Health and Medical Research Council (Australia). ST's work was supported by the Foundation for Education and European Culture (IPEP), the Sara Borrell postdoctoral program (reference number CD15/00019 from the Instituto de Salud Carlos III, Spain) and the Fondos Europeo de Desarrollo Regional (FEDER). TW acknowledges academic support from the Department of Medicine, Faculty of Medicine, University of Rajarata, Sri Lanka; the World Federation of Neurology; and the World Federation for Neuro-Rehabilitation. JHW was supported by a Scientia Fellowship from the University of New South Wales (Australia). We thank Pauline Kim and Adrienne Chew for editing assistance.
Supplementary Material Supplementary appendix

Story 114
Relive some of the best college football moments of week 9
Relive some of the best college football moments of week 9
After a 13-2 season that saw it lose in heartbreaking fashion to Alabama in the College Football Playoff, Georgia went 11-3 in 2018, falling to the Crimson Tide in the SEC Championship, shutting the door on back-to-back CFP appearances.
2019 SEC football schedule: Game times, TV channels for every week
Can the Bulldogs make it back to the playoff for the second time in school history?
Georgia Bulldogs 2019 full football schedule
Here is the full, detailed schedule for Georgia’s 2019 football season, with past games and results first, then the TV schedule for future games below.
PAST GAMES OPPONENT DATE TIME (ET) LOCATION RESULT Vanderbilt Saturday, Aug. 31 7:30 p.m. Nashville, TN W, 30-6 Murray State Saturday, Sept. 7 4:00 p.m. Athens, GA W, 63-17 Arkansas State Saturday, Sept. 14 12:00 p.m. Athens, GA W, 55-0 Notre Dame Saturday, Sept. 21 8:00 p.m. Athens, GA W, 23-17 Tennessee Saturday, Oct. 5 7:00 p.m. Knoxville, TN W, 43-14 South Carolina Saturday, Oct. 12 12:00 p.m. Athens, GA L, 20-17 (2OT) Kentucky Saturday, Oct. 19 6:00 p.m. Athens, GA W, 21-0
UPCOMING GAMES OPPONENT DATE TIME (ET) LOCATION TV Florida Saturday, Nov. 2 3:30 p.m. Jacksonville, FL CBS Sports Missouri Saturday, Nov. 9 7:00 p.m. Athens, GA ESPN Auburn Saturday, Nov. 16 TBD Auburn, AL TBD Texas A&M Saturday, Nov. 23 TBD Athens, GA TBD Georgia Tech Saturday, Nov. 30 TBD Atlanta, GA TBD
Tickets
You can find tickets to each of Georgia’s home games here.
2018 results
The Bulldogs went 11-3 last year, losing to Alabama in the SEC Championship, and to Texas in the Sugar Bowl.
Here’s what happened in every game of Georgia’s 2018 schedule:
OPPONENT DATE LOCATION RESULT SCORE Austin Peay Saturday, September 1 Athens, GA W 45-0 South Carolina Saturday, September 8 Columbia, SC W 41-17 Middle Tennessee Saturday, September 15 Athens, GA W 49-7 Missouri Saturday, September 22 Columbia, MO W 43-29 Tennessee Saturday, September 29 Athens, GA W 38-12 Vanderbilt Saturday, October 6 Athens, GA W 41-13 LSU Saturday, October 13 Baton Rouge, LA L 16-36 Florida Saturday, October 27 Jacksonville, FL W 36-17 Kentucky Saturday, November 3 Lexington, KY W 34-17 Auburn Saturday, November 10 Athens, GA W 27-10 UMass Saturday, November 17 Athens, GA W 66-27 Georgia Tech Saturday, November 24 Athens, GA W 45-21 Alabama Saturday, December 1 Atlanta, GA L 28-35 Texas Tuesday, January 1 New Orleans, LA L 21-28
MORE: Programs with the most national championships
Top returning players
Backup quarterback Justin Fields saw a decent amount of reps for the Bulldogs last season, but after he transferred to Ohio State in the offseason, Jake Fromm will be in sole control under center. In his sophomore year, Fromm threw for 2,761 yards, 30 touchdowns and six interceptions, finishing with a rating of 171.3.
Running back D’Andre Swift had huge shoes to fill in 2018 after both Nick Chubb and Sony Michel left Athens, and he stepped up. Swift ran for 1,049 yards and 10 touchdowns, while catching 32 passes for 297 yards and three touchdowns. After losing Riley Ridley and Mecole Hardman to the NFL Draft, Swift will likely be a large part of the passing game for the Bulldogs this year.
But Georgia is going to get a big help in the run game from what is poised to be a stellar offensive line for the Bulldogs this season. And leading that line is tackle Andrew Thomas. Thomas started at left tackle in 13 games last season, and earned SEC Offensive Line Co-Player of the Week after a win against Kentucky that saw Georgia rush for 331 yards.
Preseason ranking
We have Georgia sitting at No. 4 in our preseason Top 25. Here’s the breakdown:
4. Georgia
Perhaps no team had a more disappointing end to the season than the Bulldogs. First they blew a lead against Alabama in the SEC title game. Then they lost to Texas in the Sugar Bowl. But this team has the goods to write a different ending. QB Jake Fromm could make an earnest run for the Heisman, but he won't have to do it alone. RB D'Andre Swift should be lethal from the backfield. There may not be a huge star on defense, but the overall unit will be extremely tough. Now it's about finally beating 'Bama.
PRESEASON RANKING: The full college football preseason Top 25
The 2020 College Football Playoff
The College Football Playoff era is entering its sixth season in the 2019-20 season. Will it be the first season since the inaugural playoff that Clemson and Alabama are left out of either the CFP semifinal or national championship?
Whether the Tigers and Tide play each other or not, here are the dates and sites for the 2019 College Football Playoff semifinals and CFP national championship.
MORE: Clemson dominates Alabama to win 2018 College Football Playoff title
When are the 2019 College Football Playoff semifinals?
The CFP semifinals are set for Dec. 28, 2019. One semifinal is the Peach Bowl at Mercedes-Benz Stadium in Atlanta. The other semifinal is the Fiesta Bowl in Glendale, Arizona.
When is the 2020 College Football Playoff national championship?
The CFP national championship is a bit later in 2020. The two winners of the semifinals will meet on the second Monday of January in New Orleans on Jan. 13, 2020 at the Mercedes-Benz Superdome.
Below is a complete history of the College Football Playoff national championship game.
YEAR GAME 2015 No. 4 Ohio State 42, No. 2 Oregon 20 2016 No. 2 Alabama 45, No. 1 Clemson 40 2017 No. 2 Clemson 35, No. 1 Alabama 31 2018 No. 4 Alabama 26, No. 3 Georgia 23 2019 No. 1 Alabama vs. No. 2 Clemson
2021-2024 CFP national championship locations and dates
2021: Miami-South Florida (Hard Rock Stadium, Miami Gardens, Florida) - Jan. 11
2022: Indianapolis (Lucas Oil Stadium, Indianapolis, Indiana) - Jan. 10
2023: Los Angeles (Los Angeles Stadium at Hollywood Park, Inglewood, California) - Jan. 9
2024: Houston (NRG Stadium, Houston, Texas) - Jan. 8

Story 115
KERRY and Donegal could not be separated as a pulsating clash in the capital finished in a stalemate.
Paul Geaney hit the net for the Kingdom but Michael Murphy hit back for the Ulster champions from the penalty spot in a 1-20 apiece.
4 Kerry and Donegal could not be separated at Croke Park Credit: Sportsfile
4 Mayo got their first win of the Super 8s this afternoon Credit: Sportsfile
The result means Group 1 will go to the wire with Kerry, Donegal and Mayo all vying for the two qualification spots for the semi-finals.
Elsewhere, got their Super 8s campaign back on track with a trouncing of Meath at Croke Park.
Late goals from Kevin McLoughlin and Cillian O'Connor inspired a 2-17 to 0-14 victory at HQ.
That win means James Horan's side are one from two in Group 1 with a home tie against Donegal to come on the August Bank Holiday.
Meanwhile, Dublin and Tyrone are through to the All Ireland semi-finals after wins over Roscommon and Cork on Saturday.
The Red Hands produced a stirring second-half comeback to beat Cork having trailed the Rebels by seven points in the first half after two quickfire goals.
4 Tyrone downed Cork in their second Super 8s match
However, Cathal McShane palmed the ball home shortly after the restart and minutes later Peter Harte fired home a penalty to eliminate the deficit as Cork were eliminated with a game to spare.
In the second game, Dublin hammered Roscommon to return to the last four of the All Ireland stage for the 10th year in a row.
Dean Rock and Michael Darragh MacAuley each found the net as the Dubs cruised to a 16 point victory over the Rossies
GROUP 1: Donegal, Kerry, Mayo, Meath
GROUP 2: Dublin, Roscommon, Tyrone, Cork
GROUP TABLES:
#GAA #Super8s Group 2 Table after Phase 2

Dublin 2-26 v 0-14 Roscommon
Cork 2-12 v 2-15 Tyrone

Dublin and Tyrone have qualified for the All Ireland Semi Finals.#gaaleaguetables pic.twitter.com/JHJSdp9Uos — GAA League Tables (@GAALeagueTables) July 20, 2019
These tables will be updated after each round of matches
FIXTURES AND RESULTS:
GROUP 1
Sunday 14 July
Donegal 2-19 Meath 1-13
Kerry 1-22 Mayo 0-15
Sunday 21 July
Mayo 2-17 Meath 0-14
Kerry 1-20 Donegal 1-20
Saturday, August 3/Sunday, August 4
Mayo v Donegal - MacHale Park - Time TBC
Meath v Kerry - Páirc Tailteann - Time TBC
4 Tyrone got the better of Roscommon at Dr Hyde Park Credit: Sportsfile
GROUP 2
Round 1:
Roscommon 0-13 Tyrone 0-17
Dublin 5-17 Cork 1-17
Round 2:
Saturday 20 July
Cork 2-12 Tyrone 2-15
Dublin 2-26 Roscommon 0-14
Round 3:
Saturday, August 3/Sujnday, August 4
Cork v Roscommon - Pairc Ui Chaoimh - Time TBC
Tyrone v Dublin - Healy Park - Time TBC
How does the Super 8s system work?
THE four provincial champions make the last eight of the All-Ireland Championship and are joined there by the four teams that successfully come through Round 4 of the qualifiers (contested between provincial runners-up and Round 3 winners in qualifiers).
MOST READ SPORT keogh of support Ireland stars slam Derby for sacking Keogh after boozy crash injuries Video WATER FURY Conor McGregor has water bottle hurled at him during Moscow press conference OGH NO Richard Keogh 'sacked by Derby' after Ireland star's car crash injuries CARA-HOW? Carabao Cup fix storm with fans fuming Man Utd, Liverpool & City avoid each other Live Blog UTD LATEST Man Utd news LIVE: Latest news and gossip from Old Trafford Live Blog Carabao Cup draw LIVE Man Utd home to Colchester, City go to Oxford & Villa host Liverpool 'DISGRACEFUL' Ronaldo accused of blatant diving to win last-minute penalty for Juventus CARABA-OUT What happens if Liverpool pull out of Carabao Cup and who would go through? MAK V MAC Conor McGregor should stick to hitting old men, says UFC's Islam Makhachev NO DANA DEAL Dana White reveals he's looking to book McGregor v Donald Cerrone for January
But with the new Super 8 system, these eight teams will split into two round-robin groups of four.
Each team plays the other three teams in their group once and every team plays one home fixture, one away fixture, and one of the Super 8 games at Croke Park.
Dublin play twice at GAA HQ and only once away from home.

Story 116
East Carolina baseball’s Jake Kuchmaner made program history on Sunday. The sophomore lefty threw the Pirates' first perfect game, shutting down 27 straight Maryland hitters in the 3-0 victory.
HISTORY FOR JAKE KUCHMANER!

He tosses the first perfect game in school history! pic.twitter.com/0FZalU1FGR — ECU Baseball (@ECUBaseball) March 17, 2019
Kuchmaner throwing the perfect game may not be all that surprising. The southpaw started his run of dominance two starts back, coming within one strike of East Carolina’s first no-hitter in 14 years. That day, he shut down the Ole Miss bats for 8.2 innings, until he walked his second-to-last batter on a full count, allowing the Rebels' Thomas Dillard to break up the bid with a single to right.
RED-HOT PITCHERS: 5 college baseball hurlers you don't want to face right now
This past Tuesday, Kuchmaner one-hit Duke over 5.2 innings. He was a little wild, for him at least, walking three batters. That’s uncharacteristic for Kuchmaner who has just two walks over his other four appearances this season.
Kuchmaner baffled Maryland right off the bat, needing less than 10 pitches to get a couple of ground outs and a pop out in the first inning. He fell behind a few hitters on the day but faced only four full counts in his nine innings of work, needing 103 pitches to get through the Maryland lineup three times without a base runner.
COLLEGE BASEBALL RANKINGS: Vandy still on top as newcomers highlight the latest poll
First baseman Alec Burleson had the big play in the ninth, saving Kuchmaner’s quest for perfection on a day where the fielders made everything look easy. Kuchmaner struck out eight batters in the game, five of which were swinging, including Kody Milton for the final out.
The win gives the Pirates a much-needed sweep as they head into conference play this coming weekend against UCF.

Story 117
WIRED
For 15 years, Facebook has been built around one idea: all sharing is good. “That's what I believe in – helping people share information with the people they want to share it with,” Mark Zuckerberg wrote in a Facebook post in September 2006. In February 2009, on the eve of Facebook’s fifth birthday, he reiterated his position: “Since its founding, one of the constants of Facebook is that it has continuously evolved to make it easier to share.”
But if the last three years have taught Zuckerberg anything, it’s that too much sharing is a very, very bad thing. After years of providing a platform for misinformation and extremism, Facebook just banned 12 far-right groups and figureheads. The ban, effective from midday on April 18, included the BNP and its former leader Nick Griffin, the EDL, National Front, Knights Templar International as well as Britain First and its leaders Paul Golding and Jayda Fransen.
Advertisement
And Facebook says it will go further than just banning these organisations and individuals. It will also go after their followers. “Posts and other content which expresses praise or support for these figures and groups will also be banned,” the company said in a statement.
This is a dramatic switch for a company that, until a month ago, still talked about itself as a digital “town square” – a space where all voices, including the distasteful and dubious, jostled for attention, free from any interference. It is a seductive ideal that harks back to the early days of the internet and its promise of unfettered freedom of speech.
Read next Facebook's new Portal is a last-ditch attempt at hardware success Facebook's new Portal is a last-ditch attempt at hardware success
Zuckerberg’s town square philosophy positions Facebook as a neutral space, allowing people to gather together while being agnostic about what they have to say. It is a philosophy that equates Facebook with the internet itself – merely the infrastructure through which other people broadcast their thoughts. For over a decade, Facebook has presented itself as a blank sheet of paper, open to (almost) everyone. That is why, until relatively recently, Facebook resisted pressure to crack down on far-right extremism on its platform.
Then, in March of this year, Zuckerberg wrote a long Facebook post arguing that the era of the town square was over, and that Facebook would instead focus on enabling smaller-scale, more private, modes of communication – building out Messenger and WhatsApp instead of the News Feed. Social networks were still about sharing, he argued, but of a more restrained, kinder, nature.
Advertisement
But Zuckerberg was wrong. Facebook never was the town square. Far from being a place of neutrality, the News Feed – and its governing metric, engagement – amplified divisive content and suppressed the inane. It barged into the town square and handed every lunatic a megaphone, creating a space where fringe views could take centre stage. Its own algorithms made a mockery of the idea that Facebook was a neutral platform.
So what has Facebook done? It has embraced its lack of neutrality. The social network has always been allowed to ban whoever it wants – it has just chosen to exercise that right when public criticism has given it little other choice. Now that seems to be shifting as the company starts to explore what kind of platform it wants to be seen as – and whether that’s one where far-right views aren’t welcome.
This means Facebook admitting to itself that it isn’t the whole internet. The web is a big place and there are spaces, such as Gab, that allow almost any kind of speech. They aren’t very nice places, but perhaps it’s better that people who want to share hatred are isolated from an algorithm that will fling their vitriol in the faces of people who didn’t ask for it.
Read next What is Libra? Facebook's cryptocurrency, explained What is Libra? Facebook's cryptocurrency, explained
The rules that govern online hellholes such as Gab and 4Chan don’t work for a network of 2.3 billion people. But now Facebook needs to decide what kind of platform it wants to be.
Advertisement
Two-and-a-half years ago the social network defended its decision to keep Britain First on its platform, saying “Facebook is used by parties and supporters of many political persuasions to campaign for issues they feel passionately about.” Now it isn’t just banning Britain First and its leaders, but is also threatening to remove posts that praise them. Britain First hasn’t changed much in the last couple of years, but Facebook has.
It hasn’t done so willingly, of course. Facebook’s latest move is another attempt to quell the non-stop criticism that has beset the firm since the US election in November 2016. And Zuckerberg is running out of time. If he doesn’t work out what kind of social network he wants to run, there are plenty of lawmakers around the world who would be more than happy to make that decision for him.
More great stories from WIRED
– The Play Store is packed with nasty, violent games for kids
– Why does the London Tube still not have Wi-Fi in tunnels?
– Netflix's Love, Death & Robots is just tedious sexist sci-fi
Advertisement
– The grim reality of life under London's Gangs Matrix
– Care about online privacy? Then change your phone number

Story 118
Man kann sich derzeit einfachere Dinge vorstellen, als den USA ein wenig Datenschutz abtrotzen zu wollen. Noch dazu, wenn es auf Kosten ihrer "nationalen Sicherheit" gehen soll. Genau dieser Konflikt aber ist an diesem Dienstag vor dem Europäischen Gerichtshof in Luxemburg ausgetragen worden, und was soll man sagen: Die Amerikaner waren mit vier Anwälten zugegen. Nach allem, was man bei der EuGH-Verwaltung erfahren konnte, war das die US-Premiere im Verhandlungssaal des obersten EU-Gerichts.
Auslöser des Verfahrens ist wieder der österreichische Datenschutzaktivist Max Schrems, der sich - wie schon vor ein paar Jahren - gegen den Transfer von Facebookdaten von Europa in die USA gewandt hat; im EuGH spricht man nun von Schrems I und Schrems II. Vor vier Jahren kippte der EuGH das Safe-Harbor-Abkommen, mit dem die EU den Amerikanern bescheinigt hatte, ein "sicherer Hafen" für europäische Daten zu sein. Edward Snowden hatte enthüllt, wie freihändig die US-Sicherheitsbehörden auf Datenbestände zugreifen konnten - sicher war nur, dass nichts sicher war. Nach dem Paukenschlag aus Luxemburg haben EU und USA 2016 ein neues Abkommen ausgehandelt, das den Namen "Privacy Shield" trägt, Datenschutzschild.
Auf Vorlage des irischen High Court wird nun also Schrems II verhandelt. "Die US-Gesetze verpflichten Facebook, die US-Behörden bei der Überwachung von EU-Bürgern zu unterstützen und hebeln so den Datenschutz aus", kritisierte sein Anwalt Eoin McCullough. Er wendet sich gegen Überwachungsinstrumente wie Prism und Upstream, die man dank Snowden kennt. Mit Upstream habe die US-Regierung Zugriff auf Metadaten und Inhalte, bei Prism sei dies ähnlich. Und wenn die Datenströme - wovon alle ausgehen - aus einem Kabel im Atlantik abgezapft würden, dann gebe es dagegen keinen Rechtsschutz, sekundierte der Anwalt des irischen Datenschutzbeauftragten.
US-Anwälte: Überwachung ist gut für die Sicherheit der EU-Bürger
Was nun das Kabel angeht, wollten die Amerikaner zwar keine "operationellen Details" bestätigen. Aber wenn man mal ein solches "hypothetisches Szenario" unterstelle, dann gehe es hier gerade nicht um eine "ungerichtete" Massenüberwachung, versicherte Eileen Barrington, Anwältin der US-Regierung. Sondern um "zielgerichtete" Datenerhebung - nach ihren Worten eine Lehre aus den Snowden-Enthüllungen, nach denen die USA das Vertrauen der Europäer zurückgewinnen wollten. Mit Upstream werde anhand bestimmter Selektoren verdächtiges Material herausgefiltert und eben nicht ziellos im Trüben gefischt. Die Anwältin hatte noch eine Botschaft fürs europäische Sicherheitsgefühl im Gepäck: "Es ist erwiesen, dass es einen wesentlichen Nutzen aus der Signalaufklärung der USA gibt - für die Sicherheit der amerikanischen wie auch der EU-Bürger."
Bemerkenswert war, wer sich als Bundesgenosse der USA präsentierte - nämlich Facebook. Deren Anwalt Paul Gallagher beließ es nicht dabei, den Nutzen des freien Datenflusses für Handel und Dienstleistung zu preisen. Auch er verlor ein paar Worte zum Anti-Terror-Kampf: "Die nationale Sicherheit erfordert dieses Screening, sonst wäre es unmöglich, Gefahren zu erkennen." Was den Vertreter Österreichs, Gerhard Kunnert, zu dem sarkastischen Kommentar veranlasste: "Da stellt sich die Frage, ob Facebook sich als Tochterfirma der NSA versteht."
Auch Standardvertragsklauseln stehen mit vor Gericht
Entscheidend für den Ausgang des Verfahrens dürfte sein, wie valide der EuGH die Rechtsschutzmöglichkeiten betroffener Europäer einschätzt. In diesem Punkt zogen sich große Zweifel durch die gesamte Anhörung. Die Überwachung von Nicht-US-Bürgern beruht wesentlich auf einer Direktive des Präsidenten sowie einer "Executive Order", also auf Regierungsanordnungen und nicht auf förmlichen Gesetzen. Daraus wird ein EU-Bürger wenig Honig saugen können - schon gar nicht, wenn er nichts von der Überwachung erfährt, lautete das Fazit vieler Kritiker. Bleibt die Ombudsperson, zu deren Einrichtung sich die USA im Privacy-Shield-Abkommen verpflichtet haben. Ist das wirklich eine unabhängige Beschwerdeinstanz? Unabhängig ist er nur von den Nachrichtendiensten, nicht aber von der Regierung.
Sollte der EuGH, ein strenger Hüter des Datenschutzes, gravierende Defizite entdecken, dann steht womöglich noch mehr auf dem Spiel als damals bei Safe Harbor. Zur Überprüfung steht nämlich nicht nur der Safe-Harbor-Ersatz an. Die Vorlage des irischen Gerichts betrifft auch die sogenannten "Standardvertragsklauseln". Das ist ein System vertraglicher Datenschutzgarantien. Sie beruhen auf einem Beschluss der EU-Kommission von 2010 und haben in der Praxis weitaus größere Bedeutung als bilaterale Daten-Freifahrtscheine wie das Privacy Shield. EuGH-Richter Thomas von Danwitz, der das Verfahren als Berichterstatter bearbeitet, warf die Frage auf, inwieweit ein mangelhaftes Datenschutzniveau in den USA letztlich auch diesen für die Wirtschaft so wichtigen Mechanismus infizieren könnte. Würde die Grundlage dieser Klauseln vom EuGH für unwirksam erklärt, dann wären digitale Dienstleistungen und Vernetzung erheblich beeinträchtigt.

Story 119
Media coverage about MTG stock has trended extremely negative this week, InfoTrie Sentiment Analysis reports. The research group scores the sentiment of press coverage by reviewing more than six thousand news and blog sources in real time. The firm ranks coverage of publicly-traded companies on a scale of negative five to positive five, with scores closest to five being the most favorable. MGIC Investment earned a media sentiment score of -4.0 on InfoTrie's scale. They also assigned news stories about the insurance provider a news buzz of 0.0 out of 10, meaning that recent press coverage is extremely unlikely to have an effect on the stock's share price in the next several days. View News Stories for MGIC Investment.

Story 120
Conclusions Routine vaccination of girls aged 12-13 years with the bivalent HPV vaccine in Scotland has led to a dramatic reduction in preinvasive cervical disease. Evidence of clinically relevant herd protection is apparent in unvaccinated women. These data are consistent with the reduced prevalence of high risk HPV in Scotland. The bivalent vaccine is confirmed as being highly effective vaccine and should greatly reduce the incidence of cervical cancer. The findings will need to be considered by cervical cancer prevention programmes worldwide.
Results 138 692 records were retrieved. Compared with unvaccinated women born in 1988, vaccinated women born in 1995 and 1996 showed an 89% reduction (95% confidence interval 81% to 94%) in prevalent cervical intraepithelial neoplasia (CIN) grade 3 or worse (from 0.59% (0.48% to 0.71%) to 0.06% (0.04% to 0.11%)), an 88% reduction (83% to 92%) in CIN grade 2 or worse (from 1.44% (1.28% to 1.63%) to 0.17% (0.12% to 0.24%)), and a 79% reduction (69% to 86%) in CIN grade 1 (from 0.69% (0.58% to 0.63%) to 0.15% (0.10% to 0.21%)). Younger age at immunisation was associated with increasing vaccine effectiveness: 86% (75% to 92%) for CIN grade 3 or worse for women vaccinated at age 12-13 compared with 51% (28% to 66%) for women vaccinated at age 17. Evidence of herd protection against high grade cervical disease was found in unvaccinated girls in the 1995 and 1996 cohorts.
In the present study, we report at a national, programme level and through linkage to screening records the effect of routine immunisation of girls aged 12-13 years with the bivalent HPV vaccine on levels of cytological abnormalities and cervical intraepithelial neoplasia (CIN). These findings supplement previous studies in Scotland and the Netherlands, which indicate that the bivalent vaccine will afford protection against most HPV related cervical cancers.
Recently we reported on the effect of the bivalent HPV vaccine on prevalence of HPV types in women who were immunised at age 12-13 years and attended for screening at age 20. 12 In the 1995 birth cohort (associated with 90% uptake of vaccine at age 13) a virtual eradication of infection related to HPV types 16 and 18 and a statistically significant reduction in cross protective types was observed. Furthermore, no evidence of replacement by other HPV types was evident and statistically significant herd protection in unvaccinated women was identified. Similar reductions have been reported in the Netherlands, where the bivalent vaccine is used. 13 The considerable reduction in the most carcinogenic HPV types clearly has implications for associated disease and the way it is managed clinically.
Up to and including 5 June 2016, women in Scotland were invited for cervical screening at age 20. Thereafter, they are screened from age 25. Women from the catch-up cohorts have been screened since 2010 and women from the routinely immunised cohorts have been screened since 2015. Scotland has comprehensive cervical screening data that contain a woman’s entire screening record, immunisation status, and unique personal identifier (community health index (CHI) number). We have been able to show the effectiveness of immunisation on various outcomes, including HPV prevalence, herd immunity, cervical disease, colposcopy outcomes, and uptake of cervical screening. This constitutes a comprehensive programme of immunisation surveillance. 6 7 8 9 10 11 12
In 2008, Scotland introduced a national immunisation programme against HPV using the bivalent vaccine, which was used until 2012. The immunisation programme was school based, targeted girls aged 12 and 13 (routine vaccination), and was supplemented with a three year catch-up programme to age 18. Uptake in the catch-up cohort was about 65% overall, but uptake in the routinely immunised cohorts has consistently exceeded 85%. 4 5
Cervical carcinoma is the fourth most common cancer in women and a major cause of morbidity and mortality worldwide. 1 In developed countries where organised cervical screening programmes have been implemented, the incidence and mortality from cervical cancer has decreased, although in many there is either no further diminution or even an increase in incidence. Many factors might contribute to these trends, including decreased uptake of screening, increased rates of human papillomavirus (HPV) infection, and changes in sexual behaviour. 2 3 Middle and lower income countries mostly do not have the resources to support organised screening, and cervical cancer remains a considerable problem. The development of vaccines against the most important oncogenic HPV types has the potential to be a major step in the prevention of cervical cancer.
There was no patient or public involvement in the design or analysis of this study. The records were anonymised before analysis, with preservation of linkage between immunisation, cytology, and histology when appropriate. Caldicott Guardian approval, a UK process to ensure that the use of personal data complies with legal requirements for data protection and is in the public interest, was obtained for the use of data. The data were generated through the routine activity of the Scottish cervical screening programme. Participation in the programme gives implied consent for the use of data derived from this participation for service monitoring and improvement. Management of individual patients is not affected by this study, and no individuals can be identified from the anonymised dataset used by the researchers.
Cytology was recorded as negative (no evidence of disease), borderline (including borderline glandular changes), and low, moderate, or severe grade dyskaryosis (including glandular abnormalities). Histology was coded as normal (no CIN detected), CIN grade 1, CIN grade 2, and CIN grade 3 or worse (glandular neoplasia or cancer). We categorised women not referred for colposcopy as having no CIN detected. Wilson’s method was used to calculate the confidence intervals for the percentages of women in the outcome groups. We used multivariate multinomial logistic regression models to explore the associations between cytology results, referral for colposcopy and histological diagnosis, and immunisation and demographic variables. Odds ratios for the cytological and histological outcomes are reported with 95% confidence intervals. Vaccine effectiveness for three doses compared with no doses was calculated as 100×(1−odds ratio), and for those fully vaccinated we estimated vaccine effectiveness separately by age at vaccination with reference to unvaccinated women in the pre-immunisation cohorts (born 1988-90). We used interaction tests to determine if the trend over time was the same between fully vaccinated and unvaccinated women. In addition to the number of doses of vaccine, we investigated the influence of birth cohort, Scottish index of multiple deprivation fifth, and the urban rural indicator on vaccine effectiveness. The pre-immunisation cohorts (born 1988-90) acted as the comparator group, although a small proportion of women born in 1990 were eligible for immunisation. Girls in the catch-up group (1991-94) are more likely to have been exposed to HPV before immunisation, whereas the routinely immunised group (1995-96) are considered more likely to be HPV naïve. We investigated herd protection by comparing the disease rates among unvaccinated women in the 1991-92, 1993-4, and 1995-96 cohorts with unvaccinated women in the 1989-90 cohort. The statistical analysis was carried out in R version 3.5.1 and SPSS version 21.
Schedule of immunisation, screening, and data collection. Only a few birth years in the 1990s were eligible. Girls born in 1994 not covered in first year of catch-up and immunised either side of 15th birthday, depending on date of birth. For first invitation to screening at age 20, women born in 1996 only eligible if date of birth was before 6 June. Data collated for all screening related events in first year of screening. Women born in 1996 had at least 15 months between initial invitation to screening and data extraction
For all cohorts we restricted the data to those who had cytology tests and colposcopy appointments at age 20. The results for most women corresponded to their first smear test or first colposcopy examination; for the few women with more than one smear test or biopsy in their first year of screening, we used the most severe result. We excluded records without a deprivation and rurality score from analysis. Although data on all screening events were extracted, for this analysis we only used data on attendance in the first year of eligibility, minimising bias resulting from differences in age at time of screening and opportunity for disease detection. Age at immunisation was calculated based on age at first vaccination. Figure 1 shows the relation between immunisation, year of first screen, and data extraction.
The Scottish Cervical Call-Recall System (SCCRS) is a national IT system, which contains comprehensive data relating to screening and acts as an active management tool. We interrogated SCCRS for screening data on all women born between 1 January 1988 and 5 June 1996 from the date of first eligibility for screening (age 20) to the date of data extraction (August 2017). Data extracted included CHI number, postcode of residence, date of birth, attendance, immunisation status, cytology result, colposcopy referral, and related histological diagnosis. The postcode of residence was used to derive the Scottish index of multiple deprivation fifth (where the first fifth represents the most deprived), and rurality index (derived from the Scottish government eight level indicator, with three levels: urban, accessible rural (30-60 minute drive to a settlement of ≥10 000), and remote rural (>60 minute drive to a settlement of ≥10 000)). Duplicate records for a woman are linked in SCCRS under the most recent CHI number, and personal data (including postcode) are updated daily from the Scottish national population register used throughout the Scottish school and healthcare systems.
Women are referred for colposcopy after one finding of high grade dyskaryosis or ASCH (atypical squamous cells, cannot rule out high grade squamous intraepithelial lesion), two findings of low grade dyskaryosis or three findings of borderline change during an episode of abnormal follow-up, or three abnormal results in the past 10 years. Women with low grade dyskaryosis or borderline changes are followed up with cytology at six months if not referred for colposcopy. Smear tests are repeated within three months if results are unsatisfactory, and women with three consecutive unsatisfactory results are referred for colposcopy. Ablation or excision is routinely carried out for CIN grade 2 or worse. Conservative management is the expected treatment for low grade disease. Scotland does not use HPV testing for the triage of low grade cytology.
Scotland has an organised, national cervical screening programme, which achieves about 70% uptake. 14 Up to and including 5 June 2016 women aged between 20 and 60 were eligible for screening and thereafter the age range changed to between 25 and 64, 364 days in line with the rest of the United Kingdom. Eligible women are screened every three years until age 50 and then every five years until age 65. Screening is extended for a further five years if needed to complete follow-up of screen detected abnormalities. Scotland uses Thinprep liquid based cytology with image assisted screening (ThinPrep Imaging System; Hologic, Marlborough, MA). Eight National Health Service cytology laboratories served the programme during the period reported and processed around 400 000 samples a year. Cytological and histological findings are classified according to British Association for Cytopathology and NHS cervical screening programme criteria. 15 16 Table 1 compares the three commonly used reporting systems.
Tables 2 and 3 show the number of women with one dose or two doses of vaccine and outcomes. Although reductions occurred in both cytological and histological outcomes with two doses, no statistically significant effect was seen for either one dose or two doses. The numbers were too small to allow analysis by year of birth.
Herd protection was observed for the unvaccinated women in the 1995-96 cohort, with a 63% reduction in the odds of CIN grade1 (11% to 85%), 67% reduction for CIN grade 2 (19% to 86%), and 100% (69% to 100%) reduction for CIN grade 3, compared with unvaccinated women in 1988-90. Similar reductions were noted for moderate dyskaryosis/HSIL-M (58%, 21% to 78%) and high grade dyskaryosis/HSIL-H (85%, 38% to 96%) but not for borderline/ASCUS or low grade dyskaryosis/LSIL ( table 4 ).
For fully immunised women, first vaccinated at age 12-13, vaccine effectiveness for CIN grade 1 was 78% (66% to 86%), for CIN grade 2 was 89% (81% to 94%), and for CIN grade 3 or worse was 86% (75% to 92%), compared with unvaccinated women in the 1988-90 cohorts. Vaccine effectiveness was lower for women first vaccinated at age 17: 41% (14% to 59%) for CIN grade 1, 56% (35% to 70%) for CIN grade 2, and 45% (17% to 64%) for CIN grade 3 or worse ( table 3 ).
CIN grade 1 decreased from 0.69% (0.58% to 0.63%) of women before immunisation (1988 cohort) to 0.15% (0.10% to 0.21%) overall for women born in 1995-96: a 79% (69% to 86%) reduction ( table 2 ). The trend over birth cohort was the same for fully immunised and unimmunised women (interaction test P=0.90), and there was no evidence that the rates differed between fully immunised and unimmunised women (P=0.17; fig 3 ).
High grade CIN showed a significant overall decline ( table 2 and fig 2 ). The rates of CIN grade 3 or worse decreased by 89% (81% to 94%), from a pre-immunisation rate of 0.59% (0.48% to 0.71%) in women born in 1988, to 0.06% (0.04% to 0.11%) in women born in 1995-96. CIN grade 2 or worse decreased by 88% (83% to 92%), from a pre-immunisation rate of 1.44% (1.28% to 1.63), to 0.17% (0.12% to 0.24%) in women born in 1995-96. No CIN grade 2 or worse (upper confidence limit 0.7%) was found in unvaccinated women in this age group (n=545). The decline in high grade CIN was steeper in fully vaccinated women (P=0.005 interaction test), but by the 1995-96 cohort, rates of high grade CIN were not significantly different between unvaccinated and vaccinated women (P=0.47) ( fig 3 ).
The overall rate of severe dyskaryosis or worse decreased from 0.75% (0.63% to 0.89%) for women born in 1988 to 0.06% (0.04% to 0.11%) for women born in 1995-96, and moderate dyskaryosis decreased from 1.18% (1.04% to 1.36%) to 0.27% (0.21% to 0.35%), representing reductions of 92% (85% to 95%) and 77% (69% to 83%), respectively ( table 2 ). Rates of severe and moderate dyskaryosis in unvaccinated compared with fully vaccinated women born in 1995 and 1996 were not significantly different ( fig 2 ). Overall, borderline/ASCUS rates declined by 34% (30% to 39%), with a similar trend over the cohort in vaccinated and unvaccinated women (interaction test P=0.11), although the rate was lower in vaccinated women (15%, 11% to 19%). The reporting of low grade dyskaryosis/LSIL increased during the period of observation. The trend with birth cohort was the same for vaccinated and unvaccinated women (interaction test P=0.17); vaccinated women had 19% (14% to 24%) lower rates ( table 2 and fig 2 ).
Tables 3 and 4 show the adjusted odds ratios for cytological and histological outcomes by immunisation status and age at which the first dose was administered and by year of birth in unvaccinated women, respectively. Figures 2 and 3 show the trends in cytological abnormalities and histologically confirmed CIN by percentage of the screened population stratified by no or complete immunisation.
In total, 138 692 women born between 1 January 1988 and 5 June 1996 had a smear test result recorded at age 20. Table 2 and supplementary table 1 show the distribution of the records by year of birth and immunisation status. Three groups are identified, broadly corresponding to unvaccinated women (born 1988-90, age 18-20 in 2008), women vaccinated during the catch-up programme (born 1991-94, age 14-17 at vaccination), and women routinely vaccinated (born 1995-96, age 12-13 at vaccination). Cumulatively within the extract, 64 026 women were unvaccinated and 68 480 had three doses of vaccine (fully vaccinated). Only 2051 women received one dose and 4135 women received two doses. The number of women born in 1996 in the dataset is less than in other years as only those born before 6 June were eligible for screening because of changes to the age range for the screening programme. The number of women who had their first dose at age 14 is lower than in other years because of the phasing of the catch-up programme ( fig 1 ).
Discussion
This study reports statistically significant reductions in all grades of cervical intraepithelial neoplasia (CIN), equating to vaccine effectiveness estimates of 80% or greater after routine immunisation at age 12-13 years. The prevalence of high grade dyskaryosis was similarly reduced. Herd protection has been shown in unvaccinated women in the cohort offered routine immunisation. The changes in cytological abnormality and histologically confirmed cervical disease in women attending for their first cervical screen aged 20 associated with routine vaccination at age 12-13 years with the bivalent human papillomavirus (HPV) vaccine in a setting that offered both a catch-up programme and that achieved high and consistent uptake. The results of this study were derived from data that directly link immunisation status and screening outcome at the level of the individual. We are confident that the reduction in disease does not relate to the inability of cytological screening to detect disease in vaccinated women, given previous data on cytology performance that showed no loss of sensitivity in vaccinated compared with unvaccinated women, and the deterioration in the clinical significance or positive predictive value of cytologically defined low grade disease described elsewhere.5
The increase in reporting of low grade dyskaryosis/LSIL in immunised women was statistically significant, in contrast with the reduction in all other cytological categories and all grades of CIN. Scottish surveillance data indicate that vaccine types and cross protected types (HPV 16, 18, 31, 33, and 45) are found in a higher proportion of samples with borderline/ASCUS cytology than in samples with low grade dyskaryosis/LSIL cytology and this could, in part, explain this observation. The human papillomavirus (HPV) types that remain after immunisation might not be associated with persistent disease. The cytological differential diagnosis of borderline/ASCUS changes is often moderate dykaryosis/HSIL rather than low grade dyskaryosis/LSIL (cases of borderline, atypical squamous cells, cannot rule out high grade squamous intraepithelial lesion (ASCH) are reported but not recorded separately). Also, changes have occurred in the classification of HPV related cytological changes, and the management of CIN grade 1 or less at colposcopy that will have affected the relation between low grade cytology and a diagnosis of CIN grade 1.
Strengths and limitations of this study The strengths of this study include direct linkage of data between immunisation status and screening outcomes, and that the data are from the screened population rather than a selected cohort. The completeness of the screening database and the longstanding, organised nature of the surveillance programme means that it is possible to show trends and to examine their correlation to several variables. The data therefore form a sound basis for development of cervical cancer prevention strategies. This study has limitations. The analysis was confined to women attending for cervical screening at age 20. Uptake of screening in fully vaccinated women aged 20 or 21 is 51%, and only 23% in unvaccinated women.1418 It is possible therefore that vaccine effectiveness was over-estimated. However, the high uptake of vaccination, similarity in distribution of HPV type in attenders and non-attenders, and appearance of herd protection give reassurance that the observations can be extrapolated to the general population.19 The shorter follow-up time for women born in 1995 and 1996 necessarily affects the robustness of the estimation of vaccine effectiveness for younger women; however, further planned longitudinal studies will help elucidate true protection from the effects of routine vaccination. The formal adoption of a conservative management protocol for women with CIN grade 1 at colposcopy over the study period could have affected the numbers of biopsies carried out. However, it is unlikely that this change in practice accounted for the magnitude of the reductions in CIN grade 1, particularly when considered along with the reductions in CIN grades 2 and 3, for which there were no changes in clinical management or treatment over the study period. CIN grade 3 is now considered the best predictor of risk of invasive cancer, but a proportion will still regress. It is known that the likelihood of developing CIN grade 3 varies with the HPV genotype and is highest with HPV types 16, 31, and 33.20 The propensity for the CIN to regress is also related to the HPV type, and there are fewer cancers attributable to HPV type 33 than would be expected from the prevalence of this genotype in CIN grade 3 lesions.21 As the most oncogenic types have been effectively removed from the population it might be that regression of CIN grade 3 is more likely in vaccinated women, increasing vaccine effect on rates of CIN grade 3. Another unavoidable limitation of high compliance with full vaccine schedules is the inability to assess the impact of fewer than three doses. The characteristics of partially immunised women in Scotland have been described previously.5 Briefly, partial immunisation was associated with increased deprivation, having left school, and increasing age. In girls offered routine, in-school vaccination, only 1.6% were partially immunised compared with 9.8% in the first full year of catch-up.
Comparison with other studies These results are the clinical counterpart of the reductions in type specific HPV infection shown in routinely vaccinated women.12 Kavanagh and colleagues showed statistically significant vaccine effectiveness against HPV types 16 and 18 (90%) and cross protective HPV types (80-85%), with cross protection lasting a minimum of seven years. Herd protection against HPV 16 and 18 related infection was also found in unvaccinated women in the routine vaccination cohort. The reduction of CIN grade 3 and the estimates of vaccine effectiveness reported are of a similar magnitude to those reported by Kavanagh and colleagues for HPV infection.12 The vaccine specific and cross protected HPV types covered by the vaccine (HPV 16, 18, 31, 33, and 45) are implicated in 90% of cancers in Scotland.22 CIN grade 3 is the precursor of invasive cervical carcinoma, with the least diagnostic variability and lowest rate of spontaneous regression, and it is recognised as the best indicator of the risk of invasive cancer.232425 It is therefore reasonable to expect that the reduction in CIN grade 3 will lead to a reduction in cervical cancer in future years. The anticipated impact of immunisation on cancer will take more time to become apparent. A recent Cochrane review of the effectiveness of bivalent and quadrivalent HPV vaccination in randomised trials has shown unequivocal, high quality evidence of the benefits of immunisation.26 Our results are in keeping with this review. Population studies in other settings have shown a major impact of the quadrivalent vaccine on infection and associated benign and neoplastic disease.2728293031323334 The present work complements these studies in being the first to report on the impact of the bivalent vaccine on disease when delivered to girls aged 12-13 years within a national programme. It will now be of interest to see the impact of the nonavalent vaccine at the population level. It is postulated that the nonavalent vaccine will protect against 90% of cervical cancers globally.35 However, worthwhile additional protection against cancer because of the nonavalent vaccine will be difficult to show in Scotland, given the distribution of HPV types in the UK, the effect of the bivalent vaccine, and the absence of type replacement to date, although the effect on genital warts is clear.27 The Scottish cervical screening programme is incorporating HPV immunisation into its routine programme monitoring statistics. This, along with the projected move to HPV primary screening, will facilitate the monitoring of changes in vaccine effectiveness in the future.
Policy implications Low levels of cervical cancer after routine vaccination clearly have ramifications for screening vaccinated women. Although major disease is reduced in Scotland, it has not been eradicated, and continued screening is therefore necessary, particularly as for some years most women within the screening programme will not have been vaccinated. Previous work has suggested that the performance of cytology based and HPV based screening deteriorates in vaccinated women, despite preservation of sensitivity.78 This can be attributed to reduced disease levels leading to a higher number of false positive test results and a lower positive predictive value for important disease. The effectiveness of HPV primary screening in highly immunised populations will need close monitoring. Novel methods for improving uptake of screening, the effectiveness of the screening and, crucially, the triage test will be needed to maintain the performance of cervical screening as a process. The reduced rate of disease in those referred for colposcopy will likewise make the maintenance of colposcopy standards challenging.1011 Different modelling approaches have been used to inform optimal scenarios for screening of vaccinated women but have converged on the conclusion that, for some women, two or three screens in a lifetime using HPV testing might be sufficient.3637 Such sporadic screening, coupled with much reduced disease and decreasing numbers of women referred for colposcopy and treatment, necessitates redesign of cervical screening programmes. Ultimately, the clinical and economic rationale for cervical screening will need to be reviewed.

Story 121
Verhalten gute Nachrichten von Formel-2-Pilot Juan Manuel Correa. Wie seine Familie in einem Statement mitteilte, ist der 20-Jährige inzwischen wieder bei vollem Bewusstsein und wurde in eine orthopädische Spezialklinik in London verlegt.
Allerdings steht dem US-Ekuadorianer der schwerste Kampf noch bevor. Denn bislang konnten die Ärzte die schweren Beinverletzungen Correas noch nicht behandeln, weil die Regeneration der Lunge oberste Priorität hatte. Correa musste im Koma zunächst künstlich beatmet werden, sein Zustand war lange Zeit kritisch.
Nachdem die Regeneration der Lunge schneller und besser als erwartet verlief, kämpft Correa nun gegen die Verletzungen an seinem rechten Bein. Der Nachwuchsrennfahrer entschied sich gegen eine Amputation und lässt sich am Sonntag einer mehr als zehnstündigen Operation unterziehen.
Erstmals seit dem Unfall haben die Ärzte vollständigen Zugang zu den Verletzungen am rechten Unterschenkel. Bei der Operation werden sich die Spezialisten zunächst ein genaues Bild vom Zustand des Schienbeins, des Sprunggelenks und des Fußes machen. "Sie werden retten, was zu retten ist und entfernen, was entfernt werden muss", heißt es in dem Statement.
Correa war im Rahmen des Belgien GP im Hauptrennen der Formel 2 schwer verunfallt. Der 20-Jährige fuhr fast ungebremst in das Auto des Franzosen Anthoine Hubert, der noch in Spa in Folge des Unfalls verstarb.

Story 122
Cannabis plants growing in a greenhouse in Quebec, Canada. The drug is legal for both recreational and medical purposes throughout the country Chris Roussakis/Bloomberg via Getty Images
“I think that we’ve opened a Pandora's box,” Dame Sally Davies, the chief medical officer for England, told a parliamentary committee on medical cannabis earlier this month. Stressing how little is known about the health benefits of marijuana, Davies warned of its potential dangers. And she isn’t alone in her concerns.
Since legislation was introduced by home secretary Sajid Javid in November 2018, only a token few NHS doctors have prescribed cannabis to patients, despite the high demand from advocacy groups.
Advertisement
In this cannabis vacuum, private clinics could be the country’s first major legal dealers. Costing £200 for an appointment and between £600 and £700 a month for a prescription, these clinics, the first of which opened in Greater Manchester earlier this month, look set to supply the budding patients left wanting by the NHS.
So is the NHS withholding valuable medicine, or are the private clinics distributing dangerous drugs? “There is a belief that cannabis works for many conditions,” says Davies. “Meanwhile, what is the impact of taking it for a prolonged period of time? We know [THC, a cannabis chemical] has an impact on the brain and causes depression, schizophrenia, brain development problems in young and adolescence. If a pregnant mother was taking it, I'd be very worried.”
Read next Can you trip on music alone? This psychedelic startup thinks so Can you trip on music alone? This psychedelic startup thinks so
THC, short for tetrahydrocannabinol, is the main psychoactive compound in cannabis. When consumed, it binds to the brain’s cannabinoid receptors, associated with memory, coordination, and time perception, causing a high. The feeling is enticing enough to make cannabis the most commonly used illicit substance around the world. But research shows that prolonged consumption can have some less-than dope effects. One recent study linked high-THC cannabis varieties with psychosis and even estimated that half of first-time psychotic disorders cases in Amsterdam could be avoided if the potent drug wasn’t available.
But studies such as these are often based on recreational, ‘street’ varieties, which have been pushed to high-THC potencies by prohibition and consumer demand. Medical cannabis is instead high in CBD, the ‘miracle molecule’ that’s been hailed by many users as a cure for everything from chronic pain to cancer. Despite being a legal medicine in multiple countries, the claims associated with CBD can lead many to question its true benefits.
Advertisement
“There is considerable evidence of usefulness in chronic pain, epilepsy, sickness during chemotherapy, as well for anxiety, PTSD, and sleep,” says Mike Barnes, a neurologist. He is also the clinical director of the new specialist cannabis clinics and gave evidence at the recent parliamentary debate, urging the panel to take heed of CBD’s existing evidence base.
“Cannabis can be a good remedy for many conditions like fibromyalgia, appetite stimulation, Crohn's disease, and cancer,” he says. “Sure, we need more evidence of exactly what type of cannabis, in what dose and what format serves each condition best, but there is enough evidence for their doctor to seriously consider a prescription. If that doctor will not prescribe, then they should seek a cannabis expert to assist.”
While more evidence is needed to properly convince the NHS, there is still a large stack of studies to back up Barnes’ claims. Among many revelations, research has shown how cannabis can help reducemethamphetamine addiction, remedy anxiety, suppress inflammation, treat autism spectrum disorder, and even increase sperm counts.
Read next What is microdosing and does it make you smarter? WIRED Explains What is microdosing and does it make you smarter? WIRED Explains
It also seems to help with epileptic conditions. After all, it was the plights of two boys with severe epilepsy that kick-started the UK’s cannabis conversation last summer. And after being temporarily granted the medication, the children’s seizures reportedly went down from 150 a month to zero.
Advertisement
Certain CBD studies have also been shown to trigger unwanted side effects, such as decreased appetite and diarrhoea. But when bombarded with examples where it does help, it’s almost no wonder that medical cannabis advocates can get frustrated with the reticence of the NHS.
“Davis said that we have to wait three or four years before that kind of high-quality data is with us. How do you explain it to a parent?” says Peter Carroll, founder of the End Our Pain, a campaign to broaden medical cannabis access to children with epilepsy. Speaking alongside Professor Barnes, Carroll confronted the parliamentary panel with a story of a mother who illegally purchased cannabis products to treat her child. “The child has improved dramatically,” he stated. “So that's her random controlled trial. And her own local doctors in the NHS have said, ‘we see the improvement’, and then they say, ‘but we're not going to prescribe it’.”
“I think that we have to take a broader view of the evidence here because there is a point where multiple anecdotal stories do actually build on to a pattern of evidence,” he continued. “And it seems absurd to me that we have to wait three, four or five years on these trials to be produced when there are actually real-life cases now.”
The randomised controlled trials Carroll mentions are the gold-standard for clinical drug testing. In such trials, two groups are studied, one supplied the drug, the other a placebo, with no one knowing which they’ve been given. But any resulting drug can take years to become available.

“You’ve got consider what's happening in the context of the NHS, the culture of the NHS, the revered nature of the NHS,” says Steve Moore, who helps run the Centre for Medical Cannabis, a think tank with the aim of escalating cannabis clinical trials. “People are asking for things quickly at the moment, but I think what they need to realise is that it will work at the pace of the NHS.” Last summer, Moore directed the campaign to grant Billy Caldwell, one of the boys living with epilepsy, his cannabis oil.
Read next Inside the first placebo-controlled studies testing if microdosing LSD actually works Inside the first placebo-controlled studies testing if microdosing LSD actually works
While these trails get underway, those with means may opt out of the state structure and sign up to the private clinics, two more of which are planned to open in Birmingham and London later this year. Others will undoubtedly continue to source cannabis from the black market.
“I really hope we can do the trials,” said Davies as she concluded her parliament testimony. “Because without those, how can we help the patients? And that's what we’re all here for.”
More great stories from WIRED
– The games industry should be worried about Google Stadia
– How the petition to revoke Article 50 went viral
Advertisement
– I tried to keep my baby secret from Facebook and Google
– Care about online privacy? Then change your phone number

Story 123
A Volocopter looks like a drone on steroids. It’s a sleek machine with 18 rotors and two seats -- either for a pilot and a passenger, or for two travelers in remote-controlled or autonomous flight mode.
Stuttgart: The volocopter , an electrically powered air taxi, flew for the first time over Stuttgart in Germany on Saturday. This was its first public test flight in a European city, according to the manufacturer.Volocopter GmbH, a German startup backed by Intel Corp . and Daimler AG , has built the drone-like electric helicopter to ferry travelers across city skies. The company expects to offer its first commercial trips in the next three to five years. It’s now seeking at least $100 million to gear up manufacturing of the flying taxis. The aircraft will be booked by a mobile app.A Volocopter looks like a drone on steroids. It’s a sleek machine with 18 rotors and two seats -- either for a pilot and a passenger, or for two travelers in remote-controlled or autonomous flight mode. The company claims the drones are so quiet that you can’t hear them over city noise from 100 meters away.Volocopter plans to build a four-seater and is open to autonomously transport parcels, which its product could do with "very few modifications," Reuter said. With more scale, there’s no reason why production of a Volocopter should cost more than an upscale taxi, for example a Mercedes-Benz E class, the CEO said.Last week, Volocopter developer said it had raised 50 million euros ($55.1 million) from investors including automaker Geely, risking a revived debate about Chinese investments in EU firms. "The new funds will be used towards bringing the VoloCity aircraft to commercial launch within the next three years," Volocopter said in a statement.

Story 124
It took Virginia three overtimes in two games just to advance to the national championship game, but they only needed 60 to capture the crown with a 13-9 win over Yale.
The win gave the Cavaliers their first title since 2011, and their sixth overall.
UVA advanced to the championship game thanks to a double overtime game-winner from Ian Laviano against ACC rival Duke. The Cavs won the back-and-forth affair 13-12.
SHOP OFFICIAL VIRGINIA MEN'S LACROSSE 2019 CHAMPIONSHIP GEAR
Below is everything you may have missed from the final moments.
2019 NCAA men's lacrosse tournament bracket
Click here for an interactive bracket.
2019 NCAA Men's Lacrosse Tournament: Schedule, scores, live updates
National Championship — Monday, May 27
at Lincoln Financial Field in Philadelphia
Virginia 13, Yale 9
Semifinals — Saturday, May 25
Games at Lincoln Financial Field in Philadelphia
No. 3 Virginia 13, No. 2 Duke 12
No. 5 Yale 21, No. 1 Penn State 17
You can listen to Westwood One / NCAA Radio Network here.
Opening Round — Wednesday, May 8
UMBC 14, Marist 8
First Round — Saturday, May 11
No. 8 Loyola Maryland 15, Syracuse 13
No. 5 Yale 19, Georgetown 16
No. 4 Penn 13, Army 8
No. 3 Virginia 19, Robert Morris 10
First Round — Sunday, May 12
No. 1 Penn State 25, UMBC 10
Maryland 14, No. 6 Towson 13
No. 2 Duke 12, Richmond 11
No. 7 Notre Dame 16, Johns Hopkins 9
Quarterfinals — Saturday, May 18
Games at James M. Shuart Stadium in Hempstead, N.Y.
No. 3 Virginia 13, Maryland 12 (OT)
No. 2 Duke 14, No. 7 Notre Dame 13 (OT)
Duke advances past Notre Dame
Quarterfinals — Sunday, May 19
Games at Rentschler Field in East Hartford, Conn.
No. 1 Penn State 21, No. 8 Loyola Maryland 14
No. 5 Yale 19, No. 4 Penn 18
Yale survives Penn in OT classic
Sunday, May 5 — Selection Show
— Selection Show Wednesday, May 8 — Opening Round
— Opening Round Saturday, May 11 and Sunday, May 12 — First Round
— First Round Saturday, May 18 and Sunday, May 19 — Quarterfinals
— Quarterfinals Saturday, May 25 — Semifinals
— Semifinals Monday, May 27 — National Championship
NCAA Lacrosse: Track automatic qualifiers
2019 NCAA Men's Lacrosse Tournament: Teams, seeds
Nine teams are eligible for automatic bid consideration. However, only eight will make the final field of 16, as the last two AQs will play in the Opening Round.
CONFERENCE WINNER America East UMBC Big East Georgetown Big Ten Penn State CAA Towson Ivy League Penn MAAC Marist Patriot League Army Northeast Robert Morris Southern Richmond
Seeds:
Penn State: 14-1 Duke: 11-4 Virginia: 13-3 Penn: 11-3 Yale: 12-3 Towson: 11-4 Notre Dame: 8-6 Loyola Maryland: 11-4
RANKINGS: The Top 25 for men's lacrosse
NCAA men's lacrosse tournament: Champions, history
YEAR CHAMPION COACH SCORE RUNNER-UP HOST OR SITE 2018 Yale (17-3) Andy Shay 13-11 Duke Foxborough, Mass. 2017 Maryland (16-3) John Tillman 9-6 Ohio State Foxborough, Mass. 2016 North Carolina (12-6) Joe Breschi 14-13 (ot) Maryland Philadelphia 2015 Denver (17-2) Bill Tierney 10-5 Maryland Philadelphia 2014 Duke (17-3) John Danowski 11-9 Notre Dame Baltimore 2013 Duke (16-5) John Danowski 16-10 Syracuse Philadelphia 2012 Loyola (Md.) (18-1) Charley Toomey 9-3 Maryland Foxborough, Mass. 2011 Virginia (13-5) Dom Starsia 9-7 Maryland Baltimore 2010 Duke (16-4) John Danowski 6-5 (ot) Notre Dame Baltimore 2009 Syracuse (16-2) John Desko 10-9 (ot) Cornell Boston 2008 Syracuse (16-2) John Desko 13-10 Johns Hopkins Boston 2007 Johns Hopkins (13-4) Dave Pietramala 12-11 Duke Baltimore 2006 Virginia (17-0) Dom Starsia 15-7 Massachusetts Philadelphia 2005 Johns Hopkins (16-0) Dave Pietramala 9-8 Duke Philadelphia 2004 Syracuse (15-2) John Desko 14-13 Navy Baltimore 2003 Virginia (15-2) Dom Starsia 9-7 Johns Hopkins Baltimore 2002 Syracuse (15-2) John Desko 13-12 Princeton Rutgers 2001 Princeton (14-1) Bill Tierney 10-9 (ot) Syracuse Rutgers 2000 Syracuse (15-1) John Desko 13-7 Princeton Maryland 1999 Virginia (13-3) Dom Starsia 12-10 Syracuse Maryland 1998 Princeton (14-1) Bill Tierney 15-5 Maryland Rutgers 1997 Princeton (16-0) Bill Tierney 19-7 Maryland Maryland 1996 Princeton (14-1) Bill Tierney 13-12 (ot) Virginia Maryland 1995 Syracuse (13-2) Roy Simmons Jr. 13-9 Maryland Maryland 1994 Princeton (14-1) Bill Tierney 9-8 (ot) Virginia Maryland 1993 Syracuse (12-2) Roy Simmons Jr. 13-12 North Carolina Maryland 1992 Princeton (13-2) Bill Tierney 10-9 (2ot) Syracuse Penn 1991 North Carolina (16-0) Dave Klarmann 18-13 Towson Syracuse 1990 Syracuse* (13-0) Roy Simmons Jr. 21-9 Loyola Maryland Rutgers 1989 Syracuse (14-1) Roy Simmons Jr. 13-12 Johns Hopkins Maryland 1988 Syracuse (15-0) Roy Simmons Jr. 13-8 Cornell Syracuse 1987 Johns Hopkins (10-3) Don Zimmerman 11-10 Cornell Rutgers 1986 North Carolina (11-3) Willie Scroggs 10-9 (ot) Virginia Delaware 1985 Johns Hopkins (13-1) Don Zimmerman 11-4 Syracuse Brown 1984 Johns Hopkins (14-0) Don Zimmerman 13-10 Syracuse Delaware 1983 Syracuse (14-1) Roy Simmons Jr. 17-16 Johns Hopkins Rutgers 1982 North Carolina (14-0) Willie Scroggs 7-5 Johns Hopkins Virginia 1981 North Carolina (12-0) Willie Scroggs 14-13 Johns Hopkins Princeton 1980 Johns Hopkins (14-1) Henry Ciccarone 9-8 (2ot) Virginia Cornell 1979 Johns Hopkins (13-0) Henry Ciccarone 15-9 Maryland Maryland 1978 Johns Hopkins (13-1) Henry Ciccarone 13-8 Cornell Rutgers 1977 Cornell (13-0) Richie Moran 16-8 Johns Hopkins Virginia 1976 Cornell (16-0) Richie Moran 16-13 (ot) Maryland Brown 1975 Maryland (11-3) Bud Beardmore 20-13 Navy Johns Hopkins 1974 Johns Hopkins (12-2) Bob Scott 17-12 Maryland Rutgers 1973 Maryland (14-1) Bud Beardmore 10-9 (2ot) Johns Hopkins Penn 1972 Virginia (11-4) Glenn Thiel 13-12 Johns Hopkins Maryland 1971 Cornell (13-1) Richie Moran 12-6 Maryland Hofstra
*After the 1990 championship, the NCAA Committee on Infractions determined that Paul Gait had played in the 1990 championship while ineligible. Under NCAA rules, Syracuse and Paul Gait's records for that championship were vacated. The NCAA does not recognize Syracuse and coach Roy Simmons Jr.'s 3-0 record, and Paul Gait's 7 goals, 7 assists and his participation in that championship.

Story 125
The winner of the 2019 PGA Championship at Bethpage Black will receive nearly $2 million. The total purse for this year is $11 million.
Last year, Brooks Koepka won the Wanamaker Trophy and took home $1,980,000 by shooting 16-under. Tiger Woods finished in second at 14-under and earned $1,188,000. Adam Scott placed third (13-under) and won $748,000.
2019 PGA Championship: Prize and purse money
The winner will earn almost $2 million: $1,980,000. The purse is $11 million. Both totals are the same as in 2018, when Brooks Koepka won at Bellerive Country Club.
PGA CHAMPIONSHIP 2019: Leaderboard | Tee Times | Highlights | How to watch | Course Tour
Players making the cut but finishing below 70th will be paid in diminishing increments of $100 each ($19,500; $19,400, etc.). Players missing the cut and finishing 36 holes will get $3,100 each. Any player who makes the cut but doesn't submit at 72-hole score will also receive $3,100.
SHOP: Check out the latest 2019 PGA Championship gear
2019 PGA Championship: Prize and purse money
Place | Amount
1st | $1,980,000
2nd | $1,188,000
3rd | $748,000
4th | $528,000
5th | $450,500
6th | $380,000
7th | $343,650
8th | $319,600
9th | $295,600
10th | $272,380
11th | $251,590
12th | $242,400
13th | $214,800
14th | $199,050
15th | $184,280
16th | $170,700
17th | $161,000
18th | $152,000
19th | $143,000
20th | $134,000
21st | $125,000
22nd | $116,000
23rd | $107,000
24th | $100,000
25th | $93,000
26th | $87,000
27th | $82,000
28th | $77,000
29th | $74,000
30th | $71,000
31st | $68,000
32nd | $65,000
33rd | $62,000
34th | $59,000
35th | $56,000
36th | $53,000
37th | $50,000
38th | $48,000
39th | $46,000
40th | $44,000
41st | $42,000
42nd | $40,000
43rd | $38,000
44th | $36,000
45th | $34,000
46th | $32,000
47th | $30,250
48th | $28,500
49th | $27,500
50th | $26,500
51st | $25,500
52nd | $25,000
53rd | $24,500
54th | $24,000
55th | $23,500
56th | $23,000
57th | $22,500
58th | $22,200
59th | $21,900
60th | $21,600
61st | $21,400
62nd | $21,200
63rd | $21,000
64th | $20,800
65th | $20,600
66th | $20,400
67th | $20,200
68th | $20,000
69th | $19,800
70th | $19,600
How to watch the 2019 PGA Championship
The Championship will broadcast live on both TNT & CBS.
First Round, Thursday, May 16
TNT: 1:00 – 7:00 p.m.
Second Round, Friday, May 17
TNT 1:00 – 7:30 p.m.
Third Round, Saturday, May 18
TNT: 11:00 a.m. – 2:00 p.m.
CBS: 2:00 - 7:00 p.m.
Fourth Round, Sunday, May 19
TNT: 11:00 a.m. – 2:00 p.m.
CBS: 2:00 - 7:00 p.m.
You can also stream the tournament live here.
2019 PGA Championship: Field list, players
Find the complete 101st PGA Championship field list here.
2019 PGA Championship: Winners, history
5 Championships: Walter Hagen 1921, 1924, 1925, 1926, 1927 and Jack Nicklaus 1963, 1971, 1973, 1975, 1980
4 Championships: Tiger Woods 1999, 2000, 2006, 2007
3 Championships: Gene Sarazen 1922, 1923, 1933 and Sam Snead 1942, 1949, 1951
2 Championships: Jim Barnes 1916, 1919
Leo Diegel 1928, 1929
Paul Runyan 1934, 1938
Denny Shute 1936, 1937
Byron Nelson 1940, 1945
Ben Hogan 1946, 1948
Gary Player 1962, 1972
Raymond Floyd 1969, 1982
Dave Stockton 1970, 1976
Lee Trevino 1974, 1984
Larry Nelson 1981, 1987
Nick Price 1992, 1994
Vijay Singh 1998, 2004
Rory McIlroy 2012, 2014
1 Championship (50) Jock Hutchison 1920
Tommy Armour 1930
Tom Creavy 1931
Olin Dutra 1932
Johnny Revolta 1935
Henry Picard 1939
Vic Ghezzi 1942
Bob Hamilton 1944
Jim Ferrier 1947
Chandler Harper 1950
Jim Turnesa 1952
Walter Burkemo 1953
Chick Harbert 1954
Doug Ford 1955
Jack Burke Jr. 1956
Lionel Hebert 1957
Dow Finsterwald 1958
Bob Rosburg 1959
Jay Hebert 1960
Jerry Barber 1961
Bobby Nichols 1964
Dave Marr 1965
Al Geiberger 1966
Don January 1967
Julius Boros 1968
Lanny Wadkins 1977
John Mahaffey 1978
David Graham 1979
Hal Sutton 1983
Hubert Green 1985
Bob Tway 1986
Jeff Sluman 1988
Payne Stewart 1989
Wayne Grady 1990
John Daly 1991
Paul Azinger 1993
Steve Elkington 1995
Mark Brooks 1996
Davis Love III 1997
David Toms 2001
Rich Beem 2002
Shaun Micheel 2003
Phil Mickelson 2005
Padraig Harrington 2008
Y.E. Yang 2009
Martin Kaymer 2010
Keegan Bradley 2011
Jason Dufner 2013
Jason Day 2015
Jimmy Walker 2016
Justin Thomas 2017
Brooks Koepka 2018

Story 126
News, Infos und Statistiken vor und nach dem 28. Rennen in Richmond. Martin Truex Junior gewinnt auch das 2. Playoff-Rennen der Round of 16 unter Flutlicht.
RACE CENTER: Richmond Raceway
62nd Annual Federated Auto Parts 400
Rennen 28/36 (Round of 16: Playoff-Rennen 2/10)
Nächster LIVE-Termin
Freitag, 27. September von 18:05 bis 18:55 Uhr MESZ:
Charlotte Motor Speedway Road Course
Practice 1
Hier geht es zum nächsten Rennen:
Montag, 23. September 2019
POST RACE REPORT Richmond: Martin Truex Junior gewinnt auch das 2. Playoff-Nachtrennen
Martin Truex Junior holt sechten Saisonsieg LAT Images
Der 28. Saisonlauf und das zweite Playoff-Rennen der 'Round of 16' endete nach 400 Runden mit einem Sieg von Martin Truex Junior, der damit auch das zweite Playoff-Rennen gewinnen konnte. Es war gleichzeitig der sechste Saisonsieg und der 25. Jubiläums-Sieg für Truex, der zum zweiten Mal in Folge in dieser Saison den Short-Track in Virginia bezwingen konnte. Kyle Busch mit den meisten Führungsrunden, Denny Hamlin und Erik Jones sorgten für den vierfachen Gibbs-Erfolg.
Aber einige Stunden nach dem Rennen war der 1-2-3-4-Sieg Geschichte, denn Jones wurde disqualifiziert. Sein Gibbs-Toyota fiel bei der technischen Laser-Nachkontrolle durch. Die Ausrichtung der Hinterräder wurde beanstandet und sorgte für einen Abzug von 41 Punkten. Jones verlor nicht nur die 33 Punkte für Rang vier, sondern auch neun Bonuspunkte für den neunten und vierten Platz in den beiden ersten Stages. Damit blieb nur ein winziger Punkt für den letzten Platz übrig.
Dadurch wurde Polesetter Brad Keselowski auf Rang vier gewertet. Nur Truex, Kyle Busch und Keselowski teilten sich die 400 Führungsrunden. Damit wurde der Rekord aus dem März-Rennen in Martinsville eingestellt. Bereits zum achten Mal spulte Kyle Busch die meisten Führungsrunden ab und erzielte zum 22. Mal ein Top-10-Resultat in diesem Jahr. Er löste mit insgesamt 7.790 Führungsrunden Truex an der Spitze dieser Wertung ab. Ryan Newman steigert sich weiter und erzielte mit Platz fünf das beste Saisonresultat und das dritte Top-10-Ergebnis in Folge.
Der Sechste Kyle Larson ist momentan mit sieben Top-8-Resultaten in den letzten acht Rennen der konstanteste Fahrer. Das trifft auch auf Kevin Harvick zu, der mit Platz sieben zum achten Mal in den letzten neun Rennen in den Top-7 über die Ziellinie fuhr. Mit Clint Bowyer wurden die ersten acht Plätze nur an Playoff-Teilnehmer vergeben. Außerdem landeten Daniel Suarez in seinem 100. Cup-Rennen und Jimmie Johnson in den Top-10. Zum fünften Mal war Matt Tifft der bestplatzierte Rookie in dieser Saison. Toyota sammelt mit Joe Gibbs Racing weiter Rekorde und verbuchte den 15. Hersteller-Sieg.
Außer Truex konnten sich nach dem korrigierten Zieleinlauf Harvick und Kyle Busch durch die erreichten Gesamtpunkte vorzeitig für die 'Round of 12' qualifizieren. Zwischen Rang neun und 15 wird in Charlotte um jede Platzierung und um jeden Bonuspunkt gekämpft werden. Nur Jones liegt mit 45 Punkte Rückstand fast aussichtslos zurück.
Statistiken zum 28. Saisonrennen:
Runden & Renndauer:
400 (100/100/200) Runden (300 Meilen), 2:57:27 Stunden
Sieger:
Martin Truex Jr. (6. Sieg 2019, 2. Richmond-Sieg, 25. Karriere-Sieg)
Stage-Siege 2019:
Stage 1: Martin Truex Jr. (5. Stage-Sieg)
Stage 2: Kyle Busch (11. Stage-Sieg)
Führungsrunden:
Kyle Busch (202/400 Runden)
Pole Award:
Brad Keselowski (3. Pole 2019, 2. Richmond-Pole, 17. Karriere-Pole)
Rennunterbrechungen:
5 (32 Runden), Rekord 2019: 16 (Charlotte)
Führungswechsel:
6 (3 Fahrer), Rekord 2019: 37 (Talladega)
Bester Rookie:
Matt Tifft (Platz 20)
Gesamtstand Rookie-Wertung:
1. Daniel Hemric, 405 Punkte
2. Ryan Preece, 371 Punkte
3. Matt Tifft, 292 Punkte
Gesamtstand Hersteller-Wertung:
1. Toyota, 1.028 Punkte (15 Siege)
2. Ford, 991 Punkte (8 Siege)
3. Chevrolet, 947 Punkte (5 Siege)
Gesamtstand 28/36
Neuer Zwischenstand nach dem 2. Playoff-Rennen
Round of 16
1. (1) #19 Martin Truex Jr. (2 Siege), 2.141 Punkte
2. (2) #4 Kevin Harvick, 2.120 Punkte
3. (4) #18 Kyle Busch, 2.117 Punkte
- - -
4. (5) #2 Brad Keselowski, 2.106 Punkte (+55 Punkte)
5. (7) #11 Denny Hamlin, 2.105 Punkte (+54 Punkte)
6. (3) #22 Joey Logano, 2.101 Punkte (+50 Punkte)
7. (6) #9 Chase Elliott, 2.088 Punkte (+37 Punkte)
8. (8) #42 Kyle Larson, 2.076 Punkte (+25 Punkte)
9. (13) #6 Ryan Newman, 2.065 Punkte (+14 Punkte)
10. (10) #12 Ryan Blaney, 2.059 Punkte (+8 Punkte)
11. (11) #88 Alex Bowman, 2.054 Punkte (+3 Punkte)
12. (9) #24 William Byron, 2.053 Punkte (+2 Punkte)
- - -
13. (12) #10 Aric Almirola, 2.051 Punkte (-2 Punkte)
14. (15) #14 Clint Bowyer, 2.049 Punkte (-4 Punkte)
15. (14) #1 Kurt Busch, 2.039 Punkte (-14 Punkte)
16. (16) #20 Erik Jones, 2.008 Punkte (-45 Punkte/41 Punkte Abzug)
RACE NIGHT: Samstag/Sonntag, 21./22. September 2019
RACE NIGHT (Update 06:55 Uhr MESZ): Erik Jones disqualifiziert (Post-Race Inspection)
Erik Jones disqualifiziert (Post-Race Inspection) RACE NIGHT Winner: Zweiter Playoff-Sieg für Martin Truex Junior
Zweiter Playoff-Sieg für Martin Truex Junior RACE NIGHT Stage 2: Kyle Busch gewinnt vor seinen drei Gibbs-Teamkollegen
Kyle Busch gewinnt vor seinen drei Gibbs-Teamkollegen RACE NIGHT Stage 1: Fünfter Stage-Sieg für Martin Truex Junior
Fünfter Stage-Sieg für Martin Truex Junior RACE NIGHT to the back (Update): Bubba Wallace, J.J. Yeley, Quin Houff
Bubba Wallace, J.J. Yeley, Quin Houff RACE NIGHT Fuel window (Update): 115-120 Runden
115-120 Runden RACE NIGHT Goodyear Tire Notes: 9 Reifensätze +1 Satz alt (Qualifying/Practice)
9 Reifensätze +1 Satz alt (Qualifying/Practice) RACE NIGHT Milestones: Daniel Suarez (100. Cup-Rennen)
Daniel Suarez (100. Cup-Rennen) RACE NIGHT: Die letzten News & Infos vor dem Start
Die letzten News & Infos vor dem Start RACE NIGHT: Race Facts Richmond Raceway
Race Facts Richmond Raceway RACE NIGHT live: NASCAR im Pay-TV (Motorvision TV von Samstag auf Sonntag ab 01:00 Uhr MESZ)
NASCAR im Pay-TV (Motorvision TV von Samstag auf Sonntag ab 01:00 Uhr MESZ) Driver Ranking: Kevin Harvick bleibt die Nummer eins
Kevin Harvick bleibt die Nummer eins POLE DAY Qualifying: Pole Position für Brad Keselowski im 2. Playoff-Rennen
Pole Position für Brad Keselowski im 2. Playoff-Rennen POLE DAY Qualifying Order: Austin Theriault beginnt, Jimmie Johnson letzter Starter
Austin Theriault beginnt, Jimmie Johnson letzter Starter POLE DAY Final Practice (Happy Hour): Martin Truex Junior fährt Bestzeit im letzten Training
Martin Truex Junior fährt Bestzeit im letzten Training POLE DAY Practice 1: Bestzeit für Chris Buescher im ersten Training
Bestzeit für Chris Buescher im ersten Training Entry List (Update): J.J. Yeley fährt die #52 für Garrett Smithley bei Rick Ware Racing
J.J. Yeley fährt die #52 für Garrett Smithley bei Rick Ware Racing Entry List: Richmond-Starterliste mit 38 Fahrern
Richmond-Starterliste mit 38 Fahrern Victory Lane: Die letzten Sieger und Polesetter auf dem Richmond Raceway
Die letzten Sieger und Polesetter auf dem Richmond Raceway Schedule: Richmond-Zeitplan von Freitag bis Sonntag
Richmond-Zeitplan von Freitag bis Sonntag Playoffs 2019: Playoff-Zwischenstand nach dem ersten Rennen
Playoff-Zwischenstand nach dem ersten Rennen Happy Birthday! Jimmie Johnson (17.09.1975)
Alle Bilder vom Richmond Raceway (Galerie wird ständig erweitert)
Race Facts: Die letzten News und Infos vor dem Start
Im April 2019 gewann Martin Truex Junior das letzte Rennen LAT Images
Aktive Rennsieger in Richmond: Kyle Busch (6 Siege), Denny Hamlin, Jimmie Johnson, Kevin Harvick (3), Joey Logano, Clint Bowyer, Kurt Busch (2), Kyle Larson, Brad Keselowski, Ryan Newman, Martin Truex Jr. (1)
Pole Awards in Richmond: Denny Hamlin, Kevin Harvick (3 Pole Award), Jimmie Johnson, Joey Logano, Brad Keselowski (2019) (2), Ryan Newman, Kyle Busch, Brad Keselowski, Martin Truex Jr. (1)
Debüt-Rennen in Richmond: Daniel Hemric (2018)
Erster Karriere-Pole Award in Richmond: Kein aktiver Fahrer
Erster Karriere-Sieg in Richmond: Kein aktiver Fahrer
Siege von der Pole Position (Pole Award) in Richmond: 24(23) in 125 Rennen
Letzter Sieg von der Pole Position in Richmond: 2016 (Denny Hamlin)
Die meisten Führungsrunden in Richmond: 383/400 (Brad Keselowski, 2014), 488/500 (Richard Petty, 1970)
Die meisten Führungswechsel in Richmond: 25 (1996, 1991)
Die meisten Gelbphasen in Richmond: 16 (2016)
Durchschnittswerte seit 2014 bis 2019 in Richmond: 14,9 Führungswechsel, 7,4 Gelbphasen über 48,4 Runden, 42,2 Runden ohne Rennunterbrechung


Driver Ranking
Top-16 nach Las Vegas mit Richmond-Vorschau
Kevin Harvick steht insgesamt zum vierten Mal in dieser Saison an der Spitze unseres Rankings LAT Images
Motorsport-Magazin.com ermittelt nach jedem Rennen die aktuelle Form aller NASCAR-Piloten, basierend auf den Ergebnissen der letzten sechs Rennen.
Das erste Playoff-Rennen 2019 sorgte für einige Überraschungen. Kevin Harvick bleibt mit Vorsprung die Nummer eins in unserem Ranking. Chase Elliott ist jetzt Zweiter vor dem Las Vegas-Sieger Martin Truex Junior. Die Playoff-Teilnehmer Kurt Busch und Erik Jones flogen aus den Top-16. Außerdem fehlt Aric Almirola. Matt DiBenedetto hält sich bereits seit acht Rennen in den Top-16.
1. (1) Kevin Harvick: Im April 2019 den 3. Pole Award erzielt. Bestwert mit 24 Top-10-Resultaten in 37 Rennen. 3 Siege in 2006, 2011 und 2013. Die letzten 3 Rennen auf Rang 5, 2 und 4 beendet.
2. (5) Chase Elliott: In den bisherigen 8 Rennen war in 2018 Platz 2 nach Startplatz 2 das beste Resultat. Rang 15 im letzten Rennen.
3. (8) Martin Truex Jr.: 24 Rennen ohne Erfolge. Dann 1. Pole in 2018. Im 2. Rennen 2018 Platz 3 nach Startplatz 3. Vor 5 Monaten 2. Sieg nach Startplatz 5. 41 Führungsrunden in den ersten 21 Rennen. Unglaubliche 861 Führungsrunden in 5 der letzten 6 Rennen.
4. (3) Kyle Larson: Bester im Qualifying mit einem Durchschnitt von Platz 8,6. 2017 gelang der einzige Sieg. Danach Platz 7, 7 und 37 nach Crash.
5. (4) Joey Logano: 2015 Pole Position in beiden Rennen. Davor 2014 1. Sieg und 2017 2. Sieg. Danach Platz 2, 4, 14 und 2.
6. (2) Denny Hamlin: Deutliche Bestwert mit 1.659 Führungsrunden. 3 Pole Awards 2006, 2007 und 2016. Ebenfalls 3 Siege in 2007, 2010 und 2016. Gleichzeitig letzter Sieger von der Pole Position. 8 Top-6-Ergebnisse in den letzten 9 Rennen.
7. (6) Ryan Blaney: In 7 Rennen war ein 2. Startplatz in 2017 das Highlight. Bestes Rennergebnis war Rang 18.
8. (9) William Byron: Bisher 3 Rennen auf Platz 9, 19 und 13 beendet.
9. (7) Kyle Busch: Richmond-Rekordsieger mit 6 Erfolge. Bestwerte mit 17 Top-5-Ergebnissen in 28 Rennen und einer Zielankunft von Platz 7 im Durchschnitt.
10. (11) Daniel Suarez: Die bisherigen 5 Rennen zwischen Platz 7 und 18 beendet.
11. (15) Brad Keselowski: 2014 gelang nach Pole Position der einzige Sieg mit dem unglaublichen Rekord von 383 Führungsrunden. Die letzten 8 Rennen zwischen Rang 2 und 11 beendet. Im 2. Playoff-Rennen 2019 startet er ebenfalls von der Pole Position!
12. (16) Ryan Newman: Bisher in 35 Rennen gelang 1 Sieg in 2003 und 1 Pole in 2004. Im April 2019 Platz 9.
13. (19) Alex Bowman: Vor 12 Monaten gab es mit Platz 12 das beste Resultat in 7 Rennen.
14. (14) Matt DiBenedetto: 2018 gelang mit Platz 16 das beste Ergebnis in 9 Rennen.
15. (10) Clint Bowyer: Bisher keine Pole, aber 2 Siege in 2008 und 2012. Platz 3 vor 5 Monaten.
16. (18) Paul Menard: Keine Pole und kein Sieg in 25 Rennen. Beste Platzierungen waren Rang 5 in 2013 und Platz 10 im letzten Rennen.
POLE DAY: Freitag/Samstag, 20./21. September 2019
Qualifying: Pole Position für Brad Keselowski im 2. Playoff-Rennen
Dritte Saison-Pole für Brad Keselowski LAT Images
Das Qualifying zum 28. Saisonrennen und zweitem Playoff-Lauf der 'Round of 16' auf dem 0,75 Meilen kurzen Richmond Raceway gewann Brad Keselowski. Mit 127.185 mph in 21.229 Sekunden bezwang der Penske-Pilot im Ford den Short Track zum zweiten Mal in seiner Karriere. Nach seiner ersten Richmond-Pole in der Saison 2014 gewann Keselowski anschließend mit dem unglaublichen Rekord von 383 Führungsrunden. Das Einzelzeitfahren über zwei Runden endete mit der dritten Saison- und 17. Karriere-Pole für Keselowski.
Mit 0.105 Sekunden Rückstand wurde Kevin Harvick Zweiter und startet damit ebenfalls aus der ersten Reihe in das Rennen über 400 Runden. Harvick hatte zuvor in den letzten beiden Austragungen auf Pole Position gestanden. Aus Reihe zwei starten die beiden anderen Hersteller Chevrolet und Toyota mit Chase Elliott und dem sechsfachen Rekordsieger Kyle Busch. Die Top-10 komplettieren Clint Bowyer, Denny Hamlin, Aric Almirola, der letzte April-Sieger Martin Truex Junior, Kurt Busch und Jimmie Johnson. Die ersten neun Plätze belegten Playoff-Fahrer. Die restlichen sieben Playoff-Teilnehmer platzierten sich zwischen Rang 13 und 28, den Titelverteidiger Joey Logano belegt. Die beiden Trainingseinheiten hatten Truex und Chris Buescher, der von Rang 23 beim Nachtrennen starten wird, zuvor mit Bestzeiten beendet. Daniel Suarez beginnt sein 100. Jubiläums-Rennen von Position 14. Bester Rookie war Ryan Preece auf Startplatz 21.
28. Saisonrennen: 62nd Annual Federated Auto Parts 400
Richmond Raceway, Richmond, VA
Qualifying/Startaufstellung Top-10 (Einzelzeitfahren, 2 Runden)
1. #2 Brad Keselowski (Ford) Team Penske, POLE AWARD
2. #4 Kevin Harvick (Ford) Stewart-Haas Racing
3. #9 Chase Elliott (Chevrolet) Hendrick Motorsports
4. #18 Kyle Busch (Toyota) Joe Gibbs Racing
5. #14 Clint Bowyer (Ford) Stewart-Haas Racing
6. #11 Denny Hamlin (Toyota) Joe Gibbs Racing
7. #10 Aric Almirola (Ford) Stewart-Haas Racing
8. #19 Martin Truex Jr. (Toyota) Joe Gibbs Racing
9. #1 Kurt Busch (Chevrolet) Chip Ganassi Racing
10. #48 Jimmie Johnson (Chevrolet) Hendrick Motorsports
weitere Startplätze (Playoff-Fahrer):
13. #42 Kyle Larson (Chevrolet) Chip Ganassi Racing
15. #12 Ryan Blaney (Ford) Team Penske
16. #20 Erik Jones (Toyota) Joe Gibbs Racing
19. #6 Ryan Newman (Ford) Roush Fenway Racing
20. #88 Alex Bowman (Chevrolet) Hendrick Motorsports
25. #24 William Byron (Chevrolet) Hendrick Motorsports
28. #22 Joey Logano (Ford) Team Penske
Freitag, 20. September 2019
Final Practice (Happy Hour): Martin Truex Junior fährt Bestzeit im letzten Training
Dritte Trainingsbestzeit für Martin Truex Junior in 2019 LAT Images
Im zweiten und letzten Training zum 28. Saisonrennen auf dem Richmond Raceway erzielte Martin Truex Junior nach 61 absolvierten Runden im Gibbs-Toyota die absolute Bestzeit. Mit 121.885 mph in 22.152 Sekunden fuhr Truex zum dritten Mal in dieser Saison eine Trainingsbestzeit. Der vorzeitig für die nächste Playoff-Runde qualifiziere Champion aus 2017 hatte das letzte Richmond-Rennen im April gewonnen.
Zweiter wurde mit einem gewaltigen Rückstand von 0.374 Sekunden Chase Elliott im Hendrick-Chevrolet. Rookie Daniel Hemric belegte in Childress-Chevrolet einen starken dritten Rang. Denny Hamlin wurde Vierter vor Austin Dillon. Erst auf Rang sechs platzierte sich mit Kevin Harvick ein Ford-Pilot. Brad Keselowski folgte auf Rang sieben vor Ryan Blaney, Kyle Busch und dem Zehnten Ryan Newman.
Auch die Longrun-Wertung ging an Truex mit einem Durchschnitt von 23.198 Sekunden. Harvick wurde Zweiter vor Elliott, Kyle Busch und Clint Bowyer.


Practice 1: Chris Buescher fährt die erste Bestzeit
Zweite Trainingsbestzeit für Chris Buescher in dieser Saison LAT Images
Das erste von zwei Trainingseinheiten vor dem Qualifying zum zweiten Playoff-Rennen 2019 endete nach 50 Minuten mit einer Bestzeit von Chris Buescher im JTG-Chevrolet. Mit einer Geschwindigkeit von 121.147 mph in 22.287 Sekunden bezwang Buescher den 0,75 Meilen kurzen Short Track in Richmond nach 42 absolvierten Runden. Titelverteidiger Joey Logano wurde mit 0.034 Sekunden Rückstand im Penske-Ford Zweiter vor William Byron. Bester Toyota-Pilot war Vorjahressieger Kyle Busch.
Die Top-10 komplettierten Denny Hamlin, Erik Jones, Ryan Blaney, Chase Elliott und Ryan Newman. April-Sieger Martin Truex Junior belegte den 13. Platz. Die Longrun-Wertung ging mit einem Durchschnitt von 22.864 Sekunden an Kyle Larson im Ganassi-Chevrolet. Zweiter wurde Erik Jones vor Clint Bowyer, Kurt Busch und Newman.
Donnerstag, 19. September 2019
Entry List für das 28. Saisonrennen auf dem Richmond Raceway mit 38 Fahrern
Nachtrennen auf dem Richmond Raceway NASCAR
Für das 28. Saisonrennen wurden 38 Fahrer von den Teams für das Wochenende auf dem Richmond Raceway gemeldet. Damit gibt es zum 22. Mal in dieser Saison kein komplettes Starterfeld mit 40 Fahrern. Die beiden Open-Teams sind unabhängig vom Ergebnis im Qualifying startberechtigt.
Es gab zwischen Las Vegas und Richmond insgesamt drei Fahrerwechsel bei den Teams. Austin Theriault fährt für Petty Ware Racing seinen vierten Einsatz in diesem Jahr. Bei den Open-Teams setzt Premium Motorsports Quin Houff für Joe Nemechek in die #27. Außerdem kommt Spenser Boyd bei Rick Ware Racing für J.J. Yeley zu seinem zweiten Rennen in der #53.
Entry List: Richmond Raceway
28. Saisonrennen: 36 Charter-Teams, 2 Open-Teams
3 Fahrerwechsel (**) / Rookie (R)
Charter-Teams
#00 Landon Cassill (Chevrolet) StarCom Racing
#1 Kurt Busch (Chevrolet) Chip Ganassi Racing
#2 Brad Keselowski (Ford) Team Penske
#3 Austin Dillon (Chevrolet) Richard Childress Racing
#4 Kevin Harvick (Ford) Stewart-Haas Racing
#6 Ryan Newman (Ford) Roush Fenway Racing
(R) #8 Daniel Hemric (Chevrolet) Richard Childress Racing
#9 Chase Elliott (Chevrolet) Hendrick Motorsports
#10 Aric Almirola (Ford) Stewart-Haas Racing
#11 Denny Hamlin (Toyota) Joe Gibbs Racing
#12 Ryan Blaney (Ford) Team Penske
#13 Ty Dillon (Chevrolet) Germain Racing
#14 Clint Bowyer (Ford) Stewart-Haas Racing
#15 Ross Chastain (Chevrolet) Premium Motorsports
#17 Ricky Stenhouse Jr. (Ford) Roush Fenway Racing
#18 Kyle Busch (Toyota) Joe Gibbs Racing
#19 Martin Truex Jr. (Toyota) Joe Gibbs Racing
#20 Erik Jones (Toyota) Joe Gibbs Racing
#21 Paul Menard (Ford) Wood Brothers Racing
#22 Joey Logano (Ford) Team Penske
#24 William Byron (Chevrolet) Hendrick Motorsports
#32 Corey LaJoie (Ford) GO FAS Racing
#34 Michael McDowell (Ford) Front Row Motorsports
(R) #36 Matt Tifft (Ford) Front Row Motorsports
#37 Chris Buescher (Chevrolet), JTG Daugherty Racing
#38 David Ragan (Ford), Front Row Motorsports
#41 Daniel, Suarez (Ford) Stewart-Haas Racing
#42 Kyle Larson (Chevrolet) Chip Ganassi Racing
#43 Bubba Wallace (Chevrolet) Richard Petty Motorsports
(R) #47 Ryan Preece (Chevrolet) JTG Daugherty Racing
#48 Jimmie Johnson (Chevrolet) Hendrick Motorsports
(**) #51 Austin Theriault für B.J. McLeod (Chevrolet/Ford) Petty Ware Racing
#52 Garrett Smithley (Chevrolet/Ford) Rick Ware Racing
#77 Reed Sorenson (Chevrolet) Spire Motorsports
#88 Alex Bowman (Chevrolet) Hendrick Motorsports
#95 Matt Di Benedetto (Toyota) Leavine Family Racing
Open-Teams
(**) #27 Quin Houff für Joe Nemechek (Chevrolet) Premium Motorsports
(**) #53 Spencer Boyd für J.J. Yeley (Chevrolet/Ford) Rick Ware Racing


Die letzten Sieger und Polesetter auf dem Richmond Raceway
Zeitplan für das 28. Saisonrennen in Richmond
Cup-Rennen 28 (Round of 16): 62nd Annual Federated Auto Parts 400 NASCAR
Das 28. Rennen der Saison 2019 ist das zweite von drei Playoff-Rennen der 'Round of 16'. Gleichzeitig ist Richmond in dieser Saison Austragungsort des ersten sowie des neunten und letzten Nachtrennens des Jahres. Auf dem Richmond Raceway wurde 1953 das erste Cup-Rennen ausgetragen. Seit der Saison 1955 ist die Strecke fester Bestandteil des NASCAR-Kalenders. Zwei Austragungen pro Jahr gibt es seit 1959 im US-Bundesstaat Virginia. Geschwindigkeiten eines Superspeedways und die Action eines Short Tracks machen dieses Rennen so spannend. Auf dem 0,75 Meilen langen D-Oval wurden bisher insgesamt 126 Rennen gefahren.
Die Renndistanz beträgt 400 Runden aufgeteilt in drei Stages über 100, 100 und 200 finalen Runden. Die Kurven haben ein Banking von 14 Grad, die Start-Ziel-Gerade ist um acht Grad überhöht und die Gegengerade nur um zwei Grad.
Kevin Harvick stand in den letzten beiden Rennen auf Pole Position. Der Stewart-Haas-Pilot und Denny Hamlin gewannen insgesamt drei Pole Awards. Hamlin ist auch der letzte Pilot der 2016 von der Pole Position gewinnen konnte. Die Sieger-Statistik führt Kyle Busch deutlich mit sechs Siegen an. Vor zwölf Monaten war der Gibbs-Fahrer zuletzt erfolgreich. Jimmie Johnson, Harvick und Hamlin gewannen bisher drei Rennen. Das letzte Rennen im April 2019 endete mit dem ersten Sieg von Martin Truex Junior.
28. Saisonrennen (Round of 16: Playoff-Rennen 2/10):
62nd Annual Federated Auto Parts 400
Richmond Raceway, Richmond, VA
0,75 Meilen D-Oval, Short Track
400 Runden (Stages: 100/100/200), 300 Meilen
Die letzten Sieger (Polesetter)
Sieger 13.04.2019: Martin Truex Jr. (Pole: Kevin Harvick.)
Top-10 Stage 1: #18, 22, 19, 4, 14, 2, 1, 37, 21, 41
Top-10 Stage 2: #22, 19, 4, 2, 14, 41, 1, 20, 37, 21
Sieger 22.09.2018: Kyle Busch (Pole: Kevin Harvick)
Sieger 21.04.2018: Kyle Busch (Pole: Martin Truex Jr.)
Sieger 09.09.2017: Kyle Larson (Pole: Matt Kenseth)
Sieger 30.04.2017: Joey Logano (Pole: Matt Kenseth)
Sieger 10.09.2016: Denny Hamlin (Pole: Denny Hamlin)
Sieger 24.04.2016: Carl Edwards (Regen-Pole: Kevin Harvick)
Sieger 12.09.2015: Matt Kenseth (Pole: Joey Logano)
Sieger 26.04.2015: Kurt Busch (Pole: Joey Logano)
Richmond-Zeitplan (MESZ)
Freitag, 20. September
17:35 - 18:25 Uhr: Practice 1
19:35 - 20:25 Uhr: Final Practice (Happy Hour)
Samstag, 21. September
00:05 Uhr: Qualifying (Einzelzeitfahren, 2 Runden)
Sonntag, 22. September
01:46 Uhr: Rennen über 400 Runden (Stages: 100/100/200)
Die 16 Playoff-Teilnehmer NASCAR
Gesamtstand 27/36
Neuer Zwischenstand nach dem 1. Playoff-Rennen
Round of 16
1. (3) #19 Martin Truex Jr. (1 Sieg), 2.082 Punkte
2. (4) #4 Kevin Harvick, 2.079 Punkte
3. (5) #22 Joey Logano, 2.075 Punkte
4. (1) #18 Kyle Busch, 2.063 Punkte
5. (6) #2 Brad Keselowski, 2.058 Punkte
6. (7) #9 Chase Elliott, 2.057 Punkte
7. (2) #11 Denny Hamlin, 2.056 Punkte
8. (11) #42 Kyle Larson, 2.044 Punkte
9. (13) #24 William Byron, 2.040 Punkte
10. (12) #12 Ryan Blaney, 2.039 Punkte
11. (9) #88 Alex Bowman, 2.037 Punkte
12. (14) #10 Aric Almirola, 2.033 Punkte
- - -
13. (16) #6 Ryan Newman, 2.027 Punkte
14. (8) #1 Kurt Busch, 2.019 Punkte
15. (15) #14 Clint Bowyer, 2.012 Punkte
16. (10) #20 Erik Jones, 2.007 Punkte
Playoffs Grid: Round of 16 NASCAR


NASCAR-Saison 2019 NASCAR


Alle NASCAR-News, Rennberichte und Bilder:
NASCAR Ergebnisse & Gesamtstand:
NASCAR Fahrer & Teams aktuell:
Monster Energy NASCAR Cup Series 2019 - Fahrer & Teams in Bildern:
NASCAR-Rennkalender 2019:
NASCAR-Rennkalender 2020:

Story 127
Add another milestone to the storied career of Florida State baseball coach Mike Martin.
Already college baseball's winningest coach in DI history, Martin became the first coach to reach 2,000 career wins Saturday night after Florida State's 5-2 victory over Virginia Tech. All 2,000 have come at Florida State, his alma mater.
It’s no coincidence that MM are the roman numerals for 2,000.

For the first time in the history of NCAA athletics, a head coach has reached 2,000 career wins.

Congratulations to our beloved head coach, Mike Martin. pic.twitter.com/c4BYcdUOaA — FSU Baseball (@FSUBaseball) March 9, 2019
Martin entered Saturday's doubleheader with the Hokies at 1,999 career wins in 39+ seasons. After dropping Game 1 6-0, marking FSU's first loss of the season, the Noles bounced back to split the day and take the weekend series.
SEMINOLES BASEBALL: Here is Florida State's all-time starting nine lineup
Martin took the helm in Tallahassee in 1980 and has stayed put for four decades. His remarkable tenure has seen 16 College World Series appearances and 39 consecutive trips to the NCAA tournament. FSU has twice finished runner-up in the CWS under Martin (1986, 1999).
Last season, on May 5, Martin surpassed Augie Garrido for most wins in DI history at 1,976 and ended the season at 1,987 after a run to NCAA regionals. Martin has guided Florida State to a 13-1 start this year and a No. 11 ranking in the latest D1Baseball.com poll.
First! Most! Best!
Mike Martin is officially the only 2,000 win coach in NCAA History.#OneLastRun pic.twitter.com/OZQpAfjAAB — NCAA Baseball (@NCAACWS) March 9, 2019
Martin's career record now stands at 2,000-714-4, good enough for the best winning percentage among active coaches (.737). He's also the only NCAA coach in any sport to reach 2,000 career wins.
It was announced in June that this season would be Martin's last. As part of his final act, the Seminoles will try to check off one last item missing from Martin's resume: A national title.

Story 128
CHAPEL HILL, N.C. – Trailing by three goals with less than four minutes to play, the unranked University of North Carolina men's lacrosse team staged a stunning late rally to defeat seventh-ranked Syracuse in the first round of the 2019 Atlantic Coast Conference Men's Lacrosse Tournament before 942 at UNC Lacrosse Stadium Thursday night.

The victory kept UNC's NCAA post-season hopes alive as it improved to 8-6 on the season while Syracuse saw its four-game winning streak come to an end. The Orange is now 9-4 on the campaign.
SELECTION SHOW: Time, date and TV channel for 2019 tournament

UNC, seeded fifth in the tournament, will play top-seeded Virginia Saturday at 2 p.m. in the semifinals of the tournament followed by second-seeded Duke against third-seeded Notre Dame at 4:30 p.m. The two winners Saturday play for the ACC championship on Saturday, May 4 at the home site of the highest remaining seed.
4️ goals in 4️ minutes

Call it a comeback! pic.twitter.com/86v690S9Nh — UNC Men's Lacrosse (@UNCMensLacrosse) April 26, 2019
The late Tar Heel comeback marked the first time UNC has ever trailed the Orange in the fourth quarter of a game and come back to win in the 27-game history of the series which dates back to 1981. Thursday's win was the ninth for the Tar Heels in the series compared to 18 wins over Syracuse.

Syracuse broke a 7-7 deadlock on Jacob Buttermore's third goal of the game with 11:43 to play in the fourth quarter. Bradley Voigt followed with his fourth goal of the game at the 8:31 mark to make it 9-7 in favor of Syracuse and when Brendan Curry tallied a man-up goal with 6:12 to play in the final period the Orange had a three-goal lead and had all the momentum on its side.
SURPRISE: These 3 teams have been the most shocking this season

After a media timeout, Syracuse had three possessions but Michael Nathan, Brian Cameron and Nicky Solomon forced turnovers to keep the Tar Heels alive in the match. Solomon forced a turnover by Orange goalkeeper Drake Porter with 4:13 to play and Andy Matthews seized the ground ball. Sixteen seconds later Matt Gavin drove around the crease from right to left for an unassisted goal with 3:46 to play in the match.

Carolina's Zachary Tucci won the ensuing face-off for Carolina and freshman attackman Brian Cameron scored off an assist from freshman attackman Nicky Solomon 39 seconds later to cut the Tar Heel deficit to 10-9. Carolina then made it three goals in a span of just 45 seconds as Tucci won another face-off, claimed the ground ball on his own and sped down the middle of the field to score high and hard past SU goalkeeper Drake Porter with 3:01 to play. It was just the second goal of the season for Tucci.

Syracuse won the next face-off but Caton Johnson made his 11th save of the game for the Tar Heels on a shot by David Lipka with 2:09 to play. After a successful clear, Gavin was again Johnny-on-the-spot for the Tar Heels as he dodged toward the crease from the right side and scored a second unassisted goal in the fourth quarter with 18 seconds left on the shot clock.

Hear from Carolina Head Coach Joe Breschi following tonight's comeback win over Syracuse! #GoHeels pic.twitter.com/D5R7VRtPjM — UNC Men's Lacrosse (@UNCMensLacrosse) April 26, 2019
After Syracuse won the ensuing face-off both teams turned the ball over and the Orange called a timeout with 26 seconds to play after clearing the ball. Jamie Trimboli's shot with eight seconds left went wide and the Tar Heel defense clamped down and did not allow another shot by the Orange.

Carolina had eight different goal scorers in the game with Brian Cameron, William Perry and Matt Gavin each scoring two goals. Nicky Solomon, Justin Anderson, Tanner Cook, Zachary Tucci and Jacob Kelly all scored single goals for UNC. Anderson, Cameron, Timmy Kelly, Perry and Solomon had assists for UNC.

Bradley Voigt had four goals and an assist for Syracuse while Jacob Buttermore had three goals and an assist. Brendan Curry, Jamie Trimboli and Nate Solomon all scored for the Orange. Stephen Rehfuss led all players in the game with four assists while David Lipka had two helpers for the Orange.

It was a very even game statistically as the Tar Heels outshot the Orange 38-32 and had a 32-31 edge in ground balls. Drake Porter made 12 saves for Syracuse and Caton Johnson had 11 saves for the Tar Heels. Syracuse had 15 turnovers, five on failed clears, while UNC committed 16 turnovers and was 12 for 13 in the clearing game.
HISTORY: Upset still resonates for 1975 Morgan State | Memorable championship moments

UNC won 14 of 24 face-offs as Zachary Tucci was 10 of 19 at the X and Ryan O'Connell was four of five. Attackman Andy Matthews led UNC with five ground balls while O'Connell and Tucci each had four ground balls for the Tar Heels. Syracuse defenseman Tyson Bomberry had eight ground balls to lead all players in the game in that category.

After Syracuse jumped on top 2-0, UNC answered with back-to-back goals by William Perry, the second on an EMO, to tie the score at 2-2 with 6:17 left in the first period. Trimboli's unassisted goal put Syracuse up 3-2 at the end of the period.

Goals by freshmen Nicky Solomon and Brian Cameron gave the Tar Heels their first lead of the game with 11:11 left in the half before a goal by Voigt at 10:24 proved to be the last goal of the opening 30 minutes.

Syracuse outscored the Tar Heels 3-2 in the third quarter. Nate Solomon's unassisted goal with two seconds to play in the quarter gave the Orange a 7-6 lead heading into the final 15 minutes. Justin Anderson drove from behind the goal to score unassisted with 12:49 to play to tie things up again at 7-7. Just 1:06 later Syracuse began its three-goal scoring run, setting up the wild finish over the final 12 minutes with momentum swinging strongly to Syracuse and then back to Carolina.

GAME NOTES

Story 129
It was, in the end, a tale of two first rounds.
At the top of the NCAA tournament ladder, all was well. The three highest seeds in each region won and moved on, including Roy Williams going 29-0 in his first game at North Carolina and Kansas. But just below? Carnage.
CHECK YOUR BRACKET: See where you stand in the Bracket Challenge Game | Printable
So behold the weekend to come, after what the past two days gave us:
Zion Williamson in full gallop. His freshman running mate, too
In the first NCAA tournament game of their lives, Duke’s Williamson and RJ Barrett combined for 51 points against North Dakota State and made 21 of 34 shots. “I think last night, when I was sitting in my hotel room, I’m like, `wow, I’m actually here,” Williamson said.
So North Dakota State noticed. Coach David Richman was asked about not playing anyone like Williamson. His answer: “Is there any guys like him?”
THE ZION SHOW: Zion Williamson and RJ Barrett made sure Duke didn't have to worry about getting upset
Mike Krzyzewski mentioned how “I’ve had a lot of wow guys.” And these two are both lefthanded, whatever that means. So Krzyzewski’s latest wow guys now go against UCF, coached by Johnny Dawkins. Krzyzewski’s first wow guy at Duke. Zion, meet 7-6 Tacko Fall.
Seven Big Ten schools
Which means 22 percent of the bracket is now composed of one league. So many, they can no longer keep out of each other’s way, which is why it’ll be Michigan State vs. Minnesota Saturday. Michigan State, the team that hit 25 of 26 free throws hustling past Bradley. Minnesota, the team that was outscored in bench points 29-0 but went 26 minutes without a turnover to upset Louisville.
Iowa knocks off Cincinnati, 79-72
For a while there, it looked the Big Ten would never lose, until Wisconsin did. The conference office is waiting for your apology, Badgers. “We’ve been saying all year long it’s the most competitive league in the country top to bottom,” Iowa’s Fran McCaffery said after rallying past Cincinnati. “And you sort of expect Big Ten coaches to make those kinds of statements. But the reality is, we actually believe that, and so I think it’s proving it."
Ohio State’s Chris Holtmann added late Friday night, when his Buckeyes made the Big Ten 7-1: “You’re careful to talk too early. There’s a lot of tournament left to be played . . . But it’s the best league I’ve ever been a part of from top to bottom, this year in the Big Ten. I can’t explain how difficult it is to play on a given night.”
A No. 13 seed, three 12s, an 11 and three 10s
That’s bad news for a lot of higher seeds. Had New Mexico State come up with two more points against Auburn, the No. 12 seeds would have had a four-game sweep over No. 5. Remarkable.
Only five of the 16 games involving the two highest possible seeds. At least one upset has altered the other 11 games.
A No. 13 seed vs. a No. 12 for a spot in the Sweet 16
Lots of double digits in that sentence, for a second round game. That’d be UC Irvine – winner of 17 in a row – and Oregon. There isn’t much anything scarier out there right now – short of trying to take a charge from Zion Williamson on a breakaway – than the Ducks’ defense. On Feb. 23, they gave up 62 points to UCLA in the second half. In the nine wins since, they have allowed that many points once in an entire game.
Oregon comes up with huge Wisconsin upset
Teams from 13 different conferences
The joy has been spread around. So far.
A wish for more close finishes
Out of 32 first-round games, only 12 were decided by single digits, only three with a final margin of one possession. March is still waiting for the first buzzer-beater.
Virginia still breathing
“We’re ready to put on a show this year so we can talk about something else,” Kyle Guy had said about the UMBC memory. But how nervous was the Commonwealth – and the Cavaliers – when it was down to Gardner-Webb by 14 points? “Well, it was just intense,” coach Tony Bennett would say later. “That’s the reality of it.” And now that the first round matter has been settled, what’s next? Oklahoma, who scored 42 points against Mississippi before its first turnover.
Mr. Triple-Double
Florida State will now see what it can do with Ja Morant and his gang. Murray State has never been in the Sweet 16. The Seminoles will be one of only two teams in America – with Auburn -- who can say they have played the two hottest names in the sport, Morant and Williamson. By the way, Auburn lost to Williamson by six, beat Morant by five. And the Tigers are still playing, too.
The most prolific 3-point shooter of all time
Wofford’s Fletcher Magee passed the career record of 504 Thursday night. But look who’s going to be guarding him Saturday. . .
Kentucky vs. Wofford
A team with 129 NCAA tournament victories against a team with one. It’s Goliath and David, right? “I hate it,” Wofford coach Mike Young said of that concept Friday. But even he had to admit that in 1988, “I came down and interviewed for the job, and I had never heard of Wofford.”
Young put together a non-conference schedule this season that included North Carolina, Kansas, Oklahoma and Mississippi State, with this moment in mind. “We may get our ears pinned back tomorrow, but it will not be because my team is intimidated,” he said. “You know, there’s a method to the madness.”
Still, Magee is going to be chased by an awful lot of future NBA guys.
“I think that’s something that you try to block out and ignore as much as you can,” he said. “Getting the chance against great competition is always a great chance to prove yourself.”
An all-Virginia second round game
Virginia Tech and Liberty. Who saw that coming?
An outfielder
Speaking of Iowa’s McCaffery, that’s his redshirt freshman son Connor, who besides hitting a 3-pointer to give the Hawkeyes the lead Friday had four hits in three games the past week, playing outfield for the Hawkeyes’ baseball team. He was in the clubhouse between games of a doubleheader when Iowa was called out on Selection Sunday. He heard the opponent was Cincinnati. Then he went out and hit two doubles. “This moment’s going to pass and I’m going to look back on it and kind of like go wow, this was crazy,” he was saying in the locker room Friday. “But I need to appreciate everything for what it is.”
P.S. He had his baseball equipment sent to Indiana this weekend just in case the Hawkeyes were eliminated Friday by Cincinnati. The Iowa baseballers will have to face the Hoosiers without him.
But then, a lot of plans have been changed the past two days.

Story 130
Die Fusionen unter den Zah­lungs­dienst­leis­tern erfolgen mit immer größeren Geschwindigkeiten und die Konzentration nimmt rapide zu. Wobei hier jetzt nicht Sinn oder Unsinn des Mergers Thema des Artikels sein soll. Heute geht es um die Auswirkungen auf die Struktur der Zahlungsnetzbetreiber. Nur diese technischen Dienstleister können die girocard-Autorisierungen zu den vier Kopfstellen der Bankverbände wei­ter­lei­ten. Netz­be­trei­ber sind al­so ein es­sen­ti­el­les Bin­de­glied beim Zahl­vor­gang mit der gi­ro­card.
von Rudolf Linsenbarth
Wer wissen will, welche Unternehmen dazu in der Lage sind (also Autorisierungen zu den vier Kopfstellen der Bankverbände weiterzuleiten), findet eine komplette Liste beim Bundesverband der Electronish Cash Netzbetreiber ( https://b-ec-n.de ). Fun Fact: Lustig, das die Zahlungsdienstleister der girocard sich noch mit ec-Kürzel schmücken. Macht aber nichts – diese Unternehmen sind nur Insidern bekannt und girocard heißt ja gefühlt immer noch ec-Karte.
Also die BS-Payone ist jetzt nicht mehr im Besitz der Sparkassen, damit hat sich die vorletzte Bank aus dem aktiven Netzbetrieb zurückgezogen. Die Deutsche Bank ist zwar im Besitz der VÖB-ZVD Processing GmbH, hier betreibt man aber nur noch pro forma ein einziges Terminal, um die Netzbetreiber-Lizenz nicht zu verlieren. Den Rest hatte man schon vorher versilbert und an die SIX Payment Solution verkauft. Bei SIX Payment werden jetzt einige Leser aufhorchen, genau dieses Unternehmen ist ja gerade von ATOS Worldline übernommen. Wordline hat damit jetzt schon zwei Netzbetreiber – SIX und die vor einigen Jahren erworbene PaySquare. Ingenico spielt jetzt in der gleichen Liga und besitzt ebenfalls 2 Netzbetreiber.
Krösus im Club der Mehrfach-Eigentümer ist aber Concardis, mittlerweile selber vom dänischen Zahlungsverkehrsspezialisten Nets übernommen. Das Frankfurter Unternehmen nennt mittlerweile zwei Netzbetreiber sein Eigen, nämlich Concardis (vormals ICP), cardtech und hält an der WEAT eine wesentliche Beteiligung. Man darf gespannt sein, wann hier die Synergien gehoben werden und eine Zusammenlegung erfolgt. Zusätzlich stellt sich die Frage, ob es in Zukunft überhaupt noch Netzbetreiber braucht, um eine Kartenzahlung zu autorisieren. Vor der Beantwortung ist vielleicht ein Blick auf die Branchen, aus denen die Eigentümer kommen recht aufschlussreich.
Netzbetreiber Konzern Branche 1 BS PAYONE GmbH Ingenico Technologieunternehmen/ Terminalhersteller 2 BP Europa SE BP Handel 3 CardProcess GmbH DZ Bank Bank 4 cardtech Card & POS Service GmbH Nets Payment Provider 5 DB Vertrieb GmbH Deutsche Bahn Handel 6 Douglas Informatik & Service GmbH -- Handel 7 Elavon Financial Services DAC U.S. Bancorp Payment Provider 8 Concardis GmbH Nets Payment Provider 9 Ingenico Payment Services GmbH Ingenico Technologieunternehmen/ Terminalhersteller 10 InterCard AG Verifone Technologieunternehmen/ Terminalhersteller 11 LAVEGO AG -- Payment Provider 12 PaySquare SE Worldline Technologieunternehmen/ Terminalhersteller 13 REWE REWE Handel 14 SIX Payment Services (Europe) S.A. Worldline Technologieunternehmen/ Terminalhersteller 15 VöB-ZVD Processing GmbH Deutsche Bank Bank 16 Shell Deutschland Oil GmbH Shell Handel 17 TeleCash GmbH & Co. KG First Data Payment Provider 18 transact Elektronische Zahlungssysteme GmbH Euronet Worldwide Payment Provider 19a WEAT Electronic Datenservice GmbH Nets, First Data Payment Provider 19b WEAT Electronic Datenservice GmbH Westfalen AG, AGIP Handel
Wem Netzbetreiber gehören
Von den 19 Netzbetreibern sind 6,5 im Besitz eines reinen Zahlungsdienstleisters, 5 gehören einem Terminalhersteller (wobei ich da Worldline mal großzügig mit hinzunehme), 5,5 sind im Besitz des Handels und 2 verbleiben im Besitz einer Bank, eigentlich nur einer da VÖB-ZVD am Markt nicht mehr aktiv ist.
Wenn man schaut, wer in letzter Zeit hier massiv zugekauft hat, dann stechen vor allem die Terminalhersteller hervor. Ingenico mit dem Erwerb der Easy-Cash und Payone, Verifone mit Intercard und ATOS Worldline schließlich mit Paysquare und SIX. Für sie wird es immer wichtiger, die gesamte Wertschöpfungskette zu kontrollieren, um bei technischen Entwicklungen nicht plötzlich abgehängt zu werden. Wer mit dem technischen Fortschritt nicht Schritt hält, verliert wie ICP den Anschluss.
Autor Rudolf Linsenbarth Rudolf Linsenbarth beschäftigt sich mit Mobile Payment, NFC, Kundenbindung und digitaler Identität. Er ist seit über 15 Jahren in den Bereichen Banken, Consulting, IT und Handel tätig. Linsenbarth ist profilierter Blogger der Finanzszene und kommentiert bei Twitter unter beschäftigt sich mit Mobile Payment, NFC, Kundenbindung und digitaler Identität. Er ist seit über 15 Jahren in den Bereichen Banken, Consulting, IT und Handel tätig. Linsenbarth ist profilierter Blogger der Finanzszene und kommentiert bei Twitter unter @holimuk die aktuellen Entwicklungen. Alle Beiträge schreibt Rudolf Linsenbarth im eigenen Namen.
Im Handel bewegst sich nichts – noch …
Wenig Bewegung gab es im Netz­be­trieb des Han­dels. Ausnahme ist die WEAT. Der Name steht für die Gründungsmitglieder Westfalen, ELF, AGIP und TOTAL. Mittlerweile sind nur noch Westafalen (20%) und AGIP (20%) an Bord die restlichen Anteile besitzen jetzt Concardis (40%) und First Data (20%). Es ist jetzt nicht zu er­war­ten, dass BP, REWE oder Shell sich ebenfalls schnell von ihren Ak­ti­vi­tä­ten tren­nen. Bei der Dou­glas In­for­ma­tik sieht das aber schon an­ders aus. Durch die Zer­schla­gung der Grup­pe kämpft nun je­der für sich al­lein, wenn Dou­glas In­for­ma­tik beim Ren­nen um den bes­ten Preis die Luft aus­geht, kommt auch hier die Stun­de der Wahr­heit. Ob für die Deut­sche Bahn auf Dau­er ein ei­ge­ner Netz­be­trieb ei­nen Sinn er­gibt, wenn die meis­ten Kar­ten nicht mehr am Schal­ter oder Fahr­kar­ten­au­to­ma­ten, son­dern über ei­ne App ge­kauft wer­den, ist auch so ein Punkt.
Bei Payment Providern ist Größe alles
In Bezug auf die Größe steht LAVEGO ohne Partner oder einen starken Konzern im Hintergrund da. Hier sehe ich zumindest einen weiteren Übernahmekandidaten.
Jetzt kann man sich auch überlegen, wie es mit CardProcess weitergeht. Die Tendenz spricht eher nicht dafür, dass das Unternehmen in seiner jetzigen Struktur so bestehen bleibt.“
Zum einen se­hen Ban­ken Ih­re Kern­kom­pe­tenz nicht mehr im Netz­be­trieb. Die aus Ban­ken­sicht in­ter­es­san­te­ren Be­rei­che sind die Zah­lungs­au­to­ri­sie­rung und das Kar­ten-Pro­ces­sing. Ein Be­reich, den sich die Fi­du­cia mit 50,2% Mehr­heits­ei­ge­ner an der Card­Pro­cess viel­leicht auch ger­ne ein­ver­lei­ben möch­te. Nur was pas­siert dann mit dem Netz­be­trieb? Den könn­te zum Bei­spiel die EU­RO-In­for­ma­ti­on S. A. über­neh­men. Das Un­ter­neh­men aus der Cré­dit Mu­tu­el Grup­pe ist in Frank­reich be­reits der grö­ß­te Zah­lungs­dienst­leis­ter und zu­dem be­reits mit 5% an Card­Pro­cess beteiligt.
Die französische Bankengruppe würde bestimmt gerne eine Übernahme wie die der Targobank wiederholen. Da passen Cardprocess, Douglas Informatik und Deutsche Bahn Netzbetrieb perfekt ins Beuteschema.
Update: 7.6.2018 21:00: Bei der Recherche zu den Eigentümerverhältnissen führte uns Google auf die folgende Seite: https://www.cardprocess.de/index.php/component/content/category/7-unternehmen (die Informationen sind mittlerweile entfernt worden). Demnach habe cardprocess die folgenden Gesellschafter:
1. Fiducia GAD AG 50,2 %
2. DZ Bank AG 39,8 %
3. DG Verlag 5 %
4. EURO-Information S. A. 5 %
Nach erscheinen dieses Artikels erhielten wir den Hinweis von Cardprocess, dass der Fiducia Anteil zu Anfang diesen Jahres von der DZ Bank übernommen wurde. Bei den anderen Gesellschaftern gab es keine Veränderung.
Dies ist kann man als Bekenntnis der DZ Bank zu einem eigenständigen Zahlungsdienstleister werten. Zudem passt es zur bodenständigen Tradition der Genossenschaftsbanken. Wir vom IT-Finanzmagazin bleiben am Thema!Rudolf Linsenbarth

Sie finden diesen Artikel im Internet auf der Website:
https://itfm.link/71767

Sie finden diesen Artikel im Internet auf der Website:https://itfm.link/71767
(18 Stimmen, Durchschnitt: 4,56 von maximal 5)
Stimmen, Durchschnitt:von maximal 5)

Story 131
Getty Images / Birgit Korber / EyeEm
Few remember it today, but it was five decades ago that the populist backlash against the technocrats – found too objective, too cold, too removed from the lives and struggles of ordinary people in the streets – first broke out. Those streets were real: it was a rebellion against the bureaucrat-knows-best mentality that shaped – and still shapes – our cities. The cities of the future, if they want to remain vibrant and democratic, will have to put such elitism behind them, putting their own citizens first – and bureaucrats and big technology companies second. We have tried to do just that in Barcelona in the past four years.
Back in the 1960s, the omniscient bureaucrat, once a respected figure and a model of rationality, came under sustained attack for lacking compassion, sufficient knowledge, and respect for fellow citizens. That early challenge to public authority was never fully resolved. As a result, many cities are today caught between the democratic aspirations of their new and often radical mayors (sometimes, as in Barcelona, brought into office by social movements) and the inner workings of the highly complex ossified bureaucracies they are expected to lead. Eventually, even the boldest reformists settle for the pragmatic option of simply not rocking the boat.
Advertisement
The heavily centralised, platform-knows-best model of the smart city that has conquered many localities in the past decade is a perfect testament to this predicament. It promises so much in terms of involving citizens in policy-making, democratising access to important infrastructure – and yet such plans often yield only more centralised institutions, transferring power to Big Tech rather than the citizens and making public decision-making even less transparent than before. Just as the city was the place where initial suspicion towards public bureaucracy got its first major impetus, it can also be the place where a new type of democracy – we have practiced it, to the best of our ability, in Barcelona – is reborn to make our cities more enjoyable and liveable while helping people regain trust in public institutions. How could we bring it about to ensure that the future of cities remains bright, inclusive and democratic?
First, city officials should acknowledge that digital technology can help citizens to solve many of their problems without having to wait for help from remote bureaucracies. But the idea that all the solutions have to come from above needs to be reconsidered in light of the immense innovation from below. Bottom-up democracy inverts how our top-down cities are run: it promises to make cities people-first, not technology-first. Done properly, it will also enable new forms of solidarity and collective action – not just the perpetuation of the “solutionist” mindset that reduces all problems to the level of the individual user or consumer.
Read next This high-tech London skyscraper is the envy of every office worker This high-tech London skyscraper is the envy of every office worker
Second, city leaders should be humble and confess they do not have all the answers but that they trust the citizens to help find them; the city bureaucrat of the future learns, not preaches. It’s currently easier said than done, as such answer-finding infrastructure is either non-existent or belongs exclusively to the tech giants that have their own plans for our cities. Sensors, algorithms, digital-identity systems: without these essential components, there can be no meaningful empowerment of the citizens. Digital infrastructures that empower citizens to participate in politics cannot be run using business models based on the manipulation of collective behaviours and fake news. They must be in public hands and controlled by citizens themselves.
Third, if urban leaders hope to re-establish long-term trust with citizens, they need to assure that citizens’ data is not only safe but that it’s actually generating public, not just private, value. The experiences of the past decade suggest that’s often not the case, with public authorities either failing to ask questions about how citizen data is to be stored or who is most likely to monetise it.
Advertisement
Cities should be proactive in setting up a system of digital rights, informed by a “privacy by design” approach, that will take any guesses out of the game: citizen data should not to be commercially exploited under any circumstances. Cities can become key agents in the transition from surveillance capitalism, where data ownership is opaque, to a model where data is a common good, co-owned by all citizens. Whoever wants to build new services on top of that data would need to do so in a competitive, heavily regulated environment while paying a corresponding share of their profits for accessing it. In the absence of such interventions, public tolerance of “smart” and “digital cities” might not last very long, making it hard to deploy technology to achieve tremendous efficiencies when it comes to sustainable transportation or energy consumption
Fourth, city leaders need to remember that their task is to reconcile private and often short-term preferences of their citizens with the long-term public good, not just greenlighting every single consumer trend that captures the imagination of some group of citizens. Short-term home rental, for example, might have many benefits rightly appreciated by its users; it’s the task of city officials, though, to see how well such benefits scale and whether, in scaling, they begin to negatively affect the wellbeing of the community at large.
Finally, cities – and the people who lead them – should show more humility and stop flaunting their cosmopolitanism and uniqueness. The growing chasm between the countryside and the metropolis, often invoked in the context of explaining the populist rage of today, is also partially the consequence of letting history and globalisation run their own natural course, with all the policy debates focusing on cities and the non-urban areas being expected to fend for themselves. No wonder the countryside increasingly tends to revolt – it has been forgotten. Yet, what point is there in “greening” or “revitalising” the city if the price is environmental and economic devastation in the countryside – which, eventually, wreaks havoc on the city too?
Read next How Notre Dame is being rebuilt from 50 billion scraps of data How Notre Dame is being rebuilt from 50 billion scraps of data
While there is no guarantee of success, this revamped city agenda, attuned to the importance of the digital realm, has the potential not just to make our cities more liveable but to even restore some of the evaporating faith in the power of public institutions and democracy. Or, as we like to say in Barcelona: there’s no digital revolution without a democratic revolution.
Advertisement
Francesca Bria is chief technology and digital innovation officer for the city of Barcelona
More great stories from WIRED
– The Play Store is packed with nasty, violent games for kids
– Why does the London Tube still not have Wi-Fi in tunnels?
– Netflix's Love, Death & Robots is just tedious sexist sci-fi
Advertisement
– The grim reality of life under London's Gangs Matrix
– Care about online privacy? Then change your phone number

Story 132
Getty Images / Bloomberg / Contributor
Dixons Carphone doesn't have a good record with data. The owner of mobile retailer Carphone Warehouse and Currys PC World has been hit by two big customer data breaches in recent years and now it's revealed a 2017 hack was far worse than we originally thought.
The firm believes ten million customer records containing personal information were accessed in 2017, having originally said it was just 1.2 million records. What's more: it's found "evidence" that an unknown portion of this data may have been swiped from its systems. The data taken doesn't include payment card or bank account details.
Advertisement
Dixons Carphone admitted the new figure in a statement issued to customers and investors. It first found the data breach had happened in June 2018 but clearly hadn't figured out exactly what had happened.
When first announcing the breach the company said 1.2 million records – including, emails, names and home addresses – had been accessed. Dixons Carphone said in June that it didn't have "evidence that this information has left our systems". In addition, it said around 5.9 million cards had been impacted. On both occasions when confessing to the data breach, the company has said it believes no fraud has taken place as a result of the information being lost.
Read next Twitter needs to start exposing the UK's murky online propaganda Twitter needs to start exposing the UK's murky online propaganda
So what caused the increase in customer numbers impacted by the hack? In short: time. Europe's new General Data Protection Regulation (GDPR) requires companies to tell regulators about data breaches within 72 hours after they discover them. In this case Dixons Carphone will have had to inform the UK's Information Commissioner's Office (ICO) pretty soon after it discovered its problem.
The British Airways hack is impressively bad Hacking The British Airways hack is impressively bad
GDPR also says businesses suffering from data breaches must tell their customers if there's a "high risk of adversely affecting individuals’ rights and freedoms". In June 2018, when Dixons Carphone first publicly revealed the data breach a spokesperson said it had discovered the hack had happened during the week before.
Since then, the company has had more time to forensically analyse its IT systems to find out the full extent of the hack. So far it hasn't given any technical details of how customer information was accessed or taken. However, it's likely these will be revealed as investigations into what happened progress. Previously, Carphone Warehouse, one of the businesses owned by Dixons Carphone, was hit by a relatively straight-forward cyberattack and saw millions of records accessed.
Advertisement
The ICO issued Carphone Warehouse with a £400,000 fine in January 2018 following a cyberattack in 2015. The attack three years ago started in Vietnam and used fairly simple software to find a version of WordPress that hadn't been updated by Dixons Carphone. The ICO said it was "considerably out-of-date".
"The attacker accessed numerous databases," the ICO said in its report into the hack. The hacker ended up accessing the data of more than three million customers and 1,000 Carphone Warehouse employees. This included names, addresses, phone numbers, dates of birth, marital status and old credit card details.
The ICO, which is investigating the latest data breach, has the power to fine the company significantly more under GDPR than the £400,000 it previously issued. At the time it issued the fine for Carphone Warehouse, the ICO came to a damning conclusion: "[The Commissioner] remains of the view that deficiencies in Carphone Warehouse's technical and organisation measures created real risks of such data breaches, and that they played an essential casual role in this particular incident."

Story 133
ASSOCIATED PRESS
Spire Global, the San Francisco-based startup cofounded by Jeroen Cappaert, an alum of the Forbes 30 Under 30, has already orbited its 100th satellite.
The company's centennial package flew to space late Sunday aboard India’s Space Research Organization’s (ISRO) Polar Satellite Launch Vehicle (PSLV). The primary payload for this launch was an Indian military satellite. Spire's Lemur satellite was among 28 smaller satellites piggybacking for the ride.
Spire squarely targets the Earth observation space for both data and analytics, particularly in areas of the world that are not covered by other platforms. It tracks planes, ships and other vehicles in more remote regions of the world, and also provides weather forecasts. This service is particularly important in areas such as the far north, which is rapidly becoming more popular for ship traffic amid climate change.
Climate change is also driving the need for better weather reports, CEO Peter Platzer said in a statement. "Aside from efficiency and safety in the maritime and aviation field, we are seeing a rapidly rising demand -- and indeed, need -- for the operational provision of weather data to help governments, corporations, and individuals alike better adapt to ever more extreme, more frequent weather events," he said.
As is often the case for Spire, the company partnered with NanoRacks for the deployment. This is the first time the partners used a PSLV -- in the past, their platforms included the International Space Station and the commercial Cygnus cargo spacecraft made by Northrop Grumman.
Timothy Archibald for Forbes
"Collaboratively this is a big launch for both of us," said Jenny Barna, Spire's director of launch, in the same statement.
"Nanoracks launched our very first prototypes several years ago, so it's fitting that they launch our 100th Lemur satellite into space," she added. "Today, Spire partners with the most forward-thinking companies as an established leader in the data industry. That this is happening on [the] Nanoracks inaugural PSLV launch makes it that much sweeter."
Earlier this year, Spire and ICEYE -- also cofounded by Forbes 30 Under 30 alumni -- announced a joint project to fight crime on the high seas, such as piracy or illegal fishing. In particular, the companies plege to provide information on "dark vessels" that operate without the mandated Automatic Identification System (AIS) that broadcasts the location real-time of sailing ships.
Spire had modest beginnings in 2012, when the company launched its inaugural product -- ArduSat, an Arduino experiment -- via Kickstarter and raised nearly $107,000 from individuals. But the company has been extremely active since then, rapidly picking up Series A and Series B backers and most recently in 2017, raising $70 million in Series C funding. (Investors in the latest round included Luxembourg Future Fund.)
As the company is privately held, only limited financial information is available, but many indicators are pointing to growth. The company now has several worldwide offices and its stealth business unit alone reported 160% year-over-year revenue growth at the end of 2018.
Nanoracks stated that the latest PSLV opportunity was completed with Berlin-based Astro-und Feinwerktechnik Adlershof GmbH (Astrofein) (which manufactured and supplied deployers), as well as the commercial arm of ISRO, which is called Antrix.

Story 134
Rune Fisker
You are about to develop some new senses. This idea requires a bit of unpacking. The first thing to appreciate is that the brain is locked in silence and darkness inside the vault of the skull. All it ever has are electrical and chemical signals racing around among its specialised cells – it doesn’t directly see or hear or touch anything. Whether the information coming in represents air-compression waves from a symphony, patterns of light from a snow-covered statue, molecules floating off a fresh apple pie or the pain of a wasp sting, it’s all represented by voltage spikes in brain cells. And to a first approximation, it all looks the same.
But this prompts an as yet unanswered question in neuroscience: why does vision feel so different than smell or taste? Why is it that you would never confuse the beauty of a waving pine tree with the taste of feta cheese? Or the feeling of sandpaper on your fingertips with the smell of fresh espresso?
Advertisement
One might imagine this has something to do with the structure of the brain: the parts involved in hearing are different from the parts involved in touch. But upon closer examination, this hypothesis weakens. If you go blind, the part of the brain that we used to call the “visual cortex” gets taken over by touch and hearing. When looking at a rewired brain, it's difficult to insist that there’s anything fundamentally visual about the “visual” cortex after all.
So a different hypothesis has emerged: that the internal subjective experience of a sense – also known as its “qualia” – is determined by the structure of the data itself. In other words, information coming from the two-dimensional sheet of the retina has a different structure than data coming from the one-dimensional signal on the eardrum or from the multidimensional receptor data from the fingertips. As a result, they all feel different.
Read next Brain training apps don't really work. So why do we love them? Brain training apps don't really work. So why do we love them?
This suggests that, if we could feed a new data stream directly into the brain – such as data from a mobile robot or the state of your spouse’s microbiome or long-range infrared temperature data – it will give rise to a new qualia. It won’t feel like vision or hearing or taste or touch or smell, but something entirely novel.
It it difficult to imagine what such a new sense would be. In fact, it is impossible to imagine it. By analogy, try imagining a new colour. It seems like it should be a simple task, but it’s impossible.
Advertisement
But next year, we will be able to experience new senses at first hand by feeding new data streams into the brain. This could be a real-time feed of data from a drone, such as its pitch, yaw, roll, heading and orientation. It could be the activity on a factory floor or a Twitter feed or the stock market. And the result would be that the brain would have a direct perceptual experience of the drone, of manufacturing, of hashtags or of the real-time economic movements of the planet.
How to hack your memory and remember almost anything Science How to hack your memory and remember almost anything
This feels like pure fantasy but we are now finally at the point, technologically, where we can put it to the test.
Read next The psychological tricks designers use to make cities happier places The psychological tricks designers use to make cities happier places
There are two ways we can do this. The first is by implanting electrodes directly into the brain (or, soon enough, by stimulating the brain by small actuators in the blood stream or through nanorobots in cells). The second is to get signals to the brain non-invasively. My neuroscience laboratory and my company NeoSensory have together built wearable devices that deliver spatial patterns of vibration on the skin. Imagine wearing a wristband with multiple vibratory motors that stimulate different locations around your wrist to represent a data stream. When we establish a clear mapping between the information and the touch, people can come to easily understand how to act on the new data – and this will eventually lead to entirely new qualia.
Advertisement
Qualia develop over time. They are the brain’s way of summarising large amounts of data. Consider how babies “learn” how to use their ears by clapping their hands together or by babbling something out – and by catching the feedback in their ears. At first, the air compressions are just electrical activity in the brain; eventually they become experienced as sound. Such learning can also be seen with people who are born deaf and are fitted with cochlear implants as adults. At first, the experience of the cochlear implant is not like sound at all. A friend of mine described it as painless electrical shocks inside her head – she had no sense that it had anything to do with sound. But, after about a month, it became “sound”, albeit lousy sound, like a tinny and distorted radio. This is presumably the same process that happened to each of us when we were learning to use our ears. We simply don’t remember it.
If the ability to create new senses proves possible, a striking consequence is that we won't be able to explain the new sense to someone else. For example, you have to have experienced purple to know what purple is; no amount of academic description will enable a colour-blind person to understand purpleness. It is similarly futile to try to explain vision to someone born blind. To understand vision requires experiencing vision.
So it will go with the development of new senses. We will have to experience them to understand what they are like; and the only way to do this will be to experience the effect of data streams on our brains. Fortunately, in 2019, we’ll be able to plug in to find out.
Updated December 27, 2018: The headline of this article has been updated
Read next A vaccine for Alzheimer's is on the verge of becoming a reality A vaccine for Alzheimer's is on the verge of becoming a reality
David Eagleman is an adjunct professor in the department of Psychiatry & Behavioral Sciences at Stanford University and author of The Brain: The Story of You
More great stories from WIRED
– Inside the dark web's biggest hitman-for-hire website
– How BMW's new electric powertrain torpedos Tesla
Advertisement
– Google is no longer the best company to work for in the UK
– How to make sense of bitcoin's unrelenting death spiral
Get the best of WIRED in your inbox every Saturday with the WIRED Weekender newsletter

Story 135
SAN FRANCISCO, Feb. 19, 2019 (GLOBE NEWSWIRE) -- MobiledgeX, which is helping operators make edge infrastructure widely accessible and easy to use for third parties, today announced it has released MobiledgeX Edge-Cloud R1.0, which is powering the world’s first public mobile edge network deployment with Deutsche Telekom in Germany and live developer trials in the network. The solution connects mobile users to application cloud containers created by aggregating existing operator network resources. These containers execute close to end devices, meeting the stringent performance requirements of next-generation mobile innovations. MobiledgeX Edge-Cloud R1.0 is now in general availability globally and already supporting the prototyping of developer use cases in public networks.

Walter Goldenits, CTO of Telekom Deutschland in Germany, said: “Deutsche Telekom is proud to lead a global effort toward a smart, mobile, digital society and recognizes that ubiquitous edge availability is the foundation for this vision. For operators, Edge-Cloud R1.0’s ability to quickly aggregate existing 4G and 5G resources and make them available anywhere they are needed across the network means an extremely low barrier to entry for scalable edge deployments that can be immediately monetized. When edge networks are deployed widely, developers and device makers can more easily define business and use cases for new offerings that can be rolled out across a large number of users. The milestone announced today is an important moment not just for Deutsche Telekom and MobiledgeX, but the broader mobile ecosystem eager to capitalize on the massive edge opportunity in the lead-up to 5G.”
MobiledgeX Edge-Cloud R1.0 Supporting Mobile’s Most Promising Edge Use Cases
For developers, MobiledgeX Edge-Cloud R1.0 enables application containers to be deployed with the same simplicity as over-the-top, hyperscale datacenter-based cloud providers. At runtime, MobiledgeX Edge-Cloud R1.0 spins up the containers on-demand in edge cloud locations (also known as “cloudlets”) that optimally fulfill the needs of the desired application and user quality of experience. The solution powers compelling new use cases already live in networks today, including:
Automatically deploying application backends close to users based on their Verified Location and Identity. MobiledgeX Edge-Cloud R1.0 instantiates application containers to support streaming workloads similar to lambda functions ideally suited for increasingly immersive and massively multi-user workloads like multi-player gaming, robotics and AR maintenance that must ascertain trusted identity and location. The built-in “verified location” service automatically correlates GPS-reported location from the device using telemetry extracted from the mobile service provider’s infrastructure and directs mobile client to appropriate edge location.
MobiledgeX Edge-Cloud R1.0 instantiates application containers to support streaming workloads similar to lambda functions ideally suited for increasingly immersive and massively multi-user workloads like multi-player gaming, robotics and AR maintenance that must ascertain trusted identity and location. The built-in “verified location” service automatically correlates GPS-reported location from the device using telemetry extracted from the mobile service provider’s infrastructure and directs mobile client to appropriate edge location. Augmented Reality and Mixed Reality Performance Support. Makes lower latency available natively in the mobile network and geographically closer to end user devices. Enables AR and MR experiences on smart glasses or wearables where these devices do not natively provide the required CPU and GPU hardware capabilities, either due to cost, weight or power consumption reasons.
Makes lower latency available natively in the mobile network and geographically closer to end user devices. Enables AR and MR experiences on smart glasses or wearables where these devices do not natively provide the required CPU and GPU hardware capabilities, either due to cost, weight or power consumption reasons. Video and Image Processing That Meets Local Privacy Regulations. Platform guarantees in-country containment and privacy of user data, offering country-specific control planes that ensure country-specific applications and data remain in the country to satisfy GDPR and other privacy regulations.
MobiledgeX customers and partners are already using MobiledgeX Edge-Cloud R1.0 to enable a new breed of mobile applications.
Diana Hu, Head of Augmented Reality Platform for Niantic, said: “We’ve been hard at work on technology that bridges the physical and digital worlds to pave the way for new entertainment experiences. To achieve shared, multiplayer experiences, and translate environments in real time, Niantic’s platform requires a low latency network and high bandwidth to enable a large number of users to play shared AR experiences. Edge software makes deployment and discovery of backend services very easy. MobiledgeX Edge-Cloud R1.0 delivers just that.”
Piotr Wojcik, Co-founder and CEO/CTO for 1000 realities said: “Access to edge is ‘make or break’ for our business to work and scale, without the need for an on-premise local data center. Access to existing mobile operator infrastructure and edge services via MobiledgeX allows us to seamlessly scale our business faster and without the need for additional effort.”
Breakthrough Edge Capabilities for Operators and Developers
MobiledgeX Edge-Cloud R1.0 delivers the following new key features:
Device and platform-independent SDKs for Android and IOS devices in Java, C++, C# or REST that support edge node discovery, built-in identity and verified location services, with the ability to connect automatically to the nearest edge location. MobiledgeX will release these SDKs as open source to speed development times and flexibility.
for Android and IOS devices in Java, C++, C# or REST that support edge node discovery, built-in identity and verified location services, with the ability to connect automatically to the nearest edge location. MobiledgeX will release these SDKs as open source to speed development times and flexibility. A Distributed Matching Engine (DME) that is natively borne and integrated into Telekom Deutschland’s mobile network in Germany. The DME allows developers to ensure the identity and location of application users while guaranteeing their privacy as this data remains within the boundaries of the mobile service provider and is not disclosed to MobiledgeX.
that is natively borne and integrated into Telekom Deutschland’s mobile network in Germany. The DME allows developers to ensure the identity and location of application users while guaranteeing their privacy as this data remains within the boundaries of the mobile service provider and is not disclosed to MobiledgeX. A fully multi-tenant control plane that supports zero-touch provisioning of edge cloud resources via a Cloudlet Resource Manager . This architecture is massively scalable based on the number of distributed edge cloud locations and enables the operator to bring any combination of compute, storage and network resource pools to add to capacity independently of a preferred Virtualization Infrastructure Management (VIM) layer. For example, while Deutsche Telekom edge cloud resource pools are virtualized using OpenStack, MobiledgeX Edge-Cloud R1.0 equally supports other industry-standard VIMs such as VMware or native Kubernetes.
that supports zero-touch provisioning of edge cloud resources via a . This architecture is massively scalable based on the number of distributed edge cloud locations and enables the operator to bring any combination of compute, storage and network resource pools to add to capacity independently of a preferred Virtualization Infrastructure Management (VIM) layer. For example, while Deutsche Telekom edge cloud resource pools are virtualized using OpenStack, MobiledgeX Edge-Cloud R1.0 equally supports other industry-standard VIMs such as VMware or native Kubernetes. A global edge cloud SAAS portal that allows operators to visualize application delivery performance and developers to deploy their application containers.
MobiledgeX Edge-Cloud R1.0 will be on display powering one of the latest edge use cases in the Deutsche Telekom booth in Hall 3 at Mobile World Congress in Barcelona.
About Deutsche Telekom AG Deutsche Telekom is one of the world’s leading integrated telecommunications companies, which provides fixed-network/broadband, mobile communications, Internet and IPTV products and services for consumers, and information and communication technology solutions for business and corporate customers. DTAG owns several affiliate companies such as its telecommunication entity in Germany Telekom Deutschland GmbH (TDG), and various others across middle and eastern Europe in countries like Poland (T-Mobile Poland), Austria (T-Mobile Austria), etc.
About Niantic, Inc. Niantic, Inc., builds mobile real-world experiences that foster fun, exploration, discovery and social interaction. The company’s immersive real-world mobile games Pokémon GO and Ingress are currently available on the App Store and Google Play. Harry Potter: Wizards Unite is Niantic, Inc.’s third game and is being co-developed with Warner Bros. Interactive Entertainment. Niantic has also developed its industry-leading Niantic Real World Platform which allows unprecedented ways to model, understand, and share reality. Originally incubated within Google, Niantic, Inc., spun out in 2015, with investments from Google, The Pokémon Company, and Nintendo. More recently, Niantic was valued at over $2 billion with Series-B funding led by Spark Capital, NetEase and other investors. For more information on Niantic, visit www.nianticlabs.com .
About 1000 realities 1000 realities is a software studio focused on Virtual Reality (VR) and Augmented Reality (AR). We craft fully immersive, interactive applications which will enchant your customers. We create new, mind-blowing realities, where human imagination is the only limit. Our solutions can be applied for endless purposes in many different fields, from virtual visits, marketing, promotion, brand storytelling to HR/employer branding projects and interactive trainings and simulations. We will help you to enhance brand engagement and business-to-consumer interactions, present your project with an amazing sensation of truly ‘living’ the story you find yourself in or create an immersive, super engaging tool for training your employees/engineers.
About MobiledgeX Inc. MobiledgeX Inc. is building a marketplace of edge resources and services that will connect developers with the world’s largest mobile networks to power the next generation of applications and devices. MobiledgeX is an edge computing company founded by Deutsche Telekom AG and headquartered in San Francisco, California.
A photo accompanying this announcement is available at http://www.globenewswire.com/NewsRoom/AttachmentNg/4e9e4d15-438f-47b5-8c2b-721cfdf008a1
Brian Baumley BLB Communications for MobiledgeX

Story 136
Koki Nagahama/Getty Images
The world's population is aging while many countries' birth rates fail to keep up.
There are now more people over the age of 65 than there are under the age of five - a dispersion that's never occurred before, according to Deutsche Bank.
The data point is part of a broader trend with widespread consequences for productivity, inflation, and global growth, economists say.
Fund managers are taking notice of "secular stagnation" conditions often associated with persistent low inflation and low growth, and adjusting their allocations accordingly.
The world's population isn't getting any younger. In fact, it's getting much, much older. And that has sweeping implications for global growth, economists contend.
There are now more people on Earth older than 65 than younger than five for the first time, according to a Deutsche Bank analysis of United Nations data, Haver Analytics data, and the firm's global research.
The extreme data point underscores a broader economic trend that some economists are warning clients about: declining fertility rates lead to an aging population, which is thought to usher in depressed productivity, labor-force participation, and stagnant inflation. More indirect results of declining birth rates may also have an impact on macroeconomic factors like homeownership.
Read more: 10 countries at risk of becoming demographic time bombs
The chart below, from Torsten Sløk, Deutsche Bank's chief international economist, shows the world population of those under the age of five and those older than 65. While the under-five population has held relatively steady for the last two decades, the above-65 population has only risen.
Deutsche Bank
"The key issue for investors in equities, rates, and credit is if the global economy is able to generate enough productivity growth to offset these demographic trends," Sløk wrote to clients Tuesday. "And for [foreign exchange] the question is which parts of the world will be hit harder than others by a demographic slowdown in growth."
Sløk cited "secular stagnation," which is the Larry Summers-endorsed theory to which this pattern is connected.
It's known as a condition wherein savings rise and investment slows, causing economic growth to stall out. Summers, the former Clinton-era Treasury secretary and Obama-era National Economic Council director, has argued the condition may be the "defining macro-economic challenge of our times."
Generally, fertility rates around the world have fallen below "replacement" levels, or below the level that can support population growth, said Ed Yardeni, president of Yardeni Research. And that "baby bust" is weighing on global growth.
Read more: The US is in the danger zone for a 'demographic time bomb,' and the high cost of childcare could be partially to blame
Yardeni - who has long written about the economic impact of an aging population, particularly in China - said the US has a fertility rate slightly below replacement.
"Our fertility is right around replacement," Yardeni told Markets Insider in an interview on Tuesday. "So we're not as advanced in the birth dearth and on this kind of road to self-extinction as Japan is, and China, and some other countries."
Wall Street is taking note of the broader "stagnation" theme associated with an aging population. For a second straight month, the theme dominated Bank of America Merrill Lynch's Global Fund Manager survey, which takes the pulse of how big-money managers view global markets and economies.
Fund managers said last week their "longs" in February were traditionally low-growth investments like cash, emerging markets, and REITs, while shorting cyclical sectors.
Here's a chart from the firm showing features of what the firm calls the "return" of secular stagnation - 55% of investors surveyed now see both below-trend growth and below-trend inflation over the next year.
Bank of America Merrill Lynch
To be sure, others contend there is no clear negative association between an aging population and declining growth.
A 2017 paper by Daron Acemoglu, a Massachusetts Institute of Technology economist, and Pascual Restrepo, an assistant professor at Boston University, found that contrary to the themes and concepts Summers and others have popularized, there is "no negative relationship between between population aging and slower growth of GDP per capita."
In a counterintuitive result, they found that countries undergoing rapid aging have grown more in recent decades, likely reflecting a faster adoption of labor-replacing technologies and automation.
The paper concluded: "There is a clear need for future work that systematically investigates the relationship between demographic change and GDP growth as well as the channels via which this relationship works."
Now read:

Story 137
When Clemson and Texas A&M hit the field at Death Valley on Saturday, it will be only the sixth meeting between the two programs. Check out their series history below.
Though they haven't met often, last year's game was memorable. Then-No. 2 Clemson held off the Aggies, 28-26, by intercepting Texas A&M's two-point conversion attempt.
Clemson-Texas A&M: All-time series history, scores
Texas A&M leads the series 3-2 all-time. However, Clemson has won the last two, including a 28-26 escape from College Station in 2018.
WEEK 2 PREVIEW: The top games, what you can't miss and the Top 25 rankings
Date Winner Score Loser Location Sept. 7, 2019 TBD TBD TBD Clemson, South Carolina Sept. 8, 2018 No. 2 Clemson 28-26 Texas A&M College Station, Texas Sept. 3, 2005 Clemson 25-24 No. 17 Texas A&M Clemson, South Carolina Sept. 18, 2004 Texas A&M 27-6 Clemson College Station, Texas Sept. 14, 1974 Texas A&M 24-0 Clemson College Station, Texas Oct. 6, 1973 Texas A&M 30-15 Clemson Clemson, South Carolina
This year's matchup will be the first time both teams are ranked when facing each other.
Here's a look at how the programs compare historically and for the 2019 season:
Clemson
Tale of the Tape Texas A&M
1-0 2019 record 1-0 No. 1 AP Ranking No. 12 Dabo Swinney
(117-30) Coach
(Record at school, career) Jimbo Fisher
(10-4, 93-27) 3
(1981, 2016, 2018) National championships 2
(1919, 1939) Trevor Lawrence
168 yards (1 TD, 2 INT) Top passer Kellen Mond
194 yards (3 TD, 1 INT) Travis Etienne
205 yards (3 TDs) Top rusher Isaiah Spiller
106 yards Tee Higgins
98 yards (TD) Top receiver Quartney Davis
85 yards (TD) Isaiah Simmons
10 tackles Top defender Roney Elam
5 tackles, sack, INT def. Georgia Tech, 52-14 Last week def. Texas State, 41-7
COLLEGE FOOTBALL POLLS: This week's Top 25 rankings
Clemson-Texas A&M: Notable games in the series
No. 2 Clemson 28, Texas A&M 26 (Sept. 8, 2018 in College Station, Texas)
In one of Kelly Bryant's final starts, the second-ranked Tigers barely got out of Texas with a win. It was also one of a couple close games for the eventual national champions. Clemson intercepted A&M's two-point conversion attempt in the final minute that would have tied the game.
The Aggies outgained Clemson by almost 100 yards (501 to 413), but also lost two fumbles and missed a pair of field goals.
Bryant was 12-for-17 for 205 yards and a touchdown and also led the team with 54 rushing yards and a score. Freshman Trevor Lawrence, who would take over as the starter a few weeks later, did start the second half. He was 5-for-9 for 93 yards and a touchdown.
Texas A&M QB Kellen Mond was busy, throwing for 430 yards and three touchdowns.
While Clemson eventually won its second national crown in three years, Texas A&M regrouped to finish 9-4 and No. 16 in the polls.
Watch Lawrence to Higgins 64-yd TD
Clemson 25, No. 17 Texas A&M 24 (Sept. 3, 2005 in Clemson, South Carolina)
Jad Dean set a school record with six field goals, the last from 42 yards out in the final seconds — an attempt saved thanks to the holder on a low snap. Dean made kicks of 21, 21, 25, 18, 44 and 42 yards.
Clemson played the fourth quarter without starting QB Charlie Whitehurst, who left with a head injury. Will Proctor then took over.
Aggies QB Reggie McNeal hit the century mark in both passing (110 yards) and rushing (100 yards). He also gave A&M the lead in the fourth quarter on a 31-yard scoring pass to Chad Schroeder.
After the two teams exchanged punts, Tigers RB James Davis picked up 33 on eight straight carries on the winning drive.
Texas A&M 27, Clemson 6 (Sept. 18, 2004 in College Station, Texas)
Clemson came in ranked No. 25 in the Coaches Poll, but the Aggies crushed the Tigers.
Texas A&M gained 502 yards and was plus-5 in turnovers. Running back Courtney Lewis had 165 yards and two touchdowns, with QB Reggie McNeal totaled 178 passing and 129 rushing yards.
Clemson struggled, as QB Charlie Whitehurst threw three interceptions. The Tigers rushed for only 58 yards on 27 carries.
SEASON STATS: The nation's leaders in passing, rushing and more
Texas A&M 24, Clemson 0 (Sept. 14, 1974 in College Station, Texas)
The Aggies' defense, led by All-American Ed Simonini, dominated. Clemson used three quarterbacks in the shutout.
A&M's offense piled up 434 rushing yards, with Bubba Bean's 182 pacing the attack. Combined with the previous year's effort, Bean ran for 386 yards on 40 carries in two wins against Clemson.
Texas A&M 30, Clemson 15 (Oct. 6, 1973 in Clemson, South Carolina)
Bubba Bean had his first of two big games against Clemson, needing only 22 attempts to rush for 204 yards. As a team, the Aggies had 385 rushing yards on 60 carries.
But Clemson did have one play that still stands in the program's record book. Mitch Tyner set a school record with an 81-yard punt. On the Tigers' first possession, Tyner's punt went from Clemson's 19 to the end zone.

Story 138
Getty Images
Over the course of our lifetimes, women face a financial shortfall of £223,000 in earnings and £106,000 in pensions — that's according to a promoted tweet from investment firm Aviva.
There's one problem: Aviva's own gender gap reporting reveals it pays women less than men. Thanks to government mandated figures, we know that in 2018 Aviva paid women 27 per cent less than men — both by a mean or median comparison — with more women working in lower-paid jobs than men, who dominate the more lucrative roles. While Aviva doles out the same number of bonuses to women as men, they are worth on average half the amount. The figures are roughly the same as in 2017.
Advertisement
As the Aviva ad was on Twitter, the backlash was immediate, with people arguing that "suggesting saving when we're already dealing with a pay gap is hilarious" and offering advice to "close your own gap before you patronise women for not saving."
Aviva isn't the only company to use feminism to promote a product while failing to have its own house in order. KPMG ran a series of ads about shattering glass ceilings in 2015, but last year was sued for gender discrimination. Audi ran an ad about discrimination about girls, but had no women on the board, and International Women's Day is annually co-opted by brands to push their products, be it whiskey or Barbie dolls. UBS ran an ad on International Women's Day in 2017; this year the Financial Times reported it was refusing to restore full bonuses to bankers returning to maternity leave.
Read next We're all to blame for Wikipedia's huge sexism problem We're all to blame for Wikipedia's huge sexism problem
Such messaging can be positive, even if the companies behind the campaigns aren't delivering on their own promises. "The constant, continual reinforcement of messages about women's equality and new ideals of femininity… does make a difference to cultural values, there's no doubt about that," says Pauline Maclaran, professor of marketing at Royal Holloway, University of London. "There is an upside even if the companies are being slightly hypocritical in their own practises."
However, the mismatch between advertising and actions can harm brands, Maclaran says. "Companies can easily jump on this bandwagon, and create an advertising campaign to help women feel more empowered — like Aviva has done — but they very quickly get exposed for not being authentic, for being hypocritical," says Maclaran. "And people share these very quickly on social media, so it can really work against the company if they are not practicing what they preach."
Advertisement
Aviva said it had seen thousands of shares, likes and supportive comments across the promoted tweets. And that is true: across three promoted tweets, Aviva garnered 1,756 likes and 397 retweets. However, below each of the tweets was a string of criticism, from "thanks for the tips on how I can take personal responsibility for addressing structural inequality" to "sexist targeted ads do not work".
The company said that the goal was to raise awareness and "empower women to make changes to their finances". A spokesperson said: "There are unquestionably many women who are on top of their finances and managing them well, so we knew that this campaign could be divisive. However, we also felt we couldn’t ignore the evidence which shows if you're a woman in the UK today, the chances are you'll have less in your savings and pension than a man of the same age."
That is directly contradicted by research from NEST, the workplace pension scheme set up by the government as part of its auto enrollment scheme. The average account balance and pension contribution for men is higher, it says in a recent report analysing its own membership, "driven by female average earnings being lower than males in aggregate." But, if figures are adjusted for earnings, women have either the same or higher account balances and pension contributions than men making a similar amount. "It's also a little shaming, saying women aren't saving as much as men and it's their fault," adds Sarah Banet-Weiser, head of media and communications at London School of Economics.
Read next YouTube's plan to fix hate speech failed before it even started YouTube's plan to fix hate speech failed before it even started
Regarding Aviva's own pay gap, a spokesperson said: "We are not proud of our gender pay gap, but we are absolutely committed to closing it. We are taking a number of steps to achieve this, focusing on recruitment, progression and retention." Those actions include equal parental leave, a women in leadership programme, balanced candidate shortlists for senior positions, rehiring ex-employees who have taken a career break, and supporting flexible working.
Advertisement
Getting your own house in order doesn't wholly mitigate criticism. Hair product maker TRESemme is currently running a campaign in the UK focused on imposter syndrome, highlighting via a survey the company commissioned that nine in ten UK women experience it — before describing it as "just a little self doubt".
TRESemme is owned by Unilever, the same multinational giant that produces Dove, Lynx, Magnum and plenty more. The company's board has four women out of 11 positions, and manages to cram in a few more female faces via non-executive director roles. In the UK, it pays women 8.2 per cent on average more than men, and women hold just shy of half of the highest paid positions, while its central resources arm pays about the same, regardless of gender. Unilever has even pledged to remove sexism from its ads — a considerable move from the company behind Lynx. Unilever did not respond to a request for comment.
But the company's progress hasn't prevented criticism of TRESemme's campaign. "I reckon imposter syndrome is likely to come from the patriarchal system in which we work, not whether we're having a good hair day," one critic tweeted, while another sarcastically added that it was a good way to get "emotionally vulnerable people to become brand loyal ambassadors". Treating women fairly in the office is important, but it doesn't make up for ill-judged advertising. "You can't just take something that is circulating in media and trending like imposter syndrome and attach it to your product," says Banet-Weiser. TRESemme is offering online classes designed to help women overcome feeling less worthy, a move Banet-Weiser says is intriguing but still limited. "It's also just about you. It doesn't do anything to challenge the reasons why we feel like imposters in the first place."
And no wonder the missteps, when advertising agencies remain predominantly staffed by men. According to 2016 figures from the Institute of Practitioners in Advertising, the top-levels of advertising firms were 30 per cent female, though the gender gap closes among junior staff. Other figures, from Creative Equals, suggest only one in ten creative directors are women — perhaps it's no surprise then that 90 per cent of women polled by the company say advertisers don't understand them and seven in ten say they feel alienated by advertising.
Read next Google's Image search has a massive celebrity sexism problem Google's Image search has a massive celebrity sexism problem
"Women need to have more say, and more strategic roles," says Maclaran. "You still find in the ad agencies, the big jobs, the juicy ones and creative jobs, are often still dominated by men. So even a woman working in that area will have to conform to the cultural expectation of what is a still a masculine environment."
Even with women in charge of advertising companies and sitting on the boards of their customers, marketing isn't the best way to spread feminism, explains Banet-Weiser, calling it commodity activism. "When you harness political goals to your product, it's necessary that you're going to have to sort of defang some of those politics, dilute them in some way," she says. "One result of that is companies who do want to put feminism in their ads are going to choose really, really safe parts of feminism." And playing it safe might sell investment products, but it isn't going to push gender-pay progress.
More great stories from WIRED
– Care about online privacy? Then change your phone number
– There's a surge in dodgy Facebook adverts about Brexit
– Inside the vulnerable fame of YouTube's child ASMR stars
Advertisement
– I tried to keep my baby secret from Facebook and Google
– How SoftBank became the most powerful company in tech

Story 139
All 16,000 buses in the fast-growing Chinese megacity are now electric, and soon all 22,000 taxis will be too
You have to keep your eyes peeled for the bus at the station in Shenzhen’s Futian central business district these days. The diesel behemoths that once signalled their arrival with a piercing hiss, a rattle of engine and a plume of fumes are no more, replaced with the world’s first and largest 100% electric bus fleet.
Shenzhen now has 16,000 electric buses in total and is noticeably quieter for it. “We find that the buses are so quiet that people might not hear them coming,” says Joseph Ma, deputy general manager at Shenzhen Bus Group, the largest of the three main bus companies in the city. “In fact, we’ve received requests to add some artificial noise to the buses so that people can hear them. We’re considering it.”
We’ve received requests to add artificial noise to the buses so people can hear them Joseph Ma
The benefits from the switch from diesel buses to electric are not confined to less noise pollution: this fast-growing megacity of 12 million – which was a fishing village until designated China’s first “special economic zone” in the 1980s – is also expected to achieve an estimated reduction in CO2 emissions of 48% and cuts in pollutants such as nitrogen oxides, non-methane hydrocarbons and particulate matter. Shenzhen Bus Group estimates it has been able to conserve 160,000 tonnes of coal per year and reduce annual CO2 emissions by 440,000 tonnes. Its fuel bill has halved.
Facebook Twitter Pinterest Shenzhen was a fishing town of 30,000 people in the late 1970s. Photograph: Getty Images
“With diesel buses I can remember standing at the bus stop and the heat, noise and emissions they generated made it unbearable in the summer,” says Ma. “The electric buses have made a tremendous difference.”
China’s drive to reduce the choking smog that envelops many of its major cities has propelled a huge investment in electric transport. Although it remains expensive for cities to introduce electric buses – one bus costs around 1.8 million yuan (£208,000) – Shenzhen was able to go all-electric thanks to generous subsidies from both central and local government.
Story of cities #39: Shenzhen – from rural village to the world's largest megalopolis Read more
“Typically, more than half of the cost of the bus is subsidised by government,” says Ma. “In terms of operation there is another subsidy: if we run our buses for a distance of more than 60,000km we receive just under 500,000 yuan [£58,000] from local government.” This subsidy is put towards reducing the cost of the bus fares: “The government looks at the public transport very much as social welfare.”
To keep Shenzhen’s electric vehicle fleet running, the city has built around 40,000 charging piles. Shenzhen Bus Company has 180 depots with their own charging facilities installed. One of its major depots in Futian can accommodate around 20 buses at the same time. “Most of the buses we charge overnight for two hours and then they can run their entire service, as the range of the bus is 200km per charge,” says Ma.
Availability of charging stations is a major factor in why it is it difficult for other cities around the world to switch to all-electric bus fleets, but China being a one-party state hasn’t necessarily made it any easier in Shenzhen. “We have some of our own depots, but we also have to rent some from the municipal government, as well as from the private sector,” says Ma. “Aside from the subsidies in terms of purchasing the buses, we are very much left to ourselves to how we look for resources for our charging infrastructure.”
Facebook Twitter Pinterest Shenzhen Bus Company deputy general manager Joseph Ma. Photograph: Matthew Keegan
Getting the required charging infrastructure for taxis is proving more challenging. By the end of this month, all of Shenzhen’s 22,000 taxis are required to switch to electric. Shenzhen Bus Company has switched its entire fleet of 4,600 taxis to electric ahead of schedule.
“For taxis it’s more about distribution than the number of charging pillars because taxis run all over the place and they have no fixed routes,” says Ma. “We are looking at all sorts of different solutions – from parking spaces in public areas like municipal parks and some of the major government venues, as well as temporary sites in local villages that might have communal land we can hire.”
The lack of charging stations is causing friction between taxi drivers. “You always hear about fights between taxi drivers trying to get into the charging stations and things like that,” says Ma. “It’s difficult for the drivers because obviously they can’t go too far out of the way to charge the taxis.”
His firm is developing an app to track where charging spaces are available and notify drivers in real time.
Too expensive outside China?
More than 30 Chinese cities have made plans to achieve 100% electrified public transit by 2020, including Guangzhou, Zhuhai, Dongguan, Foshan and Zhongshan in the Pearl River Delta; and Nanjing, Hangzhou, Shaanxi and Shandong.
Urban mountains: Shenzhen's green rooftop project – in pictures Read more
But with central government planning to withdraw subsidies by 2020, introducing electric buses elsewhere could be too expensive.
There is also geography to consider. Shenzhen is fairly flat, but the hills of nearby Hong Kong have proven too much in trials of electric buses. Other cities in northern China have struggled with battery power in the extreme cold of winter.
Facebook Twitter Pinterest A hybrid electric bus in midtown Manhattan. Photograph: Peter Foley/EPA
Meanwhile, cities such as London and New York are accelerating their drive towards electric buses. London plans to make all single-decker buses emission-free by 2020, and all double-deckers hybrid by 2019. New York plans to make its bus fleet all-electric by 2040.
Riding the 222 bus the length of Shenzhen’s CBD, you hear little sound other than a soft whine when the driver accelerates. The easy-to-clean hard plastic seats are not the most comfortable but most passengers opt to stand anyway – a choice made easier by the smoothness of the ride.
Rolling into our destination, the doors open with a beep, beep, beep – the loudest noise the bus has made the entire journey.
“It’s quieter, smoother and I only pay the same fare as before,” says Lai, a regular passenger. “I would say most people here are happy with the switch.”
Follow Guardian Cities on Twitter, Facebook and Instagram to join the discussion, and explore our archive here

Story 140
Die Formel 2 schließt sich der Formel 1 in der kommenden Saison an und reist zur neuen Austragungsstätte nach Zandvoort. Frankreich raus aus dem Kalender.
Motorsport-Magazin.com - Die beiden Nachwuchsserien Formel 2 und Formel 3 haben an diesem Dienstag ihre Rennkalender für die Saison 2020 offiziell präsentiert. Beide Rennserien gastieren auch im kommenden Jahr im Rahmenprogramm der Formel 1, die mit 22 Grands Prix vor der umfassendsten Saison ihrer Geschichte steht.
Die Formel 2, in der Mick Schumacher dieses Jahr sein Debüt gibt, reist 2020 zusammen mit der Formel 1 zur neuen Austragungsstätte nach Zandvoort. Vom 01. Bis 03. Mai gibt die Königsklasse auf dem niederländischen Dünenkurs ihr Comeback. Auch die Formel 3 trägt ihre Rennen in Zandvoort aus.
Während der Formel-2-Rennkalender mit zwölf Veranstaltungen stabil bleibt - Zandvoort ersetzt Paul Ricard in Frankreich - stehen der Formel 3 in der kommenden Saison neun statt wie bisher acht Rennwochenenden bevor. In Deutschland müssen die Fans nicht nur auf die Formel 1, sondern auch auf die beiden Nachwuchsformeln weiterhin verzichten.
Die vorgestellten Rennkalender sind provisorisch, bis sie beim nächsten Treffen des World Motor Sport Council am 04. Oktober in der Michael-Schumacher-Ausstellung in Köln final abgesegnet werden. Wann Formel 2 und Formel 3 ihre Vorsaison-Testfahrten austragen, wurde noch nicht kommuniziert.
Die aus der GP2-Serie hervorgegangene Formel 2 beginnt die Saison 2020 vom 20. bis 22. März in Bahrain. Durch die Hinzunahme von Zandvoort (01.-03. Mai) verkürzt sich im Vergleich zum Vorjahr die Wartezeit bis zum nächsten Rennen in Barcelona (08.-10. Mai). Mit dem Stadt-Klassiker in Monaco (21.-23. Mai) erwartet die Nachwuchspiloten der Formel 2 ein vollgepackter Monat.
Anfang Juni reist die Formel 2 nach Baku, bevor die Sommerpause beginnt. Nach der Unterbrechung geht es im österreichischen Spielberg (03.-05. Juli) weiter. Auf dem Red Bull Ring trägt die F2 ihre sechste Saisonveranstaltung aus, bevor es in die zweite Saisonhälfte mit Rennen in Silverstone, Budapest, Spa, Monza und Sochi weitergeht. Das Finale steigt vom 27. bis 29. November in Abu Dhabi.
Formel-2-Rennkalender 2020
Rennen Austragungsort Datum 1 Sakhir, Bahrain 22.-23. März 2 Zandvoort, Niederlande 01.-03. Mai 3 Barcelona, Spanien 08.-10. Mai 4 Monte-Carlo, Monaco 21.-23. Mai 5 Baku, Aserbaidschan 05.-07. Juni 6 Spielberg, Österreich 03.-05. Juli 7 Silverstone, England 17.-19. Juli 8 Budapest, Ungarn 31. Juli - 02. August 9 Spa, Belgien 28.-30. August 10 Monza, Italien 04.-06. September 11 Sotschi, Russland 25.-27. September 12 Yas Marina, Abu Dhabi 27.-29. November
Formel-3-Rennkalender 2020

Story 141
Vanderbilt won the 2019 College World Series and a national title thanks to an 8-2 win Wednesday night in Omaha. The Commodores previously won the 2014 championship.
On Monday, the Wolverines won, 7-4, in Game 1. But Vanderbilt then won 4-1 on Tuesday before winning again on Wednesday.
CWS 2019: Full tournament bracket | Printable CWS bracket | CWS info & tickets | Shop latest CWS gear
Here's the 2019 NCAA Division I baseball tournament bracket and College World Series bracket.
VANDY WINS: 3 years after the devastating death of a teammate, Vanderbilt wins College World Series
NCAA college baseball bracket 2019
THE BRACKET: Field of 64 | College World Series
Let's take a look at what you need to know about the 2019 NCAA tournament.
2019 NCAA Division I baseball tournament: CWS schedule and results
2019 NCAA Division I baseball tournament: How it works
It took a while to get to the format that takes place today. From the 1947 field of eight to the current field of 64, the bracket has gone through several upheavals in its day. The current 64-team bracket began in 1999 with the addition of the super regions and took one more step forward by making the College World Series finals a best-of-three series in 2003.
Of the 64-team field, 31 receive automatic qualifying bids for winning their conferences, while the NCAA Division I Baseball Committee selects the final 33 teams. Sixteen of those teams receive a national seed and could host the Super Regional tournament should they advance.
Then the fun begins.
SHOP CWS GEAR: Florida State | Louisville | Michigan | Mississippi State | Texas Tech | Vanderbilt
Regionals: The first round of play has 64 teams split into 16 four-team brackets, seeded No. 1 through 4 and playing a double-elimination tournament.
Super Regionals: The 16 teams that advance from the regionals are paired into eight super regions. The teams will play a best-of-three series to see who advances to Omaha.
College World Series: The eight winners of the Super Regional tournaments head to TD Ameritrade Park in Omaha, Nebraska. Each of the eight teams is given a seed and split into two four-team brackets. The two winners of each bracket square off in a best-of-three College World Series finals.
For a detailed look at how the College World Series works, click here.
College World Series: History
California defeated Yale in the first-ever College World Series, the first of two played in Kalamazoo, Michigan. Texas put itself on the map as the first back-to-back champions in winning the only CWS ever played in Wichita, Kansas in 1949. The following season Texas won its second championship, opening Rosenblatt Stadium in Omaha.
CWS HISTORY: Coaches with most wins | Most titles | Most appearances | Conferences most represented
Here's a complete list of all the College World Series finals in the 72-year history of the event.
YEAR CHAMPION (RECORD) COACH SCORE RUNNER-UP SITE 2018 Oregon State (55-12-1) Pat Casey 5-0 Arkansas Omaha, Neb. 2017 Florida (52-19) Kevin O'Sullivan 6-1 LSU Omaha, Neb. 2016 Coastal Carolina (55-18) Gary Gilmore 4-3 Arizona Omaha, Neb. 2015 Virginia (44-24) Brian O'Connor 4-2 Vanderbilt Omaha, Neb. 2014 Vanderbilt (51-21) Tim Corbin 3-2 Virginia Omaha, Neb. 2013 * UCLA (49-17) John Savage 8-0 Mississippi State Omaha, Neb. 2012 * Arizona (48-17) Andy Lopez 4-1 South Carolina Omaha, Neb. 2011 * South Carolina (55-14) Ray Tanner 5-2 Florida Omaha, Neb. 2010 South Carolina (54-16) Ray Tanner 2-1 (11 inn.) UCLA Omaha, Neb. 2009 LSU (56-17) Paul Mainieri 11-4 Texas Omaha, Neb. 2008 Fresno State (47-31) Mike Batesole 6-1 Georgia Omaha, Neb. 2007 * Oregon State (49-18) Pat Casey 9-3 North Carolina Omaha, Neb. 2006 Oregon State (50-16) Pat Casey 3-2 North Carolina Omaha, Neb. 2005 * Texas (56-16) Augie Garrido 6-2 Florida Omaha, Neb. 2004 Cal St. Fullerton (47-22) George Horton 3-2 Texas Omaha, Neb. 2003 Rice (58-12) Wayne Graham 14-2 Stanford Omaha, Neb. 2002 * Texas (57-15) Augie Garrido 12-6 South Carolina Omaha, Neb. 2001 * Miami (Fla.) (53-12) Jim Morris 12-1 Stanford Omaha, Neb. 2000 * LSU (52-17) Skip Bertman 6-5 Stanford Omaha, Neb. 1999 * Miami (Fla.) (50-13) Jim Morris 6-5 Florida State Omaha, Neb. 1998 Southern California (49-17) Mike Gillespie 21-14 Arizona State Omaha, Neb. 1997 * LSU (57-13) Skip Bertman 13-6 Alabama Omaha, Neb. 1996 * LSU (52-15) Skip Bertman 9-8 Miami (Fla.) Omaha, Neb. 1995 * Cal St. Fullerton (57-9) Augie Garrido 11-5 Southern California Omaha, Neb. 1994 * Oklahoma (50-17) Larry Cochell 13-5 Georgia Tech Omaha, Neb. 1993 LSU (53-17-1) Skip Bertman 8-0 Wichita State Omaha, Neb. 1992 * Pepperdine (48-11-1) Andy Lopez 3-2 Cal St. Fullerton Omaha, Neb. 1991 * LSU (55-18) Skip Bertman 6-3 Wichita State Omaha, Neb. 1990 Georgia (52-19) Steve Webber 2-1 Oklahoma State Omaha, Neb. 1989 Wichita State (68-16) Gene Stephenson 5-3 Texas Omaha, Neb. 1988 Stanford (46-23) Mark Marquess 9-4 Arizona State Omaha, Neb. 1987 Stanford (53-17) Mark Marquess 9-5 Oklahoma State Omaha, Neb. 1986 Arizona (49-19) Jerry Kindall 10-2 Florida State Omaha, Neb. 1985 Miami (Fla.) (64-16) Ron Fraser 10-6 Texas Omaha, Neb. 1984 Cal St. Fullerton (66-20) Augie Garrido 3-1 Texas Omaha, Neb. 1983 * Texas (66-14) Cliff Gustafson 4-3 Alabama Omaha, Neb. 1982 * Miami (Fla.) (55-17-1) Ron Fraser 9-3 Wichita State Omaha, Neb. 1981 Arizona State (55-13) Jim Brock 7-4 Oklahoma State Omaha, Neb. 1980 Arizona (45-21-1) Jerry Kindall 5-3 Hawaii Omaha, Neb. 1979 Cal St. Fullerton (60-14-1) Augie Garrido 2-1 Arkansas Omaha, Neb. 1978 * Southern California (54-9) Rod Dedeaux 10-3 Arizona State Omaha, Neb. 1977 Arizona State (57-12) Jim Brock 2-1 South Carolina Omaha, Neb. 1976 Arizona (56-17) Jerry Kindall 7-1 Eastern Michigan Omaha, Neb. 1975 Texas (59-6) Cliff Gustafson 5-1 South Carolina Omaha, Neb. 1974 Southern California (50-20) Rod Dedeaux 7-3 Miami (Fla.) Omaha, Neb. 1973 * Southern California (51-11) Rod Dedeaux 4-3 Arizona State Omaha, Neb. 1972 Southern California (47-13-1) Rod Dedeaux 1-0 Arizona State Omaha, Neb. 1971 Southern California (46-11) Rod Dedeaux 5-2 Southern Illinois Omaha, Neb. 1970 Southern California (45-13) Rod Dedeaux 2-1 (15 inn.) Florida State Omaha, Neb. 1969 Arizona State (56-11) Bobby Winkles 10-1 Tulsa Omaha, Neb. 1968 * Southern California (43-12-1) Rod Dedeaux 4-3 Southern Illinois Omaha, Neb. 1967 Arizona State (53-12) Bobby Winkles 11-0 Houston Omaha, Neb. 1966 Ohio State (27-6-1) Marty Karow 8-2 Oklahoma State Omaha, Neb. 1965 Arizona State (54-8) Bobby Winkles 2-0 Ohio State Omaha, Neb. 1964 Minnesota (31-12) Dick Siebert 5-1 Missouri Omaha, Neb. 1963 Southern California (35-10) Rod Dedeaux 5-2 Arizona Omaha, Neb. 1962 Michigan (34-15) Don Lund 5-4 (15 inn.) Santa Clara Omaha, Neb. 1961 * Southern California (36-7) Rod Dedeaux 1-0 Oklahoma State Omaha, Neb. 1960 Minnesota (34-7-1) Dick Siebert 2-1 (10 inn.) Southern California Omaha, Neb. 1959 Oklahoma State (27-5) Toby Greene 5-0 Arizona Omaha, Neb. 1958 Southern California (29-3) Rod Dedeaux 8-7 (12 inn.) Missouri Omaha, Neb. 1957 * California (35-10) George Wolfman 1-0 Penn State Omaha, Neb. 1956 Minnesota (37-9) Dick Siebert 12-1 Arizona Omaha, Neb. 1955 Wake Forest (29-7) Taylor Sanford 7-6 Western Michigan Omaha, Neb. 1954 Missouri (22-4) John "Hi" Simmons 4-1 Rollins Omaha, Neb. 1953 Michigan (21-9) Ray Fisher 7-5 Texas Omaha, Neb. 1952 Holy Cross (21-3) Jack Barry 8-4 Missouri Omaha, Neb. 1951 * Oklahoma (19-9) Jack Baer 3-2 Tennessee Omaha, Neb. 1950 Texas (27-6) Bibb Falk 3-0 Washington State Omaha, Neb. 1949 * Texas (23-7) Bibb Falk 10-3 Wake Forest Wichita, Kan. 1948 Southern California (26-4) Sam Barry 9-2 Yale Kalamazoo, Mich. 1947 * California (31-10) Clint Evans 8-7 Yale Kalamazoo, Mich.
*Indicates undefeated teams in College World Series play.
COLLEGE WORLD SERIES: Tickets and gameday info | 2019 schedule

Story 142
Ingrid Torjesen London, UK
There is not enough evidence to conclude that screen time is harmful to the health of children and young people or advise on how much screen time is too much, says the first guidance on children’s screen time to be published in the UK.1
The guidance from the Royal College of Paediatrics and Child Health is informed by a comprehensive review of the evidence, published in BMJ Open,2 on the impact of screen time on the physical and mental health of children and young people.
Max Davie, officer for health promotion at the college, said: “We couldn’t find any …

Story 143
Motorsport-Magazin.com - Jetzt ist es auch offiziell durch die FIA abgesegnet: Beim diesjährigen Macau Grand Prix (14.-17. November) treten die aktuellen Rennwagen aus der FIA Formel 3 an, die im Rahmenprogramm der Formel 1 gastiert. So gehen 30 Rennwagen bei der 66. Auflage des Straßen-Klassikers in der chinesischen Sonderverwaltungszone an den Start.
Wie Motorsport-Magazin.com bereits vergangene Woche berichtet hatte, werden Teile der 6,2 Kilometer langen Rennstrecke überarbeitet. Die FIA spricht in ihrer Pressemitteilung von mehreren Updates, darunter eine Überarbeitung der Streckenbegrenzungen in der berühmten Lisboa-Kurve, vor der im vergangenen Jahr der schwere Unfall von Sophia Flörsch weltweit Schlagzeilen gemacht hatte.
Die neuen Formel-3-Autos sind leistungsstärker als ihre Vorgänger, die bis zur Einstellung der Serie bis zuletzt in der Formel-3-Europameisterschaft zum Einsatz kamen. Im Unterbau der Formel 1 fahren die Nachwuchstalente mit 380 PS starken Dallara-Chassis angetrieben von 3,4 Liter Sechs-Zylinder-Motoren.
Die Mehrleistung der Rennwagen - das Formel-3-EM-Auto verfügt über rund 240 PS - steht laut Insidern jedoch nicht so sehr im Fokus wie das erhöhte Gewicht. Der etablierte F3-Bolide brachte 565 Kilogramm Mindestgewicht auf die Waage, das 2019er-Auto mit Halo-Cockpitschutz hat ein Mindestgewicht von 690 Kilo und ist somit deutlich schwerer.
Es ist geplant, dass ein Großteil des aus 30 Autos bestehenden Starterfeldes der FIA Formel 3 im November 2019 zum F3 World Cup in Macau antreten wird. Ein Macau-Comeback könnte dabei Sophia Flörsch geben, wie Motorsport-Magazin.com exklusiv berichtet hatte. Es besteht die Möglichkeit, dass die Münchnerin für das Formel-3-Team HWA aus Affalterbach antritt. Alle Hintergründe lesen Sie in diesem Artikel:

Story 144
Eggenstein-Leopoldshafen, Germany – 28 March 2019: amcure, a biopharmaceutical company developing first-in-class cancer therapeutics, will present a poster on the mode of action of its lead candidate AMC303 at the upcoming American Association for Cancer Research (AACR) Annual Meeting. The first-in-class drug candidate AMC303, which is currently undergoing a Phase Ib clinical trial, targets CD44v6 to inhibit tumor growth and metastasis in epithelial tumors by blocking several relevant tyrosine kinase pathways.

AACR Annual Meeting 2019
Date: 29 March – 3 April 2019
Venue: Georgia World Congress Center, Atlanta, Georgia, USA
Title: AMC303 inhibits tumor growth and metastasis in animal models by targeting CD44v6, a co-receptor of multiple oncogenic receptor tyrosine kinases
Session: Targeted Therapies and Immunological/Tumor Microenvironment Effects
Abstract number: 4855, Section 15
Speaker: Martin Augsten, Senior Research Scientist, amcure
Time: 3 April 2019, 8:00 AM - 12:00 PM
amcure will present results of its preclinical studies demonstrating the unique mode of action of AMC303. In vitro studies demonstrate that AMC303 specifically attenuates the oncogenic signaling of three CD44v6-dependent receptor tyrosine kinases, namely c-MET, VEGFR2 and RON. In addition, they will show results from a tumor mouse model demonstrating a marked attenuation of tumor growth and metastasis and a significant increase in survival by treatment with AMC303. Treated tumors displayed increased apoptosis and necrosis along with a reduction in myofibroblast infiltration, angiogenesis and vessel permeability. The full abstract is available online via the AACR website:
https://www.abstractsonline. com/pp8/#!/6812/presentation/ 7891
About AMC303
amcure’s lead compound, AMC303, is being developed as a potential treatment for patients with advanced and metastatic epithelial tumors, e.g. pancreatic cancer, head and neck cancer, gastric cancer, colorectal cancer, breast cancer and lung cancer. AMC303 has a high specificity for inhibiting CD44v6, a co-receptor required for signaling through multiple cellular pathways (c-Met, VEGFR-2, RON) involved in tumor growth, angiogenesis and the development and regression of metastases. AMC303 has demonstrated strong effects in various in vitro and in vivo assays.
About amcure
amcure GmbH is a spin-off from the Karlsruhe Institute of Technology established in 2012. The company develops peptide-based compounds for the treatment of highly metastatic forms of cancer. amcure’s most advanced development candidate, AMC303, has entered clinical development and has demonstrated in in vivo animal proof-of-concept studies a high efficacy against different types of epithelial cancers. amcure is supported by a grant from the German Federal Ministry of Education and Research.
Contact
amcure GmbH
Dr. Klaus Dembowsky, CEO
Hermann-von Helmholtz-Platz 1
76344 Eggenstein-Leopoldshafen, Germany
Phone: +49 (0) 7247 934249-4 or +49 (0) 171 7930077
Fax: +49 (0) 7247 934249-9
E-Mail: info[at]amcure.com
Internet: www.amcure.com
Media contact
MC Services AG
Julia von Hummel
Tel.: +49 (0) 89 210 228-34
Mobil: +49 (0) 1719779192
E-Mail: Julia.vonhummel[at]mc- services.eu

Story 145
Now that there’s a bracket, which games to go to this week? Matter of fact, why don’t we plug in the virtual reality transporter and just go to all of them?

And so, 36 First Four and opening round games, and 36 reasons to go watch them. Pack lightly.
TUESDAY

Fairleigh Dickinson vs. Prairie View A&M. It’s a clash of rebooted seasons. Prairie View A&M started 1-11, Fairleigh Dickinson had a 3-10 stretch.

Belmont vs. Temple. Belmont’s at-large bid was a victory for the common man, and Fran Dunphy is retiring at Temple after a long and honorable career, so it’s a feel-good story no matter who wins.
North Carolina Central vs. North Dakota State. Apparently, you can’t have a First Four without North Carolina Central. Three consecutive MEAC titles for the Eagles, three First Fours. They’re 0-2, so maybe the third trip to Dayton is the charm.

Arizona State vs. St. John’s. Who can resist a match of two Final Four coaches? Make that two Final Four players who now coach. Maybe at halftime, Arizona State’s Bobby Hurley and St. John’s Chris Mullin can go one-on-one. Or given the fact they played last century, make that a game of HORSE. More pertinent may be the fact St. John’s started 14-1 but is 7-11 since, with seven of the losses by double digits and its last appearance an 86-54 mashing by Marquette in the Big East tournament.

THURSDAY

Maryland vs. Belmont-Temple winner. You can look it up. There never has been a year the First Four did not have a winner advance past the next game. And this looks like as good a chance as any.

LSU vs. Yale. Ivy League teams have made plucky underdogs lately, and the last time the tournament saw Yale, the Bulldogs promptly took down Baylor, and nearly Duke. Think LSU might be slowed by a last-minute interim coach? This is the 30th anniversary of the Michigan team that got Steve Fisher as interim just before the NCAA tournament. Next thing anybody knew, Fisher was holding the national championship trophy.

Louisville vs. Minnesota. Minnesota coach Richard Pitino against the team that used to be coached by Rick Pitino. Yeah, that’ll get some talk.

Michigan State vs. Bradley. Bradley started the Missouri Valley Conference season 0-5 and was 18 points down to Northern Iowa in the league tournament championship game, so the Braves are hard to kill. But Michigan State is a stat wonder; third in the nation in assists and field goal defense, fourth in rebound margin, fifth in blocked shots. The Spartans shared the Big Ten season title, won the league tournament and just beat Michigan three times in 15 days. And did a lot of that with two of their top scorers missing. They’re kind of steely themselves.

Gonzaga vs. Fairleigh Dickinson-Prairie View A&M winner. The Zags will have had eight days to ponder, study and no doubt seethe about whatever happened against Saint Mary’s. Bad news for the No. 16 seed in this game.
Mark Few shares thoughts on Zags' No. 1 seed in West Region

Baylor vs. Syracuse. OK, who’s better at form reversal? Baylor has lost four in a row, Syracuse has dropped seven of its last 11. Then again, the Orange are old hands at flipping the switch in March. They lost five of their last six in 2016 and ended up in the Final Four. They dropped five of their last eight in 2018, and went to the Sweet 16.
Marquette vs. Murray State. Surely, the selection committee folks had to gleefully giggle when they put this one up. Marquette’s Markus Howard was sixth in the nation in scoring this season and Murray State’s Ja Morant was eighth. They’re the two top scorers in the tournament, and now they’ll be in the same game.

Florida State vs. Vermont. Two teams on a roll, just in different universes. Florida State is 14-2 since Jan. 20, with the only losses to Duke and North Carolina. Vermont is 18-2 since Dec. 21, with both defeats by UMBC.
Nevada vs. Florida. The Gators held 11 major college opponents at least 19 points under their average. Nevada has the same bunch who put 87 points on Texas and 75 on Cincinnati last March to get to the Sweet 16.
BRACKET TIPS: How to pick March Madness upsets | Should you pick a No. 1 seed to win?

Michigan vs. Montana. Montana is eighth in the country in field goal percentage and scores 77 points a game. Michigan is second in the nation in scoring defense and has allowed the opponent to break 70 only five times. The Wolverines just have to be glad Montana’s school color is not green. They’re 28-3 against everyone in the world not named Michigan State.

Villanova vs. Saint Mary’s. Opportunity, the name is Saint Mary’s. What kind of March would it be to beat the No. 1 ranked team, and then the defending national champion in two gulps?


Purdue vs. Old Dominion. Carsen Edwards has shot under 33 percent since the beginning of February, and now he says his back is hurting, and if both of that continues, this could be big trouble for the Boilermakers. Old Dominion is a study in contrast — seventh in the nation in scoring defense and 10th in field goal percentage defense, but 313th in scoring and 320th in shooting. The Monarchs should get a lot of sentimental backing, with coach Jeff Jones battling prostate cancer.

Auburn vs. New Mexico State. Auburn appears to be peaking, coming off pounding Tennessee for its first SEC tournament championship in 34 years. But beware the silent power of New Mexico State, which has gotten scant attention for a 30-4 record, or 19-game winning streak, or losing by only three at Kansas.
Committee chair Bernard Muir fields questions about the selection process
Kansas vs. Northeastern. Northeastern has won 16 of 18, has five different players get double-doubles this season, beat Alabama by 16 and went 14-4 in the Colonial with two of its losses in overtime and the other two by three points each. If that hasn’t gotten the attention of Kansas, which will be pinning a lot of its tournament hopes on freshmen, it should.

Wofford vs. Seton Hall. Well, Wofford, it’s time. The Terriers own the nation’s longest winning streak at 20 games, are ranked, and have only been beaten by North Carolina, Oklahoma, Kansas and Mississippi State — NCAA tournament teams all. This has made them the flavor of the month for Cinderella story lovers. Thing is, Seton Hall is playing pretty well, especially Myles Powell, one of the Big East’s best.

Kentucky vs. Abilene Christian. A game that proves that bracket teams come in all shapes and sizes. Abilene Christian is in its first NCAA tournament. Kentucky is in its 59th.
Duke vs. North Carolina Central-North Dakota State winner. If it’s North Carolina Central, it’ll be a game between two teams only three miles apart. Just like Duke-North Carolina. Sort of.
Duke boasts top seed in East Region

VCU vs. UCF. The alphabet bowl, heavy on the defense. VCU is sixth in the nation in field goal defense, UCF is 13th... First team to 50 wins.

Mississippi State vs. Liberty. You can’t look at this game without thinking of UCLA, can you? Liberty beat the Bruins by 15 points, so its flashiest win of the season was in Pauley Pavilion. Then again, so were a lot of Mississippi State coach Ben Howland’s best wins, since he took the Bruins to three Final Fours.

Virginia Tech vs. Saint Louis. The big news is the return – timing is everything – of Virginia Tech guard Justin Robinson. The Hokies have missed him.

Buffalo vs. Arizona State-St.John’s winner. The Bulls had the Mid-American Conference’s coach of the year, player of the year, defensive player of the year, sixth man of the year. Notice a trend? At No. 6, they are the highest seeded MAC team since 1979.

Texas Tech vs. Northern Kentucky. Might be a chance to see Texas Tech’s Davide Moretti shoot free throws. He’s taken 90 and only missed six 84 this season, went 33-for-34 during a recent nine-game winning streak and leads the nation in free throw percentage. He must have shot a lot of them growing up in Bologna, Italy.

Virginia vs. Gardner-Webb. This will be played 371 days after Virginia took the court against UMBC. But nobody will mention that game this week, right?
Virginia is the No. 1 seed out of the South Region

Mississippi vs. Oklahoma. Mississippi has lost five of seven, Oklahoma has dropped eight of 12, so each probably relishes a new beginning, so to speak. Mississippi’s last six games have been settled by a combined 18 points. So chances are it’ll be close, anyway.

Wisconsin vs. Oregon. One minute Oregon was 6-8 in the Pac-12, the next the Ducks had won six in a row, holding five consecutive opponents under 62 points for the first time in the shot clock era, going back to 1984. Now they’ll take aim at Ethan Happ.

Kansas State vs. UC Irvine. Kansas State might be without one of its key players, Dean Wade, and being shorthanded is no way to be playing a UC Irvine team that has won 16 in a row and is fifth in the nation in field goal percentage defense.
PERFECT BRACKET: Putting the absurd odds of a perfect bracket into perspective

Cincinnati vs. Iowa. The game is in Columbus, which is under two hours from Cincinnati. If Iowa didn’t know that, the Hawkeyes will Friday.
Tennessee vs. Colgate. Colgate has won 11 in a row while averaging 81 points, and that surge produced the school’s first NCAA tournament bid in 23 years. Preparing to stop that offense will presumably help the Vols forget what just happened against Auburn.

North Carolina vs. Iona. According to Iona figures, since 1996, its 452 victories are more than any other Division I school within 30 miles of Madison Square Garden. So the Gaels are kings of New York. Unfortunately, the Tar Heels are a little outside that ring.
North Carolina claims the top spot in the Midwest Region
Utah State vs. Washington. It says something for the Pac-12 that its season champion is seeded ninth. But then, in their last seven games, the Huskies have scored 47 and 48 points in losses to Oregon, were beaten by last-place California, and won four games by a combined 14 points. And now here’s Utah State, winner of 17 of 18.

Iowa State vs. Ohio State. Ohio State better not count on much help from Iowa State guard Tyrese Haliburton, who has 124 assists to go with only 27 turnovers.

Houston vs. Georgia State. Georgia State thrashed Georgia by 24 points, beat Alabama and played Kansas State tough in Manhattan. And the Panthers still have coach Ron Hunter, whose tumble off his chair after his son beat Baylor in 2015 lives on forever in tournament lore. Then again, Houston is 31-3 and leads the nation in field goal defense. Georgia State wins this one, and it won’t just be the coach falling off chair.
The best coach reactions of March Madness
SECOND ROUND GAMES IT’D BE GREAT TO SEE

Gonzaga vs. Syracuse. Zags’ high octane offense, meet Jim Boeheim’s zone.

Murray State vs. Florida State. Actually, Ja Morant against anyone.

Buffalo vs. Texas Tech. Want relentless offense? Buffalo averaged 83 points in the games it lost. So a match against the Texas Tech defense should be intriguing.

Villanova vs. Purdue. Both sides have departing stars who don’t want to see it end.

Tennessee vs. Cincinnati. Cincinnati would be dangerous anywhere, but in Ohio? It’d be a moment of truth for the Vols.

North Carolina vs. Utah State. Utah State has the look of a serious trouble-maker.

Auburn vs. Kansas. Auburn is hot. Nobody really is sure about Kansas.

Wofford vs. Kentucky. It’d be Big Blue Nation against every other living, breathing college basketball fan in the world.
Greg, Clark and Seth break down the bracket
AND DOWN THE ROAD . . .

Would you believe Duke against Michigan State in the East? Think Tom Izzo would be asked about his 1-11 record against Mike Krzyzewski?

Would you believe Michigan and Texas Tech in a West semifinal, throwing defense at one another, trying to earn the right to take a crack at stopping Gonzaga’s scorers?

Would you believe Virginia and Tennessee in the South, one team that has waited three decades to get back to the Final Four, and the other who has waited forever?

Would you believe North Carolina and Kentucky in the Midwest, but maybe also having to deal with Kansas playing in Kansas City?

So many possibilities. But Fairleigh Dickinson and Prairie View A&M, you’re up first. The tee is open.
MARCH MADNESS HISTORY: 1 unforgettable thing from every tournament since 2000

Story 146
The release focuses on production operations and developer ease of use
The latest release of Hyperledger Fabric, v1.4 marks a very important milestone: it is the first LTS release. This means that the Fabric maintainers will provide bug fixes for a period of one year [from the date of release: January 10, 2019]. Let’s have a closer look at this release.
Hyperledger Fabric is becoming one of the most important frameworks for blockchain development.
Just a few months ago, it was announced that this Hyperledger project will support Ethereum Virtual Machine (EVM) bytecode smart contracts. Therefore, Hyperledger Fabric is now more accessible to developers who have already started working with Ethereum and its associated tools.
Our main motivation was to give developers a migration path from Ethereum to a robust permissioned platform of Hyperledger Fabric. We wanted to make the transition as easy as possible and also give developers the ability to reuse whatever they may have already developed on Ethereum. This line of work was motivated and initiated separately from the fact that Hyperledger and the EEA have recently joined forces. However, both are motivated by the idea that Hyperledger and Ethereum communities can work together. – Christopher Ferris, IBM Distinguished Engineer
Free: Blockchain Technology Whitepaper 2019 If building a blockchain from scratch is beyond your current scope, the blockchain technology whitepaper is worth a look. Experts from the field share their know-how, tips and tricks, development advice, and strategy for becoming a blockchain master. Download for free
Hyperledger Fabric 1.4 LTS
The latest version of Hyperledger Fabric focuses on production operations and developer ease of use. The most important production-focused features of Fabric fall into four key categories, as explained in the blog post announcing v1.4:
Serviceability and Operations: Fabric v1.4 takes a giant leap forward with logging improvements, health checks, and operational metrics. Along with a focus on stability and fixes, Fabric v1.4 is the recommended release for production operations. Future fixes will be delivered on the v1.4.x stream, while new features are being developed in the v2.0 stream.
Fabric v1.4 takes a giant leap forward with logging improvements, health checks, and operational metrics. Along with a focus on stability and fixes, Fabric v1.4 is the recommended release for production operations. Future fixes will be delivered on the v1.4.x stream, while new features are being developed in the v2.0 stream. Improved programming model for developing applications: Programming model improvements in the Node.js SDK and Node.js chaincode makes the development of decentralized applications more intuitive, allowing you to focus on your application logic. The existing npm packages are still available for use, while the new npm packages provide a layer of abstraction to improve developer productivity and ease of use. We have also provided a comprehensive business scenario and tutorial to get you started with the new developer experience.
Programming model improvements in the Node.js SDK and Node.js chaincode makes the development of decentralized applications more intuitive, allowing you to focus on your application logic. The existing npm packages are still available for use, while the new npm packages provide a layer of abstraction to improve developer productivity and ease of use. We have also provided a comprehensive business scenario and tutorial to get you started with the new developer experience. Enhanced data privacy: This release includes two new enhancements: 1) peers for organizations that are added to private data collections can now retrieve the private data for prior transactions to which they now are entitled, and 2) automatically enforce access control within chaincode based on the client organization collection membership without having to write specific chaincode logic.
This release includes two new enhancements: 1) peers for organizations that are added to private data collections can now retrieve the private data for prior transactions to which they now are entitled, and 2) automatically enforce access control within chaincode based on the client organization collection membership without having to write specific chaincode logic. Hand-on tutorials: Commercially focused training to help developers move up the Fabric learning curve quickly and efficiently to speed adoption and deployment.
SEE ALSO: Blockchain development made easy: Getting started with Hyperledger Fabric
However, what’s even more exciting is that Hyperledger Fabric v1.4 LTS marks their first long term support release. Hyperledger Fabric maintainers used to offer bug fix (patch) releases for the most recent [both major and minor] releases until the next release came along.
Since 1.4 is the first LTS release, the maintainers will offer bug fixes for a period of one year from the date of release (January 10, 2019). “This will likely result in a series of patch releases (v1.4.1, v1.4.2, …), where multiple fixes are bundled into a patch release,” according to the blog post.
Read more about the new features included in Hyperledger Fabric 1.4 here and here.

Story 147
Why did this happen?
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.

Story 148
In September 2015, hardware veterans Nigel Toon and Simon Knowles were doing the rounds of venture capital offices in Silicon Valley and London, touting their latest startup. The pair had a dazzling track record – among other achievements they’d sold their previous semiconductor company Icera to NVIDIA for $435 million (£346 million) four years earlier. And their vision for Graphcore – a new Bristol-based venture – was bold: they were building a new generation of microchips known as intelligence processing units (IPUs), designed for the rapidly approaching artificial intelligence age.
Yet early reactions to their pitch for series A financing were distinctly muted. “In many cases we were laughed out of court,” recalls Toon, Graphcore’s CEO.
Typically, Toon says, they’d find a partner in a VC firm who was excited by what they were doing. “But then they’d go to their partner meeting, where the first question would be: ‘What’s AI?’ It’s stunning to think that was a conversation that was happening [as recently as] 2015.” From there, it was an uphill struggle. “Even if they got the fact that AI might be interesting, they’d then say: ‘Your business model is to build a chip for this AI thing? Well, nobody’s made money from chip investments in the last 10 years.’”
Advertisement
Toon, who is 55 and has the mellifluous voice of an old-school BBC continuity announcer, says that chip development, in the eyes of most investors at the time, was considered highly capital intensive, with returns failing to justify the upfront financing required. “It’s not more capital intensive than software,” says Knowles, Graphcore’s co-founder and CTO. “But software has this joyful property that you can try it out in small scale first, whereas with a chip you’re all in. If it doesn’t work, you’ve spent all your money.”
That was 2015. Fast forward to today and, of course, AI hardware is a white-hot category for investors, with VC funding for US AI companies jumping by 72 per cent in 2018 to a record $9.3 billion (£7.4 billion), a fifth straight year of growth, according to a report by CB Insights and PwC.
Read next The curious tale of Julian, the last King of Brussels The curious tale of Julian, the last King of Brussels
What changed over those three years? Toon points to two things. First, in 2016 traditional chip giant Intel acquired an AI software and hardware startup called Nervana for $350 million (£280 million), raising eyebrows all over the Valley. Second, Google announced it was going to build its own chips – evidence, Toon says, that existing chips weren’t up to the task.
Knowles describes the impact of Google’s decision as “seismic”. The fact that Google thought AI was going to be a sufficiently big deal to justify the pain and expense of building its own chip team helped make the Graphcore founders’ case for them. He and Toon had been arguing that it was worth digging deep financially to develop new processor hardware because existing graphics processing units (GPUs) – used, for example, in mobile phones, games consoles and personal computers – weren’t designed for AI workloads such as machine learning and deep learning.
Advertisement
By then, their startup was already ahead of the pack in developing a new processor architecture. Soon top-tier investors – including Atomico, one of Europe’s best-known VCs – were beating a path to their door. Atomico, which went on to lead Graphcore’s $30 million (£24 million) Series B round in July 2017, was followed six months later by one of the Valley’s biggest guns, Sequoia Capital. At the time, Graphcore, having recently closed its Series B, didn’t need investment – but the west coast investor wasn't taking "No thanks" for an answer. “They came to see us here in Bristol and said, ‘No, you don’t understand, we want to invest in your business,’” laughs Toon. “So we work out terms and they invest $50m into the company. And that’s one of the very few investments they’ve made in the UK, because they’ve got so much opportunity on their doorstep.”
Sequoia partner Matt Miller, who now sits on Graphcore’s board, admits he was somewhat bemused to find himself chasing down a company based in Bristol. “We knew there was an opportunity for a new architecture that would be designed from the ground up that could massively accelerate our entry into this AI age, and we were trying to landscape all of these companies in China, the US and Europe,” he says. “But our references were all pointing to this one company in Bristol, whom we hadn’t met yet.”
A roar of laughter distorts the line from the Valley. “Lemme tell you, if you’d asked me a month prior if I’d ever [sit on] a board in Bristol I’d have said ‘No way!’ It’s not your typical destination on your tour of Europe. But to be honest, it’s been surprising for us in the Bay Area because the quality of talent in the UK, and particularly in Bristol in the semiconductor space, is very strong. The team they’ve been able to build there is on a par with the best in the world.”
Read next A mysterious death, a genetic clue and the lifelong quest for answers A mysterious death, a genetic clue and the lifelong quest for answers
Following a $200 million (£160 million) Series D round in December 2018, Graphcore was most recently valued at $1.7 billion (£1.36 billion), with investors, innovators and large corporates now seemingly convinced it will be the company to power the AI era in much the same way as Cambridge-born chip giant ARM dominated mobile devices, shipping over 130 billion chips and reaching 70 per cent of the global population. The opportunity at stake is nothing less than the future of AI, with applications ranging from medical advances to autonomous vehicles, space exploration and just about everything in between.
Advertisement
Graphcore engineer Joanna Taylor belongs to "a semiconductor team on a par with the world's best" Nick Rochowski
In fact, Bristol has a strong history as a hub for hardware engineering, which can be traced back to 1978 and £50m of seed investment (another £150m would later follow) made by the UK government in Inmos, a microprocessor startup with fabrication facilities in Newport, South Wales. “We often forget the importance of government investment,” says Hermann Hauser, the Austrian-born entrepreneur and investor best known for spinning out ARM from Acorn Computers – and Graphcore’s first backer. “It was the £200 million that the Callaghan and, later, Thatcher governments originally spent on Inmos that created the infrastructure and ecosystem around Bristol that really understood semiconductors. It created brilliant people like [leading computer scientist] David May, Simon and Nigel, who would not have been there had it not been for the government initiative at the time.”
Knowles first came to Bristol in 1989 to work for Inmos. “Historically, Bristol has been the centre of chip design [in the UK], and in many ways ARM and CSR [formerly Cambridge Silicon Radio] were anomalies,” he says. “I mean, they’re very successful, large anomalies, and now everyone associates Cambridge with chips. But in terms of numbers of chip startups, and how many years back it goes, Bristol is the dominant place in the UK.”
Graphcore emerged from a tangled family tree of semiconductor companies. Toon and Knowles were introduced to each other by Stan Boland, former CEO of Acorn Group and now CEO of autonomous vehicle startup FiveAI, who had worked with Knowles at chip company Element 14. When this was acquired by Broadcom for $640 million (£512 million) in 2000, the pair went on to found Icera in 2002 with Toon, who was previously with electrical equipment manufacturer Altera Europe. When Icera was sold to NVIDIA, it meant that Knowles had already exited two chip design startups at a total value of over $1bn. But he and Toon were far from finished. What motivated them to start all over again with Graphcore?
Read next 'We are at war': How the Brexit Party's viral hit factory upended British politics 'We are at war': How the Brexit Party's viral hit factory upended British politics
Sitting across the table from one another in a fifth floor meeting room at their Bristol HQ, the founders exchange a fleeting glance. After a while in their company, it's clear that this long-established business double act has acquired some of the hallmarks of a marriage: they have an easy rapport, finish each other’s sentences, and occasionally talk over and correct each other.
“Simon maybe has a different view,” says Toon, “but my sense of it is that this is what we get up in the morning for. The fact that the opportunity in front of us is so enormous, I feel like I’ve been waiting my whole life for this.” He adds that it comes down to purpose: “You might get some satisfaction from connecting people together in a social network, for example, or delivering food to them through an internet app. What we’re doing is potentially changing the future of compute – we’re potentially allowing lots of people to create major breakthroughs; maybe someone will come up with a cure for cancer using the tech we’re creating.”
“We’re building the motors of AI, really,” says Knowles. “And what people will build out of those motors is far greater than our motors. We want to be the Rolls-Royce jet engines of AI machinery.”
In essence, the problem Graphcore is solving is that previous generations of microprocessors – central processing and graphics processing units – weren’t designed for machine intelligence, which requires a new way of processing data.
Knowles holds up a Graphcore chip. The size of a small cracker with a dark grey, metallic centre, it contains 23.6 billion transistor devices all connected by several miles of wiring. As transistors were progressively shrunk over the decades so that more of them could fit on to each chip, the chips themselves grew correspondingly hotter as energy demands increased. “We’re almost at the end of that gravy train now,” says Knowles. “The objective of chip design always used to be to go as fast as possible; now it’s to make the most use of the energy available.”
Read next The impossible fight to save Jakarta, the sinking megacity The impossible fight to save Jakarta, the sinking megacity
“To make them as efficient as possible,” clarifies Toon.
“Exactly,” says Knowles. “And actually you design things in a completely different way if you’re most interested in energy and less interested in speed per se. So why do we want more computing performance? We’ve just started to work out how to mechanize intelligence. And what do we mean by intelligence? A machine that can learn by its experience, or by being given examples, or by itself, discovering things. In no sense, historically, has a computer solved a problem – it was always the person who wrote the program. AI flips that on its head.”
Suddenly, there’s a surge in demand for more processing power due to the AI workload, at precisely the moment when traditional silicon shrinking won’t offer it. “Explaining to a computer how to learn is quite different to explaining to it how to do traditional supercomputer maths for example,” says Knowles. “So we’ve set about trying to solve those two problems – intelligence is a different workload, and focusing on efficiency and not speed – with our IPU.”

Whereas other AI hardware companies have focused on neural networks – a type of knowledge model for capturing the sort of intelligence in the human cortex, which is essentially designed to recognise numerical patterns – Graphcore has built an architecture that is more flexible. It can run current machine-learning approaches, as well as new and emerging approaches that simply don’t work efficiently on today’s hardware. “What most of the [rival] startups are doing is building a machine to do fast neural networks, and that’s what you do if your ambition for your company is to sell it for a couple of hundred million in a year or two,” says Knowles. “What we’ve tried to do – because our ambition for the company is to be permanent, and broad enough to encompass engines for AI as opposed to just chips for perception – is build a much more general purpose machine. Nigel and I were very clear about our ambition for this company: we’ve grown and sold companies before, but this one is our magnum opus.”
Toon chips in: “This is a once-in-a-generation opportunity. If we get this right, the IPU will define the future of machine intelligence, powering world-changing innovations for decades to come.”
Graphcore's Colossus GC2 IPU is a new generation of microprocessor built for the artificial intelligence age Nick Rochowski
Read next This economist has a plan to fix capitalism. It's time we all listened This economist has a plan to fix capitalism. It's time we all listened
VCs are rarely sparing in their use of hyperbole. But when a big-hitting Valley investor like Sequoia’s Miller says “We think [Graphcore] can be a company with a market cap in the tens of billions of dollars”, and flies halfway around the world to make an investment in a startup that wasn’t raising money in the first place – with the likes of BMW, Microsoft, Bosch, Dell and Samsung also queuing up to invest – there tends to be a pretty good reason.
The answer lies in the almost limitless fields Graphcore’s IPU can be applied to – anywhere, in fact, that machine intelligence can enhance human activity. “There are still some things humans are going to be better at, typically creative things,” says Atomico partner Siraj Khaliq, a computer scientist and former entrepreneur. “But when it comes to looking at patterns and making predictions – for example looking at a radiology scan and deciding if there’s cancer there or not; looking at someone’s viewing habits and deciding what they should watch next; even looking at the attributes of a person, what they do and what they like, and recommending who they should marry via dating apps – all of these things machines will now do because they’re just better at it. So I don’t think I’d be doing it justice by saying ‘Here are one or two things that Graphcore’s IPU will be used for’, because it is really pretty much everything.”
Back in Bristol, Knowles cites medicine and law as two areas on the brink of AI-driven transformation. “What is the definition of a good doctor or a good lawyer?” he says. “It’s someone with a lot of wisdom acquired by experience, someone who’s seen a lot of cases, read and digested a lot of research material and comes up with good answers. They can’t always be correct, but given the knowledge that exists they come up with the best reasonable answer based on their experience.”
The most exciting opportunity for machine intelligence is being able to do that with all of human knowledge, he says. “Take a medical oracle which can read all of the medical research that’s ever been published and can resolve and identify discrepancies. It can read all of the patient records that have ever been recorded. And it can come up with the best answer based on all of human knowledge. It’s not perfect, because all of human knowledge isn’t all knowledge, but it’s the best we can possibly do and the opportunity there for totally solving a whole load of human conditions must be enormous.”
Graphcore’s founders say that more than 100 developers or end users are currently working with their IPUs, although they decline to identify any of them. “I’m not sure we’re allowed to say [who they are],” says Toon. Is it a fair assumption that big brand investors and individuals such as Demis Hassabis, a co-founder of DeepMind who invested personally in Graphcore, are testing the technology? He bats away the question. “They are strategic investors in our company. They’ve made a decision that our tech could be strategically important to their businesses, so you might surmise that something’s going on, but we couldn’t possibly comment.”
Read next Inside Google Stadia Inside Google Stadia
However, days after WIRED’s conversation with Toon and Knowles, an approach to BMW i Ventures (the car giant’s venture arm focused on automotive tech) suggests a possible application. While BMW wouldn't confirm whether it was working with Graphcore (this information is commercially sensitive), it’s understood from a separate source that BMW is indeed exploring the possibilities of the startup’s IPUs. Tobias Jahn, a principal at BMW i Ventures, says his firm became interested in Graphcore as an investment because of its technology's potential for automotive applications. “For highly and fully automated driving, commonly called levels 4 and 5, efficient AI acceleration is going to be indispensable,” he says.
Graphcore co-founders: Simon Knowles (left) and Nigel Toon Nick Rochowski
Graphcore is currently a niche player in a vast global semiconductor market which grew by 13.4 per cent in 2018 to $477bn, according to Gartner. Over the past two decades, the chip industry has undergone a fundamental shift that has seen manufacturing gradually move from the US and Europe to Asia. “That partly reflects the lower cost base for production in Asia and partly where incremental demand is being driven from these days – and clearly China has played a significant part in that,” says Jim Fontanelli, senior analyst at Arete Research.
With that in mind, could Graphcore’s competition ultimately come from China? It’s complicated. In 2018, there were no Chinese companies among the world’s leading 15 semiconductor corporations (which were headed by Samsung and Hynix in South Korea, Intel in the US, and TSMC in Taiwan, which manufactures leading-edge chips including Graphcore’s). Fontanelli doesn’t see China catching up with South Korea, the US and western Europe any time soon. “The ability to design chips is largely independent of the ability to manufacture, and China still has a significant gap to where the leading guys like TSMC, Samsung or Intel are from a manufacturing perspective. Certainly I don’t think they have the ability to realistically catch up in the next five years and possibly not in the next decade. The requirements around leading-edge manufacturing are far more than just having capital available.”
However, when it comes to chip design – particularly for AI – Hermann Hauser reckons the chip giants will not be able to rest on their laurels for long. “[Chip design is] still something that the west seems to be doing better than China. But having said that, China produces more STEM graduates than Europe and America put together. Chinese universities are now overtaking American universities in terms of publication of scientific articles. And China leads the way in the number of patents that it files.”
Read next The rise and fall of Flash, the annoying plugin that shaped the modern web The rise and fall of Flash, the annoying plugin that shaped the modern web
Toon says the Chinese government went through the AI equivalent of a "Sputnik moment" when DeepMind’s AlphaGo became the first computer program to defeat a professional Go player, in Seoul in 2016. “They’ve been investing a lot of money and the thing China is doing differently to other countries is that they’re making data available to companies they’re trying to support,” he says.
“They see, as we do, that this is a fundamental shift in computing and this is their opportunity to try to become independent using their own technology, rather than being dependent on other people’s. So I would say they are very actively trying to support and build their own technology at the semiconductor level, at the algorithm and application level – I wouldn’t say they are a long way behind, they’re running very quickly.”
Knowles adds that while China “can certainly build chips”, designing “state of the art microprocessors” like Graphcore's is a different matter. Historically, China has not had chip design capabilities – it has not had chip manufacturing capabilities until fairly recently – so it hasn’t got that indigenous expertise. But the Chinese diaspora has been studying and working in the west. “And now that China is becoming a more attractive place to live, I’m sure they are going back to China, bringing their skills with them, and China will learn to do this.”
A collaboration between human and robotic arms in Graphcore's Bristol laboratory Nick Rochowski
While there may not be viable Chinese competitors to Graphcore – at least not in the near term – in Europe it's a different story, and AI hardware-focused startups are emerging fast. “It’s a highly competitive space, and there are quite a few startups trying to do this now,” says Siraj Khaliq. “But they have different approaches, and I haven’t seen one with a better approach [than Graphcore].”
Read next The hidden fight to stop illegal fishing from destroying our oceans The hidden fight to stop illegal fishing from destroying our oceans
However, he concedes that people will eventually copy Graphcore’s approach, which means that Knowles and Toon will only succeed long term by moving faster, continuously innovating and having an array of products in the pipeline.
Hauser, too, accepts that there are “lots of startups trying to do this”, but says Graphcore has two big advantages. First, it was fastest out of the blocks. Second, it “got extremely lucky” in that the members of one of the best chip design units in the world – the Knowles team that went to NVIDIA in the Icera exit – were made redundant at the precise moment Graphcore needed them. “Normally with a startup you’re not given one of the world’s best design teams on a plate,” he says. “They [went on to] produce the world’s largest and most complex chip in one-and-a-half years – and they were right first time.”
It’s fair to say Toon and Knowles have ridden that initial luck. By their own calculations they have gone on to raise a total of $329 million (£263 million) over four rounds as they scale at a ferocious pace. At around 270 employees today, they expect to swell their ranks to up to 500 by the end of 2019. “Last week we added 10 people,” says Toon. “We’re in the process of building up a team in Cambridge, and we’re hiring here in Bristol at a massive rate. We’re also ramping up our team in Oslo who are building a technology of how we connect these IPU processors together, so you can have thousands of processors that all work together.” The startup also has a customer support and business development team in Palo Alto, California, and is building up an equivalent operation in Beijing.
Graphcore plainly has a decent shot at becoming one of European tech’s outsized success stories, perhaps even eclipsing the likes of Spotify (approximate market cap: $26 billion), Yandex ($12 billion), Zalando ($9.5 billion), Delivery Hero ($7.5 billion) and ARM itself, which was acquired by SoftBank for $32 billion in 2016. And yet the pick of the UK-born AI startups – such as DeepMind (acquired by Google), Magic Pony (Twitter), Evi Technologies (Amazon), Vocal IQ (Apple), and SwiftKey (Microsoft) – have generally been snapped up by one of the US goliaths before making it to global scale. Might Graphcore follow suit?
“We’ve certainly done that before,” says Toon, referring to the pair’s earlier exits. “But we think our market is massive – it’s not like this is going to be a small thing inside someone else’s chip; this is a standalone, independent piece of tech that will be sold on a very large scale. So that would suggest this is a standalone company – and all of the investors we’ve had so far are there for the long term.”
Read next The PPI scandal spawned a spam empire that just won't quit The PPI scandal spawned a spam empire that just won't quit
“They’re carefully chosen for that,” says Knowles.
Toon smiles. “When Matt Miller, from Sequoia, came for his very first board meeting – and Matt’s a big guy – he looks around the room at all the other investors and says ‘Look, the first one of you to talk about selling this company, I’m going to punch you on the nose.’ He said it as a piece of fun, but that’s what Sequoia does – it builds big companies that go public, and he just wanted to be sure that all the other investors were on the same page.” So is Graphcore’s goal ultimately to IPO? “That’s the path we’re shooting for, absolutely.”
The appetite in Europe now, particularly among the leading VCs, is not to build unicorns, but decacorns, says Toon. “It’s not about having one [tech giant], it’s about having lots. For us, it’s this idea of ‘Will people in future buy more CPUs or IPUs?’. They’ll buy more IPUs. CPUs will still be there. They’ll be doing the inputs and the outputs. They’ll be presenting and collating the data. But the compute will be done on IPUs.
“It’s like going back to the 1970s and the birth of personal computers, microprocessors, and companies like Apple and Intel that got created at that time. There are going to be Apples and Intels that will be created in the AI world. And our goal is to be one of them.”
More great stories from WIRED
😡 TikTok is fuelling India's deadly hate speech epidemic
Read next The curious quest to create the perfect artificial surfing wave The curious quest to create the perfect artificial surfing wave
🚀 The staggering power of Russia's top-secret nuclear rocket
🍫 The foods you'll really need to stockpile for no-deal Brexit
♻️ The truth behind the UK's biggest recycling myths
Advertisement
🤷🏼 How is the internet still obsessed with Myers-Briggs?
📧 Get the best tech deals and gadget news in your inbox

Story 149
If the season ended today, Baylor, Louisville, Oregon and Mississippi State would be the No. 1 seeds in the 2019 NCAA Division I Women’s Basketball Championship.
In the first of two top-16 reveals during the 2018-19 season by the NCAA Division I Women’s Basketball Committee, it was announced that UConn, defending champion Notre Dame, Stanford and NC State are currently No. 2 seeds. Rounding out the top-16 seeds included Marquette, Iowa, Maryland and Oregon State as No. 3 seeds, while South Carolina, Gonzaga, Iowa State and Miami (FL) were No. 4 seeds.
In addition, the committee designated region assignments for all 16 seeds, with Baylor the No. 1 seed in the Greensboro Region, Louisville the top seed in the Chicago region, Oregon in the Portland Region and Mississippi State in the Albany Region.
RANKINGS: South Dakota cracks AP top 25 for first time in program history
Mississippi State would be joined by UConn, Oregon State and Miami (FL) in the Albany Region. The Chicago region would include Louisville, Stanford, Marquette and Iowa State. In the Greensboro region, Baylor, Notre Dame, Maryland and South Carolina would be assigned. The Portland region would include Oregon, NC State, Iowa and Gonzaga.
“It’s been a very interesting season so far in terms of team movement from one week to the next and this first top-16 reveal reflects that,” said Rhonda Lundin Bennett, chair of the Division I Women’s Basketball Committee and senior associate athletics director and senior woman administrator at the University of Nevada. “Each of our top four seeds separated themselves by having only one loss combined with signature victories. With still over a thousand games to be played over the final month of the regular season we know what was announced today is just a snapshot in time as we await the stretch run of the season, including conference tournament play.”
Baylor, 21-1 overall and 11-0 in Big 12 Conference play, has won 13 straight games that included an historic 68-57 home win over UConn on Jan. 3 that ended the Huskies 126-game regular season winning streak that had spanned more than four years.
NAISMITH WATCH: 30 named to midseason team
Louisville, 23-1 overall and 10-1 in the Atlantic Coast Conference, also defeated UConn 78-69 on Jan. 31 at home. The Cardinals have reeled off nine straight wins since suffering their only loss of the season at Notre Dame on Jan. 10 by an 82-68 count.
Oregon, 23-1 overall and 12-0 in the Pac-12 Conference, has won 16 straight games since suffering its only loss on Dec. 9 at Michigan State. The Ducks latest outing was significant as Oregon defeated No. 11 Stanford 88-48 on Sunday, notching the Ducks' first win at Maples Pavilion since 1987.
Mississippi State, 22-1 overall has moved to the top of the Southeastern Conference standings with a 10-0 mark. Winners of 12 straight, the Bulldogs are coming off a 91-63 win over Tennessee on Sunday.
TOUGH TEAMS: 5 teams you don't want to face right now
The first and second rounds of the 2019 NCAA Division I Women’s Basketball Championship will be played March 22-25 on the home courts of the top 16 seeds. Regional action will take place March 29-April 1, with Albany, New York (Times Union Center) and Portland, Oregon (Moda Center) hosting on March 29 and 31, while Greensboro, North Carolina (Greensboro Coliseum) and Chicago, Illinois (Wintrust Arena) will host regional games on March 30 and April 1. The 2019 Women’s Final Four will be held April 5 and 7 at Amalie Arena in Tampa, Florida. Ticket information for all championship sites is available at http://www.ncaa.com/tickets.
The second and final top-16 reveal by the committee will take place on Monday, March 4 at halftime of the UConn vs. South Florida game that tips at 7 p.m. that night and will be broadcast on ESPN2. The early reveals will have no bearing on the 64-team field for the 2019 championship that will be announced on Selection Monday, March 18 on ESPN at 7 p.m. EST.
NCAA Division I Women’s Basketball Committee – February 11 – Top-16 Ranking*
Baylor (No. 1 seed – Greensboro Region) Louisville (No. 1 seed – Chicago Region) Oregon (No. 1 seed – Portland Region) Mississippi State (No. 1 seed – Albany Region) UConn Notre Dame Stanford North Carolina State Marquette Iowa Maryland Oregon State South Carolina Gonzaga Iowa State Miami (FL)
Regional Assignments
Albany:
1. Mississippi State
2. UConn
3. Oregon State
4. Miami (FL)
Chicago:
1. Louisville
2. Stanford
3. Marquette
4. Iowa State
Greensboro:
1. Baylor
2. Notre Dame
3. Maryland
4. South Carolina
Portland:
1. Oregon
2. NC State
3. Iowa
4. Gonzaga

Story 150
AN ALL-NEW Nissan Juke will arrive in UK showrooms next year, complete with more interior space and bolder styling than ever before.
What is the 2020 Nissan Juke?
The Juke is the smallest SUV that Nissan makes, and stands out from the crowd thanks to its bold styling. Nissan also says it’s an important vehicle in the history of the automobile, claiming the first generation of Juke, launched in 2010, pioneered the compact crossover class that is now one of the most hotly contested sectors of the new car market. Other car makers have made similar claims, mind you — the three-door Toyota RAV4 was launched a full 16 years before the Juke, for example.
Whatever, Nissan’s mini-crossover has proved extremely popular and in July last year the one millionth Juke rolled off the production line at Nissan’s Sunderland Plant. In a press release announcing the milestone, Nissan said a brand new Juke is built at the plant every 105 seconds.
But the model is overdue an all-new version, as it’s now nine years since it first appeared on our roads. Fortunately the second generation is imminent.
As a big part of the original Juke’s appeal stemmed from its divisive styling — its bug-eyed headlights in particular — Nissan has retained much of its bold design, though its reworked front end is likely to put off fewer buyers.
The car maker has, however, made big changes under the skin: the new Juke is claimed to have 20% more boot space than the original model and it comes with much more technology and gadgets this time around. Nissan says the car is much better to drive, of course.
While Nissan is a Japanese company, patriotic British motorists who are interested in a new crossover may want to consider the new Juke, as the car will still be built in Sunderland (at the time of writing for the foreseeable future, at least).
What engines will the 2020 Nissan Juke have?
From launch, Nissan Juke buyers will have access to just one engine: a 1-litre, turbocharged three-cylinder petrol that produces 115bhp. Regular readers of Driving.co.uk might very well be familiar with this engine, as it’s the same spec fitted to the facelifted Nissan Micra we reviewed back in February 2019.
Like the equivalent Micra, the new Juke comes out of the box with a six-speed manual transmission. Unlike the similarly-sized supermini, however, a seven-speed automatic is available on all trims bar the entry-level “Visia” spec as a £1,400 optional extra.
Fuel economy figures will be revealed closer to launch, though, the 1-litre engine in the Micra can return 47.9mpg on the combined cycle.
It’s also expected the new Nissan Juke will only be available as a front-wheel drive car.
Will there be a hybrid or electric Nissan Juke?
While Nissan has confirmed the engine it will launch the Juke with, it hasn’t said anything about adding more motors to the mix. That also means it remains to be seen whether the car maker has any plans to launch a hybrid Juke variant anytime soon.
As the Renault-Nissan-Mitsubishi Alliance is no stranger to electrified car tech (Nissan builds the pure-electric Leaf in Sunderland, and Renault is currently working on a hybrid engine for its new Clio supermini), a hybrid Nissan Juke isn’t beyond the realms of possibility.
What tech will the 2019 Nissan Juke feature?
With nearly a decade separating the original car from the new version, the second-gen Juke perhaps unsurprisingly is a more advanced piece of kit. In particular, it will feature an impressive array of safety aids.
All versions will come with lane departure warning, autonomous emergency braking, lane keep assist, traffic sign recognition and an “Active Trace Control” that applies the brakes to individual wheels to help the car hug the inside of corners.
Other items available across the range as standard or optional extras (depending on the trim buyers go for) include: Apple CarPlay and Android Auto; reversing cameras; automatic climate control; heated front seats; Bose premium stereo system; Nissan’s suite of semi-autonomous ProPilot driver aids (for use on dual carriageways and motorways).
How spacious is the 2020 Nissan Juke’s interior?
The original Nissan Juke was criticised for its limited practicality, so it’s no surprise the car maker has made big strides to improve this in its replacement. Despite being barely any bigger than its predecessor, the new Juke is now much more spacious: at 422 litres, the boot is 20% bigger than it was before, and Nissan says head and leg room have grown by 1.1cm and 5.8cm respectively.
How much will the 2020 Nissan Juke cost?
With all the new tech on board, it’s not a huge surprise the latest Nissan Juke is a bit pricier than its predecessor. Whereas the previous Juke in entry-level Visia spec started at £15,520, the same trim on the new Nissan will set buyers back £17,395. Prices for the flagship spec, the gadget-laden Tekna+ spec, begin at £23,895.
From launch, an even plusher ‘Premiere’ trim will be available, from £23,995. Mostly identical to the Tekna+ trim, this version is differentiated from the other models by its race car-like Alcantara fabric interior trimming, 19in alloy wheels (a claimed first for a Nissan Juke), “unique body styling” and an exclusive black-body-and-red-roof paint scheme. If that’s the spec for you, get your order in quick, as only 140 examples will be coming to the UK.
When will the 2020 Nissan Juke go on sale?
Nissan is now accepting orders for the new Juke. The car maker claims the first customer cars should land in the UK towards the tail end of November 2019.
What are the Nissan Juke’s rivals?
With the compact SUV market having exploded in the 10 years since the first-generation Nissan Juke was unveiled, the latest model will have many cars to compete against when it arrives on UK roads.
Some of the new Nissan Juke’s main competitors include the Kia XCeed, Citroën C3 Aircross, Hyundai Kona, Kia Soul, Mazda CX-3, Fiat 500X, Peugeot 2008, Ford EcoSport, Renault Captur, Vauxhall Mokka, Jeep Renegade, Honda HR-V, SEAT Arona, Toyota C-HR and Volkswagen T-Cross.
Tweet to @ST_Driving Follow @ST_Driving

Story 151
KIA is adding a new compact crossover to its model line-up: the XCeed.
What is the 2019 Kia XCeed?
The Kia XCeed is the latest member of the Ceed range, complementing the existing Ceed hatchback, Ceed SW estate and range-topping ProCeed shooting brake (sporty, coupé-style estate).
The XCeed is similar in many ways to the regular Ceed hatch on which it’s based — all of the engines have been carried over and both models take up roughly the same amount of space on the road.
However, the XCeed differentiates itself with a 46mm raised ride height, which gives drivers a more commanding view ahead, provides a more pliant ride over harsh surfaces and makes it a little easier to slide in and out of the car.
And although it takes the Ceed name, the Korean car maker says the XCeed’s front door panels are the only bits of bodywork that are interchangeable with the standard hatchback.
Kia also claims the crossover has been developed to be class-leading in terms of its sporty driving characteristics, technology, interior space and fuel efficiency.
What engines will the 2019 Kia XCeed have?
As mentioned, all of the XCeed’s engines are identical to the ones offered in the regular Ceed hatchback. The split between petrol and diesel options is broadly similar, too: three of the five available engines will run on unleaded while the two oil burners are 113bhp and 134bhp versions of the same 1.6-litre four-cylinder motor.
The petrol line-up starts with a 1-litre three-cylinder that produces 118bhp, with the next engine in the pecking order being a 1.4-litre four-cylinder with 138bhp. Buyers who want more power than that can choose to have the range-topping 201bhp 1.6-litre four-cylinder from the Ceed GT “warm hatch”.
As standard, all of the Kia XCeed’s engines will be fitted with a six-speed manual transmission. If you’re after an automatic gearbox, it’s best to avoid the 1-litre petrol as it’s the only engine that won’t be offered with the optional seven-speed auto ‘box.
Will there be a hybrid or electric Kia XCeed?
There won’t be any hybrids available in the Kia XCeed range from launch, though the Korean car maker has said electrified versions will join the range in early 2020.
Details are still TBC but expect a mild hybrid that uses a small electric motor to assist the combustion engine, and a plug-in hybrid that will allow the XCeed to drive for commuting distances on battery power alone.
It’s likely the plug-in hybrid will use the same 1.6-litre petrol engine and electric motor combination found in the forthcoming Kia Niro PHEV crossover.
What tech will the 2019 Kia XCeed feature?
Kia claims the new XCeed will be one of the most high-tech vehicles in its class, with even the most basic models comprehensively kitted out. Buyers who opt for the entry-level trim (which, perhaps unusually, is called the ‘2’ spec) will still have access to items such as Android Auto and Apple CarPlay connectivity, rear parking sensors, cruise control and driver aids such as a lane keep assist.
Anyone who opts for the ‘3’ spec will in addition get heated front seats, dual-zone climate control and Kia’s new UVO Connext telematics system, which allows drivers to receive real-time traffic updates, weather forecasts and nearby parking availability information. A range-topping ‘First Edition’ model adds items such as a powered tailgate, a premium stereo and a panoramic sunroof to the spec sheet.
How much interior space does the 2019 Kia XCeed have?
Kia claims the new XCeed is one of the most practical cars in its class, with 426 litres of boot space — an increase of 30 litres over the standard Ceed hatch and 51 litres more than is available in the crossover-style Ford Focus Active. Fold the XCeed’s rear seats and the cargo area expands to 1,378 litres.
How much will the 2019 Kia XCeed cost?
Prices for the Kia XCeed will begin at £20,795 for the entry-level ‘2’ grade model, with XCeed models in the ‘3’ trim starting at £23,295. The limited-run high-spec First Edition model (which only comes with the 1.4-litre petrol engine) will set buyers back £28,095, or £29,195 if they go for the optional automatic gearbox.
When will the 2019 Kia XCeed go on sale?
The Kia XCeed is available to order now. The first customer cars are scheduled to arrive in the UK in September 2019.
What are the 2019 Kia XCeed’s rivals?
The Kia XCeed’s closest rivals are other family hatchbacks that have been given an SUV-esque makeover, such as the Ford Focus Active and Volkswagen Golf Alltrack. Similarly-sized compact crossovers like the Toyota C-HR, Honda HR-V and Mazda CX-3 are also cars in the Kia XCeed’s crosshairs.
Tweet to @ST_Driving Follow @ST_Driving

Story 152
Demis Hassabis – former child chess prodigy, recipient of a double first at the University of Cambridge, five times World Mind Sports Olympiad champion, MIT and Harvard alumnus, games designer, teenage entrepreneur, and co-founder of the artificial intelligence startup DeepMind – is dressed in a yellow helmet, a hi-viz jacket and worker’s boots. Raising his hand to shield his eyes, he gazes across London from a rooftop in King’s Cross. The view is largely uninterrupted in every direction across the capital, which is bathed in spring sunshine. Hassabis crosses the paved roof and, having used his phone to determine the direction, scans his eyes northwards to see if he can see Finchley, where he spent his childhood. The suburb is lost behind trees on Hampstead Heath, but he is able to make out the incline leading to Highgate, where he now lives with his family.
He is here to inspect what will be the new headquarters of DeepMind, the startup he founded in 2010 with Shane Legg, a fellow researcher at University College London, and childhood friend Mustafa Suleyman. Currently the building is a construction site, ringing with the relentless percussion of hammering, drilling and grinding – there are 180 contractors on-site today and this number will rise to 500 at the peak of the build. Due to open in mid 2020, the site represents, literally and figuratively, a new beginning for the company.
“Our first office was on Russell Square, a little ten-person office at the top of a townhouse next to the London Mathematical Society,” Hassabis recalls, “which is where Turing gave his famous lectures.” Alan Turing, the British pioneer of computing, is a totemic figure for Hassabis. “We're building on the shoulders of giants,” Hassabis says, mentioning other pivotal scientific figures – Leonardo da Vinci, John von Neumann – who have made dramatic breakthroughs.
Advertisement
The location of the new headquarters – north of King’s Cross railway station in what has recently become known as the Knowledge Quarter – is telling. DeepMind was founded at a time when the majority of London startups submitted to the gravitational influence of Old Street. But Hassabis and his co-founders had a different vision: to "solve intelligence" and develop AGI (artificial general intelligence) – AI that can be applied in multiple domains. Thus far, this has been pursued largely through building algorithms that are able to win games – Breakout, chess and Go. The next steps are to apply this to scientific endeavour in order to crack complex problems in chemistry, physics and biology using computer science.
“We’re a research-heavy company,” Hassabis, 43, says. “We wanted to be near the university,” by which he means UCL – University College London – where he was awarded a PhD for his thesis, The Neural Processes Underpinning Episodic Memory. “That’s why we like being here, we’re still near UCL, the British Library, the Turing Institute, not far from Imperial…”
Read next DeepMind has finally thrashed humans at StarCraft for real DeepMind has finally thrashed humans at StarCraft for real
A few floors down, Hassabis inspects one of the areas that he’s most excited about, which will house a lecture theatre. With contentment he considers blue prints and renderings of what the space will look like.
Towards the north-east corner of the building he peers into a large void encompassing three floors, which will house the library. The space will eventually contain the feature that Hassabis seems most eager to see in its fully realised form: a grand staircase shaped like a double helix, which is in the process of being manufactured in sections. “I wanted to remind people of science and to make it part of the building,” he says.
Advertisement
Hassabis and his co-founders are aware that DeepMind is best known for its breakthroughs in machine learning and deep learning that have resulted in highly publicised events in which neural networks combined with algorithms have mastered computer games, beaten chess grandmasters and caused Lee Sedol, the world champion of Go – widely agreed to be the most complex game man has created – to declare: “From the beginning of the game, there was not a moment in time when I thought that I was winning.”
In the past, machines playing games against humans demonstrated characteristics that made the algorithm apparent: the style of play was relentless and rigid. But in the Go challenge, the DeepMind algorithm AlphaGo beat Sodol in a way that appeared to have human characteristics. One outlandish move – number 37 in game two – drew gasps from the live audience in Seoul and baffled millions watching online. The algorithm was playing with a freedom that, to human eyes, might be considered creative.
For Hassabis, Suleyman and Legg, if the first nine years of DeepMind have been defined by proving its research into reinforcement learning – the idea of agent-based systems that are not only trying to make models of their world and recognise patterns (as deep learning does) but also actively making decisions and trying to reach goals – then the proof points offered by gameplay will define the next ten years: namely, to use data and machine learning to solve some of the hardest problems in science. According to Hassabis, the next steps for the company will be based on how deep learning can enable reinforcement learning to scale to real-world problems.
Read next Inside the UK unicorn that's about to become the Intel of AI Inside the UK unicorn that's about to become the Intel of AI
“The problem with reinforcement was it was always working on toy problems, little grid worlds,” he says. “It was thought what maybe this can't scale to messy, real-world problems – and that's where the combination really comes in.”
Advertisement
For DeepMind, the emergence of the new headquarters is symbolic of a new chapter for the company as it turns its research heft and compute power to try to understand, among other things, the building blocks of organic life. In so doing, the company hopes to make breakthroughs in medicine and other disciplines that will significantly impact progress in a number of fields. “Our mission should be one of the most fascinating journeys in science,” Hassabis says. “We’re trying to build a cathedral to scientific endeavour.”
From left: Praveen Srinivasan, head of DeepMind for Google; Drew Purves, creative lead, Worlds; Raia Hadsell, research scientist, inside DeepMind's unfinished HQ in King's Cross Jason Madara
When studying at UCL and later at MIT, Hassabis found that interdisciplinary collaboration was a hot topic. He recalls that workshops would be organized involving different disciplines – neuroscience, psychology, mathematics and philosophy, for instance. There would be a couple of days of talks and debates before the academics returned to their departments, vowing that they must gather more regularly and find ways to collaborate. The next meeting would be a year later – grant applications, teaching assignments and the churn of research and scholarly life would get in the way of co-operation.
“Interdisciplinary research is hard,” Hassabis says. “Say you get two world-leading experts, in maths and genomics – there obviously could be some crossover. But who is going to do the work to understand the other person's field, their jargon, what their real problem is?”
Read next DeepMind's new AI predicts kidney injury two days before it happens DeepMind's new AI predicts kidney injury two days before it happens
Identifying the right question to ask, why that question hasn’t been answered – and what, if it’s not been answered, the tricky thing about it is – may seem, to outsiders, relatively straightforward. But scientists, even in the same discipline, don’t always see their work in the same way. And it’s notoriously hard for researchers to add value to other disciplines. It’s even harder for researchers to find a joint question that they might answer.
The current DeepMind headquarters – two floors of Google's King’s Cross building – has become increasingly populous in the past couple of years. There are six or seven disciplines represented in the company’s AI research alone, and it has been hiring specialists in mathematics, physics, neuroscience, psychology, biology and philosophy as it broadens its remit.
“Some of the most interesting areas of science are in the gaps between, the confluences between subjects,” Hassabis says. “What I've tried to do in building DeepMind is to find 'glue people', those who are world class in multiple domains, who possess the creativity to find analogies and points of contact between different subjects. Generally speaking, when that happens, the magic happens.”
One such glue person is Pushmeet Kohli. The former director at Microsoft Research leads the science team at DeepMind. There is much talk in artificial intelligence circles of the "AI winter" – a period where there was little tangible progress – having ended during the past decade. The same sense of movement is now also true of protein folding, the science of predicting the shape of what biologists consider to be the building blocks of life.
Kohli has brought together a team of structural biologists, machine-learning experts and physicists in order to address this challenge, widely recognised as one of the most important questions in science. Proteins are fundamental to all mammalian life – they make much of the structure and function of tissues and organs at a molecular level. Each is comprised of amino acids, which make up chains. The sequence of these determines the shape of the protein, which determines its function.
Read next Our future is about collaboration between AI and humanity Our future is about collaboration between AI and humanity
“Proteins are the most spectacular machines ever created for moving atoms at the nanoscale and often do chemistry orders of magnitude more efficiently than anything that we've built,” says John Jumper, a research scientist at DeepMind who specialises in protein folding. “And they're also somewhat inscrutable, these self–assembling machines.”
Proteins arrange atoms at the angstrom scale, a unit of length equivalent to one ten-billionth of a metre; a deeper understanding would offer scientists a much more substantial grasp of structural biology. For instance, proteins are necessary for virtually every function within a cell, and incorrectly folded proteins are thought to be contributing factors to diseases such as Parkinson’s, Alzheimer’s and diabetes.
“If we can learn about the proteins that nature has made, we can learn to build our own,” Jumper says. “It’s about getting a really concrete view into this complex, microscopic world.”
What has made protein folding an attractive puzzle for the DeepMind team has been the widespread availability of genomic data sets. Since 2006 there has been an explosion in DNA data acquisition, storage, distribution and analysis. Researchers estimate that by 2025 two billion genomic data sets may have been analysed, requiring 40 exabytes of storage capacity.
“It's a nice problem from a deep learning perspective, because at enormous expense, enormous complexity and enormous time [commitment], people have generated this amazing resource of proteins that we already understand,” Jumper says.
Read next Inside the urgent battle to stop UK police using facial recognition Inside the urgent battle to stop UK police using facial recognition
While progress is being made, scientists urge against false exuberance. The esteemed American molecular biologist Cyrus Levinthal expressed the complexity of the challenge in a bracing manner, noting that it would take longer than the age of the universe to enumerate all the possible configurations of a typical protein before reaching the right 3D structure. “The search space is huge,” says Rich Evans, a research scientist at DeepMind. “It’s bigger than Go.”
Nevertheless, a milestone in the protein-folding journey was reached in December 2018 at the CASP (Critical Assessment of Techniques for Protein Structure Prediction) competition in Cancun, Mexico – a biennial challenge that provides an independent way of plotting researchers’ progress. The aim for competing teams of scientists is to predict the structure of proteins from sequences of their amino acids for which the 3D shape is known but not yet made public. Independent assessors verify the predictions.
The protein-folding team at DeepMind entered as a way of benchmarking AlphaFold, the algorithm it had developed over the previous two years. In the months leading up to the conference, the organisers sent data sets to the team members in King’s Cross, who sent back their predictions with no sense of how they would fare. In total, there were ninety protein structures to predict – some were template-based targets, which use previously solved proteins as guidance, others were modeled from scratch. Shortly before the conference, they received the results: AlphaFold was, on average, more accurate than the other teams. And some metrics put DeepMind significantly ahead of the other teams, for protein sequences modeled from scratch — 43 of the 90 – AlphaFold made the most accurate prediction for 25 proteins. The winning margin was striking: its nearest rival managed three.
A "ribbon diagram" visualisation of a protein's backbone, folded into a 3D structure predicted by the AlphaFold algorithm for the CASP13 competition
Mohammed AlQuraishi, a fellow at the Laboratory of Systems Pharmacology and the Department of Systems Biology at Harvard Medical School, attended the event, and learned about the DeepMind approach before the results were published. “Reading the abstract, I didn't think ‘Oh, this is completely new’,” he says. “I accepted they would do pretty well, but I wasn't expecting them to do as well as they did.”
Read next Netflix's I Am Mother is a tired take on an old AI thought experiment Netflix's I Am Mother is a tired take on an old AI thought experiment
According to AlQuraishi, the approach was similar to that of other labs, but what distinguished the DeepMind process was that they were able to “execute better”. He points to the strength of the DeepMind team on the engineering side.
“I think they can work better than academic groups, because academic groups tend to be very secretive in this field,” AlQuraishi says. “And so, even though the ideas DeepMind had in their algorithm were out there and people were trying them independently, no one has brought it all together.”
AlQuraishi draws a parallel with the academic community in machine learning, which has undergone something of an exodus in recent years to companies like Google Brain, DeepMind and Facebook, where organisational structures are more efficient, compensation packages are generous, and there are computational resources that don’t necessarily exist at universities.
“Machine learning computer science communities have sort of really experienced that over the last four or five years,” he says. “Computational biology is just now waking up to this new reality.”
This echoes the explanation given by the founders of DeepMind when they sold to Google in January 2014. The sheer scale of Google's computational network would enable the company to move research forward much more quickly than if it had to scale organically, and the £400 million cheque enabled the startup to hire world-class talent. Hassabis describes a strategy of targeting individuals who have been identified as a good fit for specific research areas. “We've our roadmap that informs what subject areas, sub-fields of AI or neuroscience will be important,” he says. “And then we go and find the world's best person who fits in culturally as well.”
Read next For the good of humanity, AI needs to know when it's incompetent For the good of humanity, AI needs to know when it's incompetent
“So far as a company like DeepMind can make a dent, I think protein folding is a very good place to start, because it's a problem that’s very well defined, there’s useable data, you can almost treat it like a pure computer science problem,” AlQuraishi says. “That's probably not true in other areas of biology. It's a lot messier. So, I don't necessarily think that the success that DeepMind has had with protein folding will translate automatically to other areas.”
DeepMind staffers pictured on the roof of Google's offices in King's Cross Jason Madara
For a research company, DeepMind is big on project management. Every six months, senior managers examine priorities, reorganise some projects, and encourage teams – especially engineers – to move between endeavours. Mixing of disciplines is routine and intentional. Many of the company’s projects take longer than six months – generally in the range of two to four years. But, as much as DeepMind’s messaging is consistently around its research, it is now a subsidiary of Alphabet, Google's parent company and the world’s fourth most valuable company. While the expectation from the academics in London is that they are involved in long-term, ground-breaking research, executives in Mountain View, California, will naturally have an eye on ROI – return on investment.
“We care about products in the sense that we want Google and Alphabet to be successful and to get benefit out of the research we're doing – and they do, there are dozens of products now with DeepMind code and technology in them all around Google and Alphabet – but the important thing is that it’s got to be a push, not a pull,” Hassabis says. DeepMind for Google, led by Suleyman, comprises about one hundred people, mostly engineers who translate the company’s pure research into applications that are productised. For example, WaveNet, a generative text-to-speech model that mimics the human voice is now embedded in most Google devices from Android to Google Home, and has its own product team within Google.
“A lot of research in industry is product led,” Hassabis says. “The problem with that is that you can only get incremental research. [That’s] not conducive to doing ambitious, risky research, which, of course, is what you need if you want to make big breakthroughs.”
Read next Why London's streets are a total nightmare for self-driving cars Why London's streets are a total nightmare for self-driving cars
In conversation, Hassabis talks rapidly, often punctuating the end of a sentence with the interrogative "right?", guiding the listener through a sequence of observations. He makes frequent, lengthy digressions into various tributaries – philosophy (Kant and Spinoza are favourites), history, gaming, psychology, literature, chess, engineering and multiple other scientific and computational domains – but doesn’t lose sight of his original thought, often returning to clarify a remark or reflect on an earlier comment.
Much like the 300-year vision of Masayoshi Son, the founder of SoftBank – the Japanese multinational with large stakes in many of the world's dominant technology companies –Hassabis and the other founders have a “multi-decade roadmap" for DeepMind. Legg, the company chief scientist, still has a hard copy of the initial business plan circulated to potential investors. (Hassabis has lost his.) Legg occasionally reveals it at all-hands meetings to demonstrate that many of the approaches the founders were thinking about in 2010 – learning, deep learning, reinforcement learning, using simulations, ideas of concepts and transfer learning, and using neuroscience, memory and imagination – are still core parts of its research programme.
During its infancy, DeepMind had a single web page featuring just the company logo. There was no address, no phone number, no jaunty "about us" information. To make hires, the founders had to rely on personal contacts for people who already knew they were “serious people and serious scientists and had a serious plan”, as Hassabis puts it.
“With any startup, you're really asking people to trust you as management,” he says. “But [with DeepMind] it’s even more because you're basically saying you're going to do this in a completely unique way that no one's ever done before, and a lot of traditional, top scientists would have said was impossible: ‘You just cannot organise science in this fashion.’”
How scientific breakthroughs occur is as unknown as some of the problems that researchers are trying to solve. In academia, great minds are gathered together in institutions to undertake research that’s iterative, often with uncertain outcomes. Progress is usually painstaking and slow. Yet, in the private sector, supposedly free of restraint and with access to highly compensated management consultants, productivity and innovation are also declining.
Read next How AI is radically changing our definition of human creativity How AI is radically changing our definition of human creativity
In February 2019, Stanford economist Nicholas Bloom published a paper demonstrating declining productivity in a wide-ranging number of sectors. “Research effort is rising substantially while research productivity is declining sharply,” Bloom wrote. “A good example is Moore’s Law. The number of researchers required today to achieve the famous doubling every two years of the density of computer chips is more than 18 times larger than the number required in the early 1970s. Across a broad range of case studies at various levels of (dis)aggregation, we find that ideas – and in particular the exponential growth they imply – are getting harder and harder to find.”
Hassabis mentions the billions invested into research by Big Pharma: driven by quarterly earnings reports, the industry has become more conservative as the costs of failure have risen. According to a report by innovation foundation Nesta in 2018, over the past 50 years biomedical R&D productivity has steadily fallen – despite significant increases in public and private investment, new drugs cost much more to develop. According to the report, “the exponentially increasing cost of developing new drugs is directly reflected in low rates of return on R&D spending. A recent estimate puts this rate of return at 3.2 per cent for the world’s biggest drug companies; substantially less than their cost of capital.” Similarly, research from Deloitte estimated that R&D returns in biopharma had declined to their lowest rate in nine years, from 10.1 per cent in 2010, to 1.9 per cent in 2018.
“If you look at the CEOs of most of the big pharma companies, they're not scientists, they come from the finance department, or the marketing department,” Hassabis says. “What does that say about the organisation? It means that what they're going to do is try and squeeze more out of what has already been invented, cut costs or market better, not really invent new things – which is much more risky. You can’t put that down so easily in a spreadsheet. That’s not the nature of blue sky thinking… that's not how you do it if you're trying to land the rocket on the moon.”
Pushmeet Kohli, research lead, science team Jason Madara
For many startup founders, there is a degree of serendipity to their mission – a problem they’ve encountered that they decided to solve, a chance encounter with a co-founder or investor, an academic advocate. This is not the case for Hassabis, who has purposefully made a series of decisions – some very early in life – that would lead to DeepMind. “It’s what I spent my whole life preparing for,” he says. “From games design to games playing to neuroscience to programming, to studying AI in my undergrad, to going to a lot of the world's top institutes, doing a PhD as well as running a start-up in my earlier career… I’ve tried to use every scrap of experience. I've consciously picked each of those decision points to gather that piece of experience.”
Read next Forget about artificial intelligence, extended intelligence is the future Forget about artificial intelligence, extended intelligence is the future
Add to that list being a CEO, which is now his day job. He has another role – that of researcher – and, in order to do both, he structures his time into distinct periods so that he can balance the running of the business with his academic interests. Having played the role of executive during the day, he returns home around 7.30pm to have dinner with his young family before embarking on a “second day” around 10.30pm, which will generally end around 4.00am to 4.30am.
“I love that time,” he says. “I’ve always been a nocturnal person, since I was a kid. Everything is quiet in the city and the house and I find it very conducive to thinking, reading, writing these kinds of things. So that's when I mostly keep up to speed with the scientific literature. Or maybe I'll be writing or editing a paper, or thinking up some new algorithmic idea, or thinking about something strategic, or be investigating some area of science that AI could be applied to.”
He listens to music when he works. The nature of the music – from classical to drum and bass – depends "on the emotion I’m trying to evoke in myself. It depends on whether I’m trying to be focused or inspired.” There are a couple of rules: there can be no vocals, otherwise he will try and listen to the lyrics; and there needs to be a level of acquaintance with the music. “It needs to be something I’m familiar with, but not too familiar with. And it can’t be a new piece of music because that is too disturbing for the brain. You’ve got to break a tune in and then you can use it.”
Hassabis says that he would like to spend 50 per cent of his time on direct research. As part of this, in April 2018, he hired Lila Ibrahim, a Silicon Valley veteran who spent 18 years at Intel before becoming Chief of Staff at Kleiner, Caulfield, Perkins and Byers – one of the most established venture capital firms in the Valley – before moving to the startup Coursera. Ibrahim is taking on many of Hassabis’s managerial tasks – he says his direct reports have dropped from 20 people to six. Ibrahim describes her decision to join DeepMind as “a moral calling,” prompted by conversations she had with Hassabis and Legg regarding the establishment of its Ethics & Society initiative, which is attempting to establish standards around the application of the technology.
“I think being based in London it brings a slightly different perspective, she says. “What would have happened if DeepMind had been headquartered in Silicon Valley would have been a very different, I think. London feels like there's so much more humanity… the art, the cultural diversity. There’s also what the founders brought in from the start and the type of people who choose to work at DeepMind brought in certain ways of doing things, a mindset.”
Lila Ibrahim, DeepMind's chief operating officer Jason Madara
One incident perhaps offers insight into the approach Ibrahim describes. Hassabis was a chess prodigy. Starting at the age of four, he rose up the rankings until, when 11, he found himself competing against a Danish master at a big, international competition in the town hall of a village outside Liechtenstein.
After playing for close to twelve hours, the endgame approached. It was a scenario that Hassabis had never seen before – he had a queen, while his opponent had a rook, bishop and knight, but it was still possible for Hassabis to force a draw if he could keep his opponent’s king in check. Hours passed, the other games ended and the hall emptied. Suddenly, Hassabis realised that his king had been trapped, meaning that check mate would be forced. Hassabis resigned.
“I was really tired,” he says. “We were 12 hours in or something and I thought somehow I must have made a mistake and he's trapped me.”
His opponent – a man Hassabis recalls being in his 30s or 40s – stood up. His friends were standing around him and he laughed and gestured at the board. Hassabis realised that he had resigned unnecessarily – the game should have been a draw.
“All I needed was to sacrifice my queen,” he says. “This was his last roll of the dice. He'd been trying for hours to outmanoeuvre me. And that was his final cheap trick. And it worked. Basically, I had nothing to show for 12 hours of slog.”
Hassabis recalls that, at that moment, he had an epiphany: he questioned the purpose of the brilliant minds in the room competing with each other to win a zero-sum game. He would go on to play the game at the highest level, captaining his university team, and still talks of his continued love of complex games, but the experience led to him channeling his energy into something beyond games. “The reason that I could not become a professional chess player, he says. “Is that it didn't feel productive enough somehow.”
Even as the company expands into its new headquarters, Hassabis maintains that DeepMind is still a startup, albeit one that is competing on a world stage – “China is mobilised and the US… there are serious companies trying to do these things,” he says. Indeed, the US and the China are both positioning themselves to standardise the field to their own advantage, both commercially and geopolitically. He mentions several times that, despite having made progress (“small stepping stones on the way”), there is still a long way to go in DeepMind’s bigger mission of solving intelligence and building AGI. “I still want us to have that hunger and the pace and the energy that the best startups have,” he says.
Innovation is hard and often singular. Building the processes and culture of an organisation that will enable it to “make a dent in the universe,” as Steve Jobs told the team building the Macintosh computer – and doing so in multiple fields or with more than one product – is something that few companies or institutions achieve. As DeepMind grows, it will be the role of the founders to pursue the road ahead, while keeping an eye on the founding principles of a business focused on what is likely to be the most transformative technology of the coming years, one fraught with possible dangers, as well as opportunities.
“You’re going to hit a lot of rough days and I think, at the end of the day, trying to make money or whatever isn't going to be enough to get you through the real pain points,” Hassabis says. “If you have a real passion and you think what you're doing is really important, then I feel like that will carry you through.”
More great stories from WIRED
🖼️ How to harness Google Photos to your messy pictures
😡 Heatwaves make people more violent, angry and grumpy
🚬 England has an ambitious plan to eradicate smoking by 2030
🕵🏿 It's time you ditched Chrome for a privacy-first web browser
Advertisement
🎉 A vaccine for Alzheimer's is on the verge of reality
📧 Get the best tech deals and gadget news in your inbox

Story 153
Cassius Winston steals the show from Zion in the Elite Eight
Cassius Winston steals the show from Zion in the Elite Eight
The season did not end as Zion Williamson and R.J. Barrett intended. The fabulous freshmen came to Duke to win a national championship and their bid came up short with a loss to Michigan State in the Elite Eight.
Williamson and Barrett still managed to make a bit of history.
BRACKET: Check yours | Interactive | Printable
The Duke duo was named to The Associated Press All-America team on Tuesday, becoming the second freshman teammates to make the first team in the same season. They were joined by Tennessee’s Grant Williams, Michigan State’s Cassius Winston and Ja Morant of Murray State.
Kentucky’s DeMarcus Cousins and John Wall were the only other freshman teammates to take first-team AP honors in 2010.
The 6-foot-7, 285-pound Williamson electrified college basketball with an array of thunderous dunks and soaring blocks, occasionally having to tilt his head to avoid hitting it on the backboard. He was selected unanimously by 64 voters as a first-team All-American. He averaged 22.1 points, 8.9 rebounds, 2.2 blocked shots and 1.8 steals per game while leaving everyone wondering what he would do next.
“He’s got the most incredible first step,” Michigan State coach Tom Izzo said. “That’s why he’s getting all those steals. He can take one dribble and cover more space than most human beings that I know can do. And so then he has the strength to finish at the end. So he’s not Superman, but he’s damn close.”
Barrett arrived at Duke as the higher-rated recruit and while everyone fawned over his high-flying teammate, the athletic 6-7 guard quietly had a superb season in Durham. Barrett led the Blue Devils with 22.9 points, grabbed 7.5 rebounds and dished 4.1 assists per game on a team that came a game short of the Final Four.
Williams was the SEC player of the year a season ago and may have been even better while winning the award this year.
FINAL FOUR: 19 reasons to love the 2019 Final Four | Only 0.02% predicted the Final Four
The 6-7 junior averaged 19 points per game while shooting 57% and had 7.6 rebounds, 3.1 assists and lead the Vols to the Sweet 16 for the first time in five years.
Morant was the most exciting player in college basketball not named Zion, lighting up highlight reels with emphatic dunks and no-look passes.
The 6-3 point guard may have turned himself into an NBA lottery pick his sophomore season, leading the nation with 10 assists per game and averaging 24.6 points to become Murray State’s first first-team All-American.
“He’s one of the most exceptional players that I’ve had a chance to watch play,” Florida State coach Leonard Hamilton said. “He’s kind of a throwback to guys who have the ability to score points. But also has the passion and the excitement about creating opportunities for his teammates.”
Winston is not the most athletic player, even on his own team. He is heady, ultra tough and a big reason the Spartans are in the Final Four.
He averaged 18.9 points, 7.6 assists and was Michigan State’s go-to guy when a big shot was needed.
(*Statistics through March 17)
First Team
Zion Williamson, Duke, 6-7, 285, freshman, Spartanburg, S.C., 22.1 ppg, 8.9 rpg, 2.1 apg, 69.3 fg pct, 1.8 blocks, 2.2 steals (64 of 64 first-place votes, 320 points).
Grant Williams, Tennessee, 6-7, 236, junior, Charlotte, N.C., 19.0 ppg, 7.6 rpg, 3.1 apg, 56.5 fg pct, 82.6 ft pct, 1.4 blocks, 1.1 steals (49, 286).
RJ Barrett, Duke, 6-7, 202, freshman, Mississauga, Ontario, 22.9 ppg, 7.5 rpg, 4.1 apg (44, 275).
Ja Morant, Murray State, 6-3, 175, sophomore, Dalzell, S.C., 24.6 ppg, 5.5 rpg, 10.0 apg, 50.3 fg pct, 81.0 ft pct, 1.8 steals (43, 272).
Cassius Winston, Michigan State, 6-1, 185, junior, Detroit, 18.9 ppg, 3.1 rpg, 7.6 apg, 40.4 3-pt fg pct, 84.0 ft pct (42,268).
Ja Morant leads Murray State to dominating win over Marquette
Second Team
Rui Hachimura, Gonzaga, 6-8, 230, junior, Toyama, Japan, 20.1 rpg, 6.6 rpg, 60.9 fg pct, 1.0 steals (25, 207).
Jarrett Culver, Texas Tech, 6-6, 195, sophomore, Lubbock, Texas, 18.5 ppg, 6.3 rpg, 3.7 apg, 1.4 steals (15, 188).
Markus Howard, Marquette, 5-11, 175, junior, Chandler, Ariz., 24.8 ppg, 3.9 rpg, 4.0 apg, 40.6 3-pt fg pct, 3.5 3-pt fg/game, 88.7 ft pct, 1.1 steals (11, 186).
Ethan Happ, Wisconsin, 6-10, 237, senior, Milan, Ill., 17.5 ppg, 10.1 rpg, 4.6 apg, 53.1 fg pct, 1.3 blocks, 1.1 steals (6, 139).
Carsen Edwards, Purdue, 6-1, 200, junior, Atascocita, Texas, 23.0 ppg, 3.5 rpg, 3.0 apg, 84.3 ft pct, 3.3 3-pt fg/game, 1.4 steals (6, 133).
Purdue's Carsen Edwards leaves big impression on Virginia despite loss
Third Team
De’Andre Hunter, Virginia, 6-7, 225, junior, Philadelphia, 15.1 ppg, 5.0 rpg, 2.1 apg, 53.0 fg pct, 45.7 3-pt fg pct (3, 125).
Dedric Lawson, Kansas, 6-9, 235, Memphis, Tenn., 19.1 ppg, 10.3 rpg, 82.4 ft pct, 1.1 blocks, 1.3 steals (3, 110).
Brandon Clarke, Gonzaga, 6-8, 215, junior, Phoenix, 16.5 ppg, 8.4 rpg, 69.3 fg pct, 3.1 blocks, 1.2 steals (4, 92).
PJ Washington, Kentucky, 6-8, 228 sophomore, Dallas, 14.8 ppg, 7.5 rpg, 51.5 fg pct, 41.9 3-pt fg pct, 1.2 blocks (1, 79).
Kyle Guy, Virginia, 6-2, 175, junior, Indianapolis, 15.6 ppg, 4.4 rpg, 2.2 apg, 46.3 3-pt fg pct, 83.6 ft pct (1, 44).
Honorable Mention (alphabetical order)
Keith Braxton, St. Francis (Pa.); Ignas Brazdeikis, Michigan; Tookie Brown, Georgia Southern; Chris Clemons, Campbell; RJ Cole, Howard; Jeremy Combs, Texas Southern; Jarron Cumberland, Cincinnati; Mike Daum, South Dakota State; Jordan Davis, Northern Colorado; Cameron Delaney, Sam Houston State; Lamine Diane, Cal State Northridge; Daniel Gafford, Arkansas; Jon Axel Gudmundsson, Davidson; Rapolas Ivanauskas, Colgate; Ty Jerome, Virginia; Cameron Johnson, North Carolina; Anthony Lamb, Vermont; Fletcher Magee, Wofford; Caleb Martin, Nevada; CJ Massinburg, Buffalo; Garrison Mathews, Lipscomb; Luke Maye, North Carolina; Drew McDonald, Northern Kentucky; Sam Merrill, Utah State; Jaylen Nowell, Washington; Miye Oni, Yale; Shamorie Ponds, St. John’s; Myles Powell, Seton Hall; Admiral Schofield, Tennessee; Marial Shayok, Iowa State; B.J. Stith, Old Dominion; Matisse Thybulle, Washington; Jake Toolson, Utah Valley; Marques Townes, Loyola of Chicago; Tremont Waters, LSU; Coby White, North Carolina; Justin Wright-Foreman, Hofstra; Cameron Young, Quinnipiac.

Story 154
The jump from college football Saturdays to NFL Sundays is something every college football player dreams about. Although not every player from every school reaches the NFL, some schools seem to produce more NFL talent than others.
NFL teams released their final 53-man rosters over Labor Day weekend, solidifying the official start to the professional football season.
NFL ROSTER BREAKDOWNS: FCS players on 2019 NFL rosters | DII players in the NFL | DIII in the NFL
A whopping 1,439 out of 1,696 players in the NFL come from FBS programs, about 85 percent of the entire league. What conference and team supply the most of these players? Well, if you have been paying attention on Saturdays for the past decade, you could make an educated guess.
USA Today Kyler Murray playing quarterback for the Arizona Cardinals and the Oklahoma Sooners - his college and professional teams.
Alabama, just like last year, leads all schools with 56 players on active NFL rosters, followed by Ohio State and fellow SEC schools Florida and LSU.
The top two schools on the list have supplied the NFL with loads of talent. From rookie Josh Jacobs (Oakland Raiders) to seasoned wideout and six-time pro-bowler Julio Jones (Atlanta Falcons), the Crimson Tide have their mark all over the league.
As for Ohio State (45 former players), names like Ezekiel Elliott (Dallas Cowboys), Michael Thomas (New Orleans Saints) and Joey Bosa (Los Angeles Chargers) hold it down for the Buckeyes.
Behind Alabama and Ohio State come Florida and LSU, who have 35 and 32 former team members in the NFL respectively. Seven programs in total have at least 30 representatives at the next level.
SUPER BOWL MVPS: Where all 53 Super Bowl MVPs went to college
The SEC is known for pumping out NFL talent, as five out of the top 10 programs that have the most active NFL players are SEC schools. The Southeastern Conference has 339 total active players in the NFL right now. The next closest conference is the Big Ten who trails the SEC by 87 players.
(Note: This list only highlights players on active 53-man rosters, according to NFL team websites, as of Sept. 3. It includes FBS teams and conferences only. It does not include players on the injury reserved lists, practice squads or commissioner’s exempt list).
conference players on NFL rosters SEC 339 Big Ten 253 ACC 215 Pac-12 189 Big 12 122 American 100 Mountain West 65 C-USA 59 MAC 46 Independent 35 Sun Belt 21
Want to know where your school ranks heading into the 2019 regular season?
Check out the full list of FBS schools with active NFL players below.

Story 155
Ai-Da looks at me through those mysterious hazel eyes of hers and winks a playful wink. “You’re very beautiful,” I splutter. “Thank … you,” she whispers back.
My eyes drift down to her magnificent lips. Not since I interviewed Liv Ullmann, back in the day, have I seen lips like these: full and puffy, like a beckoning sofa. Oh, how I want to throw myself onto them. If Ai-Da had a hand, I would probably have reached down, there and then, and written my phone number on it. But she doesn’t. It’s more of a functional claw, engineered specifically to hold a drawing pen. In any case, I don’t think my ballpoint works on aluminium.
I was expecting all kinds of things when I set…

Story 156
Fehler 403: Ihr Zugriff auf diese Seite wurde verweigert
Mögliche Ursachen fÃ¼r diesen Fehler sind:
Es wurde keine Index-Seite (z.B. index.html oder index.php) hinterlegt
Ihre Anfrage wurde von unserer Web Application Firewall unterbunden. Sofern Sie der Betreiber dieser Website sind, können Sie die Web Application Firewall in unserem Control Panel web174.dogado.net:8443 anpassen oder deaktivieren.
Error 403: your request was denied
Possible causes for this error are:

Story 157
LOVE Island's Tommy Fury and Molly-Mae Hague will tonight spend their first night together in the hideaway.
The couple will finally get some alone time after making their relationship official this week.
8 Molly-Mae and Tommy get close in the hideaway in tonight's episode of Love Island Credit: Rex Features
8 Tommy and Molly-Mae have already 'done bits' bit in the villa
They have already "done bits" in the villa bedroom - but tonight could give them the space they need to go all the way.
Maura gets a text saying: "Islanders, tonight the hideaway is open. It's down to you to choose one lucky couple to have a sleepover."
Everyone excitably starts chanting "Tommy and Molly" before Michael picks the boxer up in the air before landing on the kitchen floor.
Molly-Mae appears slightly nervous as she blushes over the attention. She previously denied "doing bits" with Tommy after it was revealed Tommy had performed a sexual act on her.
8 Molly-Mae looked a little nervous when the news was announced Credit: ITV
But according to former Islander Amy Hart, Love Island 2019 will be the first ever sex-free series as contestants are too worried about parents watching them in bed.
The Air Hostess, 27, who quit the villa on Monday, told The Sun's Bizarre: "No one wants to have sex as it’s a family show now.
"It used to be more niche but my 73-year-old nan and grandad are obsessed with it.
"It was hard knowing they would be watching it and seeing me upset."
8 Credit: ITV
Tommy looked excited as the boys cheered
In previous series, most of the intimate moments have taken place in the hideaway, where couples can enjoy some alone time.
The space has only been used once this series by Curtis Pritchard and Amy on day eight, and has not been seen since.
8 Maura read out a text awarding the islanders with a night in the hideaway Credit: ITV
8 Michael picked Tommy up in excitement Credit: ITV
Both Tommy and Molly-Mae were left in a hot flush last night during the "heart-racing challenge".
The Islanders had to give each other a sexy dance to boost their heart rate - before being told who had set it racing the most.
Tommy and Molly-Mae proved they fancy each other the most, with the boxer admitting: "That was the sexiest thing I've ever seen."
8 Tommy performed a sex act on Molly-Mae on Love Island – but the pair didn't go all the way
The pair haven't gone all the way since getting together on the show.
But Molly-Mae was heard gasping "Jesus Christ" from underneath the covers during the last few seconds of the programme.
Viewers said they heard "sex noises" as they laid side-by-side in their bed together.
Later they were left shocked when she reached under the covers while in bed with Tommy and shouted: "It's f***ing huge."
8
Got a story? email digishowbiz@the-sun.co.uk or call us direct on 02077824220.
We pay for videos too. Click here to upload yours.

Story 158
The Maryland Terrapins are your 2019 women's lacrosse national champions. The Terps beat Boston College 12-10 to capture their 14th title in program history, and their fourth in the past six years.
Boston College has now lost in the title game in three straight seasons.
The national championship matchup was a rematch of the 2017 national championship, which saw the Terps win 16-13.
WOMEN'S LACROSSE CHAMP: View the final interactive bracket | Box score | Latest news
No. 2 Boston College got to the finals for the third straight year following a thrilling 15-14 double overtime win over North Carolina. Senior Sam Apuzzo delivered the game-winning goal at 4:48 in the second overtime period to complete the comeback. The Eagles trailed by six goals in the first half before kicking things into gear.
Maryland broke an early 4-4 tie against Northwestern in their semifinal matchup, then never trailed again. The Terps avenged their Big Ten tournament defeat, topping Northwestern in dominating fashion 25-13. The game marked the most goals the Terps had ever scored in Cathy Reese's 13 seasons at the helm and it was an offensive effort powered by Brindi Griffin's six goals and one assist.
SHOP MARYLAND WOMEN'S LACROSSE 2019 CHAMPIONSHIP GEAR
Check out the full bracket, schedule and scores below, as well as live updates from the two semifinal matches and the championship.
2019 NCAA Women's Lacrosse Tournament: Bracket
Click here for a printable bracket | Interactive bracket
2019 NCAA Women's Lacrosse Tournament: Schedule
Click here for a scoreboard.
Sunday, May 26 — National Championship
at Homewood Field at Johns Hopkins
No. 1 Maryland 12, No. 2 Boston College 10
Friday, May 24 — Semifinals
at Homewood Field at Johns Hopkins
No. 2 Boston College 15, No. 3 North Carolina 14 (2OT)
No. 1 Maryland 25, No. 4 Northwestern 13
Follow below for live updates from the DI championship.
Tuesday, May 7 — Opening Round
Jacksonville 22, Mercer 7
Wagner 15, Fairfield 13
Friday, May 10 — First Round
Stony Brook 10, James Madison 9 (OT)
No. 8 Michigan 13, Jacksonville 9
Georgetown 13, Penn 12 (2OT)
Loyola Maryland 19, Richmond 6
Colorado 16, Dartmouth 13
Florida 16, Johns Hopkins 9
Navy 16, High Point 5
Denver 11, Southern California 10 (OT)
No. 7 Princeton 19, Wagner 7
Notre Dame 15, Stanford 9
Sunday, May 12 — Second Round
No. 1 Maryland 17, Stony Brook 8
No. 6 Virginia 15, Navy 12
Denver 9, No. 8 Michigan 5
No. 2 Boston College 21, Colorado 9
No. 3 North Carolina 15, Florida 11
No. 7 Princeton 17, Loyola Maryland 13
No. 4 Northwestern 13, Notre Dame 10
No. 5 Syracuse 14, Georgetown 8
Saturday, May 18 — Quarterfinals
No. 3 North Carolina 14, No. 6 Virginia 7
No. 2 Boston College 17, vs. No. 7 Princeton 12
No. 4 Northwestern 18, No. 5 Syracuse 14
No. 1 Maryland 17, Denver 8
2019 NCAA Women's Lacrosse Tournament: Teams, seeds
Here are the teams that qualified automatically:
Division I Women's Lacrosse Automatic Qualifiers CONFERENCE SCHOOL, RECORD American Athletic Florida (13-6) America East Stony Brook (15-4) Atlantic 10 Richmond (17-3) ACC North Carolina (15-3) ASUN Jacksonville (16-3) Big East Georgetown (11-8) Big South High Point (15-4) Big Ten Northwestern (14-4) Colonial James Madison (16-3) Ivy League Princeton (14-3) MAAC Fairfield (15-3) Northeast Wagner (15-3) Pac-12 Southern California (16-3) Patriot Loyola Maryland (15-4) SoCon Mercer (10-9)
Teams Selected At-Large:

Boston College (19-1)
Colorado (10-7)
Dartmouth (11-5)
Denver (14-3)
Johns Hopkins (10-7)
Maryland (18-1)
Michigan (15-3)
Navy (15-4)
Notre Dame (13-4)
Penn (12-5)
Stanford (13-5)
Syracuse (15-4)
Virginia (12-6)
Seeds:
Maryland: 18-1 Boston College: 19-1 North Carolina: 15-3 Northwestern: 14-4 Syracuse: 15-4 Virginia: 12-6 Princeton: 14-3 Michigan: 15-3
NCAA Women's Lacrosse Tournament: History, champions
YEAR CHAMPION COACH SCORE RUNNER-UP SITE 2018 James Madison Shelley Klaes-Bawcombe 16-15 Boston College Stony Brook, N.Y. 2017 Maryland Cathy Reese 16-13 Boston College Foxborough, Mass. 2016 North Carolina Jenny Levy 13-7 Maryland Chester, Pa. 2015 Maryland Cathy Reese 9-8 North Carolina Chester, Pa. 2014 Maryland Cathy Reese 15-12 Syracuse Towson, Md. 2013 North Carolina Jenny Levy 13-12 (3OT) Maryland Villanova 2012 Northwestern Kelly Amonte Hiller 8-6 Syracuse Stony Brook 2011 Northwestern Kelly Amonte Hiller 8-7 Maryland Stony Brook 2010 Maryland Cathy Reese 13-11 Northwestern Towson 2009 Northwestern Kelly Amonte Hiller 21-7 North Carolina Towson 2008 Northwestern Kelly Amonte Hiller 10-6 Penn Towson 2007 Northwestern Kelly Amonte Hiller 15-13 Virginia Penn 2006 Northwestern Kelly Amonte Hiller 7-4 Dartmouth Boston University 2005 Northwestern Kelly Amonte Hiller 13-10 Virginia Navy 2004 Virginia Julie Myres 10-4 Princeton Princeton 2003 Princeton Chris Sailer 8-7 (OT) Virginia Syracuse 2002 Princeton Chris Sailer 12-7 Georgetown Loyola (Md.) 2001 Maryland Cindy Timchal 14-13 (OT) Georgetown Johns Hopkins 2000 Maryland Cindy Timchal 16-8 Princeton TCNJ 1999 Maryland Cindy Timchal 16-6 Virginia Johns Hopkins 1998 Maryland Cindy Timchal 11-5 Virginia UMBC 1997 Maryland Cindy Timchal 8-7 Loyola (Md.) Lehigh 1996 Maryland Cindy Timchal 10-5 Virginia Lehigh 1995 Maryland Cindy Timchal 13-5 Princeton TCNJ 1994 Princeton Chris Sailer 10-7 Maryland Maryland 1993 Virginia Jane Miller 8-6 (OT) Princeton Maryland 1992 Maryland Cindy Timchal 11-10 (OT) Havard Lehigh 1991 Virginia Jane Miller 8-6 Maryland TCNJ 1990 Harvard Carole Kleinfelder 8-7 Maryland Princeton 1989 Penn State Susan Scheetz 7-6 Harvard West Chester 1988 Temple Tina Sloan Green 15-7 Penn State Haverford 1987 Penn State Susan Scheetz 7-6 Temple Maryland 1986 Maryland Sue Tyler 11-10 Penn State Maryland 1985 New Hampshire Marisa Didio 6-5 Maryland Penn 1984 Temple Tina Sloan Green 6-4 Maryland Boston University 1983 Delaware Janet Smith 10-7 Temple Penn 1982 Massachusetts Pamela Hixon 9-6 TCNJ TCNJ
Note: Before 2001, this championship was a national collegiate championship.

Story 159
Media coverage about CYRX stock has been trending extremely negative on Thursday, according to InfoTrie. The research firm identifies negative and positive media coverage by reviewing more than six thousand news and blog sources in real-time. The firm ranks coverage of companies on a scale of negative five to five, with scores nearest to five being the most favorable. CryoPort earned a news impact score of -4.0 on InfoTrie's scale. They also gave news articles about the consumer goods maker a news buzz of 0.0 out of 10, indicating that recent media coverage is extremely unlikely to have an impact on the company's share price in the next few days. View News Stories for CryoPort.

Story 160
Conclusion Family history of colorectal cancer in half siblings is similarly associated with colorectal cancer risk to that in siblings. The increase in risk of colorectal cancer among people with one affected second degree relative was negligible, except for half siblings, but the risk was substantially increased for a combination of family history in one affected second degree relative and an affected first degree relative (or even another second degree relative). These evidence based findings provide novel information to help to identify people at high risk with a family history of colorectal cancer that can potentially be used for risk adapted screening.
Results The overall lifetime cumulative risk of colorectal cancer in siblings of patients was 7%, which represents a 1.7-fold (95% confidence interval 1.6 to 1.7; n=2089) increase over the risk in those without any family history of colorectal cancer. A similarly increased lifetime cumulative risk (6%) was found among half siblings (standardised incidence ratio 1.5, 95% confidence interval 1.3 to 1.8; n=140). The risk in people with colorectal cancer in both a parent and a half sibling (standardised incidence ratio 3.6, 2.4 to 5.0; n=32) was close to the risk in those with both an affected parent and an affected sibling (2.7, 2.4 to 3.0; n=396). Family history of colorectal cancer in only one second degree relative other than a half sibling (without any affected first degree relatives), such as a grandparent, uncle, or aunt, showed minor association with the risk of colorectal cancer.
The aim of this study was to elucidate whether and to what extent a family history of colorectal cancer in a second degree relative is associated with an increased risk of colorectal cancer and to provide the necessary evidence to help physicians to determine risk of colorectal cancer and make more appropriate recommendations for screening of people with a family history of colorectal cancer. To accomplish this, we analysed the various combinations of family history and further stratified second degree relatives into more detailed relationship types and compared their absolute and relative risks, using the Swedish Family Cancer Data, which is the largest family cancer dataset in the world and is free from the biases of case-control studies.
However, some gaps in our knowledge about familial risk of colorectal cancer remain. Few published studies provide information on familial risk of colorectal cancer in second degree relatives. Therefore, to what extent having affected second degree relatives is associated with increased risk of colorectal cancer is still uncertain. A prospective study from Utah assessed the risk of colorectal cancer associated with various combinations of family history, including history of colorectal cancer in second degree relatives. 14 Another study showed that first degree family history alone is not enough for identification of candidates for high risk screening and suggested future studies on more extended family history (for example, second degree relatives) of colon cancer. 15 However, none of these studies has provided risk estimates by detailed types of relationship, such as half siblings, grandparent, or uncle/aunt.
Colorectal cancer screening strategies for people at different risk have been recommended in many guidelines, 10 11 12 as colorectal cancer can be detected early by screening and is one of the few cancers that can be prevented with screening by removal of polyps or adenomas. Many studies have shown that methods of screening for colorectal cancer, such as faecal immunochemical test, flexible sigmoidoscopy, and colonoscopy, are effective in reducing its incidence and mortality, and they are more cost effective than no screening. 13 Increasing screening for colorectal cancer in people at high risk has led to a decline in the incidence of and mortality from colorectal cancer in the US for several decades. 5 Family history is usually used for risk stratification of colorectal cancer screening in current guidelines. As the increased risk of colorectal cancer in first degree relatives of patients with colorectal cancer is well established, starting screening at younger ages in these people is recommended.
Environmental factors play a major role in the causes of colorectal cancer, including cultural, social, and lifestyle practices, resulting in the differences in risk of colorectal cancer between countries and regions depending on the level of economic development, to which an estimated 70-80% of cases can be attributed. 6 Germline mutations due to certain cancer related genetic defects, such as Lynch syndrome and familial adenomatous polyposis, account for about 2-5% of colorectal cancers. The causes of the remaining 20-30% of inherited colorectal cancers are not completely understood. Colorectal cancer tends to run in families, possibly because of inherited genetic predisposition, shared environmental factors, or the combination of both. 7 Many epidemiological studies have shown increased risk of colorectal cancer among first degree relatives of people with colorectal cancer, 8 9 but none for half siblings.
Colorectal cancer is a major malignant disease of the gastrointestinal tract, which is the third most common cancer and the second leading cause of death from cancer worldwide. 1 The global burden of colorectal cancer is expected to increase by 60% to more than 2.2 million new cases and 1.1 million deaths by 2030. 2 More than 400 000 people are diagnosed as having colorectal cancer and more than 200 000 die from it every year in Europe, 3 4 and colorectal cancer has become the second most common cancer and the second most common cause of death from cancer in Europe. In the US, colorectal cancer is the third most common cancer diagnosed and also the third leading cause of cancer related deaths in both men and women. 5
This was a record linkage study of multiple nationwide datasets. As such, we made no attempts to contact any cohort members for any aspect of this study. Thus, no patients were involved in setting the research question or the outcome measures, nor were they involved in developing plans for recruitment, design, or implementation of the study. No patients were asked to advise on interpretation or writing up of results. There are no plans to directly disseminate the results of the research to study participants. However, dissemination to healthcare professionals, the general public, and relevant patient groups through presentations and other media will be undertaken.
We calculated the lifetime cumulative risk (assumed to be 0-79 years on the basis of the average life expectancy in Europe in 2015, 78 years 17 ) by using the following formulas: age specific annual incidence rate=number of cases for each one year age divided by person years for that age; lifetime cumulative rate=sum of all age specific incidence rates by age 79; and lifetime cumulative risk=1–exp(–lifetime cumulative rate), which is expressed as a percentage. We used Poisson approximation to calculate the 95% confidence intervals of lifetime cumulative risk. We used exact values for person years from individual data (not from conventional aggregated data) in the calculation of cumulative incidences. We used SAS 9.4 for all analyses.
We calculated standardised incidence ratios to measure the risk of cancers in family members of patients with colorectal cancer as the ratio of observed to expected number of cases. We calculated the expected numbers from strata specific person years in people with a certain family history of colorectal cancer multiplied by strata specific incidence rates in those without a history of colorectal cancer in their first and second degree relatives. For stratification and adjustment, we used five year age group, sex, calendar period (1958-64, 1965-69, 1970-74, …, 2005-09, and 2010-15), socioeconomic status (blue collar worker, white collar worker, farmer, private, professional, or other/unspecified), and residential area (large cities, small cities in south Sweden, and small cities in north Sweden). We additionally included hospital admission for obesity, alcoholism, and chronic obstructive pulmonary disease (as a proxy for heavy smoking) in our adjustment models. The follow-up started for each family member at birth, immigration date, or 1 January 1958, whichever came latest, and it terminated at the year of diagnosis of colorectal cancer, death, emigration, or the closing date of the study (31 December 2015), whichever came first. We calculated the 95% confidence intervals of standardised incidence ratios by assuming a Poisson distribution. All family histories reported in our results are exclusive, meaning that, for example, the risk reported for one affected half sibling does not include people with both an affected half sibling and any other affected first or second degree relative.
All people living in Sweden from 1 January 1958 to 31 December 2015 were eligible for the study. Family history was extracted from the linked datasets of the nationwide Cancer Registry and Multi-generation Register (genealogy dataset including unique identification numbers for each person and his/her biological parents). Nobody in the study population had a known second degree relative and unknown first degree relatives, as the former were identified by linkage of the latter. Finally, we included 12 829 251 people with at least one first degree relative in their genealogy in our analysis.
The datasets used in this study were based on information in the Multi-generation Register, national censuses, the Swedish Cancer Registry, and death notifications ( fig 1 ). 16 Data on family relationships came from the Multi-generation Register, in which children residing in Sweden and born after 1931 were registered with their biological parents as family units. Thus, the individuals in the datasets can be divided into two generations: offspring (people born after 1931) and their parents. In this nationwide cohort study, the ages of parents were not limited, but offspring were below 84 years of age. This register was linked to the Cancer Registry data (1958-2015) by using the individually unique national registration numbers. Cancer registration in Sweden is based on compulsory reports of cases diagnosed both by clinicians and by pathologists. A four digit diagnostic code is assigned according to the 7th revision of the International Classification of Diseases (ICD-7) and subsequent ICD classifications. No information on the cancer status of individuals was missing in our dataset. We made additional linkages to the national census and death notifications to obtain data on socioeconomic background and deaths. We had full access to the whole pseudonymised population dataset but not to participants. The latest update of the datasets (Swedish family cancer data 2015) includes more than 16 million people, including about two million records of primary invasive cancers. All patients with colorectal cancer in our study had primary invasive colorectal cancer. This record linkage and therefore our exposure and outcomes are updated every two years, which is why our study design is called an ambidirectional cohort study.
Our results did not vary after further adjustment for admission to hospital for obesity, chronic obstructive pulmonary disease, or alcoholism. We also did sensitivity analyses on the stratified calendar period of diagnosis (supplementary table D). The period specific standardised incidence ratios did not vary substantially. Using Amsterdam II criteria, we found 103 likely cases of hereditary non-polyposis colorectal cancer (HNPCC); after we excluded these from our analyses, familial risks of colorectal cancer remained unchanged (data not shown). In another sensitivity analysis, after exclusion of all families who had any HNPCC related cancer other than colorectal, the standardised incidence ratio for one affected sibling changed only slightly from 1.65 (1.58 to 1.73) to 1.63 (1.54 to 1.72), and the standardised incidence ratio for one affected half sibling remained unchanged (1.5-fold, 1.2 to 1.8) (data not shown).
Our stratified analyses by colorectal cancer subsites showed that having a family history of colon cancer was associated with similar colorectal cancer risk between half siblings (1.7-fold) and siblings (1.7-fold) (data not shown). Further stratification showed similar trends for family history of cancer in the distal part of the colon (1.7-fold in half siblings and 1.7-fold in siblings) and the proximal part (1.9-fold in half siblings and 1.7-fold in siblings). For family history of rectal cancer, the risk of colorectal cancer was 1.5-fold in siblings (95% confidence interval 1.4 to 1.7) and not statistically significant in a rather small number of half siblings (1.2-fold, 0.9 to 1.7), with overlapping confidence intervals.
Further stratification by age at diagnosis of the youngest affected relative showed a higher risk of colorectal cancer when the relative’s cancer was diagnosed before age 50 (for example, 2.1-fold for having one affected sibling and 1.9-fold for one affected half sibling) compared with having a late onset of colorectal cancer in relatives (for example, 1.6-fold for one affected sibling and 1.5-fold for one affected half sibling) ( table 2 ). Median age at diagnosis of people with colorectal cancer and only one affected half sibling was 63 years, very close to that of those with one affected sibling (65 years; data not shown). The modification of colorectal cancer risk by age at diagnosis of relatives was less evident for second degree relatives other than half siblings when no first degree relative was affected alongside them (1.1-fold for one non-half sibling second degree relative diagnosed before age 50 and 1.2 for one non-half sibling second degree relative diagnosed at older ages; table 3 ). Further results by age and sex are shown in supplementary tables A, B, and C.
We also further analysed the risk in various combinations of family history excluding half siblings, considering the higher risk from affected half siblings than the other second degree relatives mentioned above, and found that the results were only minimally changed in terms of standardised incidence ratio or lifetime cumulative risk, in both sexes ( table 3 ). People with no affected first degree relative but with two affected second degree relatives excluding half siblings (standardised incidence ratio 1.6, 1.3 to 1.9) still had a similar risk of colorectal cancer to those with one affected first degree relative (1.60, 1.57 to 1.63).
A family history of colorectal cancer in other second degree relatives, such as a grandparent (standardised incidence ratio 1.2, 1.1 to 1.3) or an uncle or aunt (1.2, 1.0 to 1.3), without any affected first degree relatives, showed a minor contribution to the familial risk of colorectal cancer ( table 2 ). However, we found higher risks for people with both an affected first degree relative and an affected grandparent (standardised incidence ratio 3.0, 2.4 to 3.7) or both an affected first degree relative and an affected uncle or aunt (2.2, 1.4 to 3.1), which are close to the risk of those with two affected first degree relatives (2.5, 2.3 to 2.6).
The risk in people with both a parent and a half sibling with colorectal cancer was greatly increased (standardised incidence ratio 3.6, 2.4 to 5.0), as was the risk in those with both an affected parent and an affected sibling (2.7, 2.4 to 3.0) ( table 2 ). We also found a greatly increased risk of colorectal cancer in people with two affected siblings (standardised incidence ratio 2.2, 1.8 to 2.7), in those with both an affected half sibling and an affected sibling (3.4, 1.4 to 6.6; n=8), and even in those with two affected half siblings (3.5, 1.3 to 7.6; n=6).
Further stratification by type of relationship showed that the lifetime cumulative risk of colorectal cancer in siblings of patients with colorectal cancer was 7%, which represents a 1.7-fold (standardised incidence ratio 1.65, 1.58 to 1.73; table 2 ) increase over the 4% risk in those without any family history of colorectal cancer ( table 1 ). We also found a significantly increased lifetime cumulative risk (6.1%) among half siblings of colorectal cancer patients (standardised incidence ratio 1.55, 1.30 to 1.83). Further stratification by maternal and paternal lineage of half siblings did not show a statistically significant difference between them (confidence intervals overlapped; table 2 ).
The familial risk of colorectal cancer, in terms of both standardised incidence ratio and lifetime cumulative risk, increased with the number of affected first degree relatives and second degree relatives ( table 1 ). People with one affected first degree relative (without any affected second degree relatives) had a 1.6-fold (standardised incidence ratio 1.60, 95% confidence interval 1.57 to 1.63) increased risk of colorectal cancer compared with those with no affected relatives, similar to that in those with two affected second degree relatives without any affected first degree relatives (1.6, 1.4 to 2.0) ( table 1 ). Even the lifetime cumulative risks of these two groups were similar (6.3% and 5.7%, respectively). Having a family history in one second degree relative without an affected first degree relative was associated with only a 1.2-fold (95% confidence interval 1.1 to 1.3) increased risk.
We included 12 829 251 people in this study, of which 51% (n=6 527 022) were men. During up to 58 years of follow-up (mean follow-up 33.6 years), 173 796 people with available genealogy information (with at least one known first degree relative in our datasets) developed colorectal cancer. In our study, familial colorectal cancer patients (with at least one affected first or second degree relative; n=16 679) constituted approximately 10% (n=173 796) of all patients with colorectal cancer in Sweden.
Discussion
We found that, in addition to first degree relatives of patients with colorectal cancer being at increased risk of this cancer, a family history of colorectal cancer in half siblings is associated with a similar risk of colorectal cancer to that in siblings. In addition, we showed that the risk of colorectal cancer among people with one affected second degree relative was negligible except among half siblings. However, a combination of family history in an affected second degree relative and an affected first degree relative (or even another second degree relative) was associated with a substantially increased risk of colorectal cancer. Although familial risk of colorectal cancer in terms of relative risk (standardised incidence ratio) showed no substantial difference in men and women, the sex difference was evident in terms of absolute (cumulative) risk, which to some extent reflected the global trend of higher incidence of colorectal cancer incidence in men.1
Strengths and weaknesses of study We were able to further elucidate the familial risk in people who had affected second degree relatives, using the register based nationwide Swedish data, which are the world’s largest population based familial cancer datasets, providing novel information to improve counselling for screening for people with a family history of colorectal cancer, with a structure that makes it free from selection and recall bias. We obtained family history from the linked datasets of the Multi-generation Register (genealogy dataset) and nationwide Cancer Registry and not from patients’ reports. Collection of family history using record linkage also avoids the bias from under-reporting of self reported family history.18 Therefore, our risk estimates should be relatively accurate. Moreover, the familial risk in terms of relative risk (standardised incidence ratio) usually does not substantially change with incidence of cancer; our standardised incidence ratios thus are generalisable to almost all populations. Family size in the reference population (those without family history of colorectal cancer) in general may be smaller than that in those with a family history of colorectal cancer, and the birth order might influence the risk of some cancers. However, according to previous studies, family size and birth order do not modify the risk of colorectal cancer.1920 As obesity, smoking, and alcoholism are factors associated with risk of colorectal cancer, we made further adjustment for hospital admission related to these factors, which did not change our results substantially. As admission to hospital for these conditions includes only extreme cases, further studies with more complete information on these factors are warranted. Some information on certain risk factors for colorectal cancer was lacking in our datasets, such as physical activity and dietary habits. We alternatively adjusted our results for residential areas and socioeconomic status, which to some extent contain information on the above mentioned lifestyle related factors. We did not have information on genetic and known hereditary colorectal cancer syndromes, such as HNPCC or familial adenomatous polyposis. However, on the basis of the Amsterdam II criteria for identifying likely HNPCC families,21 we tried to identify HNPCC cases in our datasets and found that after exclusion of those likely HNPCC families, or even more strictly exclusion of all the families with any HNPCC related cancer other than colorectal cancer from the analyses, the familial risk of colorectal cancer remained unchanged. As we had no direct data on confirmed cases of HNPCC, a few undetected cases HNPCC may be present among our patients. However, owing to the rarity of such cases, our main results for families are unlikely to be overestimated due to a few cases of HNPCC, especially the standardised incidence ratios for people with few cancer patients in the family, such as only one affected sibling or half sibling. Colorectal cancer may be detected by screening or by investigation of early symptoms or may remain undetected for some time in people who do not come forward for screening or who ignore early symptoms. Hence, some of the association of cancer with a family history may reflect ascertainment bias. However, this could operate similarly or even less for a history of colorectal cancer in half siblings compared with that in full siblings. Previous Swedish studies on risk of colorectal cancer among adoptees and their adoptive parents (with solely shared environment in childhood and adolescence of the adoptee with the adoptive parents; 1.12-fold, 95% confidence interval 0.68 to 1.67) 22 and spouses (with solely shared adulthood environment; 1.06-fold, 1.00 to 1.12) 23 suggest that shared environment alone could not explain the risk of colorectal cancer aggregated in family members. Although no nationwide colorectal cancer screening programme exists in Sweden, except for pilot phase screening in Stockholm Gotland region with 8.5% invitation coverage,24 we did a sensitivity analysis by calendar period of diagnosis before and after the colorectal cancer screening era in Sweden, which in general showed no substantial change in familial risk of colorectal cancer (supplementary table D). The consistency of our findings across sex, age at diagnosis, calendar period of diagnosis, paternal/maternal lineage, and colorectal cancer subsites confirms the internal validity of our results. Altogether, the aggregation of risk of colorectal cancer among half siblings seems to be due to a combination of genetic and shared childhood environmental factors.
Comparisons with other studies and implications of findings Although several studies have shown an increased risk of colorectal cancer in people with a family history of colorectal cancer in their first degree relatives,89 few studies have determined the familial risk of colorectal cancer in second degree relatives, and most of the existing studies on risk of colorectal cancer in second degree relatives failed to present detailed relationship types of the affected second degree relatives and rather used one generalised category of second degree relatives.914252627 In particular, the risk of colorectal cancer in half siblings has not been studied before. We for the first time found that the familial risk of colorectal cancer in half siblings stood out exclusively from that in other types of second degree relatives, and the lifetime cumulative risk and relative risk (standardised incidence ratio) of colorectal cancer in half siblings of patients with colorectal cancer were similar to those of siblings of colorectal cancer patients. In contrast, a family history of colorectal cancer in second degree relatives other than half siblings, such as grandparents or uncles/aunts, did not go along with a relevant increase in risk of colorectal cancer in our study. However, the combination of a family history in one affected second degree relative and an affected first degree relative (or even another affected second degree relative) was associated with a substantially increased risk of colorectal cancer, among which the risk in the combinations involving half siblings were in some instances even higher than combinations with siblings. The reason for the latter could be the random variation due to small sample size (for example, 3.4-fold risk in those with both a sibling and a half sibling affected (n=8) or 3.5-fold risk for two affected half siblings (n=6) versus 2.2-fold risk for two affected siblings (n=105), with overlapping 95% confidence intervals; table 2). Our results are in line with the findings of a previous study from Utah suggesting that higher numbers of affected first degree relatives show much stronger associations with risk of colorectal cancer than affected second degree relatives alone, but when combined with a family history of colorectal cancer in a first degree relative, family history in a second degree relative can indicate a significantly increased risk of colorectal cancer.14 Environmental factors have been known to explain the causation of up to 80% of colorectal cancers. These include cultural, social, and lifestyle practices, resulting in major differences in risk of colorectal cancer between countries and regions depending on the level of economic development.6 On the basis of our finding of similar familial risk between half siblings and siblings, an inference might be drawn that the shared childhood environment and lifestyle may have some association with risk of colorectal cancer. Such a similarity seems to be a very strong argument for environmental dominance of risk even in families at high risk, despite controlling for probable confounders. Shared childhood environment or lifestyle seems to be associated with risk of colorectal cancer not only because of the similar risk estimates between half siblings and siblings but also because of the lower familial risk estimates for other second degree relatives (for example, aunts or uncles alone with no simultaneous shared childhood environment; table 3). A previous study points to the importance of heritable factors in familial colorectal cancer risk in siblings.28 A recent case-control study has additionally used a genetic risk score combined with family history to predict risk of colorectal cancer.29 That study showed that both family history and the so far identified genetic variants carry essentially independent risk information and in combination provide great potential for stratification of colorectal cancer risk.29 Large aetiological studies are warranted to identify the possible underlying risk factors that explain our findings. The recommended starting age of mass screening for colorectal cancer in people at average risk differs in different countries. Of current colorectal cancer screening programmes, Austria has the earliest age at start of screening (40 years), but the UK and Sweden offer screening for people from age 60 (subject to a recent change to age 50 in England and Wales), whereas most other European Union countries recommended age 50 or 55 as the starting age.24 The American Cancer Society in its latest updated guideline on colorectal cancer screening recommended age 45 as starting age for people at average risk instead of age 50 as in previous decades, owing to the increasing trend of the incidence of this cancer in younger people in the US.12 The reason for the increasing incidence of this cancer in young adults might be a change in social factors—for example, the shift in prevalence of risk factors for colorectal cancer, such as overweight and obesity, towards younger ages. Another reason for the highlighted increase in risk of early onset colorectal cancer could be screening for colorectal cancer in older people, which in some countries such as the US and Germany has controlled the increasing incidence of colorectal cancer but had no effect on the rise in young adults before the age of initial screening. Colorectal cancer screening programmes in general are effective in reducing the incidence of and mortality from colorectal cancer, and they are more cost effective than no screening.13 Several modelling studies have shown that intensive colorectal cancer screening strategies targeting people at increased risk (for example, due to family history) would be cost effective.30 Although screening guidelines are recommending screening for all people after a certain age, the next question seems to be “whom to screen early and whom to screen later,” which needs identification of people at high risk, such as those with a family history who are more prone to early onset colorectal cancer, and also identification of people at low risk who can be screened some years later. In this study, we have shown that people with an affected half sibling have a similar risk to those with an affected sibling, so screening them as early as those with an affected sibling would seem to be fair, whereas those with only one affected grandparent or uncle/aunt may not need to be screened very early.

Story 161
Motorsport-Magazin.com - Durchatmen heißt es nach dem schweren Unfall im Formel-2-Sprintrennen von Sotschi. Nachdem Nobuharu Matsushita, Jack Aitken und Nikita Mazepin in der ersten Runde gleich kollidierten, flogen Matsushita und Mazepin mit hohem Tempo in die Mauer. Die Bergung von Matsushita dauerte lange, anschließend wurden er und Mazepin in ein Krankenhaus gebracht.
Am Nachmittag kam Entwarnung: Weder Mazepin noch Matsushita hatten sich verletzt. Mazepin wurde für fit erklärt, Matsushita muss allerdings die Nacht im Krankenhaus verbringen. Am Montag wird bei ihm noch einmal ein CT-Scan durchgeführt, zur Vorsicht.
Kaum war Mazepin entlassen, holten aber die Formel-2-Stewards in Sotschi aus - und gaben dem Russen 15 Strafplätze für das nächste Rennen mit. "In den Augen der Stewards demonstrierte er ein komplettes Fehlen von notwendiger Umsicht gegenüber seinen Fahrerkollegen und hat einen schweren Unfall verursacht, der viel schlimmer hätte ausgehen können", heißt es in der offiziellen Entscheidung.
Crash-Auslöser Mazepin kassiert 15 Strafplätze
Mazepin hatte sich nämlich in der Auslaufzone von Kurve zwei grob fahrlässig verhalten. Dort muss jeder, der die Strecke verlässt und in die asphaltierte Auslaufzone fährt, die am Ende der Auslaufzone platzierten Styropor-Marker korrekt umfahren.
Daran scheiterte Mazepin. In der ersten Runde rutschten er und Jack Aitken dort von der Strecke, um ein sich drehendes Fahrzeug zu vermeiden. Während Aitken korrekt nach außen und an den beiden Blöcken vorbeifuhr, passierte Mazepin die Blöcke inkorrekt und zog in die Fahrbahn von Aitken. Aitken erwischte dabei Mazepins Hinterrad und zerstörte dabei dessen linke Aufhängung.
Ohne Kontrolle über das Auto rotierte Mazepin somit zurück auf die Strecke, und in die Fahrbahn des unbeteiligten Matsushita. Die Konsequenz: Beide flogen ab und in die Absperrung. Für die Stewards ein klarer Fall, Mazepin hat weder aufgepasst noch sich an die Vorgaben der Rennleitung gehalten. Daher eine schwere Strafe: Um 15 Plätze muss der Russe beim Saisonfinale in Abu Dhabi in der Startaufstellung nach hinten.

Story 162
Manchester United's 3-1 victory against Crystal Palace on Wednesday saw the Norweigan surpass Sir Alex Ferguson's record of seven straight away wins
Manchester United beat Crystal Palace 3-1 on Wednesday night to continue their remarkable resurgence under Ole Gunnar Solskjaer.
The Norweigan is still unbeaten in the league after 11 outings, having won nine and drawn two and his side have picked up six clean sheets along the way.
8 – @ManUtd have won eight consecutive away games in all competitions for the first time in their history. Fearless. #CRYMUN pic.twitter.com/GLTVITyIvA — OptaJoe (@OptaJoe) February 27, 2019
Not many predicted just how well Solskjaer would do but he’s making top-flight management look easy and has tumbled a few records along the way.
talkSPORT.com has examined the facts and identified all the records Solskjaer has broken since his Old Trafford arrival in December…
LATEST MANCHESTER UNITED NEWS adored Solskjaer reveals secret to Man United's incredible success away from home big plans Man United identify Wan-Bissaka, Koulibaly and Rakitic as summer targets 'CLASS' Some fans believe Shaw has overtaken Robertson as the best left-back in the league WHO ARE YA? West ham hand 19-year-old Ben Johnson debut against champions Man City opportunity Who is James Garner: Man United ace among the youngsters to profit from crisis starlet Who is Tahith Chong? Manchester United wonderkid who could play against Rochdale paper talk De Gea deal in danger, Chelsea set to keep Higuain, United chasing Barca star CRISIS How Man United could line-up against Crystal Palace with 10 players out injured leaders The 10 clubs who have topped the Premier League for the most amount of days silence broken Mourinho reveals requirement for next job in subtle dig at Man United
Most wins from first games as Manchester United manager
The first record Solskjaer set was in January, where he became the first Manchester United manager to win his first six matches in charge, surpassing the five game win record set by Sir Matt Busby.
SOLSKJAER IN THE PREMIER LEAGUE At Manchester United
11 Games 9 Wins 2 Draws 0 Defeats 29 Goals Scored 7 Goals Conceded 6 Clean Sheets
Equals opening win record for specific Premier League club
Manchester United beat Brighton at Old Trafford and Solskjaer levelled a record set by Carlo Ancellotti at Chelsea and Pep Guardiola at Man City by winning his first six matches in charge.
The draw at Burnley the following match meant Solskjaer failed to hold the most opening wins outright.
3 Solskjaer is in pole position to land the United job on a permanent basis
Most points won in opening ten matches
Thanks to the 0-0 draw with Liverpool, Solskjaer collected the most points of any top flight manager in his first 10 games in charge.
He has collected 26 points during that period – surpassing the record held by former Chelsea boss Guus Hiddink.
Beats Sir Alex for away wins
Manchester United’s 3-1 victory against Crystal Palace was the first time the club have won eight consecutive away matches in all competitions.
Sir Alex Ferguson spent 26 years with the Red Devils and the most away victories he achieved in a row was seven – a feat he did twice, including once when Solsjkaer was playing in 2002.
Getty 3 Solskjaer has surpassed an away wins record reached by his former boss Sir Alex Ferguson
Away wins at Tottenham, Arsenal and Chelsea
Manchester United’s win at Stamford Bridge in the FA Cup was their first in ten attempts and the first time they have won in west London for more than six years.
Victory meant his side have won away at Tottenham, Arsenal and Chelsea for the first time since the Ron Atkinson era.
In the 1984/85 season, Atkinson guided his side to a 3-1 victory over Chelsea at Stamford Bridge, a 1-0 win at Highbury and a 2-1 triumph at White Hart Lane during United’s FA Cup-winning season.
Getty 3 Solskjaer has toppled Mourinho’s win record this season after just 11 Premier League matches in charge
Beats Mourinho for number of wins this season
With the Palace victory, Solskjaer toppled his predecessor Mourinho’s win record for the whole season this term after just 13 matches in charge.

Story 163
Through its innovation unit ZX Ventures, AB InBev is investing in the technology and trialing how it can work in a real life situation to improve inventory visibility.
Small drones navigate the store autonomously, scanning shelves and codes to report on stockouts, planograms and more, giving ‘unprecedented levels of strategic visibility’. The drone system can collect hourly and daily data on out-of-stocks and real share-of-shelf, with 98% accuracy.
Pensa Systems has just raised $5m in additional funding to accelerate deployment of the system, bringing its total to $7.2m, with investors including ZX Ventures.
A 'one trillion dollar blind spot'
Out-of-stocks could be costing retailers nearly $1 trillion, according to research from IHL Group. Such out-of-stock situations include empty shelves or instances where consumers cannot find what they’re looking for.
Inventory visibility is an age-old problem for brands and retailers, which is only getting worse as e-commerce and physical store shopping combine. Industry studies report nearly one in 10 items as missing on the shelf or misplaced, leading to lost revenue, dissatisfied customers or excess inventory.
Aimed at tackling this ‘one trillion-dollar blind spot' around in-store inventory, Pensa’s system is designed to inform retailers and brands of what is currently on shelves – across all stores, everywhere, at any point in time.
Watch the drones in action here: The Pensa System​​
The technology uses computer vision to 'see,' patent-pending artificial intelligence to learn, as well as agile, autonomous drones as roving eyes to automate high value visual tasks for the first time.
Pensa says it is the first company to deliver a broadly scalable system that provides complete, real-time and actionable data and insights, enabling CPG brands and retailers to automatically and systematically track in-store inventory.
AB InBev's Montreal trial​
ZX Ventures - AB InBev’s incubator, operation and venture capital team - first invested with Pensa in its initial series funding round which completed in May 2018. The two players have now completed a successful pilot the new inventory visibility system in an IGA Extra Beck store in Montreal, Canada.
With less than 90 minutes of set-up time, Pensa’s drone-based system collected hourly and daily data on out-of-stocks and real share-of-shelf within the beer section.
'Out-of-stock products are a significant challenge for CPG companies and retail partners, with hundreds of millions of dollars in potential sales impact,' said Patrick O’Riordan, vice president of Explore at ZX Ventures. 'Pensa’s expertise and technology — including scalable AI and advanced computer vision — provides an opportunity to make both timely and significant impacts to inventory visibility.'
Over a period of two weeks, Pensa’s system scanned dry shelves and coolers with multiple product types (such as cans, bottles, packs), capturing 15.9M SKU images during 200 flights (totaling 2 miles of travel), with its continuously learning accuracy already reaching 98% for out-of-stock detection.
“Retailers and brands throughout this trial (as well as other trials) reported positively on the system’s tangible benefits—such as improving stockouts, ensuring planogram compliance, protecting shelf integrity—as well as how smoothly it deployed and operated in a store environment,” ​Richard Schwartz, CEO, Pensa Systems, told BeverageDaily.
“Shoppers were for the most part oblivious to the drone when it was 10-15ft away, but when they noticed the drone at work they were overwhelmingly positive and wanted to learn more. ​
“Overall, based on our experience with our live store trials, the Pensa system can be up and running in a couple days with no operational requirements to integrate into retailer infrastructure or software interfaces. First data can be collected in as little as 90 minutes on a per store basis.​
“Also, this approach is highly accurate (98+%) for out-of-stock detection. We believe that is a significant leap over the capabilities of other systems on the market. This is due partly to the autonomous vision capture via the drone, which in effect is as if there were up to 100 fixed cameras focused on every product on every shelf in every location, and partly due to the cognitive AI processing on the backend in the cloud.”​
Schwartz says the technology is ‘uniquely effective’ in understanding real product and shelf conditions – and can do so at a lower costs per location than any other manual or automated approaches.
“Pensa breaks through the complexity and overcomes the limitations of prior attempts by marrying a lightweight, low-cost drone with powerful, patent-pending AI in the cloud to process the input and learn just like a person would,"​ said Schwartz. ​
"We call this combination an 'autonomous perception system,' and it’s the core of how we are able to achieve breakthrough results.​
“Specifically, our system is able to see every individual product, recognizes missing items and spots misplacements and other planogram misalignments. It can also learn, evolve and get more accurate as it goes. ​
“As a result, we provide complete, real-time and actionable data on in-store inventory and conditions, including out-of-stocks (current and predicted), misplacements and planogram misalignments and real share-of-shelf.​
Wider potential
version="1.0" encoding="utf-8"? Richard Schwartz
Furthermore, once the technology is set up in a store, operators can start training the system to highlight other issues - end caps, shelf performance of a new product placed relative to others, shelf performance of a major brand against a competitor for stockouts, share of shelf and other shelf conditions impacting revenue.
"In other words, we gives retailers and brands a common, zero-lag view of what is actually happening on shelves – across all stores, any product category, at any point in time,"​ said Schwartz. ​
"Because of that, we think our system is uniquely qualified to eliminate the $1trillion retail inventory visibility blind spot, so brands like AB InBev and retailers can minimize stockouts, optimize product planning and increase revenue.”​

Story 164
Posted 14 March 2019 | By Ana Mulero
Health Canada launched two public databases on Wednesday as the first step in making clinical information about the safety and effectiveness of drugs and medical devices publicly available.The drug and device databases currently display just one record for each: a notice of compliance issued to CSL Behring Canada in 2016 and an approval granted to Siemens Healthcare GmbH last December.Following consultation on Health Canada’s plans to start making clinical information public, the agency finalized guidance from last April that sets the stage for how to implement its Public Release of Clinical Information (PRCI) initiative.The 32-page guidance is intended to aid industry and others in understanding the procedures to follow in preparing clinical information for public release of the clinical data, the protection of personal information and the requirements for proposed redaction of confidential business information (CBI).Health Canada said that it has “described limited and specific circumstances, prescribed in regulations, where information found within the clinical component of a drug submission or medical device application may possess ongoing commercial value following the final regulatory decision.” These circumstances set the eligibility criteria for industry to propose redactions of CBI in drug submissions.The agency intends to specify the eligible CBI categories for medical devices in future guidance. Device applications in Canada are currently being revamped based on the globally agreed upon Table of Contents (ToC) format, with implementation set to start in April. In the meantime, Health Canada said “device manufacturers should refer to Section 5 for guidance in proposing redactions consistent with the exceptions specified in the Medical Device Regulations section 43.12(2).”The release of clinical information will be a phased-in process for different types of submissions and products throughout the next four years. For existing products, Health Canada also intends to release clinical information, upon request, through the agency’s clinical information portal.For the proactive disclosure of clinical information, Health Canada will follow four implementation stages. The first two stages will only apply to certain drug submissions, whereas stages 3 and 4 will apply to the publication of Class III and IV medical device applications. The tables below detail the schedule to implement and apply the regulations, followed by the schedule for proactive disclosure by application type based on the four stages.

Story 165
Why did this happen?
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.

Story 166
Jacqui Thornton London
Newspapers and researchers are eager to credit a parenting programme, but are they premature? Jacqui Thornton investigates
The city of Leeds in Yorkshire, UK, was roundly congratulated on 1 May with the news that it had succeeded in cutting the prevalence of childhood obesity—a feat achieved only by a few other cities, such as Amsterdam.1
A paper in Pediatric Obesity analysing figures from England’s National Child Measurement Programme over 2009-17 found that the proportion of children entering primary school (ages 4 and 5) who were obese fell from 9.4% in 2009-10 to 8.8% in 2016-17.2
The reduction was chiefly among the most deprived children—from 11.5% to 10.5% over the period—where the problem is worst, but also occurred among affluent children (6.8% to 6.0%). In terms of numbers, the results equated to 625 fewer reception class children who were obese in 2016-17 than in 2009-10.
No similar reduction in obesity was seen in other cities or England as a whole. In older children, at year 6 (ages 10 and 11), prevalence of obesity was unchanged in Leeds but increased elsewhere.
One of the authors, Susan Jebb, professor of diet and population health at the Nuffield Department of Primary Care Health Sciences in Oxford, presented the “startling” research at the European Congress on Obesity in Glasgow to great acclaim. “Everybody is going around saying Amsterdam is doing something amazing. Well, actually, Leeds is too,” she told the congress.

Story 167
Three new rounds in 2020 WRC calendar
Japan, Kenya and New Zealand will return to the FIA World Rally Championship for 2020 in a refreshed calendar displaying a more global profile.
Japan’s inclusion, 10 years after it last featured in the WRC fixture list, marks mainstream Asia’s first appearance in the series since then.
The addition of Kenya’s iconic Safari Rally, one of global motorsport’s legendary contests, means the WRC returns to Africa, the world’s second largest continent by size, for the first time since 2002.
It is the first time the WRC has included six continents – Europe, North America, South America, Asia, Africa and Australasia – in its 48-year history. Not since 1999 have Africa and Asia appeared side-by-side in the fixture list.
“It’s no secret we wanted to further globalise the series by incorporating more events outside Europe and we’ve achieved that next year with this exciting new-look calendar,” said Oliver Ciesla, managing director of WRC Promoter, which owns the championship’s commercial rights.
All three countries were confirmed on a 14-round schedule approved by the FIA, world motorsport’s governing body. Their promotion follows the introduction of a second South American round in Chile this year.
Returning events add rally history and tradition to calendar
Unlike previous editions of Rally Japan, which were held on the northern island of Hokkaido, the 2020 event will be based in Nagoya, on the country’s main island of Honshu. It is about three hours’ drive from capital city Tokyo.
The all-new asphalt encounter will form the coveted final round of the championship and take place on 19 - 22 November.
Sébastien Loeb won the last Rally New Zealand in 2012
The Safari was notorious for being the WRC’s toughest round as open-road gravel tracks, unpredictable weather and a route three times longer than other rallies created hazards unmatched elsewhere.
It has evolved to fit the modern-day WRC, but its character remains with challenging closed dirt roads, superb picture-postcard scenery and exotic wildlife. The East African event will form the championship’s eighth round on 16 - 19 July.
Rally New Zealand returns after a seven-year hiatus on 3 - 6 September. The picturesque North Island coastal city of Auckland will host round 10, the country’s 33rd WRC appearance adding to its impressive heritage.
Its smooth, flowing gravel roads are a drivers’ delight and spectacular scenery north of the city will guarantee fabulous global TV images.
Ciesla described the calendar as a ‘significant step’ in the WRC’s growth.
“The return of Japan and Kenya provide a presence in the world’s largest two continents by size for the first time in more than two decades. The last time Asia and Africa appeared in the WRC together was 1999.
“The two continents are huge markets for the WRC and I thank everyone involved from both countries and the FIA who have been instrumental in returning the rallies to the calendar for 2020.
“New Zealand requires no introduction. It has a long and successful WRC history and the return of its curving billiard-table smooth special stages near Auckland will be one of the year’s highlights,” he added.
Rallye Monte-Carlo opens the 2020 season
Latin American carnival as Mexico, Chile and Argentina go back-to-back
The 2020 championship kicks-off with the traditional season-opening Rallye Monte Carlo in the French Alps. It will be followed by Rally Sweden, the series’ only pure winter fixture.
The focus switches to the Americas for the next months with a triple-header in three Spanish-speaking countries.
Consecutive dirt road rounds in Mexico, Chile and Argentina span the middle of March to early May. The latter two will run in reverse order to 2019, with Chile taking place two weeks before the action moves across the Andes mountains.
Hot weather gravel rounds in Portugal in May and Italy in June complete the opening half of the season.
Kenya opens the second sector in July, before further gravel encounters in Finland, New Zealand and Turkey across August and September.
Germany marks the first pure asphalt round ahead of the final dirt road fixture in Great Britain, which moves back in the calendar to become the penultimate counter. The season ends with another sealed surface event in Japan.
“This is the most varied WRC calendar ever in terms of geographic locations, visiting six of the world’s seven continents,” added Ciesla. “The additions provide a refreshing new feel to our fixture list and open an exciting new chapter to the championship, one that will appeal to both competitors and fans alike.”
The full 2020 calendar is:
Round Rally Date 1. Monte-Carlo 23 - 26 January 2. Sweden 13 - 16 February 3. Mexico 12 - 15 March 4. Chile 16 - 19 April 5. Argentina 30 April - 3 May 6. Portugal 21 - 24 May 7. Italy 4 - 7 June 8. Kenya 16 - 19 July 9. Finland 6 - 9 August 10. New Zealand 3 - 6 September 11. Turkey 24 - 27 September 12. Germany 15 - 18 October 13. Great Britain 29 October - 1 November 14. Japan 19 - 22 November
More News

Story 168
There are many polls to keep track of during the college football season, from the AP Poll and College Football Playoff rankings in the FBS to the FCS and Division II polls. Here's what you need to know about the major polls — and how college football rankings work.
Some of these polls go back decades. Others, like the College Football Playoff rankings, have been around for only five completed seasons.
College football rankings: Every poll explained and how they work
Guide to the College Football Playoff rankings system
Unlike other polls, the College Football Playoff rankings come out only until well into the season. And unlike other polls, it's the only one that really matters, as it's for the four-team playoff. The CFP Selection Committee ranks its own Top 25, using factors like strength of schedule, results, championships won, common opponents and more. The top four teams go to the playoff, which plays two semifinals before the national title game in a No. 1 vs. No. 4 and No. 2 vs. No. 3 format.
The CFP, which started with the 2014 season, has its committee members meet in person to rank teams. For the 2019 season, the first rankings will be revealed on Tuesday, Nov. 5. However, only the final rankings matter for CFP and New Year's Six inclusion.
Here's the 2019 CFP rankings release schedule
Tuesday, Nov. 5
Tuesday, Nov. 12
Tuesday, Nov. 19
Tuesday, Nov. 26
Tuesday, Dec. 3
Sunday, Dec. 8 (selection day)
Along with selecting the teams in the CFP, the committee also assigns teams to New Year's bowls. Some conferences are already contracted to send their champions to specific bowls, provided that champion doesn't make the CFP (Big Ten and Pac-12 to the Rose Bowl; SEC and Big 12 to the Sugar Bowl; ACC to the Orange Bowl against highest-ranked available team from the SEC, Big Ten and Notre Dame). If a conference champion makes the CFP, the bowl will pick a replacement from the same conference. Also, when one of these bowls is part of the CFP and the conference champion is not picked for the CFP, that team will play in one of the other bowls.
The rankings also matter for selection for the highest-ranked "Group of 5" champion (The American, Conference USA, MAC, Mountain West and the Sun Belt). That team automatically goes into a New Year's Six game. UCF has gone the last two years.
There is no new CFP rankings after the bowl games or the championship game.
Here is a list of the first No. 1 teams in the College Football Playoff rankings, the final CFP No. 1 team and the eventual national champion for each season of the College Football Playoff rankings:
Year First CFP No. 1 Final CFP No. 1 National Champion 2014 Mississippi State Alabama Ohio State 2015 Clemson Clemson Alabama 2016 Alabama Alabama Clemson 2017 Georgia Clemson Alabama 2018 Alabama Alabama Clemson
Here are the College Football Playoff Selection Committee members:
Rob Mullens, Chair (University of Oregon)
Gary Barta (University of Iowa athletics director)
Frank Beamer (Former Virginia Tech head coach)
Paola Boivin (Arizona State University professor)
Joe Castiglione (University of Oklahoma athletics director)
Ken Hatfield (Former head coach)
Chris Howard (Robert Morris University president)
Ronnie Lott (Former Southern California All-American)
Terry Mohajir (Arkansas State University athletics director)
Ray Odierno (Former Chief of Staff, United States Army)
R.C. Slocum (Former head coach, Texas A&M interim athletics director)
Todd Stansbury (Georgia Tech athletics director)
Scott Stricklin (University of Florida athletics director)
Guide to the AP Poll Top 25
Starting with the preseason poll, the Associated Press Poll will rank the Top 25 teams each week during the season and after the bowl games and the College Football Playoff.
The 61 sportswriters and broadcasters from throughout the country vote individually. Teams are given points on a scale: No. 1 gets you 25, No. 2 gets you 24, etc. These ballots, which are made public each week, are then combined for one AP Top 25 poll.
Once the season starts, the poll is released each Sunday afternoon.
Last season, Alabama received 42 first-place votes in the preseason poll and started the season ranked No. 1. It remained No. 1, though its first-place votes changed many weeks, until Clemson beat the top-ranked Tide in the CFP title game matchup. Clemson then finished the season No. 1, receiving all 61 No. 1 votes.
But the AP Poll voters are not obligated to rank the CFP winner No. 1. In the 2017 season, undefeated UCF, which beat Auburn in the Peach Bowl, received four No. 1 votes. The last time the AP Poll and the Coaches Poll had different No. 1 teams at the end of the season was in 2003, during the BCS era. That year, LSU beat Oklahoma in the Sugar Bowl to win the BCS National Championship and thus the ESPN/Coaches Poll No. 1 ranking. The AP, however, ranked Southern California No. 1 after the Trojans defeated Michigan in the Rose Bowl.
Alabama has the most season-ending No. 1 rankings in AP Poll history with 11. The Crimson Tide finished No. 1 in 1961, 1964, 1965, 1978, 1979, 1992, 2009, 2011, 2012, 2015 and 2017. Notre Dame is second with eight, winning most recently in 1988.
Minnesota won the first AP title, ranking No. 1 in 1936. The final AP Poll finally came out after the bowl games for good starting with the 1968 season.
Final AP No. 1 teams since the 2000 season:
2000: Oklahoma
2001: Miami (FL)
2002: Ohio State
2003: Southern California
2004: Southern California
2005: Texas
2006: Florida
2007: LSU
2008: Florida
2009: Alabama
2010: Auburn
2011: Alabama
2012: Alabama
2013: Florida State
2014: Ohio State
2015: Alabama
2016: Clemson
2017: Alabama
2018: Clemson
All FBS teams can earn rankings in the poll, as can FCS programs. In 2007, Appalachian State upset then-No. 5 Michigan, 34-32, prompting the AP Poll to allow voters to rank FCS teams ("Appalachian State Rule)". In 2016, North Dakota State upset then-No. 11 Iowa and received 74 votes in the AP Poll.
Guide to the college football Coaches Poll
Like the AP Poll, the Coaches Poll starts with a preseason Top 25 and continues weekly on Sundays during the season and after the bowl games. There are 62 coaches voting in the poll, which gives teams points on a scale from 1 to 25 (25 for ranking a team No. 1, 24 for No. 2, etc.).
Like the AP Poll, the Coaches Poll isn't obligated to vote the College Football Playoff winner as the national champion, though it's been awarded to the same team each year.
The Coaches' Trophy is awarded to the national champion. Before the CFP, this went to the Bowl Championship Series (BCS) winner. The College Football Playoff has its own trophy.
Through the 1973 season, the final Coaches Poll came out at the end of the regular season but before the bowl games.
Clemson received the Coaches' Trophy as the final Coaches Poll No. 1 this past season. The Tigers also finished No. 1 in the AP Poll after routing Alabama in the College Football Playoff National Championship Game.
College Football: Split national titles
Though the College Football Playoff has eliminated (almost) all worries about avoiding a split national champion, there are instances where there are multiple national champions in a single season. Some of that had to do with different national champions for the AP and Coaches Poll.
Here are the years with split national champions, per this list of champions on NCAA.com, since 1970.
Year Schools (Polls) 2003 LSU (Coaches), Southern California (AP) 1997 Michigan (AP), Nebraska (Coaches) 1991 Miami (FL) (AP), Washington (Coaches) 1990 Colorado (AP), Georgia Tech (Coaches) 1978 Alabama (AP), Southern California (Coaches) 1974 Oklahoma (AP), Southern California (Coaches) 1973 Alabama (Coaches), Notre Dame (AP) 1970 Nebraska (AP, FWAA), Texas (Coaches, NFF), Ohio State (NFF)
How the FCS rankings work
Like in FBS, there is more than one poll for the Football Championship Subdivision. The weekly STATS poll is voted on by the media, while the Coaches Poll is voted on by FCS coaches. Both of these polls release a preseason Top 25 and continue to vote weekly through the end of the regular season and again after the conclusion of the 24-team playoff.
During the 2018 season, North Dakota State started as the preseason No. 1 in both the STATS and Coaches Poll. They remained in the top spot all season long, as the Bison beat Eastern Washington, 38-24, to win the FCS National Championship for the seventh time in eight years.
NATIONAL CHAMPIONS

North Dakota State completes the perfect 15-0 season and wins the 2018 FCS National Championship!#FCSChampionship 🏆 pic.twitter.com/E1XmSDkx1r — FCS Football (@NCAA_FCS) January 5, 2019
How the DII football rankings work
Before 1973, champions for the then "NCAA College Division" were decided by polls at the end of the regular season. Starting with 1973, there has been the DII Football Championship, which had 28 teams in the 2018 edition. Valdosta State beat Ferris State, 49-47, for the national crown.
In the final AFCA Coaches Poll, Valdosta State received all 33 first-place votes; Ferris State ended No. 2.
There are also regional rankings, which play a major role in deciding the playoff participants. The 28-team playoff is made up of seven teams from each of these four regions. Participants in each region are determined by regional rankings. A conference's highest-ranked team qualifies automatically if it ranks in the top nine. Other participants are determined by the region rankings.
🏆🏆🏆🏆

Valdosta State completes its undefeated season with a thrilling 49-47 win for its 4th #NCAAD2 national title! https://t.co/Me63uqllhq pic.twitter.com/NinaF9yvFI — NCAA (@NCAA) December 16, 2018
FBS: Championship History
National Champions
SEASON CHAMPION SELECTING ORGANIZATION 2018 Clemson CFP 2017 Alabama CFP 2016 Clemson CFP 2015 Alabama CFP 2014 Ohio State CFP 2013 Florida State BCS 2012 Alabama BCS 2011 Alabama BCS 2010 Auburn BCS 2009 Alabama BCS 2008 Florida BCS 2007 Louisiana State BCS 2006 Florida BCS 2005 Texas BCS 2004 Southern California* BCS 2003 Louisiana State, Southern California BCS, AP, FWAA 2002 Ohio State BCS 2001 Miami (Fla.) BCS 2000 Oklahoma BCS 1999 Florida State BCS 1998 Tennessee BCS 1997 Michigan, Nebraska AP, FWAA, NFF, USA/ESPN 1996 Florida AP, FWAA, NFF,USA/CNN 1995 Nebraska AP, FWAA, NFF, USA/CNN, UPI 1994 Nebraska AP, FWAA, NFF, USA/CNN, UPI 1993 Florida St. AP, FWAA,NFF, USA/CNN, UPI 1992 Alabama AP, FWAA, NFF, USA/CNN, UPI 1991 Washington, Miami (Fla.) FWAA, NFF, USA/CNN, UPI,AP 1990 Colorado, Georgia Tech FWAA, NFF, USA/CNN, AP, UPI 1989 Miami (Fla.) AP, FWAA, NFF, USA/CNN, UPI 1988 Notre Dame AP, FWAA, NFF, USA/CNN, UPI 1987 Miami (Fla.) AP, FWAA, NFF, USA/CNN, UPI 1986 Penn St. AP, FWAA, NFF, USA/CNN, UPI 1985 Oklahoma AP, FWAA, NFF, USA/CNN, UPI 1984 Brigham Young AP, FWAA, NFF, USA/CNN, UPI 1983 Miami (Fla.) AP, FWAA, NFF, USA/CNN, UPI 1982 Penn St. AP, FWAA, NFF, USA/CNN, UPI 1981 Clemson AP, FWAA, NFF, UPI 1980 Georgia AP, FWAA, NFF, UPI 1979 Alabama AP, FWAA, NFF, UPI 1978 Alabama, Southern California AP, FWAA, NFF, UPI 1977 Notre Dame AP, FWAA, NFF, UPI 1976 Pittsburgh AP, FWAA, NFF, UPI 1975 Oklahoma AP, FWAA, NFF, UPI 1974 Southern California, Oklahoma FWAA, NFF, UPI, AP 1973 Notre Dame, Alabama AP, FWAA, NFF, UPI 1972 Southern California AP, FWAA, NFF, UPI 1971 Nebraska AP, FWAA, NFF, UPI 1970 Nebraska, Texas, Ohio St. AP, FWAA, NFF, UPI, NFF 1969 Texas AP, FWAA, NFF, UPI 1968 Ohio St. AP, FWAA, NFF, UPI 1967 Southern California AP, FWAA, NFF, UPI 1966 Notre Dame, Michigan St. AP, FWAA, NFF, UPI, NFF 1965 Michigan St., Alabama FWAA, NFF, UPI, AP 1964 Alabama, Arkansas, Notre Dame AP, UPI, FWAA, NFF 1963 Texas AP, FWAA, NFF, UPI 1962 Southern California AP, FWAA, NFF, UPI 1961 Alabama, Ohio St. AP, NFF, UPI, FWAA 1960 Minnesota, Mississippi AP, NFF, UPI, FWAA 1959 Syracuse AP, FWAA, NFF, UPI 1958 LSU, Iowa AP, UPI, FWAA 1957 Ohio St., Auburn FWAA, UPI, AP 1956 Oklahoma AP, FWAA, UPI 1955 Oklahoma AP, FWAA, UPI 1954 UCLA, Ohio St. FWAA, UPI, AP 1953 Maryland AP, UPI 1952 Michigan St. AP, UPI 1951 Tennessee AP, UPI 1950 Oklahoma AP, UPI 1949 Notre Dame AP 1948 Michigan AP 1947 Notre Dame AP 1946 Notre Dame AP 1945 Army AP 1944 Army AP 1943 Notre Dame AP 1942 Ohio St. AP 1941 Minnesota AP 1940 Minnesota AP 1939 Texas A&M AP 1938 Texas Christian AP 1937 Pittsburgh AP 1936 Minnesota AP 1935 Minnesota CFRA, HAF, NCF 1934 Minnesota CFRA, HAF, NCF 1933 Michigan CFRA, HAF, NCF 1932 Southern California CFRA, HAF, NCF 1931 Southern California CFRA, HAF, NCF 1930 Alabama, Notre Dame CFRA, HAF, NCF 1929 Notre Dame CFRA, HAF, NCF 1928 Georgia Tech. CFRA, HAF, NCF 1927 Illinois, Yale HAF, NCF, CFRA 1926 Alabama, Stanford CFRA, HAF, NCF, HAF 1925 Alabama CFRA, HAF, NCF 1924 Notre Dame CFRA, HAF, NCF 1923 Illinois, Michigan CFRA, HAF, NCF, NCF 1922 California, Cornell, Princeton NCF, HAF, CFRA, NCF 1921 California, Cornell CFRA, NCF, HAF 1920 California CFRA, HAF, NCF 1919 Harvard, Illinois, Notre Dame, Texas A&M CFRA, HAF, NCF, CFRA, NCF, NCF 1918 Michigan, Pittsburgh NCF, HAF, NCF 1917 Georgia Tech. HAF, NCF 1916 Pittsburgh HAF, NCF 1915 Cornell HAF, NCF 1914 Army HAF, NCF 1913 Harvard HAF, NCF 1912 Harvard, Penn St. HAF, NCF, NCF 1911 Penn St., Princeton NCF, HAF, NCF 1910 Harvard, Pittsburgh HAF, NCF, NCF 1909 Yale HAF, NCF 1908 LSU, Pennsylvania NCF, HAF, NCF 1907 Yale HAF, NCF 1906 Princeton HAF, NCF 1905 Chicago HAF, NCF 1904 Michigan, Pennsylvania NCF, HAF, NCF 1903 Michigan, Princeton NCF, HAF, NCF 1902 Michigan HAF, NCF 1901 Michigan HAF, NCF 1900 Yale HAF, NCF 1899 Harvard HAF, NCF 1898 Harvard HAF, NCF 1897 Pennsylvania HAF, NCF 1896 Lafayette, Princeton NCF, HAF, NCF 1895 Pennsylvania HAF, NCF 1894 Yale HAF, NCF 1893 Princeton HAF, NCF 1892 Yale HAF, NCF 1891 Yale HAF, NCF 1890 Harvard HAF, NCF 1889 Princeton HAF, NCF 1888 Yale HAF, NCF 1887 Yale HAF, NCF 1886 Yale HAF, NCF 1885 Princeton HAF, NCF 1884 Yale HAF, NCF 1883 Yale HAF, NCF 1882 Yale NCF 1881 Yale NCF 1880 Princeton, Yale NCF, NCF 1879 Princeton NCF 1878 Princeton NCF 1877 Yale NCF 1876 Yale NCF 1875 Harvard NCF 1874 Yale NCF 1873 Princeton NCF 1872 Princeton NCF 1871 None selected NCF 1870 Princeton NCF 1869 Princeton, Rutgers NCF

Story 169
In 60 minutes – and the clock has just begun ticking – Prof Blacksheep will have hacked the computer mainframe in the abandoned lab of his arch-nemesis, Mr Q, who is a mouse. The professor, who accidentally turned himself into a sheep during an experiment to gain animal superpowers, wants to do more dark stuff with genes and unleash a global internet supervirus. My job, as a secret agent, is to stop it and save the world after first shrinking myself to mouse size to get into the lab.
I’ve had simpler nights out in north London, where I am confined to the basement of a former nightclub. My other mission, beyond the whole sheep-hacking thing, is to explore the rise of the escape room. After five years of steep growth – there are now almost 1,500 escape rooms across Britain – this upstart entertainment hybrid is mutating into something mainstream.
Eleven days from now, Red Bull, the energy drink more commonly associated with extreme sports, will stage the Escape Room world championships in Shoreditch, London. Four-strong teams from 23 countries will travel to the event, which will culminate in Omni’s Escape, a room that will have an ethical theme involving artificial intelligence, designed by Scott Nicholson, a professor of gaming in Ontario, Canada.
Meanwhile, entertainment giants are realising that escape rooms can give new life to their worlds and characters. Doctor Who rooms have just arrived in Bristol, Leeds, Oxford, Manchester, Reading and Birmingham; an official BBC Sherlock escape room opened in London in December, featuring original footage of the show’s stars. “Pretty much all the major entertainment companies with significant intellectual property are looking at escape rooms now,” says Ken Ferguson, a blogger and consultant who helped create the Red Bull event.
I find Prof Blacksheep at clueQuest, an escape room company run by four Hungarian brothers. I am joined by one half of the British team for the Red Bull championships; Sarah Dodd and Sharan Gill are a power couple who have completed more than 1,500 games around the world. They will be showing me Origenes, clueQuest’s newest game, based in King’s Cross, London. The company opened its first room in Tottenham in 2013, when it was only the second such facility in London. There are now 136 games at more than 50 venues in the capital, including one in a former church just over the road.
Facebook Twitter Pinterest At clueQuest. Photograph: David Levene/The Guardian
Origenes starts in the Shrink-o-mat, where we have to work out how to shrink ourselves and gain access to the lab. It looks like a bathroom on Starship Enterprise. There are flashing lights, mysterious wheels and cogs, miles of exposed circuitry, and compartments bearing strange symbols. Bolted to all the MDF, which has been artfully rendered as grimy steel, a screen shows the countdown clock.
As an escape room newbie, I have no idea where to begin. I’ve never really been into gaming, puzzles – or locked rooms – and have an aversion to organised fun (call it stag fatigue; happily I’m now deep into the Netflix and soft-play stage of life). But I’m, well, game – and glad to be in a team of pros. “We always start a room by just trying things,” says Dodd, who was a doctor before her move into gaming. Gill, a civil engineer, reaches inside some of the boxes attached to the wall. “So if you put your hand in this one you can feel a handprint and in here I can feel bumps,” she says. “Is it … a pattern?”
As Dodd and Gill do their thing, working around each other like fast-forwarded detectives at a movie murder scene, I can begin to see the appeal. There is the childlike thrill of exploring a strange world made real. Then the satisfaction of discovery as patterns suggest themselves. The bumps Gill feels match the combination lock on the far wall, it turns out. There are several more around the room, and a different bump – or button – is depressed in each one. Together they produce a string of numbers, but what is the order? And what do we do with it? I feel immediately immersed in the story, however silly it is. “If I read a book I can’t be the protagonist or touch it,” Dodd says. “In escape rooms I can.”
The escape room trend is late to bloom in the UK, yet has roots in the Dungeons & Dragons craze that started in the 1970s, and the adventure games that were big on British television in the 1980s. Now Get Out of That (1981) and the sci-fi themed The Adventure Game, which started in 1980, pre-dated the most successful adventure show of them all: The Crystal Maze, which first aired in 1990.
That trend fed into computer gaming, which had spawned “escape the room” titles in Japan. In 2007, Takao Kato, a 34-year-old publishing employee, launched his first Real Escape Game in Kyoto. Teams were given an hour to decipher clues and find hidden objects to get out. “I wondered why interesting things didn’t happen in my life, like they did in books,” Kato, a manga fan, told the Japan Times in 2009. “I thought I could create my own adventure, a story, and then invite people to be a part of it.”
As the rooms spread across Asia and America, Hungary emerged as Europe’s escape room crucible when, in 2011, Attila Gyurkovics, a former social worker, launched the Parapark franchise. Escape rooms in Budapest multiplied in empty buildings with low rents and cool cellars. The country has a heritage of puzzling: Ernő Rubik sold his first cube in Budapest in 1977. In 2012, Attila Nagy and Csaba Vinkler, two thirtysomething Hungarians, opened Britain’s first escape room in north London. HintHunt is now a global chain.
Escape rooms quickly appealed to a nostalgic generation of Brits who had grown up watching Crystal Maze and playing low-fi computer games. “People were also starting to move away from their screens,” says Zoltan “Zoli” Papp, 31, one of the brothers from Budapest who launched clueQuest. PLAN52, its first game, involved a similar mix of clues and puzzles with a secret-agent theme. Gigi, Zoltan’s brother, a puzzle fiend and former PE teacher, led the design. ClueQuest has welcomed more than 55,000 groups through its imaginatively locked doors.
Facebook Twitter Pinterest Sarah Dodd and Sharan Gill play Origenes. Photograph: David Levene/The Guardian
Dodd and Gill, who have been together for five years, caught the escape room bug in 2016. They, too, were looking for something new that didn’t involve a screen, to celebrate Dodd’s birthday. They were into games and puzzles, but the visceral thrill of escape rooms immediately seduced them. “I can also get out of the house with friends and have a drink afterwards. It’s not solitary,” Dodd says, adding: “Ultimately, humans like escapism and adventure, and to challenge themselves … and we gain most satisfaction from doing these things in a group of friends.”
Dodd has hit pause on her NHS career to become an escape room consultant, podcaster and writer. She co-founded the UK Escape Room Industry Conference, which welcomed more than 450 owners to its second event in London last October. She advises Houdini’s Escape Room Experience, which started in Southampton in 2016, and has just won a contract to open rooms within more than 40 bowling alleys operated by the Tenpin company.
As they did in Budapest, escape rooms often thrive in spaces that may not be otherwise viable. They have sprung up in castles, pubs, warehouses and disused underground stations. Startup costs can be low for those willing to put in the hours. Last June, Nick Scott, a former set builder, launched Cave Escape in a vacant shop in a former lace factory in Nottingham. “It’s something people can come and do that isn’t sitting in a cinema for two hours in silence,” he says.
Papp says his rooms unite generations, often drawing teens from their screens into family activities. Groups of adults arrive with memories of The Crystal Maze. The show gave the escape room trend a boost in 2016 when a temporary live experience opened in north London, complete with an Aztec zone, retro bomber jackets and a gold ticket-filled Crystal Dome. Two new Crystal Maze experiences have just opened in central London and Manchester.
Nick Moran came from an immersive theatre background; he launched Time Run, an elaborately produced escape room with a time-travel theme, in east London, in 2015. Thousands played, including Stephen Moffat and Sue Vertue, the couple behind Hartswood Films. They showed up one evening with Mark Gatiss, the co-creator of Sherlock, which Hartswood makes for the BBC. “They all loved it,” Moran recalls. “They didn’t have plans for a new season any time soon and had wanted to make a live experience. So we sat in a room and talked.”
Moran launched Sherlock: The Game Is Now after almost two years of development, offering players the chance to emulate the detective. He says he is surprised that it has taken this long for the trend to go fully mainstream. While many incorporate sophisticated technology – the room I am in is controlled by more than 40 computers – the trend is not driven by it. As Moran puts it, they’re “a decisively offline social experience”.
Elsewhere, museums and schools are exploiting escape rooms as interactive alternatives to historical reenactment or creepy waxworks of old sailors. Nicholson, the academic who designed the Red Bull game, has created an escape-room-inspired game for Canadian schools about the country’s electoral system. “Escape rooms have something other group activities don’t have because they are not about competition but collaboration,” he says. “We now want to design games that can make a real difference.”
At clueQuest, Dodd and Gill welcome mainstream attention if it dispels some of the myths around escape rooms. They are not scary, Dodd says, and very few have an explicit horror theme. The couple were disappointed in Escape Room, Hollywood’s latest take on the trend, in which six players end up in a series of death traps. The film jarred uncomfortably with a real tragedy, coming out just weeks after five teenage girls died in a fire in a Polish escape room in January. All the doors at clueQuest have a release button and are never genuinely locked. “I don’t like being scared and I’m claustrophobic,” Dodd says. “That’s not what it’s about.”
Prison escapees caught at Canadian escape room interactive game Read more
I have promised Papp that I will not reveal the secrets of the Origenes game. But I can report that it is captivating yet fiendishly difficult. Only 20% of teams succeed, even with hints from the control room. Dodd’s and Gill’s brains work on a different level from mine, spotting patterns and remembering sequences with startling ease. With their help – a lot of it – I shrink myself and gain access to the lab. Our task there is to understand and manipulate an array of giant objects in search for codes. There is a giant padlock, a giant floppy disc and a lot of clever lighting and moving parts. With 17 minutes to spare, we manage to save the world (you’re welcome). Slightly breathless, and more energised than I have felt doing anything that isn’t actual sport, I return to the Shrink-o-mat to get back to human size – and reality.

Story 170
One of the UConn women's basketball team's many streaks was snapped Thursday night when the Huskies suffered their first regular-season loss since 2014.
RELATED: 13 of the greatest winning streaks in NCAA history
In their first test of 2019, the top-ranked Huskies fell to No. 8 Baylor in Waco, Texas, 68-57. UConn was plagued with shooting trouble early in the game, never fully recovering against a strong defensive effort from Baylor.
* This marks UConn's first regulation loss in its last 209 games.
* UConn had won 126 straight regular-season games.
* Last time UConn lost a true road game in regulation was Dec. 18, 2011 -- at No. 1 Baylor. (Via @ESPNStatsInfo) — ESPN Women's Hoops (@ESPN_WomenHoop) January 4, 2019
UConn was led by senior Napheesa Collier with 16 points and 10 rebounds and Katie Lou Samuelson (12 points, 11 rebounds). Crystal Dangerfield scored 11 points, while Megan Walker had 10 and Christyn Williams ended the night with eight. They shot 29 percent from the field, scoring only 10 points in the paint.
The Huskies got off to a slow start, struggling against Baylor's size advantage. They shot just 23.5 percent in the first quarter, while the Bears shot 43.8 percent. The only UConn players who scored in the first quarter -- aside from free throws -- were Dangerfield, Collier and Walker. With a few uncontested shots, Baylor quickly took the lead and finished the first quarter up 16-13.
Baylor extended its lead in the second quarter, going up by as much as nine points before the Huskies started to rally back in the final three minutes of the half. Collier gave the Huskies their momentum, knocking down a 3-pointer followed immediately by a steal on the other end of the court. One made free throw later, Collier had UConn trailing by just five points. Samuelson and Walker both hit threes, followed by a last second offensive rebound and putback from Samuelson sent the Huskies into halftime down 30-29.
The Lady Bears post a win over a No. 1 team for the first time in program history, knocking off top-ranked UConn, 68-57! #SicEm #SicUConn pic.twitter.com/zO2O2vdZBg — Baylor Lady Bears (@BaylorWBB) January 4, 2019
Just over a minute into the third quarter, Samuelson sank a three to tie it up at 32-32, but the momentum quickly went back to Baylor. The Bears went on a 9-2 run and the Ferrell Center exploded as they went into a timeout up 41-34.
But UConn has a habit of fighting back just when things seem to be trending too far in the wrong direction, and that's exactly what it did. A few made shots and it felt like the Huskies were back in it, but turnovers and fouls helped Baylor pull away again. This time, UConn let Baylor get out to a 10-point lead before back-to-back threes from Williams silenced the Bears' crowd as the quarter ended. Baylor led 51-47 at the end of the quarter.
This is UConn's first road loss in regulation since Dec. 18, 2011 ... which was also against Baylor. pic.twitter.com/OxNb7aX4yW — espnW (@espnW) January 4, 2019
The fourth quarter began with a string of missed shots from behind the arc for UConn, once again putting them down by 10. The deficit would prove too much to overcome as they continued to struggle against Baylor's defense.
MORE: Women's college basketball rankings
(c)2019 The Hartford Courant (Hartford, Conn.)

Story 171
AP Photo/Richard Drew
Stocks ended mostly higher on Thursday as the Dow Jones Industrial Average closed at a fresh high Thursday, a day after the Federal Reserve signaled that the US central bank would soon step in to keep the economy humming.
The Dow Jones Industrial Average briefly topped 27,000 for the first time.
Expectations for a cut held up even after government data showed a key measure of core inflation came in at its fastest pace in nearly a year and a half in June.
Visit Markets Insider for more stories.
Stocks ended mostly higher on Thursday as the Dow Jones Industrial Average closed at a fresh high, a day after the Federal Reserve signaled the central bank would soon step in to keep the economy humming.
Fed Chairman Jay Powell signaled in a second day of congressional testimony that officials would slash interest rates at the end of the month, sending the Dow Jones Industrial Average above 27,000 for the first time.
Here's a look at the numbers:
"It appears that uncertainties around trade tensions and concerns about the strength of the global economy continue to weigh on the US economic outlook," Powell said, adding that the central bank would take actions to sustain the decade-long expansion.
His comments, along with minutes from the policy-setting Federal Open Market Committee on Wednesday, reassured investors who had seen a rate cut as less likely following a strong June jobs report last week. The central bank has dimmed its outlook for the economy this year on the back of slowing growth, below-target inflation, and trade tensions.
The probability of a half-percentage-point cut edged slightly higher on Thursday, according to CME Group, but most expected the central bank to lower its benchmark interest rate by 25 basis points. That was even as government data showed that a key measure of core inflation came in at its fastest pace in nearly a year and a half in June.
"To cut to the chase: the higher-than-expected print will not prevent the Fed from cutting rates in July," said Eric Winograd, a senior economist at AllianceBernstein. "Inflation momentum remains limited—it will take a lot more than one month of firm price data to change the narrative around tepid price pressures."
Healthcare and drug-distributor shares were in focus Thursday after the Trump administration withdrew a plan that would have limited annual prescription drug rebates under Medicare. Within the S&P 500, these were the largest gainers:
Cigna Corp (+9.22%)
Anthem (+5.55%)
UnitedHealth Group (+5.53%)
And the largest decliners:
Iron Mountain (-7.48%)
Merck & Co Inc (-4.50%)
Eli Lilly and Co (-4.09%)
The yield on the 10-year rose to 2.129%, and the short-term two-year yield climbed to 1.852%.
On the commodities front, oil prices were mixed as traders weighed an expected storm in the Gulf of Mexico against expectations for weaker demand. Lower-than-expected inventory in the US and Iran tensions have also supported prices in recent days.
Markets Insider is looking for a panel of millennial investors. If you're active in the markets, CLICK HERE to sign up.

Story 172
The 25-year-old has been sidelined since early April but is targeting the Madrid showpiece on June 1 for his return
Harry Kane is optimistic he will be fit to play in the Champions League final.
The England striker – currently sidelined with an ankle injury – was a spectator in Amsterdam as Tottenham came from 2-0 down on the night, and 3-0 down on aggregate, to beat Ajax in another dramatic semi-final.
getty 2 Harry Kane celebrates Tottenham’s incredible victory against Ajax in Amsterdam
Kane was able to run across the pitch to celebrate with his team-mates, and he now has his sights set on the all-English showdown with Liverpool in Madrid on June 1.
“Hopefully. Rehab is going well so far,” he said. “I start straight-line running this week.
“We’ll see. So far so good, so if it carries on as it should I would hope to be (fit). There’s still a few weeks to go.”
How's the ankle, Harry? 😂🤣 pic.twitter.com/SG8MDZhOQE — Football on BT Sport (@btsportfootball) May 8, 2019
Kane, who has been out since April 9, joked that he faces a battle to earn his place, after Lucas Moura’s hat-trick and substitute Fernando Llorente’s inspirational performance against Ajax in his absence.
He said: “We beat Manchester City, we beat Ajax in the semi… I’ve got to start training even harder and prove myself in front of the gaffer.”
Getty 2 Lucas Moura celebrates completing his hat-trick in Amsterdam
LATEST FOOTBALL NEWS BOOKED When the real Pele had no clue about Arsenal legend Ray 'Romford Pele' Parlour off the mark Chris Smalling scores first goal for Roma since joining from Man United disgraceful Fan rages at ‘clueless’ Emery after ‘shambolic’ Arsenal lose to Liverpool teens VERDICT Mourinho is 'exactly what Spurs need' and can take them to 'elite level' - Durham ALMOST HAPPENED Origi to blame for denying Emery the chance to win by 'preferred' scoreline unexpected Mustafi shows Xhaka how to address Arsenal fans following a bad performance CLASSY Tierney 'already gets it' as Arsenal man is praised for actions after Liverpool loss selfless Barca players offered to alter contracts so club could sign Neymar, says Pique Homecoming 'It would be amazing' - Milner discusses Leeds return before retiring SPYGATE II? FA demands Man City 'Spygate' answers from Liverpool GOSSIP Liverpool to sign Werner, Man United eye £45m striker, Pochettino wanted by Bayern Play him Unai Emery told by Jamie Carragher he must put Mesut Ozil in his Arsenal XI

Story 173
Which of the last eight teams will go the whole way and lift the trophy in June?
The remaining eight teams in the Champions League now know their routes to the final in Madrid at the Wanda Metropolitano on June 1.
This week clubs are playing the first legs of their quarter-finals as we get set for a thrilling conclusion to the competition.
4 The Champions League quarter-final draw.
We’ve got some tasty ties, including one all-English affair between Tottenham Hotspur and Manchester City, while Manchester United must play Barcelona – 20 years after Ole Gunnar Solskjaer’s winner at the Camp Nou saw the Red Devils down Bayern Munich and lift the European Cup in Spain.
After plenty of drama in the round of 16 saw Paris Saint-Germain and Real Madrid knocked out it’s going to be hard to predict what will happen in the rest of the competition.
But unafraid of the odds, talkSPORT.com have fired up their famous Super Computer to predict final stages of the Champions League, including the final.
You can see the results below…
And if you think you’re better at predictions than the super computer, give the talkSPORT predictor game a go!
LATEST FOOTBALL STORIES NEW THREADS Ronaldo scores controversial winner as Juventus sport 'unique' new Palace kit AWKWARD Owen and Shearer could face awkward reunion as Amazon announce pundits BOOKED When the real Pele had no clue about Arsenal legend Ray 'Romford Pele' Parlour off the mark Chris Smalling scores first goal for Roma since joining from Man United disgraceful Fan rages at ‘clueless’ Emery after ‘shambolic’ Arsenal lose to Liverpool teens VERDICT Mourinho is 'exactly what Spurs need' and can take them to 'elite level' - Durham ALMOST HAPPENED Origi to blame for denying Emery the chance to win by 'preferred' scoreline unexpected Mustafi shows Xhaka how to address Arsenal fans following a bad performance CLASSY Tierney 'already gets it' as Arsenal man is praised for actions after Liverpool loss selfless Barca players offered to alter contracts so club could sign Neymar, says Pique Homecoming 'It would be amazing' - Milner discusses Leeds return before retiring SPYGATE II? FA demands Man City 'Spygate' answers from Liverpool
Quarter-finals
Ajax vs Juventus
First leg – 1-1
Second leg – 2-0 – Juventus win 3-1 on aggregate
Liverpool vs Porto
First leg – 3-0
Second leg – 1-2 – Liverpool win 5-1 on aggregate
4 Liverpool players celebrate beating Man City in last season’s Champions League
Tottenham Hotspur vs Manchester City
First leg – 1-1
Second leg – 3-1 – Manchester City win 4-2 on aggregate
Barcelona vs Manchester United
First leg – 2-1
Second leg – 1-2 – Barcelona win 4-2 on aggregate
4 Lionel Messi scored twice in Barcelona’s 5-1 win against Lyon in the round of 16
Semi-finals
Manchester City vs Juventus
First leg – 1-1
Second leg – 2-1 – Juventus win 3-2 on aggregate
Barcelona vs Liverpool
First leg – 2-1
Second leg – 2-2 – Barcelona win 4-3 on aggregate
4 Cristiano Ronaldo was the star of the show for Juventus in their round of 16 comeback against Atletico Madrid
Final
Juventus 2-1 Barcelona

Story 174
MG HAS made its first foray into electric cars with the launch of the pure-electric ZS EV SUV.
What is the 2019 MG ZE EV?
The MG ZS EV is the British brand’s first pure-electric production car.
The ZS EV looks like a conventional SUV crossover at first glance, and MG says there haven’t been any practicality compromises in creating the electric model, thanks to some clever packaging around the battery pack.
MG, which is owned by Chinese company SAIC Motor, is also making the bold assertion its ZS EV is “the first truly affordable, family friendly electric car”. Scroll down for prices.
How far can the 2019 MG ZS EV go on a charge?
Under the new, tougher WLTP testing cycle, MG claims the ZS EV can be driven up to 163 miles on a single charge.
While this doesn’t match the best electric cars on sale right now, it is a respectable range for a car of this type and price — the entry-level version of the ZS EV’s closest rival, the Hyundai Kona Electric, can go up to 180 miles before it needs to be recharged (if you want the 279-mile Kona Electric, you have to pay upwards of £32,000).
Speaking of recharging, MG says a 50kW rapid charger can take the battery from flat to 80% in 40 minutes, while a 7kW domestic charging point can fully replenish the ZS EV’s batteries in six hours.
It can also be topped up from a standard 3-pin domestic plug socket if need be. However, as with other EV companies, MG stresses ZS EV buyers should only resort to this in emergencies.
How fast is the 2019 MG ZS EV?
With its electric motor producing 141bhp and 260 lb ft of torque, the ZS EV will offer a decent turn of speed for a compact SUV — MG is quoting a 0-62mph time of 8.5 seconds. The top speed won’t set the world alight but its official limit of 87mph is enough to break the motorway speed limit.
What tech will the 2019 MG ZS EV have?
While MG is pitching the ZS EV as an affordable electric car option, on paper it hasn’t cut corners with the car’s spec sheet. Buyers who opt for the base ‘Excite’ model will still have access to items like an 8in touchscreen display with Apple CarPlay and Android Auto compatibility, built-in navigation and a panoramic sunroof.
MG says the ZS EV majors on safety, too, as all models come with adaptive cruise control, lane keep assist, blind spot monitoring and auto emergency braking, which brings the car to a halt if it detects an imminent forward collision (albeit only if the car is going no faster than 12mph).
Opt for the range-topping ‘Exclusive’ trim and you also get rear cross traffic alert, which warns of oncoming cars when you’re reversing out of a driveway.
How spacious is the 2019 MG ZS EV?
Because the car uses a platform designed from the outset with battery power in mind, MG claims the ZS EV is just as practical as the regular, petrol-powered car. The boot space is identical, at 448 litres, and MG is claiming more rear shoulder and head room than the segment average.
When will the 2019 MG ZS EV go on sale?
The MG ZS EV is available to order now and prospective buyers are able to reserve their example with a £500 deposit. MG says UK deliveries will begin in September 2019.
How much will the 2019 MG ZE EV cost?
Though the “first truly affordable, family friendly electric car” claim is debatable, the MG ZS EV is certainly at the affordable end of EV ownership.
Once the UK government’s £3,500 Plug-in Car Grant is applied, prices for the ZS EV start at £24,995 for the base ‘Excite’ model and rise to £26,995 for the top-spec ‘Exclusive’ version.
To temp early adopters, MG has said it will match the £3,500 government grant for the first 1,000 ZS EVs it sells, bringing the car’s price down to £21,495 for the Excite-spec model and £23,495 for the Exclusive spec.
The car maker also says it will throw in a free home electric car charging point with the first 1,000 ZS EV orders.
What are the 2019 MG ZE EV’s rivals?
The ZS EV won’t have many SUV competitors when it arrives on UK roads in September – its most direct rivals come in the form of cars like the Hyundai Kona Electric and Kia e-Niro, though both those cars have long waiting lists. The Kia Soul EV is a little smaller and isn’t expected to land in dealers until early 2020.
There are a growing number of hatchback alternatives if you’re not too fussed about the MG’s raised ride height, however. Take that out of the equation, and the ZS EV offers a similarly-priced package to the Nissan Leaf or, for a bit more, the Hyundai Ioniq Electric, BMW i3 or VW e-Golf. If space isn’t such an issue, there are also superminis like the Renault Zoe and upcoming Peugeot e-208, Vauxhall Corsa-e and MINI Electric.
Tweet to @ST_Driving Follow @ST_Driving

Story 175
The actor-writer will perform her comic monologue, on which the hit TV show was based, for 30 performances this summer
It is the filthy, fiercely funny monologue that received mixed reviews when it was staged in a tiny venue at the Edinburgh festival in 2013. After six years, several revivals, two TV series and a sold-out run off-Broadway, Phoebe Waller-Bridge is to perform her play Fleabag for the last time. She will do so at Wyndham’s theatre in London’s West End for 30 performances over four weeks this summer. The news will delight those fans of the hit TV show who are still grieving over Waller-Bridge’s decision not to write a third series of Fleabag.
Facebook Twitter Pinterest Phoebe Waller-Bridge as Fleabag in Soho theatre, London, 2016. Photograph: Linda Nylind/The Guardian
Written and performed by Waller-Bridge, and directed by Vicky Jones, Fleabag is an account of “some sort of woman living her sort of life”. Waller-Bridge received a Fringe First award in Edinburgh for the play, whose scenarios and characters formed the basis for its first series on TV. It followed the eponymous heroine’s disastrous cafe business, unruly sex life and struggle to deal with the death of her best friend.
The TV version made Waller-Bridge a household name and was soon followed by further success as a writer with her series Killing Eve. She returned to the role of Fleabag in 2016 at Soho theatre, which had played a key part in the solo show’s early success. Waller-Bridge has just finished performing the part in New York.
Fleabag will begin previews at Wyndham’s theatre on 20 August. Tickets go on sale at 3pm on Thursday, with 25% of tickets at £25 or less.
Before then, Waller-Bridge will be focusing on her next mission: livening up the script of the new James Bond film, at the special request of Daniel Craig.

Story 176
Brendan and Nicola Quinn promoted high-risk investments, including car parks and offices in Dubai and renewable energy plants
A married couple who persuaded savers to plough millions into high-risk products that went wrong have set up a claims management service for mis-sold investments, Money can reveal.
Brendan Quinn, 56, and his wife Nicola, 45, promoted investments including car parks and offices in Dubai and renewable energy plants in Wales to ordinary savers. Returns were advertised at more than 8.5% a year.
The couple’s company was an “introducer” firm called Aspire Business Management, set up in December 2013. Based in Ayrshire, it earned commission of up to 17% of the sums investors handed over, one document seen by Money reveals.
Aspire worked with at least three regulated financial advisers to rubber stamp the products so they could be included in self-invested personal pensions (Sipps).

Story 177
Samsung / WIRED
You've seen the shouty adverts and breathless tech articles. 5G is fast and it's here and you should drop everything and buy a 5G phone right now.
EE is the first UK network to offer 5G plans. You can pre-order phones attached to them at EE’s website now, starting at £54 per month for the Oppo Reno 5G. The price rises to £69 if you want a phone your friends have actually heard of, like the Samsung Galaxy S10 5G, or data allowances that justify faster internet. Vodafone plans to follow suit more-or-less imminently, in July. Three says its 5G network is coming later this year.
Advertisement
The first 5G phones are here too: the OnePlus 7 Pro 5G, Samsung Galaxy S10 5G, Oppo Reno 5G, Xiaomi Mi Mix 3 5G and LG V50 5G. Each is either very similar to a top-end 4G phone, or has tweaks like a larger screen to help justify the often-significant added cost.
Samsung’s Galaxy S10 5G has a 6.7-inch screen, four cameras on its back (rather than three) and two on the front. It costs a packet and has the tech to match. The Oppo Reno 5G costs significantly less - Oppo is relatively new to the UK, but is popular in China and India.
Read next Amazon Kindle Kids Edition review: a good idea with several flaws Amazon Kindle Kids Edition review: a good idea with several flaws
5G is firing on all cylinders. And if you come across the right articles online, or find the right circles on Twitter, you’ll see photos of handfuls of technology journalists and influencers wandering around London showing off internet speed test results in the 400-500Mbps range.
This is great. It’s four or five times quicker than the fastest home internet available to much of Greater London, let alone rural areas. But this is not the time for most people to invest in a 5G phone. Give it a year or two. Here's why.
Advertisement
The state of 5G in 2019
Today’s 5G phones offer a snapshot of today’s 5G progress. We are only at the beginning of its development and this plays out in a few different ways.
Spectrum is one of the easiest to explain. Phone networks license bands of the frequency spectrum, over which they transmit mobile internet services. These are auctioned off for vast sums of money: EE paid £302,592,000 for 40MHz of the 3.4GHz band. At launch, 5G services are using this 3.4GHz band.
They were auctioned off by regulator Ofcom in April 2018, and were previously used by the Ministry of Defence. These frequency bands are remarkably solid and finite for something “floating” invisibly in the air.
Read next Apple's new AirPods Pro get noise cancelling and a design makeover Apple's new AirPods Pro get noise cancelling and a design makeover
Mobile networks now have some more frequency bandwidth to start rolling out 5G. But even Telefonica UK CEO Mark Evans described this as merely “laying the foundations for 5G in Britain”.
Advertisement
5G will get more interesting when further parts of the spectrum are auctioned off. The marketing tells us that 5G is a tech masterpiece that will solve all the bandwidth issues of the congested 4G networks. But you don’t get this simply by using slices of the 3.4GHz band and early testers report seeing 4G-like speeds in many areas where a phone displays a 5G signal, before the public are even using 5G plans.
More antennas are needed
5G antennas also use "massive MIMO” tech, responsible for the claims it will allow for an exponential increase in the number of connected devices. This is a great step forward, but the decreased wavelength of 5G’s bands also means decreased range for each transmitter. More 5G masts, or smaller antenna clusters, are needed, everywhere. And until we get them, 5G signal will be restricted to fairly small pockets in cities around the UK.
Building the required infrastructure will take years. And it is likely to be slowed both by protests of those who believe the baseless claims that 5G is gradually sautéing their brains, and the current hot water Huawei is in.
Huawei is one of the primary manufacturers of networking hardware, and was a giant in this area before anyone had heard of its smartphones. Views and allegations around Huawei include that it is a shameless IP thief, an unacceptably successful rival to non-Chinese companies, and effectively the Chinese government in a friendly Bill Clinton face mask. (Huawei has denied claims against it).
Read next Victorinox's new watch is as tough as one of Nasa's space shuttles Victorinox's new watch is as tough as one of Nasa's space shuttles
Many are now incensed by the idea Huawei has a part in the UK’s 5G setup. Bad news for those people: it was already there in our 3G and 4G infrastructure, although BT and EE have reportedly started removing Huawei’s kit.
The signal isn't great yet
Outside a few hotspots, you’re likely to see 4G-like speeds in most places, even in central London, for some time. Even if your phone says you’re connected to 5G.
There’s another issue. The boldest claims about 5G speed rely on the 'mmWave' bands that phone networks don’t have access to, yet. This refers (primarily) to bands in the 28GHz range, frequencies so high that the signal’s wavelength is reduced to a millimetre, instead of the around 90mm of the current 3.4GHz 5G signal.
MmWave is what will provide the real mind-blowing speed of 5G once lots of actual people start using it. There are, you guessed it, more problems. MmWave signals have trouble passing through walls, and the maximum range of antennas, even with line of sight, is around 500m according to Verizon tests in the US. The network is actually using mmWave tech.
If Ofcom, as is expected, grants access to the 26GHz band, we’ll start seeing 5G antennas everywhere. Bus stops, the sides of buildings, underneath the shopping trolleys of unsuspecting old ladies. That said, they’ll likely become immediately invisible like the routers strapped to the ceilings of just about all London tube stations.
Read next The best compact cameras for any budget in 2019 The best compact cameras for any budget in 2019
5G is important, but it is not simply a switch that is flicked at Vodafone HQ. It’s a process, and a long one.
The phone hardware could be better
Today’s hardware is not quite ready for all the changes either. All 5G launch phones – the OnePlus 7 Pro 5G, Galaxy S10 5G, Oppo Reno 5G and LG V50 5G - have the Qualcomm Snapdragon X50 modem.
This lacks a few features that may be important for the future of UK 5G (and already are in other countries including the US). The Snapdragon X50 does not support SA, required for full standalone 5G networks not paired with 4G, or FDD. This is where upload and download data use distinct frequency channels. The alternative, TDD (used by the Snapdragon X50 and launch 5G services), makes both travel in the same band. TDD makes sense now, when the network 'space' for 5G is limited. But networks started using FDD fairly soon after 4G’s introduction.
Perhaps this doesn’t matter if Brexit slows infrastructure improvements and leaves us huddled around a burnt-out Morrisons, holding up our phones to a 5G mast made of old spoons and a coat hanger. But the Snapdragon X50 is very much a first-wave 5G modem.
Qualcomm announced the X50 way back in 2016, and the upcoming Snapdragon X55 fills all its major holes, and is likely to built into future SoCs as standard. The Snapdragon X50 is not – it has to be added by the manufacturer.
Read next Google Pixel 4 review: the ultimate Android phone has a big flaw Google Pixel 4 review: the ultimate Android phone has a big flaw
Data is too expensive
The most impactful change we need to see as mobile phone users has nothing to do with infrastructure, 5G hardware or phones. Data allowances are the biggest issue.
EE’s early 5G contracts come with no more data than a high-end 4G one. You can pay £59 a month for a contract with just 10GB of data allowance, which reduces 5G’s appeal to faster-loading web pages. Its £79, 120GB plan is much closer to what we want to see for 5G, but the cost is prohibitively high for most.
To return to the Samsung example: you can get an EE plan for the regular Galaxy S10 (128GB) from £45 a month; the more comparable Galaxy S10+ (128GB) from £50 a month and the Galaxy S10 5G (256GB) from £69 a month with 30GB of data.
If 5G has a 'user experience' purpose, it's to remove the barriers between local and streamed content. So you should be able to stream a movie as if it were a file on your phone. A game played through Google Stadia should seem the same as one installed on internal memory.
Even if the low latency and high speed of 5G are capable of this trick, it’s not much use if you have to constantly worry about how much data you use.
Read next The (genuinely good) deals in Amazon's smart home sale The (genuinely good) deals in Amazon's smart home sale
Thanks to the smart home, any vision of having one internet connection for home and away are far off. How will you control your smart thermostat when you accidentally leave it on, and your phone is five miles away from it, in your pocket? In future we might see plans with home 'access points' that share the same allowance as your phone. But any claims 5G will spark a behavioural or major experiential change seem thin when too many of us have to treat our mobile internet like a pre-pay boiler.
5G is a jigsaw puzzle. The pieces already in place look great. They’re shiny and colourful, but it will be some time before the picture looks complete. Early adopters are right to be excited by what is already on offer. But until it's more mature, the 5G experience may be a little too close to that of stumbling across the occasional bafflingly fast Wi-Fi hotspot. 2019 may be the official year of 5G, but in 2020 and 2021 it’s more likely to be ready for mass adoption.
More great stories from WIRED
🐄 How our addiction to big beef ended up ruining the planet
👎 Google's Image search has a massive sexism problem
💰 Here's what Facebook, Google and Tesla pay staff in 2019
👽 The best science fiction books everyone should read
Advertisement
👍 Follow these essential tips to using Trello like a boss
📧 Never miss an awesome story again with our weekly WIRED Weekender newsletter

Story 178
Nach dem Todesfall von Anthoine Hubert stehen für die Formel 2 in Monza die nächsten Rennen an. In Italien sind die Nachwehen zu spüren. Infos im Ticker.
Motorsport-Magazin.com - In der Formel 2 kehrt nach dem tragischen Tod von Anthoine Hubert nur langsam Normalität ein. Beim Rennwochenende in Monza nur eine Woche nach dem Unglück sind die Nachwehen zu spüren. Die Motorsportwelt trauert weiter, in der F2 fehlen zudem einige Rennautos und mit Juan Manuel Correa auch ein Fahrer, der in den Spa-Unfall verwickelt war. In Spa wurde das Sonntagsrennen aus Respekt vor dem Verstorbenen abgesagt. In Monza geht es nun weiter mit den nächsten beiden Rennen der Saison 2019.
In der Formel 3 ist die erste Titelentscheidung bereits gefallen. Prema hat sich im zweiten Belgien-Rennen vorzeitig die Teammeisterschaft gesichert. An dieser Stelle liefern wir euch alle Infos zum Rennwochenende der Formel 2 und der Formel 3 in Italien.
Formel 2 und Formel 3 Monza 2019: Der Zeitplan
Freitag, 06. September:
09:35 - 10:20 Uhr: Formel 3 - Freies Training
13:00 - 13:45 Uhr: Formel 2 - Freies Training
16:55 Uhr: Formel 2 - Qualifying
17:50 Uhr: Formel 3 - Qualifying
Samstag, 07. September:
10:30 Uhr: Formel 3 - Rennen 1
16:45 Uhr: Formel 2 - Hauptrennen
Sonntag, 01. September:
09:30 Uhr: Formel 3 - Rennen 2
10:50 Uhr: Formel 2 - Sprintrennen
Live-Übertragungen von allen Sessions gibt es im offiziellen Streaming-Dienst der Formel 1, F1 TV Pro. Für jene, die den Dienst nicht nutzen, bietet RTL im Rahmen ihrer Formel-1-Berichterstattung zumindest Zusammenfassungen der Formel 2 mit Mick Schumacher. Mehr Details gibt es im Zeitplan zum F1-Wochenende von Motorsport-Magazin.com.
Formel 3 - Neues zu Peroni: Alex Peroni hatte bei seinem Horror-Überschlag in Monza noch einmal Glück im Unglück. Der Australier kam lediglich mit einem gebrochenen Wirbel davon. Das teilte er über seinen Instagram-Account mit.
Formel 2 - Rennen 2: Jack Aitken gewinnt das F2-Sprintrennen von der Pole aus. Ganz so einfach war es aber nicht, denn der Renault-Junior hielt vier Gegner in Schach. Mick Schumacher landete nach Aufholjagd von Startplatz 14 auf dem sechsten Rang. Mehr zum Sprintrennen gibt es hier in unserem Rennbericht:
Formel 3 - Rennen 2: Yuki Tsunoda hat seinen ersten Sieg in der Formel 3 geholt. Der Japaner siegte auf nasser Strecke vor Liam Lawson und Jake Hughes. Fabio Scherer wurde Siebter, David Beckmann Vorletzter. Mehr dazu:
Formel 2 - Grid-Strafe für Zhou: Guan Yu Zhou erhält für das Sprintrennen eine Grid-Strafe von drei Plätzen. Er wurde als Schuldiger für die Kollision mit Nicholas Latifi ausgemacht. Beide kamen sich im Hauptrennen ins Gehege. Zhou musste das Rennen vorzeitig beenden, Latifi kam als 13. und Letzter ins Ziel.
Formel 3 - Nachträgliche Strafen: Marcus Armstrong und Felipe Drugovich erhielten nach dem ersten Rennen noch Strafen. Beide leisteten sich Vergehen während der Safety-Car-Phasen. Armstrong erhielt eine 20-Sekunden-Strafe und fiel dadurch von P2 auf P21 zurück. Drugovich wurden fünf Sekunden drauf gerechnet, sodass er in der Wertung von P11 auf P16 abrutschte.
Formel 2 - Rennen 1: Nobuharu Matsushita hat sich im ersten Rennen der Formel 2 durchgesetzt. Er gewann vor Luca Ghiotto. Gesamtleader Nyck De Vries startete von ganz hinten und wurde am Ende Dritter - ein großer Schritt Richtung Meisterschaft. Mick Schumacher schied wegen eines Leistungsverlusts vorzeitig aus. Mehr dazu:
Formel 3 - Rennen 1: Robert Shwartzman hat das erste Rennen in Monza gewonnen. Er setzte sich am Ende gegen seine Prema-Teamkollegen Marcus Armstrong und Jehan Daruvala durch. Nach einem schweren Unfall von Alexander Peroni ging das Rennen hinter dem Safety Car zu Ende. Lirim Zendeli führte anfangs, musste aber das Rennen nach einer Kollision mit Christian Lundgaard bereits in der vierten Runde beenden. Mehr dazu:
Formel 3 - Qualifying-Update: Für die Farce am Ende des Qualifyings setzt es Strafen für - wörtlich zu nehmen - das halbe Feld. 16 (!) Fahrer kassieren Strafversetzungen für unnötig langsames Fahren. Armstrong, Daruvala, Shwartzman, Bnt Viscaal, Jke Hughes und Natori werden um 10 Plätze versetzt. Die Fahrer hatten allesamt für insgesamt je zwei Vergehen zwei 5-Platz-Strafen erhalten, die sich zu 10-Platz-Strafen addieren.
Lawson, Drugovich, Sargeant, Kari, Pulcini, Vips und Yifei bummelten allesamt 'nur' einmal, erhalten daher je fünf Plätze Strafe. Beckmann, Fewtrell und Lundgaard kommen für weniger schlimmer Fälle mit drei Plätzen davon. Damit wird die Startaufstellung natürlich erheblich durcheinandergewürfelt. Kurios: Unter dem Strich behält Lundgaard sogar P1.
Formel 2 - Qualifying-Update: Gesamtleader Nyck De Vries ist nachträglich im Qualifying disqualifiziert worden! In seinem Tank befanden sich nach der Session weniger als die vorgeschriebenen 0,8 kg Benzin. De Vries muss damit von ganz hinten starten.
Formel 2 - Neues zu Correa: Es gibt neue Entwicklungen bei Juan Manuel Correa. Offenbar kam es zu Problemen im Bereich der Lunge. Sein Zustand wird als kritisch, aber stabil bezeichnet. Mehr Infos dazu gibt es in nachfolgendem Bericht:
Formel 3 - Qualifying: Ein vorzeitiger Qualifying-Abbruch brachte Christian Lundgaard die Pole Position für das Samstagsrennen in Monza ein. Der ART-Teamkollege von David Beckmann (Platz 17) erzielte in 1:38.834 Minuten die schnellste Runde aller 30 Piloten. Hinter Lundgaard lauern mit Marcus Armstrong, Robert Shwartzman und Jehan Daruvala alle drei Piloten aus dem Prema-Team. Für eine Überraschung sorgte Lirim Zendeli, der mit Platz fünf sein bestes Ergebnis in der Formel 3 erzielte.
Formel 2 - Qualifying: Callum Ilott sicherte sich bei regnerischen Bedingungen seine erste Pole Position in der Formel 2. Mit einer Zehntelsekunde Rückstand qualifizierte sich Guanyu Zhou auf dem zweiten Startplatz. Der Meisterschaftsführende Nyck de Vries musste sich mit P4 hinter seinem ART-Teamkollegen Nikita Mazepin begnügen. Mick Schumacher schaffte es als Neunter in die Top-10 beim Heimspiel seines Prema-Teams. Nach Abflügen von Nobuharu Matsushita und Tatiana Calderon musste das Qualifying zweimal mit roten Flaggen abgebrochen werden.
Formel 2 - Freies Training: In der ersten Session nach dem Tod von Anthoine Hubert setzte sich Luca Ghiotto durch. Auf abtrocknender Strecke erzielte der Uni-Virtuosi-Pilot die Bestzeit in 1:33.017 Minuten. In der größtenteils ereignislosen Session belegten Titelfavorit Nyck de Vries, Louis Deletraz und Carlin-Teamkollege Nobuharo Matsushita die Plätze zwei bis vier. Mick Schumacher beendete das Training auf dem achten Platz mit einem Rückstand von sieben Zehntelsekunden auf die Spitze.
Formel 3 - Freies Training: Rutschpartie zum Auftakt des Rennwochenendes! Starker Regen beeinträchtigte die einzige Trainings-Session der F3-Piloten in Monza. Bei nassen Bedingungen erzielte der Meisterschaftsführende Robert Shwartzman die Bestzeit in 1:42.587 Minuten. Prema-Teamkollege Marcus Armstrong ordnete sich mit 0,193 Sekunden Rückstand auf dem zweiten Platz ein. Pedro Piquet (Trident), Jehan Daruvala (Prema) und Teppei Natori (Carlin) komplettierten die Top-5, David Beckmann konnte wegen technischer Probleme kaum fahren und wurde Letzter. 29 Minuten vor Sessionende wurde das Training mit roten Flaggen unterbrochen. Der deutsche Nachwuchspilot Andreas Estner war auf regennasser Piste in die Streckenbegrenzung eingeschlagen. In der Folge kamen zahlreiche Fahrer von der Strecke ab, in den Schlussminuten sorgte MP Motorsport-Youngster Richard Verschoor für einen Dreher. Giorgio Carrara von Jenzer Motorsport schaffte es nach einem Dreher, sich auf einem Kerb festzufahren.
Die Vorschau auf Monza
Formel 2:
Die Formel 2 steht noch sehr unter dem Eindruck des tragischen Todesfalls von Anthoine Hubert vor einer Woche in Spa-Francorchamps. Das geplante Sonntagsrennen in Belgien wurde aus Respekt vor dem Verstorbenen abgesagt. In Monza sind die Nachwehen noch zu spüren. Drei Autos fehlen in Italien, teilweise wegen laufender Polizeiermittlungen. Der in den Unfall involvierte Juan Manuel Correa befindet sich nach seinen erlittenen Beinverletzungen weiterhin im Krankenhaus. In der Meisterschaft führt weiter Nyck de Vries mit 34 Punkten Vorsprung auf Nicholas Latifi.
Formel 3:
Für die Formel 3 steht in Monza die siebte Runde der Saison 2019 auf dem Plan. In einer Meisterschaft ist die Entscheidung bereits gefallen: Prema hat sich in Spa vorzeitig den Teamtitel gesichert. Prema-Youngster Robert Shwartzman führt auch die Fahrerwertung an. Der Russe hat bislang 152 Punkte gesammelt. Sein ärgster Verfolger, Jehan Daruvala, belegt den zweiten Platz mit 129 Zählern. David Beckmann ist als Gesamtzwölfter bestplatzierter Deutscher.

Story 179
The first college football game was played 150 years ago, when students from Princeton and Rutgers faced off in New Jersey.
Today, the plot of grass they played that game on has since been replaced by a gymnasium. Still, some of the sports' oldest venues live on. There are several college football stadiums across the country that are 100 or more years old.
GAME DAY: Locations, all-time appearances, most times hosting for the ESPN show
These stadiums have undergone renovations, expansions and clean-ups — some major and some minor — since they first opened their doors, but each of them holds a special place in the sport's history.
On the embedded Google Map below, you can find out where each stadium is located and fun facts about these old gridirons.
WHAT TO KNOW FOR NEXT SEASON: 2019-20 CFP semifinal and championship dates and sites
Franklin Field (Philadelphia, Pennsylvania) — 1895
Franklin Field has been a host for baseball, the opera, military training, soccer and a U2 concert, but it’s a football venue, first and foremost. It is the oldest college football stadium in the U.S., the site of the first game to be broadcast on radio in 1922. In addition to hosting countless Penn Quakers games, it was the site of 18 Army-Navy games.
FCS in 2019: 7 teams that could end North Dakota State's dominance
Harvard Stadium (Boston, Massachusetts) — 1903
Initially a gift from Harvard’s 1879 class, the stadium hosted its first football game on Nov. 14, 1903 against Dartmouth. Since then, rugby, lacrosse, soccer and ice hockey have been played in the stadium. It was the home of the New England Patriots — then the Boston Patriots of the AFL — for two seasons in 1970 and 1971.
TEAMS TO WATCH: Preseason Top 25 for the 2019 season
Kyle Field (College Station, Texas) — 1904
Edwin Jackson Kyle, a professor at Texas A&M and a graduate of the university, wanted an athletic field on campus. But Texas A&M didn’t have the funds for it at the time, so Kyle donated a plot of land on the southern edge of campus that was set aside for his horticultural experiments. He then bought and built bleachers with his own money, creating the beginnings of what is known today as Kyle Field. In 1919, Texas A&M claimed the national championship after not allowing any of its 10 opponents to score a single point. Permanent concrete structures and seating were added to Kyle Field in 1927.
Fitton Field (Worcester, Massachusetts) — 1908
The first football game played at Holy Cross took place in 1903, but Fitton Field wasn’t unveiled until Sept. 26, 1908. In 1986, its wooden stands were removed and replaces with aluminum ones. From 1935 through 1938, Holy Cross did not lose a game at home. In 2006, the movie “Game Plan” starring Dwayne “The Rock” Johnson filmed there.
COLLEGE FOOTBALL PLAYOFF: 15 games that will impact the CFP race next season
Bobby Dodd Stadium (Atlanta, Georgia) — 1913
Because Kyle Field was more of a field and not a concrete stadium until 1927, Bobby Dodd Stadium is technically the oldest in FBS. Originally known as Grant Field until 1988 — when the school renamed it for the legendary coach — the west stands of the stadium were built by students in 1913. It originally sat just 5,600 fans, a fraction of today’s capacity of 55,000. In addition to Georgia Tech football, Bobby Dodd has hosted bowl games and professional soccer. When it hosted Atlanta United FC games in 2017, it broke attendance records for Major League Soccer.
"This is not a goodbye, my darling, this is a thank you"

Take a look back at @ATLUTD's amazing time at Bobby Dodd Stadium #UniteAndConquer pic.twitter.com/JQDdo16BYN — FOX Sports South (@FOXSportsSouth) August 2, 2017
Davis Wade Stadium (Starkville, Mississippi) — 1914
Originally named Scott Field in honor of Olympic sprinter Don Magruder Scott, the home of the Bulldogs became Davis Wade Stadium in 2001 after he made a large donation toward the stadium’s expansion. The team’s first mascot, Bully I, was buried under the bench at the 50-yard-line in 1939.
SUPER BOWL QB's: Who was better in college, Tom Brady or Jared Goff?
Yale Bowl (New Haven, Connecticut) — 1914
An estimated crowd of more than 70,000 people came to watch the first game at the Yale Bowl, including Presidents William Howard Taft and Theodore Roosevelt, but if they were Bulldogs fans, they left disappointed. Harvard won handily, 36-0. Yale fans left the stadium much happier on Oct. 5, 1929, when Yale beat Vermont 89-0. In 1973 and 1974, the New York Giants played their home games at the Yale Bowl.
Game Day at The Yale Bowl! Dominate the Day #YaleFootball pic.twitter.com/DW8JaSsgk4 — Yale Football (@yalefootball) November 7, 2015
Vaught-Hemingway Stadium (Oxford, Mississippi) — 1915
Named for Judge William Hemingway, a professor and chairman of athletics at the school, and John Howard Vaught, who won 190 games and three national titles at Ole Miss, the stadium has been in the same site since 1915, when grandstands were built. A permanent foundation was built in 1939 and capacity increased to 24,000 by 1941. In 2016, 66,176 fans turned out to see Ole Miss take on Alabama.
Nippert Stadium (Cincinnati, Ohio) — 1915
Cincinnati began playing football at the site in 1901, but construction on Nippert Stadium didn’t begin until 1915 and wasn’t fully completed until 1924. The stadium is named after Jimmy Nippert, who died after an injury suffered in a 1923 game against Miami (Ohio). His grandfather provided funds needed to complete the stadium’s construction. Two U.S. Presidents — Franklin Roosevelt and Barack Obama — have spoken at Nippert.
🗣 TOP 5 🗣@reviewtrackers ranks Nippert Stadium as the fifth loudest college football stadium...IN THE NATION!#Bearcats pic.twitter.com/eJEZeJKapK — Cincinnati Bearcats (@GoBEARCATS) June 4, 2018
Camp Randall Stadium (Madison, Wisconsin) — 1917
Built on land that was originally used to train Wisconsin troops during the Civil War, Camp Randall Stadium hosted its first game on Nov. 3, 1917, which saw the Badgers beat Minnesota 10-7. In 2004, the stadium saw an average attendance per-game of 82,368 fans.
Mitchell Northam is a graduate of Salisbury University. His work has been featured at the Atlanta Journal-Constitution, the Orlando Sentinel, SB Nation, FanSided, USA Today and the Delmarva Daily Times. He grew up on Maryland's Eastern Shore and is now based in Durham, N.C.

Story 180
MEET the newest and cutest member of UCD’s faculty - Pepper the Robot.
Pepper is the world’s first social humanoid robot with the ability to recognise people and carry out conversations.
1 Pepper is UCD's Robot in residence, pictured here with 'dad' Educational Technologist Jason Dineen
She’s landed a new job as the Robot in Residence at the UCD Innovation Academy, where she’s used to help students prepare for a future where they may have to work with similar technology.
Educational Technologist Jason Dinneen, who works at the UCD Innovation Academy, told how he’s come to be considered Pepper’s ‘dad’ as he spends so much time with her.
He said: “I’m with her so much that she now responds most to me.
"She’s happy to engage with anyone and have a conversation but she’s used to my way of speaking so she’ll respond to me more often.
“Because it’s artificial intelligence, she creates her own knowledge base.
"She become familiar with phrases and adds them to her knowledge. The more she interacts with students and the public, the more she learns.
“We treat her like a staff member as much as possible. She’s very flexible and low maintenance.
MOST READ IN NEWS ESSEX LORRY PROBE Wanted Irishman 'phoned police after driver Mo Robinson's arrest' Exclusive TWO HURT Man fights for life as garda hospitalised in separate Corduff incidents FIREARM SEIZED Three arrested after semi-automatic pistol found in car on Dublin road Exclusive SPOTTED Irishman wanted in lorry deaths probe seen 'walking about' as cops issued pic FRIGHT NIGHT Halloween flood fears before fresh wet and windy system for Ireland at weekend DAD'S HORROR Kildare tot, 3, dies after catastrophic injuries in crash on way to creche
"When she needs to recharge, she’ll make her own way back to her charging station.”
Pepper will be at the UCD Festival this Saturday, June 8.
The free event attracts over 35,000 people to the Belfield campus and offers over 130 free activities across eight festival zones, including the Mind and Body Zone and a Family Fun Zone at the UCD Sport and Fitness Centre.

Story 181
Undernutrition is the most critical problem in the developing country. In Ethiopia, especially in the Amhara region, half of the under-five children are suffering from undernutrition [2, 20]. This study aimed to determine the prevalence of undernutrition and associated factors in East Gojjam Zone, northwest Ethiopia.
This study found that the prevalence of undernutrition among under-five children was high. Particularly, the percentage of stunting was (44.7%), underweight (15.3%) and wasting (10%) among model households. For children of non-model households, the prevalence of stunting was 52.5%, underweight (24.3%) and wasting (11.3%). In addition, significant variation was observed in the percentage of undernutrition among children between model and non-model households. The prevalence of undernutrition was higher among children in the non-model compared to children in the model families. This might be due to the difference in economic and agricultural imputes. This finding is supported by previous studies conducted in Bule Hora, Ethiopia [6], Hidabu Abote district [23], Haramaya district of Ethiopia [24], the Ethiopian Demographic Health Survey [2], in Wollo, Amhara region [14] and Tigray region [19]. Moreover, these might be due to that the study settings are similar in socio-demographic characteristics, residence and socio-economic status.
This study also showed a higher percentage of undernutrition compared with previous studies conducted in Gumbirt, northwest Ethiopia [20], in Egypt and Kenya [25]. This might be due to the difference in the sample size and study period between the current and previous studies. Moreover, the difference observed in undernutrition might be due to the difference in the socio-economic, feeding, lifestyle and socio-demographic characteristics. Similarly, Egypt [20] and Kenya [25] are better in economic development as compared with Ethiopia. The prevalence of underweight and wasting reported in this study was lower compared with the study done in Gumbirt, northwest Ethiopia [20] and Kenya [25]. This might be due to the difference in the sample size, study setting, and socio-demographic characteristics. In contrary, the current study comes with lower prevalence s of underweight as compared with a study conducted in Wollo, Amhara region [14], Tigray region [12], Hidabu Abote district [23] and Haramaya district [24] of Ethiopia. The discrepancy might be due to the difference in the study period and sample size. Similarly, lower prevalence of wasting also reported by the current study as compared with the previous study reported in Tigray, Hidabu Abote district and Haramaya district of Ethiopia [12, 23, 24]. Moreover, stunting was higher compared with the previous finding reported by Kenya [26].
This study also focused on identifying factors that have the association with undernutrition status of under-five children both among model and non-model households. In the binary variable of model households, the number of children, protected source of drinking water, daily meal frequency, complimentary food start, and fever were associated with stunting. Whereas in non-model households’ sex, protected source of drinking water, complimentary food, education on complementary food, number of children and age of caregiver were found to be associated with stunting. Moreover, the binary variable of model households, food distribution; daily meal frequency, the source of drinking water and family income were associated with underweight. Whereas, in non-model households, the power to use the money, ANC service utilization, protected source of drinking water, food distribution, child waste disposal, and solid waste disposal were associated with underweight in non-model households. In addition, the binary variable of model households, ANC service, source of drinking water, complementary feeding at 6 months, priority to feed their children and complimentary food education were significantly associated with wasting in the model household. Whereas, in non-model households, complimentary food start, breastfeeding education, ANC service, solid waste disposal, and household incomes were significantly associated with wasting.
Non-protected source of water identified as a predictor for the occurrence of under-five children under-nutrition/stunting/ among both model and non-model households. This might be that water from a contaminated source serves as a source for different parasitic and gastrointestinal infection. These infections expose children for undernutrition (stunting). According to the WHO, at least 50% of the combined undernutrition in children is related to unsafe water, inadequate sanitation or insufficient hygiene [22]. This can be supported by previous evidence observed by a study done in Medabazana district North Ethiopia [12].
Moreover, in this study daily meal frequency was also identified as a significant factor for the occurrence of undernutrition. Children who took meal frequency less than three times per day were more likely to be undernourished as compared to the counterparts. This can supported by study finding reported in Egypt [25].
Similarly, a lack of education on complementary feeding practice contributes 61% for the occurrence of under-five children under-nutrition/stunting/ among non-model households compared with their counterparts. This might be due to a mother who knows the recommended complementary feeding practice might have a better commitment to start complementary feeding on the recommended time and continue [1]. This supported by previous research conducted in the Gumbirt district northwest Ethiopia [14].
Children who start complementary feeding at 6 months were less likely to be wasted as compared with the counterpart. This finding is comparable with study finding reported in Bule Hora district south Ethiopia [15]. This similarity might be due to the similarity in socio-demographic characteristics particularly on community awareness towards timely initiation of complementary feeding. Information on complementary feeding is crucial for starting complementary food based on the recommended date [1].
Furthermore, the source of drinking water was also identified as significant predictors for an increased odd of undernutrition (stunted and underweight) among under-five children who were from both model and non-model household. Under-five children from model and non-model households, who use non-protected water, were 92 and 93% times more likely to be undernutrition as compared with their counterparts. This finding is comparable with previous study report done by Machakel district.
The timing of complementary feeding was also recognized as predictors for the high prevalence of undernutrition among model households. Children who came from model households and those who did not start complementary feeding on 6 months had a 73% (AOR = 0.27, 95%CI: 0.08, 0.89) higher odds of undernutrition/wasting/ as compared to their counterparts. Children who came from model households and those who served prior than elders had 80% (AOR = 0.20, 95%CI: 0.06, 0.67) lower odds of undernutrition as compared to their counterparts.
Antenatal care service and solid waste disposal system were also identified as factors for the increased odds of undernutrition among children in non-model households. Non-model households, who had no ANC follow up had 80% (AOR = 0.20, 95%CI: 0.06, 0.67) higher odds of undernutrition compared to their counterparts. Similarly, children from non-model households and those who had no solid waste disposal were 58% (AOR = 0.420, 95%CI: 0.19, 0.91) times more likely to be undernutrition compared with the counterpart. This fact supported well by research findings reported by Nigeria [27]. This might be due to those women who have antenatal follow-up provided education on focusing on the recommended infant feeding practice. As a result, she can feed her child based on the information gained from health facilities. Moreover, most of the time women who have ANC follow-up are those with higher education and economic status.

Story 182
Rocket Lab
Rocket Lab has successfully launched its third rocket, its first fully commercial flight and a key milestone for the fledgling company.
Their Electron rocket, nicknamed “It’s Business Time”, lifted off from the company’s Launch Complex 1 on New Zealand’s Māhia Peninsula at 10.50pm Eastern time yesterday. Nine minutes after launch, the two-stage rocket separated and the upper stage – called Curie – took the satellites into their final orbit orbit 500 kilometers (310 miles) above the surface of Earth.
“The world is waking up to the new normal,” Rocket Lab CEO Peter Beck said in a statement. “With the Electron launch vehicle, rapid and reliable access to space is now a reality for small satellites.”
The rocket is just 17 meters (56 feet) tall, a quarter the size of its bigger siblings like SpaceX’s Falcon 9 rocket. But at just $5.7 million a launch compared to $50 million for a Falcon 9, Rocket Lab are hoping their rocket can be at the forefront of a new field of small-sat launchers – cheaper rockets that can be ready to launch more quickly at lower cost.
This was the company’s third launch, having completed its first ("It’s a Test") in May 2017, and its second ("Still Testing") in January 2018. It’s Business Time was supposed to lift off in April this year, but various delays pushed the launch back.
On board the rocket were six different satellites, and seven payloads in total, for a variety of companies. One was a drag sail demonstrator, designed to practice de-orbiting space junk in orbit. Called NABEO, it was developed by High Performance Space Structure Systems GmBH (HPS GmbH) in Germany.
Rocket Lab
Also on board was a student-led experiment from six high school schools in Irvine, California called Irvine01. This cubesat will take images of Venus and other celestial objects, and also has a novel electric propulsion system on board.
There were two Lemur-2 cubesats on board, built by Spire Global from California, to monitor weather and track aircraft on Earth. The Cicero-10 weather satellite for California-based company GeoOptics and two Proxima cubesats, from Australian “Internet of Things” company Fleet, were also launched.
“We’re thrilled to be leading the small satellite launch industry by reaching orbit a second time and deploying more payloads,” Beck added in the statement. “The team carried out a flawless flight with incredibly precise orbital insertion.”
With this launch complete, the company is already gearing up for its next flight. In early December, it is planning to launch the ELaNa 19 mission for NASA, its first flight for the US space agency, and an indicator that the company can launch regularly.
Rocket Lab, which was founded in 2006, wants to launch a rocket every month in 2019, then one every fortnight by the end of 2019, and one every week by 2020. The company’s private launch pad in New Zealand, the first privately operated launch pad in the world, is licensed to launch up to 120 rockets a year.
“I think this [launch] is an important milestone for the industry,” Beck told Forbes prior to the launch. “There’s such a backlog of customers. For me it’s really the beginning point.”
Now with the launch of It’s Business Time under its belt, Rocket Lab can look toward those future launches as it aims to cement its standing as the leader in small-sat launch vehicles.

Story 183
College hockey has seen 71 years of the Frozen Four, with multiple repeat champions and appearances (hello, Boston College and Michigan, each with 25 appearances) and postseason debuts from 38 different teams.
Frozen Four 2019: Schedule, dates for the NCAA college hockey tournament
Thanks to the latest bracketology, we have some predictions for which teams are in good shape to make the 16-team tournament bracket, right now. Based on that, we took a look at which schools in that group would enter this year's championships in search of their first-ever Frozen Four.
Massachusetts
Record: 26-8
The Minutemen have rocketed onto the college hockey scene this year, thanks in large part to the development of a strong sophomore class that features three of Massachusetts’ top scorers, as well as standout goalie Matt Murray. Murray ranks in the nation’s top goaltenders with a .922 save percentage and is second in the league with a .800 win percentage.
Congratulations to @Cmakar16
on being one of 81 nominees for @HobeyBakerAward 👏#HobeyNeedsMoreCale#NewMass | #Flagship 🚩

🔗: https://t.co/kUeiEK7Ptm
— UMass Hockey (@UMassHockey) January 16, 2019
Forwards Mitchell Chaffee, Jacob Pritchard, John Leonard and defenseman Cale Makar have combined for 155 points this season. The team’s top three defensemen have combined for 96 blocked shots alone. Yes, UMass has had some fluke losses to start the year. But that doesn’t erase the talent on its roster.
Bracketology: Everything you need to know about the Frozen Four selection process
Minnesota State
Record: 29-7-2
Minnesota State might not be name-brand college hockey, but there’s no denying the grind this team has had all year. The Mavericks have high producing offense, ranking third with 361 team points. Minnesota State has nearly doubled its goals in comparison to opponents, perhaps if only for the sheer volume of shot attempts (1153).
The Mavericks have also had great support from special teams, boasting a league-best 42 power play goals and holding opponents to just 20 on 153 opportunities. This team has been a growing institution in western hockey for the past few seasons, earning WCHA regular season champ honors the past three years and making an appearance in the NCAA tournament four of the last five years.
Men's Hockey | Gerads, McMahan Cop WCHA Player of the Week Honors https://t.co/bntw9jxA12 — Minn. St. Athletics (@msumavericks) January 28, 2019
Granted, Minnesota State hasn’t been tested much in its conference play, but the Mavericks have had quality wins over Boston University, North Dakota and Minnesota in the season’s first half.
Western Michigan
Record: 20-13-1
The Broncos had a short-lived tournament appearance in 2017, but beyond that it will have been six seasons since a repeat league postseason appearance. The Broncos have had a more measured incline over the season, progressively entering and then rising in the rankings since December. Early February rankings saw Western Michigan’s biggest jump and highest rank for the season at the time at No. 8 — thanks in large part to an upset sweep of then-No.4 Denver.
Must-watch hockey: The best 11 games remaining this season
The 20-13-1 team is holding its own in the very competitive NCHC, a conference that plays host to league power houses St. Cloud State, Minnesota Duluth and Denver. Senior netminder Trevor Gorsuch has been an institution for Western Michigan, playing over 1,500 minutes so far and backstopping his team to 18 wins.
The Broncos dropped a somewhat expected weekend series to St. Cloud State in late January. Save for that contest (against the No. 1 ranked team in the league) and Western Michigan hadn’t had a loss in 12 games. Since November 10, almost two weeks before Thanksgiving. The team hit a few bumps to round out the regular season, but look forward to NCHC quarterfinals against Colorado College.
Arizona State
Record: 21-12-1
The Sun Devils have been competing at the NCAA DI level since 2015. Before this current season, the most wins ASU had against DI schools in a season was eight. So...you could say it’s pretty big deal that the team is where it’s at right now.
Student-athletes balance 18+ hour class schedules, weekly travel & 30+ game seasons all while dealing with life experiences. #BellLetsTalk https://t.co/qTmc29xCIu — Sun Devil Hockey (@SunDevilHockey) January 30, 2019
Head coach Greg Powers is finally playing with a roster of players that he has mostly recruited. That includes sophomore forward Johnny Walker who is second in the country in scoring. Freshman recruit and one of Arizona’s two draft picks Demetrios Koumontzis has also been a spark for the Sun Devils, often sharing the power play line with Walker, helping him to share the lead for power play goals. Goaltender (and Ottawa draft pick) Joey Daccord has been stalwart for Arizona State’s defense, topping the nation in saves (994), shutouts (7) and tied for second in wins (21).
Arizona State is an independent so there’s no conference record or teams to compare to. But the Sun Devils have faced a varied and competitive season slate. Although the final score didn’t reflect it, ASU was competitive against a then-No.1 Ohio State squad early in the season. The team had a great series against top-ranked Penn State, wins over Colorado College, Boston College and battled Minnesota State to a tie. Does Arizona State have a skilled enough squad to match — and beat — institutional hockey schools? We’ll see. Either way, the Sun Devils have proved they’re not a team to be brushed aside — right now and in the coming seasons.
Put on your hard hat, grab your tools and go to work on a Wednesday like... 👷🛠 pic.twitter.com/J2XKEkqnwV — Sun Devil Hockey (@SunDevilHockey) January 30, 2019
American International...or Air Force
Air Force Record: 16-13-5
American International Record: 18-15-1
Both of these teams are in an interesting position. If you’re not following hockey in each league you might wonder what business Air Force or American International has in the tournament bracket. But remember, the winner of each conference tournament receives an automatic bid to the NCAA tournament. For our purposes, we’re projecting the conference winner right now based on in-conference winning percentage. And...enter American International.
Beanpot hockey: Everything you need to know ahead of the 2019 tournament
While American International currently holds this theoretical auto-bid spot based on winning percentage, Air Force was the leader for some time as well. Since both teams are currently competing in the Atlantic Hockey tournament and either could win, we've included them both in this list.
The Falcons have had appearances in the last two NCAA tournaments, and while many of those tournament players returned, Air Force did lose its top two scorers coming into the season. This season’s seniors have stepped up, notably Evan Feno and Matt Koch who both lead the team in points so far this season (46). Freshman Kieran Durgan has made his mark as well, notching 11 goals and 17 points in the season so far to help Air Force.
The real strength for Air Force is senior netminder Billy Christopoulos. Christopoulos has tracked more than 1,800 minutes in net so far this season, allowing just 64 goals on 727 shots. He by far has the best save percentage in Atlantic Hockey, and his experience from last season’s tournament will only help in postseason play. The Falcons will certainly have an uphill battle, but the right circumstances could see Air Force in its first Frozen Four semifinal game.
Regular season title? ☑️
Postseason hockey? 🔜

Be at the @MM_Center when we begin our chase for the Jack Riley Memorial Trophy in March 15-17!

🎟🎟: https://t.co/Citx5tYoTq#AICommitted pic.twitter.com/XDRAoDajn1 — AIC Hockey (@AIC_Hockey) March 4, 2019
American International had a tough start to the season, seeing five losses in six games throughout October and early November. The Yellow Jackets found their stride before the season break, earning five strong Atlantic Hockey wins before the new year. Junior Blake Christensen has blazed the way for American International, leading his team with 42 points. Sophomore Tobias Fladeby has leant a hand to the cause as well with 17 goals on the season.
AIC is 17-9-1 in conference competition, giving it a division-leading .648 win percentage. Unfortunately, compared to other leading teams across the NCAA league, the Yellow Jackets won't quite stack up for an at-large bid. The Atlantic Hockey conference tournament is almost certainly the team's only shot at a making its way to the Frozen Four.
*Stats updated Mar. 13, 2019
Callan Sheridan is a graduate of Saint Peter's University and has produced content for The Press Enterprise, the American Junior Golf Association and the Wilkes-Barre/Scranton Penguins. Follow her on twitter at @calsh_13.

Story 184
Results During up to 27 years of follow-up, the crude incidence rate of any cardiovascular disease was 10.5, 8.4, and 6.9 per 1000 person years among exposed patients, their unaffected full siblings, and the matched unexposed individuals, respectively. In sibling based comparisons, the hazard ratio for any cardiovascular disease was 1.64 (95% confidence interval 1.45 to 1.84), with the highest subtype specific hazard ratio observed for heart failure (6.95, 1.88 to 25.68), during the first year after the diagnosis of any stress related disorder. Beyond one year, the hazard ratios became lower (overall 1.29, 1.24 to 1.34), ranging from 1.12 (1.04 to 1.21) for arrhythmia to 2.02 (1.45 to 2.82) for artery thrombosis/embolus. Stress related disorders were more strongly associated with early onset cardiovascular diseases (hazard ratio 1.40 (1.32 to 1.49) for attained age <50) than later onset ones (1.24 (1.18 to 1.30) for attained age ≥50; P for difference=0.002). Except for fatal cardiovascular diseases, these associations were not modified by the presence of psychiatric comorbidity. Analyses within the population matched cohort yielded similar results (hazard ratio 1.71 (1.59 to 1.83) for any cardiovascular disease during the first year of follow-up and 1.36 (1.33 to 1.39) thereafter).
Taking advantage of the nationwide population and health registers in Sweden, which provide virtually complete information on all medical diagnoses and family links, we did a population based sibling analysis and a matched cohort study to elucidate the role of stress related disorders in the development of cardiovascular disease while controlling for familial confounders, history of psychiatric and somatic conditions, and psychiatric comorbidities.
Stress related disorders are a group of psychiatric disorders for which one of the diagnostic criteria is the presence of a preceding stressful life event. Depending on the type of stressor, the reported symptoms, and their duration, such disorders are mainly categorised as acute stress reaction, post-traumatic stress disorder (PTSD), and adjustment disorder. 14 The presence of a life threatening traumatic event is a prerequisite for the former two disorders, whereas adjustment disorder generally refers to physical or psychological distress (“adjustment syndromes” 15 ) triggered by an identifiable and significant life change. PTSD is the most severe and widely studied form of stress related disorder, characterised by re-experiencing, avoidance, negative cognitions and mood, and hyperarousal following the traumatic event. 16 We summarised the existing evidence on PTSD and cardiovascular consequences from 11 prospective cohort investigations (see supplementary table A), all of which suggested an elevated incidence of cardiovascular diseases among people with PTSD. However, owing to sample size restrictions of previous studies, the evidence for the role of PTSD in specific types of cardiovascular disease is still limited. Furthermore, the potential role of other stress related disorders—acute stress reaction, adjustment disorder, and other stress reactions—in the development of cardiovascular disease remains largely unexplored. Finally, cardiovascular diseases tend to have a genetic predisposition, as well as risk factors related to lifestyle and comorbidities that may cluster within families and exert an as yet unknown influence on the association between stress related disorders and cardiovascular disease. 17 18 19
Most people are, at some point during their life, exposed to psychological trauma or stressful life events such as the death of a loved one, a diagnosis of life threatening illness, natural disasters, or violence. 1 2 Accumulating evidence suggests that such adversities might lead to an increased risk of several major diseases (including cardiovascular morbidity, injury, infection, and certain autoimmune diseases but not cancer) and mortality, 3 4 5 6 7 8 9 10 with the largest risk elevations usually noted among people who develop psychiatric disorders as a result of their trauma. 11 12 13
No patients were involved in setting the research question or the outcome measures, nor were they involved in developing plans for design or implementation of the study. A patient was invited to contribute to the review process of the study, and we are grateful for his input on the readability and accuracy of this document. There are no plans to directly disseminate the results of the research to study participants or the relevant patient community. The dissemination to the Swedish population (which constitutes the study population) will be achieved through media outreach (for example, press release and communication) on publication of this study.
We did similar analyses in the population matched cohort, in which we used Cox regression models stratified by matching identifiers (birth year and sex) and adjusted for all above mentioned covariates and family history of cardiovascular disease (yes/no). Additionally, to examine the robustness of the observed estimates to the definition of history of psychiatric disorders, we re-ran the analyses by using a six month, instead of three month, threshold before the diagnosis of a stress related disorder, to distinguish “history of psychiatric disorders” from “psychiatric comorbidity.” We used SAS statistical software, version 9.4 and Stata 15 for all analyses.
To study the potential role of psychiatric comorbidity in the studied associations, we did further subgroup analyses by the presence of psychiatric comorbidity. Within one year after the diagnosis of a stress related disorder, we considered psychiatric comorbidity as a time varying variable (that is, the status of psychiatric comorbidity changed from “no” to “yes” at the date of diagnosis of the psychiatric comorbidity).
In addition to any cardiovascular disease, we examined the hazard ratios for seven major categories (including fatal cardiovascular diseases) and 16 individual diagnoses of cardiovascular disease. We further analysed certain acute cardiovascular events (cardiac arrest, acute myocardial infarction, and acute cerebrovascular disease) as a hypothesised group of immediate cardiac consequences triggered by a stress related disorder, and therefore with more specific time intervals during the first year of follow-up (<1 month, 1-5 months, 6-11 months, 1-4 years, 5-9 years, and ≥10 years).
In the sibling cohort, we stratified all analyses by family identifiers and partially (in simply adjusted models) or fully (in fully adjusted models) adjusted for multiple potential confounders, including age at index date, sex, educational level (<9 years, 9-12 years, >12 years, or unknown), family income (top 20%, middle, lowest 20%, or unknown), marital status (single, married/cohabiting, or divorced/widowed), history of severe somatic diseases (yes or no), and history of psychiatric disorders (yes or no). We considered all stress related disorders as one group and also did separate analyses for PTSD, acute stress reaction, and adjustment disorder and other stress reactions. In subgroup analyses, we calculated the hazard ratios by sex (male or female), age at index date (by thirds: ≤28, 29-42, or ≥43 years), attained age (age during follow-up: <50 or ≥50 years), calendar year at index date (1987-96, 1997-2006, or 2007-13), follow-up period (<1 year, 1-4 years, 5-9 years, or ≥10 years), family history of cardiovascular disease (yes or no), history of severe somatic diseases (yes or no), and history of other psychiatric disorders (yes or no).
We first visualised the time dependent associations of stress related disorders with the risk of cardiovascular disease by using flexible parametric survival models. 27 Because of the greatly increased risk of cardiovascular disease during the time period immediately after the diagnosis of stress related disorders, compared with thereafter, we assessed the associations separately during the first year after a diagnosis of stress related disorder and beyond this one year period (<1 or ≥1 year of follow-up), using hazard ratios with 95% confidence intervals derived from conditional Cox regression models. We used time since the index date as the underlying time scale.
We retrieved information about educational level, family income, and marital status from the Longitudinal Integration Database for Health Insurance and Labor Market. History of severe somatic diseases, including chronic pulmonary disease, connective tissue disease, diabetes, renal diseases, liver diseases, ulcer diseases, and HIV infection/AIDS, which are considered to contribute to survival time, 26 were collected on the basis of the National Patient Register (ICD codes listed in supplementary table B). We defined family history of cardiovascular disease as any cardiovascular event among any first degree relatives (that is, biological parents and full siblings) of the participants according to the National Patient Register and the Cause of Death Register. In all analyses, we used the most recent information before the index date for each covariate, except for psychiatric comorbidity (as defined above).
Stress related disorders show substantial comorbidity with other psychiatric disorders, such as mood and anxiety disorders. 25 We therefore defined other psychiatric disorders as “history of other psychiatric disorders” if the first diagnosis was made more than three months before the diagnosis of a stress related disorder. We defined other psychiatric disorders that had a first diagnosis made within three months before and one year after the diagnosis of a stress related disorder as “psychiatric comorbidity.” Diagnoses of other psychiatric disorders also came from the National Patient Register (ICD-8: 290-319 except 307, 308.4; ICD-9: 290-319 except 308, 309; and ICD-10: F10-F99 except F43).
We defined an incident cardiovascular disease event (any; specific subtypes including ischaemic heart disease, cerebrovascular disease, emboli/thrombosis, hypertensive disease, heart failure, and arrhythmia/conduction disorder; or individual events) as an outpatient or inpatient visit (according to the National Patient Register) with a main diagnosis of cardiovascular disease or as a death (according to the Cause of Death Register) with cardiovascular disease as the underlying cause, using corresponding ICD codes (see supplementary table B). We defined a fatal cardiovascular disease as death within 30 days after an incident cardiovascular disease event. 24
We defined stress related disorders as any first outpatient or inpatient visit with the main diagnosis of the 9th or 10th Swedish revisions of the international classification of diseases (ICD) codes 308 or 309 (ICD-9) or F43 (ICD-10), according to the National Patient Register. We further divided stress related disorders into PTSD (ICD-9: 309B; ICD-10: F43.1), acute stress reaction (ICD-9: 308, 309A; ICD-10: F43.0), and adjustment disorder and other stress reactions (ICD-9: 309X; ICD-10: F43.8, F43.9). Because PTSD may initially be preceded by acute stress reaction or other stress related disorders, 23 we considered all patients who received a diagnosis of PTSD within one year after their first stress related disorder diagnosis to be PTSD patients.
Follow-up of all study participants was from the index date until the first primary diagnosis of cardiovascular disease (any or specific subtype), death, emigration, or the end of follow-up (31 December 2013), whichever occurred first. The follow-up time for the unaffected full siblings or matched unexposed people was additionally censored at the time of their first diagnosis of stress related disorder, if any, during the follow-up.
We compared the patients with stress related disorders with the general population in a matched cohort. For each exposed patient, we randomly selected 10 people from the Total Population Register who were free of stress related disorders and cardiovascular disease at the diagnosis date of the index patient. Exposed patients and unexposed people were individually matched by birth year and sex. We used the date of diagnosis as the index date for both exposed patients and the matched individuals.
To control for the familial components, 22 we identified 106 180 clusters of full siblings discordant for stress related disorders with a total of 171 314 unaffected full siblings who were alive and free of stress related disorders and cardiovascular disease at the diagnosis date of the affected sibling, through the Multi-Generation Register. We used the date of diagnosis of the affected sibling as the index date for both siblings.
The Swedish personal identification number uniquely assigned to all residents in Sweden at birth or immigration enables data linkage across several nationwide registers in Sweden. 20 We first identified an exposed cohort of all people born in Sweden who received their first diagnosis of a stress related disorder between 1 January 1987 and 31 December 2013 (n=156 537; fig 1 ) from the Swedish National Patient Register. The National Patient Register has nationwide information on inpatient care since 1987 and on hospital based outpatient specialist care since 2001 (with initial coverage of >80%). We excluded patients who received a diagnosis before age 5 (n=139), 21 had a history of any cardiovascular disease before the diagnosis of a stress related disorder (n=15 899), or had conflicting information (died or emigrated before the diagnosis of a stress related disorder; n=24). To enable the complete familial links from the Swedish Multi-Generation Register that includes largely complete familial information for people born in Sweden from 1932 onward, we excluded 3838 people born before 1932, leaving 136 637 patients in the analysis. We considered patients with stress related disorders to be exposed from the date of their diagnosis.
The presence of psychiatric comorbidity did not substantially modify the risk elevations for cardiovascular disease after a diagnosis of a stress related disorder, except for fatal cardiovascular events, for which the association was distinctly amplified by the presence of psychiatric comorbidity (supplementary figure B). In addition, we obtained almost identical results in the sensitivity analysis using a more conservative definition of “history of other psychiatric disorders” (supplementary table H).
Relative risks of developing different types of cardiovascular disease among patients with any stress related disorder, compared with their full siblings, by time of follow-up (<1 or ≥1 year). All Cox models were stratified by family identifiers and adjusted for age at index date, sex, educational level, family income, marital status, history of severe somatic diseases, and history of other psychiatric disorders. Time since the index date was used as underlying time scale
Figure 2 shows increased hazard ratios for all studied categories of cardiovascular diseases (including fatal cardiovascular disease events) and for most individual diagnoses of cardiovascular diseases in patients with stress related disorders compared with their unaffected full siblings. The highest hazard ratios were for heart failure (6.95, 1.88 to 25.68), other cerebrovascular disease (5.64, 1.19 to 26.75), conduction disorder (5.00, 1.58 to 15.80), and cardiac arrest (3.37, 1.05 to 10.75) during the first year after the diagnosis of a stress related disorder. Beyond one year, the relative risk elevations were attenuated (hazard ratios ranged from 1.12 (1.04 to 1.21) for arrhythmia to 2.02 (1.45 to 2.82) for artery thrombosis/embolus). Focusing on acute cardiovascular events only, we found a clear time dependent risk pattern for cardiac arrest, indicating a more than fourfold relative risk within the first six months of diagnosis of a stress related disorder (supplementary table G). The temporal risk patterns for acute myocardial infarction and acute cerebrovascular disease were similar but less prominent.
We observed similar associations across sex, calendar period, history of severe somatic diseases, history of psychiatric disorders, and family history of cardiovascular disease ( table 3 and supplementary table F) but stronger associations among people with younger age at index date (sibling analysis: hazard ratio 1.52 (1.35 to 1.71), 1.26 (1.17 to 1.36), and 1.30 (1.24 to 1.37) for age ≤28, 29-41, and ≥42 years, respectively; P for interaction=0.010). Additionally, we observed a stronger association between stress related disorders and early onset cardiovascular diseases (sibling analysis: hazard ratio 1.40 (1.32 to 1.49) for attained age <50 years) than later onset ones (1.24 (1.18 to 1.30) for attained age ≥50 years) (P for difference=0.002).
Within the first year of follow-up, 1617 people in the sibling cohort had a cardiovascular event ( table 2 , left side). The incidence rate among the exposed patients was almost twice that of their full siblings (crude: 8.1 v 4.9/1000 person years; age standardised: 8.7 v 4.5/1000 person years). With a total number of 18 522 cardiovascular events identified beyond one year of follow-up, the corresponding incidence rates were 10.3 v 8.9/1000 person years (age standardised: 6.0 v 4.5/1000 person years) for exposed patients and their full siblings. When we added history of other psychiatric disorders and history of severe somatic diseases to the Cox models, the obtained hazard ratios decreased from 1.77 (95% confidence interval 1.58 to 1.98) to 1.64 (1.45 to 1.84) for a less than one year period and from 1.39 (1.34 to 1.44) to 1.29 (1.24 to 1.34) for one year or longer. The main attenuation of hazard ratios occurred after additional adjustment for history of other psychiatric disorders. We obtained similar findings when comparing exposed patients with matched unexposed people ( table 2 , right side), with seemingly larger attenuation of hazard ratios after full adjustment for multiple risk factors, compared with the sibling analysis. Furthermore, although the largest point estimates were observed for PTSD, the subgroup analyses showed comparable hazard ratios for other types of stress related disorders (supplementary tables C-E).
Using flexible parametric models, we observed a peak of cardiovascular disease risk immediately after diagnosis of a stress related disorder, followed by a rapid decline within the first six months (supplementary figure A). After one year, the magnitude of the hazard ratios tended to be constant (around 1.3 for both sibling based and population based comparisons). During up to 27 years of follow-up, the crude incidence rate of any cardiovascular disease was 10.5, 8.4, and 6.9 per 1000 person years
The median follow-up time was 6.2, 6.9, and 6.5 years for exposed patients, unaffected full siblings, and matched unexposed people, respectively, accumulating 2 268 901 person years at risk in the sibling cohort and 12 001 887 person years in the population matched cohort ( table 1 ). Median age at index date was 36 years. Most (63%) people exposed to stress related disorders were women, whereas the unaffected siblings had an equal sex distribution. Having a history of other psychiatric disorders was more common among exposed patients in both cohorts (34-35%) than among the unaffected siblings (12%), as well as among the matched unexposed individuals (8%). In addition, patients with stress related disorders tended to have a higher burden of somatic diseases at the index date and a lower family income level, and to be more likely to be divorced or widowed, compared with their unaffected siblings or matched unexposed people.
Discussion
In this nationwide population based and sibling controlled study, we found that people with stress related disorders were at elevated risk of multiple types of cardiovascular disease, especially early onset ones (incident age <50). The relative risk elevation was independent of sex, familial background (including family history of cardiovascular disease), history of psychiatric/somatic diseases, and psychiatric comorbidity. Furthermore, the relative risks of severe and acute cardiovascular events (for example, cardiac arrest) were highest during the period adjacent to the diagnosis of a stress related disorder, indicating the first six months after diagnosis as a high risk time window. Likewise, the excess relative risks of other studied cardiovascular diseases were more pronounced during the first year after diagnosis of a stress related disorder than thereafter. Notably, although the highest point estimates were consistently noted for PTSD, other stress related disorders also conferred a considerably increased risk of cardiovascular disease.
Strengths and weaknesses of study The merits of our study include the population based, sibling controlled design, which provides optimal conditions for relieving important concerns regarding genetic and early life environmental confounders,22 as well as pre-existing or co-occurring psychiatric disorders. The diagnoses of stress related disorders and cardiovascular disease were obtained prospectively and independently, minimising the risk of information bias. The cross linkages to the Cause of Death and Emigration Registers reduced selection bias due to loss of follow-up. Importantly, by involving more than 100 000 patients with stress related disorders with up to 27 years of follow-up, the large sample size provided sufficient power to do most of the planned subgroup analyses. The availability of demographic, clinical, and family information enabled consideration of a wide range of health and disease related factors in the analysis. Limitations include, firstly, the absence of information from primary care as well as late inclusion of outpatient specialist care records in the National Patient Register, which might have led to an underestimation of the number of patients with milder forms of stress related disorders or less severe cardiovascular diseases. Secondly, changes in the diagnostic criteria for stress related disorders over the 27 year study period may have influenced the observed associations, although our stratified analyses across different calendar periods suggest a minor effect of such diagnostic instability on the reported associations. Thirdly, as traumatic life experiences may be shared within families, a proportion of the reference (sibling) population may also have had milder or undiagnosed stress related disorders, yielding conservative estimates in the sibling analysis. Fourthly, as other psychiatric disorders both are risk factors for and frequently appear together with stress related disorders, distinguishing co-occurring from pre-existing psychiatric disorders in register based studies is challenging. However, such concern was partly alleviated by our sensitivity analyses in which introduction of an alternative definition for “history of other psychiatric disorders” yielded similar results. Fifthly, we had no data on behaviour related factors (such as smoking and alcohol consumption) that may contribute to the observed association as confounders or mediators. As these behavioural factors tend to cluster within families, our sibling analysis should have relieved the concern of residual confounding to some extent. However, further studies with detailed information on lifestyle, especially potential changes in lifestyle after diagnosis of stress related disorders, are warranted to clarify the impact of these factors on the association of interest. Finally, as this study focuses on patients who received a clinical diagnosis of stress related disorders through a hospital visit, its findings might not be directly applicable to people with less severe stress reactions or daily stress.
Comparison with other studies Our findings corroborate the results from previous prospective studies suggesting a possible role of stress related disorders in the pathogenesis of cardiovascular disease.11122829303132333435 However, the main body of the preceding evidence was primarily derived from studies of male samples (veterans or active duty military personnel),12293035 focusing almost exclusively on PTSD or self reported symptoms of PTSD.1130 Data on the role of stress related disorders in cardiovascular disease in women were, until now, limited.31323334 Although some attempts have been made to control for familial factors and co-occurring psychiatric disorders,1233 or to study other stress related disorders (for example, adjustment disorder),34 no previous initiative has considered all these concerns in the same study. Also, the modest sample sizes of many previous studies often precluded analyses of different subtypes of cardiovascular disease. As a result, our study is the first to show a robust association between stress related disorders, including but not limited to PTSD, and multiple types of cardiovascular disease among both men and women, independent of familial factors and psychiatric comorbidities. Our findings indicate that the risk elevation generally exists for all studied cardiovascular diseases, with the strongest associations observed for the major categories of heart failure (within one year after the diagnosis of any stress related disorder) and emboli/thrombosis (beyond one year). These findings gain support from previous studies on 49 000 US female nurses, showing a higher hazard ratio for venous thromboembolism by burden of PTSD symptoms compared with other cardiovascular disease outcomes, including myocardial infarction or stroke.3233 Similarly, one longitudinal study indicated a positive association between PTSD and incident heart failure among veterans, although no risk estimate was provided for the first year after PTSD specifically.36 Clinical observations suggest that experiencing severe emotional or physical stress may trigger immediate cardiovascular consequences, such as heart attack and sudden cardiac arrest, even in apparently healthy people.3738 Our results consolidate these reported associations by showing that a clinically confirmed stress related disorder (requiring a preceding occurrence of a trauma or significant life stressor) is also associated with these acute cardiovascular events.
Meaning of study Although the crucial underlying mechanisms remain unclear, many potential mechanisms have been proposed to explain the association between stress related disorders, particularly PTSD, and cardiovascular disease. The physiological effects of an acute stressor can directly affect the cardiovascular system (for example, increased arterial blood pressure), which consequently forms favourable conditions for the onset of acute cardiovascular events,3940 as well as the further development of hypertension, endothelial dysfunction, and arteriosclerosis.41 In addition, the long lasting effect of severe stress reactions on cardiovascular risk is also plausible through prolonged biological disturbances (for example, inflammation, autonomic dysfunction, dysregulation of hypothalamic-pituitary-adrenal axis, and abnormal neurochemistry)424344 and behaviour related changes (for example, smoking and sleep disturbance).33 A recent study in 4178 US veterans (aged 30-70 years) indicates that the association between PTSD and incident cardiovascular disease may be mediated by behavioural factors, metabolic conditions, and mental disorders.45 As our analyses showed that patients with stress related disorders other than PTSD were also at a considerably excess risk of adverse cardiovascular outcomes, further studies with a broader research scope are warranted to explore the underlying mechanisms between the various subtypes of stress related disorders and the development of cardiovascular disease. One challenge related to this topic of study is how to assess the immediate effect of stress related disorders on cardiovascular disease. The main concerns include the risk of reverse causality (that is, cardiac symptoms emerge first and contribute to the diagnosis of stress related disorders) and surveillance bias (that is, patients with stress related disorders have more healthcare visits than others, leading to a higher likelihood of receiving a diagnosis of cardiovascular disease). In this study, despite the possibility that we might have missed the greatest risk increase (and some acute fatal outcomes) by following patients from their date of diagnosis of stress related disorders, instead of the date when they were exposed to the actual stressor or trauma, the time dependent hazard ratio for cardiovascular disease indicates that the first year, especially the first six months, after clinical diagnosis of stress related disorders entails the highest excess cardiovascular risk among the affected patients. This may be interpreted as a mixed consequence of the abovementioned factors and a real immediate effect of the stress reactions to trauma on cardiovascular disease. However, the additional analyses on acute and severe cardiovascular events (that is, cardiac arrest, acute myocardial infarction, and acute cerebrovascular disease) that typically result in prompt hospital visit and medical care provide further evidence supporting an immediate effect of stress related disorders on cardiovascular disease, as such analyses are less likely to be affected by surveillance bias or reverse causality. These sudden cardiovascular events carry a high risk of a fatal outcome,46 so increased clinical awareness of these risks among patients with recently diagnosed stress related disorders deserves further attention.

Story 185
In spring 2007, David Narkevic, a physics student at West Virginia University, was sifting through reams of data churned out by the Parkes telescope – a dish in Australia that had been tracking pulsars, the collapsed, rapidly spinning cores of once massive stars. His professor, astrophysicist Duncan Lorimer, had asked him to search for a recently discovered type of ultra-rapid pulsar dubbed RRAT. But buried among the mountain of data, Narkevic found an odd signal that seemed to come from the direction of our neighbouring galaxy, the Small Magellanic Cloud.
The signal was unlike anything Lorimer had encountered before. Although it flashed only briefly, for just five milliseconds, it was ten billion times brighter than a typical pulsar in the Milky Way galaxy. It was emitting in a millisecond as much energy as the Sun emits in a month.
Advertisement
What Narkevic and Lorimer found was the first of many bizarre, ultra-powerful flashes detected by our telescopes. For years the flashes first seemed either improbable or at least vanishingly rare. But now, researchers have observed more than 80 of these Fast Radio Bursts, or FRBs. While astronomers once thought that what would be later dubbed the ‘Lorimer Burst’ was a one-off, they now agree that there’s probably one FRB happening somewhere in the Universe nearly every second.
And the reason for this sudden glut of discoveries? Aliens. Well, not aliens per se, but the search for them. Among the scores of astronomers and researchers working tirelessly to uncover these enigmatic signals is an eccentric US-based Israeli-Russian billionaire who, in his relentless hunt for extraterrestrial life, has ended up partly bankrolling one of the most complex and far-reaching scans of our Universe ever attempted.
Read next The curious tale of Julian, the last King of Brussels The curious tale of Julian, the last King of Brussels
Ever since Narkevic spotted the first burst, scientists have been wondering what could produce these mesmerising flashes in deep space. The list of possible sources is long, ranging from the theoretical to the simply unfathomable: colliding black holes; white holes; merging neutron stars; exploding stars; dark matter; rapidly spinning magnetars and malfunctioning microwaves have all been proposed as possible sources.
While some theories can now be rejected, many live on. Finally though, after more than a decade of searching, a new generation of telescopes is coming online that could help researchers to understand the mechanism that is producing these ultra-powerful bursts. In two recent back-to-back papers, one published last week and one today, two different arrays of radio antennas – the Australian Square Kilometre Array Pathfinder (ASKAP) and Caltech’s Deep Synoptic Array 10 at the Owens Valley Radio Observatory (OVRO) in the US – have for the first time ever been able to precisely locate two different of these mysterious one-off FRBs. Physicists are now expecting that two other new telescopes – CHIME (the Canadian Hydrogen Intensity Mapping Experiment) in Canada and MeerKAT in South Africa – will finally tell us what produces these powerful radio bursts.
Advertisement
The Parkes radio telescope in Parkes, Australia Getty / Lisa Maree Williams
But Narkevic’s and Lorimer’s discovery nearly got binned. For a few months after they first spotted the unusually bright burst, it looked like the findings wouldn’t make it any further than Lorimer’s office walls just beyond the banks of the Monongahela River that slices through the city of Morgantown in West Virginia.
Soon after detecting the burst, Lorimer asked his former graduate advisor Matthew Bailes, an astronomer at Swinburne University in Melbourne, to help him plot the signal – which to astronomers is now a famous and extremely bright energy peak, rising well above the power of any known pulsar. The burst seemed to come from much, much further away than where the Parkes telescope would usually find pulsars; in this case, probably from another galaxy, potentially billions of light years away.
Read next A mysterious death, a genetic clue and the lifelong quest for answers A mysterious death, a genetic clue and the lifelong quest for answers
“It just looked beautiful. I was like: ‘Whoa, that's amazing’. We nearly fell off our chairs,” recalls Bailes. “I had trouble sleeping that night because I thought if this thing is really that far away and that insanely bright, it’s an amazing discovery. But it better be right.”
Advertisement
Within weeks, Lorimer and Bailes crafted a paper and sent it to Nature – and swiftly received a rejection. In a reply, a Nature editor raised concerns that there had been only one event, which appeared way brighter than seemed possible. Bailes was disappointed, but he had been in a worse situation before. Sixteen years earlier, he and fellow astronomer Andrew Lyne had submitted a paper claiming to have had spotted the first ever planet orbiting another star – and not just any star but a pulsar. The scientific discovery turned out to be a fluke of their telescope. Months later, Lyne had to stand up in front of a large audience at a American Astronomical Society conference and announce their mistake. “It’s science. Anything can happen,” says Bailes. This time around, Bailes and Lorimer were certain that they had it right and decided to send their FRB paper to another journal, Science.
After it was published, the paper immediately stirred interest; some scientists even wondered whether the mysterious flash was an alien communication. This wasn’t the first time that astronomers had reached for aliens as the answer for a seemingly inexplicable signal from space; in 1967, when researchers detected what turned out to be the first pulsar, they also wondered whether it could be a sign of intelligent life.
Just like Narkevic decades later, Cambridge graduate student Jocelyn Bell had stumbled across a startling signal in the reams of data gathered by a radio array in rural Cambridgeshire. Not much of the array is left today; in the fields near the university where it once stood, there’s an overgrown hedge, hiding a collection of wonky, sad-looking wooden poles that were once covered in a web of copper wire designed to detect radio waves from faraway sources. The wire has long been stolen and sold on to scrap metal dealers.
“We did seriously consider the possibility of aliens,” Bell says, now an emeritus professor at Oxford University. Tellingly, the first pulsar was half-jokingly dubbed LGM-1 – for little green men. With only half a year left until the defence of her PhD thesis, she was less than thrilled that “some silly lot of little green men” were using her telescope and her frequency to signal to planet Earth. Why would aliens “be using a daft technique signalling to what was probably still a rather inconspicuous planet?” she once wrote in an article for Cosmic Search Magazine.
Read next 'We are at war': How the Brexit Party's viral hit factory upended British politics 'We are at war': How the Brexit Party's viral hit factory upended British politics
Just a few weeks later, however, Bell spotted a second pulsar, and then a third just as she got engaged, in January 1968. Then, as she was defending her thesis and days before her wedding, she discovered a fourth signal in yet another part of the sky. Proof that pulsars had to be a natural phenomenon of an astrophysical origin, not a signal from intelligent life. Each new signal made the prospect even more unlikely that groups of aliens, separated by the vastness of the space, were somehow coordinating their efforts to send a message to an uninteresting hunk of rock on the outskirts of the Milky Way.
Lorimer wasn’t so lucky. After the first burst, six years would pass without another detection. Many scientists began to lose interest. The microwave explanation persisted for a while, says Lorimer, as sceptics sneered at the notion of finding a burst that was observed only once. It didn’t help that in 2010 Parkes detected 16 similar pulses, which were quickly proven to be indeed caused by the door of a nearby microwave oven that had been opened suddenly during its heating cycle.
Yuri Milner on stage with Mark Zuckerberg at a Breakthrough Prize event in 2017 Kimberly White / Stringer / Getty
When Avi Loeb first read of Lorimer’s unusual discovery, he too wondered if it was nothing more than the result of some errant wiring or miscalibrated computer. The chair of the astronomy department at Harvard happened to be in Melbourne in November 2007, just as Lorimer’s and Bailes’ paper appeared in Science, so he had a chance to discuss the odd burst with Bailes. Loeb thought the radio flash was a compelling enigma – but not much more than that.
Still, that same year Loeb wrote a theoretical paper arguing that radio telescopes built to detect very specific hydrogen emissions from the early Universe would also be able to eavesdrop on radio signals from alien civilisations up to about ten light years away. “We have been broadcasting for a century – so another civilisation with the same arrays can see us from a distance out to 50 light years,” was Loeb’s reasoning. He followed up with another paper on the search for artificial lights in the Solar System. There, Loeb showed that a city as bright as Tokyo could be detected with the Hubble Space Telescope even if it was located right at the edge of the Solar System. In yet another paper he argued how to detect industrial pollution in planetary atmospheres.
Read next The impossible fight to save Jakarta, the sinking megacity The impossible fight to save Jakarta, the sinking megacity
Ever since he was a little boy growing up in Israel, Loeb has been fascinated with life – on Earth and elsewhere in the Universe. “Currently, the search for microbial life is part of the mainstream in astronomy – people are looking for the chemical fingerprints of primitive life in the atmosphere of exoplanets,” says Loeb, who first dabbled in philosophy before his degree in physics.
But the search for intelligent life beyond Earth should also be part of the mainstream, he argues. “There is a taboo, it’s a psychological and sociological problem that people have. It’s because there is the baggage of science fiction and UFO reports, both of which have nothing to do with what actually goes on out there in space,” he adds. He’s frustrated with having to explain – and defend – his point of view. After all, he says, billions have been poured into the search for dark matter over decades with zero results. Should the search for extraterrestrial intelligence, more commonly known as SETI, be regarded as even more fringe than this fruitless search?
Lorimer didn’t follow Loeb’s SETI papers closely. After six long and frustrating years, his luck turned in 2013, when a group of his colleagues – including Bailes – spotted four other bright radio flashes in Parkes’ data. Lorimer felt vindicated and relieved. More detections followed and the researchers were on a roll: at long last, FRBs had been confirmed as a real thing. After the first event was dubbed ‘Lorimer’s Burst,’ it swiftly made it on to the physics and astronomy curricula of universities around the globe. In physics circles, Lorimer was elevated to the position of a minor celebrity.
Keeping an eye on events from a distance was Loeb. One evening in February 2014, at a dinner in Boston, he started chatting to a charismatic Russian-Israeli called Yuri Milner, a billionaire technology investor with a background in physics and a well-known name in Silicon Valley. Ever since he could remember, Milner had been fascinated with life beyond Earth, a subject close to Loeb’s heart; the two instantly hit it off.
Milner came to see Loeb again in May the following year, at Harvard, and asked the academic how long it would take to travel to Alpha Centauri, the star system closest to Earth. Loeb replied he would need half a year to identify the technology that would allow humans to get there in their lifetime. Milner then asked Loeb to lead Breakthrough Starshot, one of five Breakthrough Initiatives the Russian-born entrepreneur was about to announce in a few weeks – backed by $100 million (£79m) of his own money and all designed to support SETI.
Read next This economist has a plan to fix capitalism. It's time we all listened This economist has a plan to fix capitalism. It's time we all listened
Fast-forward six months, and at the end of December 2015 Loeb got a call asking him to prepare a presentation summarising his recommended technology for the Alpha Centauri trip. Loeb was visiting Israel and about to head on a weekend trip to a goat farm in the southern part of the country. “The following morning, I was sitting next to the reception of the farm – the only location with internet connectivity – and typing the PowerPoint presentation that contemplated a lightsail technology for Yuri’s project,” says Loeb. He presented it at Milner’s home in Moscow two weeks later, and the Breakthrough Initiatives were announced with fanfare in July 2015.
The Initiatives were an adrenaline shot in the arm of the SETI movement – the largest ever private cash injection into the search for aliens. One of the five projects is Breakthrough Listen, which was championed, among others, by the famous astronomer Stephen Hawking (who has died since) and British astronomer royal Martin Rees. Echoing the film Contact with Jodie Foster playing an astronomer listening out for broadcasts from aliens (loosely based on real-life SETI astronomer Jill Tarter), the project uses radio telescopes around the world to look for any signals from extraterrestrial intelligence.
After the Breakthrough Initiatives were announced, Milner’s money quickly got invested into the deployment of cutting-edge technology – such as computer storage and new receivers – at existing radio telescopes, including Green Bank in West Virginia and Parkes in Australia; whether the astronomers using these observatories believed in alien life or not, they welcomed the investment with open arms. It didn’t take long to receive the first scientific returns.
In August 2015 one of the previously spotted FRBs decided to make a repeat appearance, triggering headlines worldwide because it was so incredibly powerful, brighter than the Lorimer Burst and any other FRB. It was dubbed ‘the repeater’ and is also known as the Spitler Burst, because it was first discovered by astronomer Laura Spitler of the Max Planck Institute for Radio Astronomy in Bonn, Germany. Over the next few months, the burst flashed many more times, not regularly, but often enough to allow researchers to determine its host galaxy and consider its possible source – likely, a highly magnetised young, rapidly spinning neutron star (or magnetar).
This localisation was done with the Very Large Array (VLA), a group of 27 radio dishes in New Mexico that feature heavily in the film Contact. But the infrastructure at Green Bank Telescope upgraded by Breakthrough Listen caught the repeating flashes many more times, says Lorimer – allowing researchers to study its host galaxy more in detail. “It’s wonderful – they have a mission to find ET, but along the way they want to show that this is producing other useful results for the scientific community,” he adds. Detecting FRBs has quickly become one of the main objectives of Breakthrough Listen.
Read next Inside Google Stadia Inside Google Stadia
Netting the repeater was both a boon and a hindrance – on the one hand, it eliminated models that cataclysmic events such as supernova explosions were causing FRBs; after all, these can happen only once. On the other hand, it deepened the mystery. The repeater lives in a small galaxy with a lot of star formation – the kind of environment where a neutron star could be born, hence the magnetar model. But what about all the other FRBs that don’t repeat?
Researchers started to think that perhaps there were different types of these bursts, each with its own source. Scientific conferences still buzz with talks of mights and might-nots, with physicists eagerly debating possible sources of FRBs in corridors and at conference bars. In March 2017, Loeb caused a media frenzy by suggesting that FRBs could actually be of alien origin – solar-powered radio transmitters that might be interstellar light sails pushing huge spaceships across galaxies.
That Parkes is part of the SETI project is obvious to any visitor. Walking up the flight of stairs to the circular operating tower below the dish, every button, every door and every wall nostalgically screams 1960s, until you reach the control room full of modern screens where astronomers remotely control the antenna to observe pulsars.
Up another flight of stairs is the data storage room, stacked with columns and columns of computer drives full of blinking lights. One thick column of hard drives is flashing neon blue, put there by Breakthrough Listen as part of a cutting-edge recording system designed to help astronomers to search for every possible radio signal in 12 hours of data, much more than ever before. Bailes, who now splits his time between FRB search and Breakthrough Listen, takes a smiling selfie in front of Milner’s drives.
The Green Bank telescope in West Virginia Andrew Caballero-Reynolds / Getty
Read next The rise and fall of Flash, the annoying plugin that shaped the modern web The rise and fall of Flash, the annoying plugin that shaped the modern web
While many early FRB discoveries were made with veteran telescopes – single mega dishes like Parkes and Green Bank, new telescopes, some with the financial backing of Breakthrough Listen, are now revolutionising the FRB field.
Deep in South African’s semi-desert region of the Karoo, eight hours by car from Cape Town, stands an array of 64 dishes, permanently tracking space. They are much smaller than their mega-dish cousins, and all work in unison. This is MeerKAT, another instrument in Breakthrough Listen's growing world-wide network of giant telescopes. Together with a couple of other next generation instruments, this observatory might hopefully tell us one day, probably in the next decade, what FRBs really are.
The name MeerKAT means “More KAT,” a follow up to KAT 7, the Karoo Array Telescope of seven antennas – although real meerkats do lurk around the remote site, sharing the space with wild donkeys, horses, snakes, scorpions and kudus – moose-sized mammals with long, spiralling antlers. Visitors to MeerKAT are told to wear safety leather boots with steel-toes as a precaution against snakes and scorpions. They're also warned about the kudus, which are very protective of their calves and recently attacked the pickup truck of a security guard, turning him and his car over. Around MeerKAT there is total radio silence; all visitors have to switch off their phones and laptops. The only place with connectivity is an underground ‘bunker’ shielded by 30-centimetre-thick walls and a heavy metal door to protect the sensitive antennas from any human-made interference.
MeerKAT is one of the two precursors to a much bigger future radio observatory – the SKA, or Square Kilometre Array. Once SKA is complete, scientists will have added another 131 antennas in the Karoo. The first SKA dish has just been shipped to the MeerKAT site from China. Each antenna will take several weeks to assemble, followed by a few more months of testing to see whether it actually works the way it should. If all goes well, more will be commissioned, built and shipped to this faraway place, where during the day the dominant colour is brown; as the sun sets, however, the MeerKAT dishes dance in an incredible palette of purples, reds and pinks, as they welcome the Milky Way stretching its starry path just above. MeerKAT will soon be an incredible FRB machine, says Bailes.
There is another SKA precursor – ASKAP in Australia. Back in 2007, when Lorimer was mulling over the Nature rejection, Ryan Shannon was finishing his PhD in physics at Cornell University in New York state – sharing the office with Laura Spitler, who would later discover the Spitler Burst. Shannon had come to the US from Canada, growing up in a small town in British Columbia. About half an hour drive from his home is the Dominion and Radio Astronomical Observatory (DRAO) – a relatively small facility that was involved in building equipment for the VLA.
Read next The hidden fight to stop illegal fishing from destroying our oceans The hidden fight to stop illegal fishing from destroying our oceans
Subconsciously, says Shannon, DRAO must have impacted his choice of career. And it was at DRAO that a few years later a totally new telescope – CHIME – would be built that would greatly impact the nascent field of FRB research. But in 2007 that was still to come. After graduating from Cornell in 2011, Shannon decided not to stay close to home – “something my mum would’ve wanted.” Instead, he moved to Australia and ultimately to Swinburne University on the outskirts of Melbourne.
Shannon joined Bailes’ team in 2017 – and by then astronomers had begun to understand why they weren’t detecting more FRBs, even though they were already estimating that these flashes were happening hundreds of times every day, if not more. “Our big radio telescopes don’t have wide fields of view, they can’t see the entire sky – that’s why we missed nearly all FRBs in the first decade of realising these things exist,” says Shannon.
When he, Bailes and other FRB hunters saw the ultra-bright repeater, the Spitler Burst, they understood that there were fast radio bursts which could be found even without gigantic telescopes like Parkes, by using instruments that have a wider field of view. So they started building ASKAP – a new observatory conceived in 2012 and recently completed in the remote Australian outback. It sports 36 dishes with a 12 metre diameter each, and just like with MeerKAT, they all work together.
To get to ASKAP, in a very sparsely populated area in the Murchison Shire of Western Australia, one has first fly to Perth, change for a smaller plane bound for Murchison, then squeeze into a really tiny single propeller plane, or drive for five hours across 150 kilometres of dirt roads. “When it rains, it turns to mud, and you can’t drive there,” says Shannon, who went to the ASKAP site twice, to introduce the local indigenous population to the new telescope constructed – with permission – on their land and see the remote, next generation ultra-sensitive radio observatory for himself.
MeerKAT and ASKAP bring two very different technological approaches to the hunt for FRBs. Both observatories look at the Southern sky, which makes it possible to see the Milky Way’s bright core much better than in the Northern hemisphere; they complement old but much upgraded observatories like Parkes and Arecibo in South America. But the MeerKAT dishes have highly sensitive receivers which are able to detect very distant objects, while ASKAP's novel multi-pixel receivers on each dish offer a much wider field of view, enabling the telescope to find nearby FRBs more often.
Read next The PPI scandal spawned a spam empire that just won't quit The PPI scandal spawned a spam empire that just won't quit
“ASKAP’s dishes are less sensitive, but we can observe a much larger portion of the sky,” says Shannon. “So ASKAP is going to be able to see things that are usually intrinsically brighter.” Together, the two precursors will be hunting for different parts of the FRB population – since “you want to understand the entire population to know the big picture.”
MeerKAT only started taking data in February, but ASKAP has been busy scanning the Universe for FRBs for a few years now. Not only has it already spotted about 30 new bursts, but in a new paper just released in Science, Shannon and colleagues have detailed a new way to localise them despite their short duration, which is a big and important step towards being able to determine what triggers this ultra-bright radiation. Think of ASKAP’s antennas as the eye of a fly; they can scan a wide patch of the sky to spot as many bursts as possible, but the antennas can all be made to point instantly in the same direction. This way, they make an image of the sky in real time, and spot a millisecond-long FRB as it washes over Earth. That’s what Shannon and his colleagues have done, and for the first time ever, managed to net one burst they named FRB 180924 and pinpoint its host galaxy, some four billion light years away, all in real time.
Another team, at Caltech’s Owens Valley Radio Observatory (OVRO) in the Sierra Nevada mountains in California, have also just caught a new burst and traced it back to its source, a galaxy 7.9 billion light years away. And just like Shannon, they didn’t do it with a single dish telescope but a recently built array of ten 4.5-meter antennas called the Deep Synoptic Array-10. The antennas act together like a mile-wide dish to cover an area on the sky the size of 150 full moons. The telescope’s software then processes an amount of data equivalent to a DVD every second. The array is a precursor for the Deep Synoptic Array that, when built by 2021, will sport 110 radio dishes, and may be able to detect and locate more than 100 FRBs every year.
What both ASKAP’s and OVRO’s teams found was that their presumably one-off bursts originated in galaxies very different from the home of the first FRB repeater. Both come from galaxies with very little star formation, similar to the Milky Way and very different from the home of the repeater, where stars are born at a rate of about a hundred times faster. The discoveries show that “every galaxy, even a run-of-the-mill galaxy like our Milky Way, can generate an FRB,” says Vikram Ravi, an astronomer at Caltech and part of the OVRO team.

But the findings also mean that the magnetar model, accepted by many as the source of the repeating burst, does not really work for these one-off flashes. Perhaps, Shannon says, ASKAP’s burst could be the result of a merger of two neutron stars, similar to the one spotted two years ago by the gravitational wave detectors LIGO and Virgo in the US and Italy, because both host galaxies are very similar. “It’s a bit spooky that way,” says Shannon. One thing is clear though, he adds: the findings show that there is likely more than one type of FRBs.
Back in Shannon’s hometown in Canada, the excitement has also been growing exponentially because of CHIME. Constructed at the same time as MeerKAT and ASKAP, this is a very different observatory; it has no dishes but antennas in the form of long buckets designed to capture light. In January, the CHIME team reported the detection of the second FRB repeater and 12 non-repeating FRBs. CHIME is expected to find many, many more bursts, and with ASKAP, MeerKAT and CHIME working together, astronomers hope to understand the true nature of the enigmatic radio flashes very soon.
Read next Inside the UK unicorn that's about to become the Intel of AI Inside the UK unicorn that's about to become the Intel of AI
But will they fulfill Milner’s dream and successfully complete SETI, the search for extraterrestrial intelligence? Lorimer says that scientists hunting for FRBs and pulsars have for decades been working closely with colleagues involved in SETI projects.
After all, Loeb’s models for different – alien – origins of FRBs are not fundamentally wrong. “The energetics when you consider what we know from the observations are consistent and there’s nothing wrong with that,” says Lorimer. “And as part of the scientific method, you definitely want to encourage those ideas.” He personally prefers to find the simplest natural explanation for the phenomena he observes in space – but until we manage to directly observe the source of these FRBs, all theoretical ideas should stand, as long as they are scientifically sound – whether they involve aliens or not.
Updated July 24, 2019 11:40: This article has been updated to reflect Yuri Milner's Israeli citizenship
More great stories from WIRED
🎉 A vaccine for Alzheimer's is on the verge of reality
⛈️ The UK's big flooding problem is only going to get worse
🤦🏽 Reddit’s ‘Am I the Asshole’ is your new guilty pleasure
🔍 The disturbing return of scientific racism
Advertisement
🤵🏻 The NHS has a plan to get more men donating blood
📧 Get the best tech deals and gadget news in your inbox

Story 186
Relive some of the best college football moments of week 4
Relive some of the best college football moments of week 4
In front of a record crowd at Sanford Stadium, No. 3 Georgia did just enough to beat No. 7 Notre Dame in a top-10 matchup with possibly College Football Playoff implications.
Here's how Georgia got the 23-17 win.
Georgia vs. Notre Dame: How the Bulldogs won the top-10 showdown
It wasn't easy. The blowout some expected never materialized, as Notre Dame pushed Georgia to the end in a 23-17 loss.
Though the Irish were one dimensional most of the night, Irish QB Ian Book almost pulled out a crazy rally.
Here's what we learned from Georgia's win:
Georgia flashed more offensive balance, rushing for 152 yards; Notre Dame had only 46 yards and had 12 penalties.
A crucial decision to kick a field goal instead of going for the clincher almost cost UGA.
Though Georgia remains undefeated, Notre Dame might have changed some of its big-game perceptions that have hurt it.
TOP 25 scores: Get caught up with ranked results
Jake Fromm and Georgia didn't spread out Notre Dame much in the first half, as he had 11 completions for only 59 yards. But he ended with 187 yards and a touchdown on 20-for-26 passing. He also got support from the ground game, especially in the second half. D'Andre Swift had 98 yards and a score on 18 attempts.
Notre Dame would have welcomed that kind of balance. While Book had 275 passing yards and two touchdowns, he also had two interceptions (one off a receiver's hands) and had 47 attempts. On the ground, the Irish had only 46 yards.
Despite all that, Georgia almost let the Irish rally from in the fourth quarter.
STAYING PERFECT: Here are the remaining unbeaten teams this season
With it 20-10 UGA, the Bulldogs faced a 4th and 1 from the Notre Dame 26. Instead of trying to get the first down and possibly score what would essentially be the clinching touchdown with less than seven minutes to go, Georgia settled for a Rodrigo Blankenship field goal to make it 23-10.
Notre Dame answered with a Book touchdown pass and then forced a punt to give itself a chance to steal a win in front of the largest crowd in Sanford Stadium history (93,246).
THE BULLDOGS SAY NO pic.twitter.com/5jJlO2Fz2v — CBS Sports (@CBSSports) September 22, 2019
Though the stunner never happened, the Irish might have changed some perceptions. Coming in ranked No. 7, Notre Dame was 1-18 in its most recent 19 games against AP top-5 teams. It also had a blowout loss to Clemson in the CFP semifinals a year ago. And there's no forgetting the brutal 42-14 rout to Alabama in the national championship game during the 2012 season.
Notre Dame drops to 2-1, with a visit from ranked Virginia up next. Georgia doesn't play again until it heads to Knoxville to play slumping Tennessee on October 5.
Georgia vs. Notre Dame: Score, updates
Click here for live stats.
Georgia 23, Notre Dame 17 | Final
Whew — if you're a Georgia supporter. The Bulldogs chased Ian Book, who heaved it deep but didn't find the miracle catch.
The Bulldogs almost coughed it away, but did just enough to remain undefeated.
Georgia 23, Notre Dame 17 | 2:00 4Q
Notre Dame kicks it deep and it works out perfectly. A bad snap on third down forces Fromm to hurry and throw it away.
And then UGA has only a 27-yard punt.
Georgia 23, Notre Dame 17 | 3:12 4Q
Well, well, well. Notre Dame struggled all second half until it really needed to score. Book guides the Irish to the end zone and is up to 261 passing yards and 2 touchdowns.
Notre Dame has only 46 rushing yards, but it's keeping it close.
The Irish continue to fight and Georgia's lead is down to six. pic.twitter.com/U3Sh4VVLop — CBS Sports (@CBSSports) September 22, 2019
Georgia 23, Notre Dame 10 | 6:53 4Q
Notre Dame tries for a spark on a flea-flicker but it ends in Irish disaster, as J.R. Reed jumps it for the interception.
Notre Dame this half: Interception, punt, punt, interception.
UGA takes off four more minutes from the clock, but gets a field goal instead of a touchdown. Blankenship is again clutch, this time from 43.
Georgia 20, Notre Dame 10 | 13:19 4Q
Georgia adds space on the scoreboard thanks to a great 15-yard TD catch from Lawrence Cager, who maintains possession and gets down one foot for the score.
Notre Dame hasn't been able to do anything in the second half, while Georgia has started to assert itself. Fromm is up to 172 yards through the air as UGA continues to throw it down field unlike the first half.
Georgia 13, Notre Dame 10 | End 3Q
As Notre Dame's offense sputters, Georgia is starting to get physical. Swift is up to 81 yards on 14 attempts — and added an impressive highlight hurdle.
D'ANDRE SWIFT ISN'T AFRAID OF HEIGHTS pic.twitter.com/XYZu2U48NY — CBS Sports (@CBSSports) September 22, 2019
It's also officially a record crowd at Sanford Stadium, with 93,246 in attendance.
Georgia 13, Notre Dame 10 | 2:18 3Q
Notre Dame's offense is falling apart. The Irish had a very manageable third-and-2 but commit a false start...and then do it again on fourth down. That's now six on the night.
The Irish have also gone three-and-out on three consecutive possessions.
Georgia 13, Notre Dame 10 | 4:21 3Q
Georgia is starting to open it up a bit. And it's working. Fromm has 62 passing yards in the third quarter after only 59 in the first half.
It doesn't end in 6, as Simmons can't make the tough catch. Blankenship comes in and gives UGA the lead for the first time.
Georgia 10, Notre Dame 10 | 8:31 3Q
A truly wild play that sees a Book throw to an Irish receiver, who can't grab it, allowing Divaad Wilson to make the interception. Wilson then fumbles it, but UGA gets possession as it goes out of bounds.
But the Irish, with some help from a personal foul penalty, hold UGA to a Blankenship 40-yard FG. Fromm is 14-for-17 but has only 85 yards (5 yards per attempt).
Notre Dame 10, Georgia 7 | 10:49 3Q
Georgia almost gets Notre Dame with the draw on third-and-16, but the Bulldogs come a few yards short.
Really huge stop by the Irish defense as UGA gets around midfield with a couple first downs but then stalls. Swift is up to 53 yards on 10 attempts. We'll see if Georgia tries to establish the run even more.
Notre Dame 10, Georgia 7 | Halftime look
Yards: Notre Dame 163; Georgia 114
Turnovers: Georgia 1; Notre Dame 0
First Downs: Both with 7
QBs: Book (ND): 16-for-24, 146 yards, TD; Fromm (UGA): 11-for-12, 59 yards
RBs: Jones (ND): 4 attempts, 9 yards; Swift (UGA): 7 attempts, 33 yards, TD
Notre Dame hasn't had much success when it's tried to run, but that hasn't hurt it yet. The Irish are trusting Book to win this, sometimes with short passes that are acting as semi-run plays, other times by actually going deep.
Book has already connected with Kmet seven times for 68 yards and a touchdown.
Notre Dame 10, Georgia 7 | Half
A fun end of the half. Notre Dame shows field goal, prompting UGA to call a timeout. So the Irish send out back the offense and take a shot in the end zone...only to throw incomplete.
In the end, Notre Dame gets the field goal it was originally looking for and leads at the half.
Georgia 7, Notre Dame 7 | 2:27 2Q
What a response by Georgia. No quick strike, but a methodical drive of 13 plays and 75 yards in 8:12.
Swift secured the touchdown with a 3-yard run. Fromm continues to be efficient — and the playbook seemed to open up a bit down the field. He's now 11-for-12 for 59 yards.
Notre Dame 7, Georgia 0 | 4:53 2Q
It's been a fast-moving quarter. And more injuries for Georgia, as LG Solomon Kindley is helped off the field with a leg injury.
Bulldogs are inside the Notre Dame 30.
Notre Dame 7, Georgia 0 | 10:39 2Q
It took a ton of effort, but Notre Dame finally finishes off the big Georgia mistake with a 1-yard Ian Book TD pass to Cole Kmet.
Georgia made the first HUGE mistake of the game, as Tyler Simmons tried to call fair catch but didn't come up with the ball. The Irish recovered inside the Georgia 10.
The Irish decided to try to get the TD through the air. It took a the limit — and included a dangerous pass — but Notre Dame finally scored.
Georgia 0, Notre Dame 0 | 2:34 1Q
A crucial holding penalty on 2nd and 1 hurts UGA, as does good pressure from the Notre Dame defensive front. Fromm is 6-for-7 but has only 16 passing yards.
Georgia 0, Notre Dame 0 | 6:47 1Q
First big decision for Notre Dame is to go for it on 4th and 2 from UGA 32...it did not go well. A bad snap forces Book to hurry and throw it. Good effort falls incomplete near a diving receiver.
This play was a roller coaster of emotions. pic.twitter.com/1FV0jtYcWQ — CBS Sports (@CBSSports) September 22, 2019
Georgia 0, Notre Dame 0 | 8:29 1Q
UGA goes pass heavy on the first drive and Jake Fromm goes 4-for-4 for 8 yards, so nothing deep yet. The Bulldogs punt it back to the Irish.
Only one rushing attempt on that first possession.
Georgia 0, Notre Dame 0 | 12:05 1Q
Georgia is already without starting corner Tyson Campbell and now see Eric Stokes getting helped off the field with an injury.
In Notre Dame's first series, the Irish picked up two first downs and got close to the 50, but Ian Book's incomplete pass forces a punt.
How We Got Here — 8:10 p.m.
Georgia is No. 3 after routing Vanderbilt 30-6, Murray State 63-17 and Arkansas State 55-0.
Notre Dame is ranked No. 7 with a 35-17 win at Louisville and a 66-14 win against New Mexico.
The Stakes — 8 p.m.
As we get ready for kick, here's a look at some other big results from this week.
Three top 15 teams have lost: No. 10 Utah to USC, No. 11 Michigan to No. 13 Wisconsin and No. 15 UCF at Pitt. It's UCF's first loss in the regular season since 2016. In a big SEC game, No. 8 Auburn won at No. 17 Texas A&M, 28-20.
So there's going to be some big movement this week — and there will be even more if Notre Dame can shock Georgia.
Pregame — 7:45 p.m.
Georgia is 2-0 against Notre Dame all-time, but this is the first time they're playing in Athens. When UGA played at the Irish two years ago, there were a lot of fans in the stands. Looks like Notre Dame won't repeat that in Georgia.
Thirty minutes before kickoff, and looks like Georgia has the usual dominance of its home stadium. Only pockets of Notre Dame green to be seen. pic.twitter.com/lM6UIfe3P6 — Seth Emerson (@SethWEmerson) September 21, 2019
Pregame — 7:30 p.m.
ESPN's "College GameDay" was in Athens, Georgia for only the fourth time ever. It's Notre Dame's first visit to UGA. And it's in a game between two top-10 teams.
Georgia vs. Notre Dame: Time
The Bulldogs and Irish play at 8 p.m. ET on Saturday, Sept. 21.
Georgia v. Notre Dame: TV channel, how to watch
You can watch the game live on CBS. It can also be watched on CBSSports.com here.
Georgia vs. Notre Dame: Preview, prediction
No more waiting. The much-hyped UGA-Notre Dame showdown is finally in game week.
It's the second top-10 nonconference matchup of the season, following No. 6 LSU vs. No. 9 Texas in Week 2. But this one will feel a little different.
WEEK 4: Live scoreboard, stats | TV schedule for every game
The Irish have played a top-5 SEC program on the road only once before: 1999 at No. 4 Tennessee. The Vols won by 24.
Two years ago, Georgia went to Notre Dame and beat the Irish in Jake Fromm's first start. Since then, UGA has done just about everything except beat Alabama and win a national title. Notre Dame is also looking to take that jump over the final hurdle, as the Irish fell big to Clemson in the CFP semifinals last year.
This game could do a lot for people's perceptions of Notre Dame. The Irish haven't beaten a top-5 team since defeating No. 3 Michigan in 2005 in Ann Arbor. Notre Dame coach Brian Kelly is 0-4 against top-4 teams; Georgia beat two top-5 teams in consecutive games in the 2017 season alone (Auburn and Oklahoma).
Any time a non-SEC school can beat a highly ranked team in the SEC, it will turn heads.
RANKINGS: AP Top 25 Poll | Coaches Poll
Notre Dame
Tale of the Tape Georgia
2-0 Record 3-0 (1-0 SEC) No. 7 AP ranking No. 3 Brian Kelly
(62-35, 233-92-2) Coach (record at school, overall) Kirby Smart
(35-10) 13 (1988 most recent) National championships 1 (1980) Ian Book
553 yards (6 TDs, 0 INTs) Passing leader Jake Fromm
601 yards (5 TDs, 0 INTs) Ian Book, Tony Jones Jr.
Both with 127 yards Rushing leader D'Andre Swift
290 yards, 2 TDs Chase Claypool
190 yards, TD Receiving leader George Pickens
162 yards, TD 507.0 Offensive yards per game 565.3 373.0 Yards per game allowed 243.0 50.5 Points per game 49.3 15.5 Points against 7.7
And even if Georgia loses, it still has plenty of time and opportunities to make the CFP for the second time in three years. The Bulldogs still must play Florida, Auburn, Texas A&M and then possibly in the SEC Championship Game. UGA reached the playoffs in 2017 as the one-loss SEC Champion. That could happen again. However, in the five-year history of the CFP, there has yet to be a two-loss team to make the field. That could mean UGA has no margin for error if it loses to Notre Dame.
As for the Irish, could a loss mean the end to CFP hopes? Ranked Virginia and Michigan are still to come, but Southern California, Virginia Tech, Boston College and Stanford don't look like the big-game opportunities they could have been even a week ago — three of them lost and Virginia Tech beat FCS Furman by 7. And since Notre Dame is Independent, there is no conference title game (or 13th game data point) to make a last-minute statement to the Selection Committee. If Notre Dame loses to Georgia, it might be too much of a hill to climb.
UNBEATEN TRACKER: Here are the remaining undefeated teams this season
Both teams have looked mostly dominant, though really remain untested. With Fromm and D'Andre Swift, UGA has clear offensive starpower. The offensive line might be the difference, as the Bulldogs average 286.7 yards per game and 7.6 yards per rushing attempt.
Notre Dame's Ian Book leads the Irish in both passing and rushing. But there could be big trouble on the defensive front. Through two games against New Mexico and Louisville (teams a combined 5-19 last season), Notre Dame is allowing 461 yards total and nearly 5 yards every attempt. That could doom any Irish chances.
Notre Dame might keep it close for a half, but Georgia should be able to wear down the visiting Irish.
The Pick Georgia 31, Notre Dame 17
Georgia vs. Notre Dame: Series history, scores
This is only the third meeting between UGA and Notre Dame, but the first two had big championship implications.
In the 1980 season, No. 1 Georgia played No. 4 Notre Dame in the Sugar Bowl (Jan. 1, 1981). With the game tied 3-3, the Irish didn't field a kick, allowing the Bulldogs to fall on the ball. Star UGA RB Hershel Walker scored his first of two touchdowns two plays later. Walker finished with 150 yards as the Bulldogs won 17-10 and the national title.
The two didn't play again until 2017. With No. 15 Georgia playing at No. 24 Notre Dame — and with UGA fans making parts of South Bend look like a sea of red — the Bulldogs won on a late Rodrigo Blankenship field goal. That helped charge Georgia to an eventual appearance in the College Football Playoff National Championship Game.

Story 187
EGGENSTEIN-LEOPOLDSHAFEN, Germany--(BUSINESS WIRE)--amcure, a biopharmaceutical company developing first-in-class cancer therapeutics, presented clinical trial data from its lead oncology drug candidate, AMC303, at the European Society for Medical Oncology (ESMO) Congress in Munich. The data presented on Sunday, 21 October in a proffered oral presentation demonstrated the favorable safety profile of AMC303. The company is currently conducting a Phase 1b expansion cohort and expects to publish updates from the study in 2019.
AMC303 is a cyclic peptide targeting CD44v6, a key cell membrane protein in pathways of several receptor-tyrosine kinases, such as c-MET, VEGFR-2 and RON. This approach provides a potential novel mechanism for the treatment of patients with advanced and solid tumors that have already begun to spread throughout the body. Trial results presented at ESMO 2018 have shown the compound to be well-tolerated in 27 patients with a total of 11 different cancer types, with a favorable PK profile. No related serious adverse events (SAEs) were reported, and most frequently reported related events were infusion related reactions and hypersensitivity (grade 1-2, in 22% of patients), followed by nausea, diarrhea and fatigue.
“AMC303 was well tolerated in a heavily pretreated and diverse cancer patient population. The most related adverse events were transient and manageable. AMC303 has thus the potential of being a safe therapeutic option with a unique and additive mechanism of action,” said Dr. Emiliano Calvo, MD, Lead Investigator of the trial at the Hospital Madrid Norte Sanchinarro and Director at the START Madrid-CIOCC Early Phase Clinical Drug Development program.
“These encouraging data support the continuation of the trial into its second part, targeting patients with a moderate to high expression of the target molecule CD44v6 and selected cancer types with a confirmed squamous cell histology. We look forward to updating the community on the progress of this trial and publish additional data sets as they emerge,” added Klaus Dembowsky, CEO of amcure GmbH.
The trial, conducted in Belgium and Spain, is designed to assess the safety, tolerability and pharmacokinetics of multiple and increasing doses of AMC303 as monotherapy in patients with advanced metastatic malignant solid tumors of epithelial origin. In addition, the study includes a comprehensive biomarker program. The study was designed to include a broad variety of tumor types in the first part of the study irrespective of the target expression and a tumor type-specific expansion cohort at the recommended dose for a subsequent Phase 2 study. With the expansion cohort, amcure focuses its patient selection on patients with a moderate to high expression of the target molecule CD44v6 in four specific tumor types of squamous tumors: head and neck squamous cell carcinoma (HNSCC), squamous non-small-cell lung carcinoma (NSCLC), esophageal and cervical tumors.
For more information on the trial please visit http://www.clinicaltrials.gov/
About AMC303
amcure’s lead compound, AMC303, is being developed as a potential treatment for patients with advanced and metastatic epithelial tumors, e.g. pancreatic cancer, head and neck cancer, gastric cancer, colorectal cancer, breast cancer and lung cancer. AMC303 has a high specificity for inhibiting CD44v6, a co-receptor required for signaling through multiple cellular pathways (c-Met, VEGFR-2, RON) involved in tumor growth, angiogenesis and the development and regression of metastases. AMC303 has demonstrated strong effects in various in vitro and in vivo assays.
About amcure
amcure GmbH is a spin-off from the Karlsruhe Institute of Technology established in 2012. The company develops peptide-based compounds for the treatment of highly metastatic forms of cancer. amcure’s most advanced development candidate, AMC303, has entered clinical development and has demonstrated in in vivo animal proof-of-concept studies a high efficacy against different types of epithelial cancers. amcure is supported by a grant from the German Federal Ministry of Education and Research.

Story 188
A PERSONAL trainer has told how she hopes to find love on First Dates – because she’s fed up of dating ‘superficial’ fitness buffs.
Sophia Delavari, 24, from Dublin, will appear on tonight's episode of the popular RTE 2 show where viewers will see her get paired up with army hunk Ryan.
6 Personal trainer Sophia Delavari says other person trainers can sometimes be concerned with the superficial
And Sophia says Limerick man Ryan was a breath of fresh air compared to the lads who she usually goes out with.
She said: “I tend to attract personal trainers all the time but I always find that’s my downfall.
"I hate to say it and I wouldn’t want to brush them all with the same brush but I find that a lot of personal trainer guys can be quite superficial.
"I’ve been on few dates with some of them. I like someone who is athletic, but for personal trainers, it’s their whole life.
6 Sophia said Ryan had a 'different background' but 'similar interests'
“With Ryan, it was so nice to speak with someone who has a different background with similar interests.”
Dublin-born Sophia got into personal training after battling her own weight problems.
And she insists she’s good inspiration for her clients as she can "relate" to their struggle to lose weight.
She said: “I started doing personal training because I was a little bit overweight myself at one stage and eventually I just got really into a whole fitness regime and I loved the fact that I could change my own body.
6 Delavari says she likes 'someone athletic' but personal trainers can allow their fitness regime to become their whole lives Credit: www.instagram.com/richarddonelan/
6 Sophia says she tends to attract personal trainers in her romantic life
6 Sophia believes she relates well to clients because she started personal training to manage her own 'little bit' of overweight
6
“I felt if I could do it, anybody could do it so I feel like now I’ve been in other people’s shoes, it really helps. When I’m teaching someone or I’m giving them a programme, I can relate to them because I know the struggle behind it all. It honestly doesn’t feel like my job anymore because it’s such a rewarding job.”
Sophia admits there is one downside to her career however – lads always get competitive when they find out she’s super fit.
most read in TV and Showbiz weigh to go Gemma Collins looks unrecognisable as she shows off weight loss in latest snap Different beast The Chase's Mark Labbett shows off huge weight loss after marriage problems CAPITAL TRIP Katie Price visits Trinity College to accept medal and film reality show Exclusive NIC'S HOME HELL Girls Aloud's Nicola Roberts loses £1.25m home to bank after stalker ordeal scar-crash Topless Katie Price reveals surgery scars as she poses on a rock in Turkey am-azing Love Island's Amber Gill stuns in red dress as India & Ovie avoid awkward run in
She added: “Guys are always like, ‘oh how much do you squat, how much can you bench, I’m sure you have a great ass’.
"That’s always the way when someone sees you’re a personal trainer.”
Find out if Sophia and Ryan are a match on tonight’s episode of First Dates on RTE 2 at 9.30pm.

Story 189
More than 2,000 students with three Ds or lower got the top grade for their degrees ALAMY
Hundreds of students with the worst A levels are going on to get first-class degrees each year, fuelling fears of grade inflation at universities.
Analysis by The Times shows that more than 2,000 students who had achieved three D grades or lower ended up being awarded a first at university. Forty universities awarded firsts to at least a quarter of those with the lowest A-level grades.
Critics said that universities faced conflicting pressures to tackle grade inflation while ensuring that more students from poor backgrounds achieved the highest degrees.
Damian Hinds said the rise in first-class grades was not justified JACK HILL/THE TIMES
Damian Hinds, the education secretary, told universities last month that they must end the steep rise of “unjustifiable” first-class degrees. The percentage of students getting first-class degrees has increased from 16 to 27 per cent in…

Story 190
Strike comes as negotiations for higher wages, more resources and smaller class sizes have hit an impasse
Chicago teachers are planning to walk out on Tuesday in what’s believed to be the country’s first major charter school teacher strike.
Teachers and their union argue the independent schools are overcrowded and underfunded and have been used to create a “second tier in the teaching profession”. The strike comes as negotiations for higher wages, more resources and smaller class sizes have hit an impasse.
Caroline Rutherford, who has worked at Donald J Marquez Elementary in Chicago said the charter schools were struggling to retain staff. Her school is run by the not-for-profit charter operator Acero Schools, one of Chicago’s largest charter networks.
“We’ve had turnover at the teacher, apprentice and administration level. So I’ve had six or seven different principals since I’ve started, and I’ve had nine master teachers, a new one every year,” Rutherford said.
“It’s a practice for the charters to hire really young, inexperienced teachers and work them like crazy, pack as many kids as they can in front of them, in my school it’s 32 a class, and not give them a lot of tools to work,” said Rutherford. “After a couple years, they’re burnt out from either the charter system or the teaching practice altogether.”
The US spends more on education than other countries. Why is it falling behind? Read more
Martha Baumgarten, a fifth-grade teacher at Carlos Fuentes Elementary, another Acero school, also has 32 students in her class. “That’s just way too many students to really give the best educational opportunity possible,” she said. “That’s 32 different personalities, different academic levels, different needs, and my school serves a high population of low income and immigrant families, so there are a lot of needs, everything from hunger to winter coats to unstable family and living situations.”
The threatened walkout comes as the Chicago Teachers Union and charter school operators appear deadlocked over new contract negotiations. The union and charter school operators were unable to come to an agreement on a new contract during several bargaining sessions over the past week. The strike is the first against a charter school operator in the United States and was authorized in a union membership vote by 98% of members.
The Chicago action follows a wave of teacher strikes across the US in the spring that led to significant victories for teachers in Oklahoma, West Virginia and other states.
Chicago’s teachers are demanding a new contract that grants teachers and staff equal pay compared with their public school counterparts, reduced class sizes, making each school a sanctuary school for immigrant students and their families, and a prioritization of educational funding for students over charter management fees and executive pay.
“Charters have essentially been used to create a second tier in the teaching profession where wages and working conditions are much less, people don’t have a union, and even when we get a union and contract, our working conditions, pay, benefits, rights are less than most of the traditional public school contracts,” said Chris Baehrend, the Chicago Teachers Union Division Chair for the Alliance of Charter Teachers and Staff (ACTS). He noted pay for teachers and staff at charter schools is up to 30% lower than public school salaries. “We have 12 employers with 12 contracts. We’ve lined up 11 of them to negotiate at the same time to change the way the charter industry works.”
Sign up for the new US morning briefing
Those contracts include union members in the Chicago International Charter School network and UNO/Acero Network.
According to research conducted by the Chicago Teachers Union, charter school teachers in Chicago are paid less than public school teachers, despite working over an hour longer every day and several extra school days a year. This wage gap exists even as 2017 state legislation in Illinois increased charter school funding to about 8% more per student than public schools.
Though teachers and staff are paid less at Chicago’s charter schools than within the Chicago Public Schools system, the leaders of charter school operators receive higher salaries than those at Chicago Public Schools, despite overseeing fewer students and schools. The UNO/Acero Charter Schools operator CEO, Richard Rodriguez, makes over $260,000 a year, presiding over 15 schools with 8,000 students. The CEO of Chicago Public Schools, Janice Jackson, makes $260,000 a year overseeing more than 500 schools and about 360,000 students.
This emphasis on profit comes at a cost to students, teachers, paraprofessionals and school staff, union members argue.
“Do we have students or do we have customers? That’s what we’re fighting for, to change the idea of what it is we do here,” said Andy Crooks, a special educator apprentice at the UNO/Acero operated Sor Juana Inés de la Cruz K-12 school.
“Under the new funding formula, charter schools are getting more money. But what we’ve seen this year is across our 15 UNO/Acero schools, rather than pouring that money directly into the classrooms, they are hiring administrative positions.”
In an email, an Acero schools spokesperson said they are committed to reaching an agreement at the bargaining table: “While we are disappointed at the strike announcement, we are not entirely surprised. Based on statements the CTU has made, there is a real focus on making an example out of charter schools.”

Story 191
Saturday night, as the Colorado Avalanche came back to win a thrilling overtime game and tie their first-round series with the Calgary Flames in the Stanley Cup playoffs, Cale Makar was playing his final game for the Massachusetts Minutemen — a 3-0 loss to Minnesota Duluth in the NCAA championship.
FROZEN FOUR: Minnesota Duluth shuts out UMass to repeat as national champion
Two days later, Makar — who was selected by Colorado with the fourth pick of the 2017 NHL draft — was on the ice for the Avs in game 3. That quick turnaround would have been impressive enough, but Makar has never settled for enough.
Late in the first period, with Colorado leading 2-0 in Denver, the rookie defenseman joined a rush, took a drop-off pass from Nathan MacKinnon, and fired a shot past Calgary goalie Mike Smith to extend the lead to 3-0.
Hey NHL, meet Cale Makar.

You’re going to love him! #GoAvsGo pic.twitter.com/XgOMJljcpj — x- Colorado Avalanche (@Avalanche) April 16, 2019
That goal would prove the game-winner, as Colorado won 6-2 to take the 2-1 series lead. The Avalanche haven’t won a Stanley Cup series since they beat Minnesota in 2008.
Makar — who grew up in Calgary — was named as the 2019 Hobey Baker Memorial Award winner for the top NCAA men’s ice hockey player on April 12.
MORE MAKAR: Cale Makar of UMass named 2019 winner of Hobey Baker Award
“It’s a weird feeling playing against the team you grew up loving,” he told the Denver Post.
But that didn’t slow him down. With the goal, Makar became the first defenseman in NHL history to score in the playoffs in his first professional game.
Cale Makar of the @Avalanche is the seventh player in NHL history and first defenseman to make his League debut in the #StanleyCup Playoffs and score a goal. #NHLStats pic.twitter.com/c9IOTiOhbz — NHL Public Relations (@PR_NHL) April 16, 2019
“It was pretty weird,” Makar said. “But pretty special.”


Story 192
Apple has announced its iPhones for the 2019/2020 season: the iPhone 11, the iPhone 11 Pro and the 6.5-inch iPhone 11 Pro Max.
As ever, Apple detailed fistfuls of improvements and new features present in these new phones. But we are going to break it down and highlight only the parts that really matter if you are considering an upgrade from an iPhone XS, something older, or even an Android.
Advertisement
There are no 5G iPhones
Most major makers of Android phones have either released a 5G phone, or are planning to do so in the near future. Apple did not even mention the term “5G” in its iPhone launch. This was no huge surprise. We have known for some time the first 5G iPhone will likely arrive in 2020, not 2019.
5G is not actually a particularly compelling prospect for most of us right now. You have to pay more for the contracts and most don’t come with quite enough data to justify the extra speed. 5G is only available in a handful of UK cities. And we find 5G coverage to be very patchy, and speeds highly variable, even in the centre of London.
Read next Apple's new AirPods Pro get noise cancelling and a design makeover Apple's new AirPods Pro get noise cancelling and a design makeover
Nevertheless, upgrading to a 4G iPhone 11 may not be the wisest idea if you tend to buy one very high-end phone every 3-5 years. 5G will seem pretty mainstream in 2020-2021. Phone networks will do their best to make sure that happens too, as the infrastructure spend involved in 5G is huge.
The iPhone 11 is not an iPhone 11
Advertisement
Apple has also changed the semantic balance of power in this year’s iPhones. Last year the “iPhone XS” seemed the default iPhone. That baton has been passed to the iPhone 11, but this phone is actually an update of the more affordable iPhone XR, not the iPhone XS.
This is, to an extent, Apple following its audience. The iPhone XR sold in greater numbers than any other Apple phone over the last 12 months. We suggested Apple should focus on the iPhone XR range in a recent opinion piece. In one sense it has, even if there is no new “R” model at all.
The iPhone 11 gains a certain credibility in the loss of the “R”, becoming the default iPhone rather than an offshoot branch. But it has some of the same drawbacks as the previous lower-tier iPhones.
Read next iPhone 11 Pro and Pro Max review: the best yet, but you don’t care iPhone 11 Pro and Pro Max review: the best yet, but you don’t care
Its screen uses a lower-resolution LCD panel, not an ultra-high pixel density OLED. Its sides are aluminium rather than the steel seen in the iPhone 11 Pros and all the previous iPhone X and Xs models. And it does not have a telephoto camera lens.
Advertisement
Better battery for the Pros
Battery life appears to be one of the more compelling reasons to upgrade to the iPhone 11 series. Last year the iPhone XR was comfortably the longest-lasting of the new phones.
The iPhone 11 builds on this appeal, adding an extra hour of video playback off a full charge according to Apple’s own testing. Stamina gains in the Pro range are much more substantial, though.
Let’s use Apple’s video playback figures to compare. The iPhone X was rated for 12 hours, the iPhone XS 14 hours. These phones are widely considered to have fairly mediocre stamina for anyone approaching a “power user”. The iPhone XS Max was pegged at 15 hours, and the XR at 16 hours.
Our 2019/2020 league table looks completely different. Apple says the iPhone 11 Pro lasts for 18 hours of video, the iPhone 11 Pro Max 20 hours. And the iPhone 11 lasts 17 hours. This is initially confusing. How has the Pro range flipped things when all three new phones should benefit from the power efficiency of the new Apple A13 Bionic processor?
Read next More radio, more live: where Apple Music's headed in 2020 More radio, more live: where Apple Music's headed in 2020
We need to look at one stat Apple did not mention, thickness, and extrapolate one Apple never puts on its spec sheets, battery capacity. The iPhone 11 Pros are 0.4mm thicker than the iPhone XS and XS Max. That is because Apple has increased the battery capacity of both by 20%.
If you are frustrated by the battery life of your iPhone X or iPhone XS phone, the iPhone 11 Pros seem to solve that issue.
The 11 series gets Night mode
Apple has also fixed another major iPhone complaint, the quality of these phones’ low-light image quality. The iPhone X and iPhone XS series lagged behind phones from the likes of Huawei, which was the first to put serious time and money into developing ultra-low light camera performance.
This seems to have finally been rectified with “Night” mode. It does more-or-less what the Google and Huawei modes do, combining a handful of exposures to radically improve dynamic range, detail and the perceived brightness of low-light photos.
It is arguably the single most important upgrade of the iPhone 11 range for keen mobile photographers. Ready to get annoyed? As this is primarily a software improvement, Apple could create a version of it for the iPhone XS and iPhone X ranges. But, for now at least, it is an iPhone 11-exclusive feature.
Read next Apple iPhone 11 review: forget the Pro, this is the iPhone you need Apple iPhone 11 review: forget the Pro, this is the iPhone you need
Apple says Night mode uses short exposures captured in anticipation of the shutter press, as well as ones shot after, which may well make it faster than the Huawei P30 Pro’s take.
And an ultra wide angle lens
All three iPhone 11s also have a 120-degree wide angle camera. These are, just like dedicated night modes, common in high-end Android phones. But this is the first time one has been added to an iPhone.
Wide-angle cameras are always fun to experiment with. They can emphasise the scale of your subject in a manner you’d never achieve by stepping backwards and using the standard-view camera. The night mode is still likely more important for more photographers, particularly as some of the most impressive new features concern video, not stills.
iPhone 11s have two rear cameras, the Pro models three, and all of them can shoot 4K video at 60 frames per second. This kind of consistency of standards is very “Apple”, and effectively continues where the iPhone X and iPhone XS ranges left off. Both let you shoot 4K, 60 frames with their dual rear cameras.
Read next The iOS Checkm8 jailbreak is hugely significant, but not for you The iOS Checkm8 jailbreak is hugely significant, but not for you
Extended Dynamic range is the new iPhone 11-only software feature for video. This involves shooting at 120fps for a 60fps result, combining two exposures with different exposure durations per frame to enhance shadow detail. Consider the physics of this and you’ll realise it will only work particularly well in great lighting, though.
Two of the most important iPhone 11 upgrades are the Night mode and the fact that the “blurry background” Portrait mode can now be used to take pictures of objects (and, yes, pets) as well as people.
This is thanks to the ultra-wide camera. As it covers the field of view of the main 28mm lens (and more besides), it lets the iPhone 11 create stereoscopic depth maps. This is the technique the first “background blur” phones used. The iPhone X and iPhone XS range Portrait modes were relatively unusual in that they relied on machine learning-based facial recognition, not the parallax effect.
All three phones also have better selfie cameras than the iPhone X and iPhone XS. Apple used 7-megapixel selfie cameras in 2016’s iPhone 7 and continued with the same core spec until now, switching to 12-megapixel sensors.
These will capture, you guessed it, 4K 60 frames per second video just like the rear cameras. And there’s a new 1080p 120fps mode that let Apple dip into the world of cringey marketing portmanteau with the term “slofie”. A Slofie is a slow motion selfie, to be seen spattered all over social media from September 20, when the phones are released.
Read next Amazon and Apple are quietly building networks that know the location of everything Amazon and Apple are quietly building networks that know the location of everything
More power than last year
And are these phones more powerful too? Yes, but the use of the new Apple A13 Bionic processor may make you question the validity of the “Pro” series phones.
The Apple A13 Bionic has a roughly 20 per cent more powerful CPU and 20 per cent added GPU power over the A12 Bionic of the iPhone XS and iPhone XS Max. This is a respectable boost in power, but less than we’ve seen in previous years. That the £729 iPhone 11 uses the same processor as the Pro models lessens the impact of those more expensive models.
There simply isn’t the same gap in power seen in the iPad and iPad Pros, which have “X” series CPUs. And do we need it the extra power? No. These iPhone 11 models didn’t gain Apple Pencil support to make use of taxing creativity apps. And those big art apps and somewhat comparable music production suites just make more sense on a larger canvas.
Even when demonstrating what is perhaps the most taxing game in the first wave of Apple Arcade titles, the Dark Souls-inspired Pascal’s Wager, the developer said the aim was 60fps performance. This tell us the actual visual fidelity is geared towards lower-end hardware. We don’t need 60fps mobile games.
Divisive design – and watch out for the iPhone XR
There has already been some minor backlash online around the iPhone 11s’ design. The Pro models are thicker and heavier than last year’s XS phones, and the look of the new camera housing has raised eyebrows.
Read next Apple's dropped some huge hints about its first AR glasses Apple's dropped some huge hints about its first AR glasses
Apple has attempted to “style out” that the new camera array makes the housing bloom out of the rear panel slightly, using a single milled piece of glass that avoids seams. The combined effect may seem unsightly if you are used to the low-key rear of an iPhone XS Max.
One other important point is liable to get lost in the discussion of new specs and design changes: the new range’s pricing. The weakened pound has done UK buyers no favours, with sterling figures rising above the dollar count in the US. But Apple’s more affordable iPhones are more attractive than they have been in a long time.
Apple’s iPhone XS and XS Max have been discontinued, but the iPhone XR has not. This phone now costs £629, only slightly more expensive than the Samsung Galaxy S10. And the iPhone XR is more powerful by most metrics.
If only the iPhone XR gained the Night photography mode of the iPhone 11, it would be the smart choice for many. While the £629 price itself is in no way groundbreaking, the phone is far more compelling than the “budget” £599 iPhone 8 seemed last year.
The iPhone 11 costs marginally less than the iPhone XR did at launch too, despite UK-wide price increases, at £729 instead of £749. Prices for the other phones in the 2019 range track fairly well with those of the iPhone XS, though. The iPhone 11 Pro starts at £1,049, the iPhone 11 Pro Max £1,149.
Read next The best Apple Arcade games you should download first The best Apple Arcade games you should download first
Verdict
These may not be the prettiest iPhones ever, but Apple does seem to have listened more than it has in the past. People complained the iPhone XS battery didn’t last long enough. The iPhone 11 Pro should now beat many rival Androids, as well as the iPhone X and iPhone XS.
The series also appears to have finally caught up with Samsung, Google and Huawei by introducing a dedicated Night camera mode that will radically increase shooting flexibility. And the sensible middle-ground iPhone 11 has been given the naming prominence it deserves.
Those upgrading from an iPhone several years old should also consider the iPhone XR, though. Aside from the lack of the Night camera mode it is not dated in any significant way. Its price, and that of the iPhone 11, are clearly intended to attract those who might normally buy an Android. At a time when Apple’s growth in iPhone sales has slowed, this kind of humility may prove sensible.
More great stories from WIRED
💩 Japanese self-cleaning toilets are conquering the West
📱 The new Android 10 features that will transform your phone
📖 The best sci-fi books everyone should read
🍫 The foods you'll really need to stockpile for no-deal Brexit
Advertisement
♻️ The truth behind the UK's biggest recycling myths
📧 Get the best tech deals and gadget news in your inbox

Story 193
Dallas-Fort Worth ranked No. 11 for patent activity out of 250 metros. Patents granted include: • An unassigned patent for a remotely controlled smart fence • Bell Textron's "mutually symbiotic aircraft systems" • CPG Technologies' geolocation using guided surface waves • I D YOU's audio announcement to called parties • IBM's "empathetic image selection" • Roka Sports' eyeglasses with interchangeable lenses • Siemens Healthcare's next-generation MRI spine evaluation • The Snoring Center's airway implant delivery device
Dallas Invents is a weekly look at U.S. patents granted with a connection to the Dallas-Fort Worth-Arlington metro area. Listings include patents granted to local assignees and/or those with a North Texas inventor. Patent activity can be an indicator of future economic growth, as well as the development of emerging markets and talent attraction. By tracking both inventors and assignees in the region, we aim to provide a broader view of the region’s inventive activity. Listings are organized by Cooperative Patent Classification (CPC).
THIS WEEK, BY THE NUMBERS
Week of Aug. 29, 2017 | Dallas-Fort Worth-Arlington (19100)
162 patents granted
Ranked No. 11 in patent production out of 250 metros
NO. OF PATENTS BY CLASSIFICATION
TOP LOCAL ASSIGNEES (NO. OF PATENTS)
Texas Instruments Inc. (Dallas) 22
Futurewei Technologies Inc. (Plano) 12
Toyota Motor Engineering Manufacturing North America, Inc. (Plano) 11
Building Materials Investment Corporation (Dallas) 3
TRAXXAS LP (McKinney) 3
UNASSIGNED 9
TOP LOCAL INVENTORS (NO. OF PATENTS)
David Mehrl (Plano) 2
Kerry Glover (Rockwall) 2
Monica Rose Martino (Plano) 2
Vijayakrishna J. Vankayala (Allen) 2
SPEED: APPLICATION TO ISSUE (NO. OF DAYS)

154 days
Current mode logic driver with level shifter
Patent No. 10396794
Assignee: Texas Instruments Inc. (Dallas)
Inventor: Steven Ernest Finn (Chamblee, GA)
4,548 days
Collections of linked databases
Patent No. 10395326
Assignees: Degrees LLC (Plano)
Inventors: Brian N. Smith (Plymouth Meeting, PA), Heather A. McGuire (Plymouth Meeting, PA), Michael J. Markus (Plymouth Meeting, PA), Peter M. Kionga-Kamau (Charlottesville, VA)
Don’t miss Dallas Invents: Sign up for the Dallas Innovates e-newsletter.
Patent information is provided by Joe Chiarella, founder of patent analytics company Patent Index and publisher of The Inventiveness Index.
For additional details on the patents granted below, search the USPTO Patent Full-Text and Image Database.
UTILITY PATENTS
H U M A N N E C E S S I T I E S
Animal toy
Patent No. 10390517
Inventor(s): Chris Wilson (Plano, TX)
Assignee(s): DOSKOCIL MANUFACTURING COMPANY, INC. (Arlington, TX)
Law Firm: Global IP Counselors, LLP (9 non-local offices)
Application No., Date, Speed: 15395182 on 12/30/2016 (970 days app to issue)
Abstract: An animal toy includes an elongated body portion having a first end and a second end, a first wheel disposed adjacent the first end, a second wheel disposed adjacent the second end, at least one electric motor configured to drive the first wheel and the second wheel independently, a receiver configured to receive signals from a transmitter, and a controller programmed to control the electric motor and the rotational speed and direction of each of the first and second wheels.
[A01K] ANIMAL HUSBANDRY; CARE OF BIRDS, FISHES, INSECTS; FISHING; REARING OR BREEDING ANIMALS, NOT OTHERWISE PROVIDED FOR; NEW BREEDS OF ANIMALS
Weighted rodent bait stations and related methods
Patent No. 10390527
Inventor(s): Ethan Vickery (Bedford, TX), Larry Covington (Weatherford, TX)
Assignee(s): VM PRODUCTS INC. (Bedford, TX)
Law Firm: Norton Rose Fulbright US LLP (Local + 13 other metros)
Application No., Date, Speed: 15808302 on 11/09/2017 (656 days app to issue)
Abstract: Rodent bait station assemblies and methods for assembly and bundling.
[A01M] CATCHING, TRAPPING OR SCARING OF ANIMALS (appliances for catching swarms or drone-catching A01K 57/00; fishing A01K 69/00-A01K 97/00; biocides, pest repellants or attractants A01N); APPARATUS FOR THE DESTRUCTION OF NOXIOUS ANIMALS OR NOXIOUS PLANTS
System and method for next-generation MRI spine evaluation
Patent No. 10390726
Inventor(s): David Liu (Richardson, TX)
Assignee(s): Siemens Healthcare GmbH (Erlangen, , DE)
Law Firm: No Counsel
Application No., Date, Speed: 15471250 on 03/28/2017 (882 days app to issue)
Abstract: A method of visualizing spinal nerves includes receiving a 3D image volume depicting a spinal cord and a plurality of spinal nerves. For each spinal nerve, a 2D spinal nerve image is generated by defining a surface within the 3D volume comprising the spinal nerve. The surface is curved such that it passes through the spinal cord while encompassing the spinal nerve. Then, the 2D spinal nerve images are generated based on voxels on the surface included in the 3D volume. A visualization of the 2D spinal images is presented in a graphical user interface that allows each 2D spinal image to be viewed simultaneously.
[A61B] DIAGNOSIS; SURGERY; IDENTIFICATION (analysing biological material G01N, e.g. G01N 33/48)
Airway implant delivery device
Patent No. 10390857
Inventor(s): Craig Schwimmer (Dallas, TX)
Assignee(s): The Snoring Center (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15981271 on 05/16/2018 (468 days app to issue)
Abstract: Embodiments of a delivery device for inserting multiple implants into an airway of a patient.
[A61F] FILTERS IMPLANTABLE INTO BLOOD VESSELS; PROSTHESES; DEVICES PROVIDING PATENCY TO, OR PREVENTING COLLAPSING OF, TUBULAR STRUCTURES OF THE BODY, E.G. STENTS; ORTHOPAEDIC, NURSING OR CONTRACEPTIVE DEVICES; FOMENTATION; TREATMENT OR PROTECTION OF EYES OR EARS; BANDAGES, DRESSINGS OR ABSORBENT PADS; FIRST-AID KITS (dental prosthetics A61C) [2006.01]
Thermoforming aids and methods
Patent No. 10390912
Inventor(s): Loren S. Adell (Sunnyvale, TX)
Assignee(s): UNASSIGNED
Law Firm: No Counsel
Application No., Date, Speed: 14703475 on 05/04/2015 (1576 days app to issue)
Abstract: A thermoforming aid for use in creating a thermoformed impression of an object such as a dental arch. The thermoforming aid has a thermoformable sheet which has inherent tendency to curl when unsupported, and a curl-resistant element which prevents the thermoformable sheet from curling. The thermoforming aid makes a person”s task of placing a sheet of thermoformable material, especially a very thin sheet having an inherent tendency to curl, in proper position in a thermoforming machine less difficult and time-consuming.
[A61C] DENTISTRY; APPARATUS OR METHODS FOR ORAL OR DENTAL HYGIENE (non-driven toothbrushes A46B; preparations for dentistry A61K 6/00; preparations for cleaning the teeth or mouth A61K 8/00, A61Q 11/00)
Aspiration devices and methods
Patent No. 10390926
Inventor(s): Vallabh Janardhan (Dallas, TX)
Assignee(s): Insera Therapeutics, Inc. (Sacramento, CA)
Law Firm: Knobbe Martens Olson Bear LLP (12 non-local offices)
Application No., Date, Speed: 16103410 on 08/14/2018 (378 days app to issue)
Abstract: An aspiration system includes a pump and a control system in communication with the pump. The control system includes a microcontroller, an antenna configured to receive a signal, and a pump control board in communication with the microcontroller. The antenna is in communication with the microcontroller. Upon receiving the signal, the pump control board operates the pump to create negative pressure according to the signal.
[A61M] DEVICES FOR INTRODUCING MEDIA INTO, OR ONTO, THE BODY (introducing media into or onto the bodies of animals A61D 7/00; means for inserting tampons A61F 13/26; devices for administering food or medicines orally A61J; containers for collecting, storing or administering blood or medical fluids A61J 1/05); DEVICES FOR TRANSDUCING BODY MEDIA OR FOR TAKING MEDIA FROM THE BODY (surgery A61B; chemical aspects of surgical articles A61L; magnetotherapy using magnetic elements placed within the body A61N 2/10); DEVICES FOR PRODUCING OR ENDING SLEEP OR STUPOR [5]
Automated intraocular lens injector device
Patent No. 10390941
Inventor(s): David A. Downer (Fort Worth, TX), Tu Cam Tran (Grapevine, TX)
Assignee(s): Novartis AG (Basel, , CH)
Law Firm: No Counsel
Application No., Date, Speed: 15233527 on 08/10/2016 (1112 days app to issue)
Abstract: An IOL injection device comprises a tubular housing with a plunger longitudinally disposed within the tubular housing. The device is configured so that when the plunger is translated towards the front of the device, its tip engages an intraocular lens insertion cartridge mounted at or near the front end of the housing. The IOL injection device further comprises a control circuit. The control circuit is configured to perform the steps of advancing the plunger to a critical point at which an axial compressive force on the lens suddenly increases, retracting the plunger from the critical point to a sufficient distance for material of the intraocular lens to relax, pausing to allow the material of the intraocular lens to relax, advancing the plunger to the critical point a second time, and continuing to advance the plunger beyond the critical point to implant the intraocular lens.
[A61F] FILTERS IMPLANTABLE INTO BLOOD VESSELS; PROSTHESES; DEVICES PROVIDING PATENCY TO, OR PREVENTING COLLAPSING OF, TUBULAR STRUCTURES OF THE BODY, E.G. STENTS; ORTHOPAEDIC, NURSING OR CONTRACEPTIVE DEVICES; FOMENTATION; TREATMENT OR PROTECTION OF EYES OR EARS; BANDAGES, DRESSINGS OR ABSORBENT PADS; FIRST-AID KITS (dental prosthetics A61C) [2006.01]
Intervertebral disc replacement
Patent No. 10390959
Inventor(s): Isador Harry Lieberman (Plano, TX)
Assignee(s): AGADA MEDICAL LTD. (Kfar Vitkin, , IL)
Law Firm: Venable LLP (7 non-local offices)
Application No., Date, Speed: 15234923 on 08/11/2016 (1111 days app to issue)
Abstract: According to some embodiments of the invention, an intervertebral disc replacement includes a first layer having a lower surface for contacting a first vertebral bone, a second layer coupled to the first layer, the second layer comprising a plurality of compressible column springs, and a third layer coupled to the second layer, the third layer having an upper surface for contacting a second vertebral bone. Each of the plurality of compressible column springs comprises a plurality of stacked coils, and each of the plurality of stacked coils has a spring constant (K). At least one of the plurality of compressible column springs includes a first coil having a first spring constant and a second coil comprising a second spring constant, wherein the first spring constant is different from the second spring constant.
[A61F] FILTERS IMPLANTABLE INTO BLOOD VESSELS; PROSTHESES; DEVICES PROVIDING PATENCY TO, OR PREVENTING COLLAPSING OF, TUBULAR STRUCTURES OF THE BODY, E.G. STENTS; ORTHOPAEDIC, NURSING OR CONTRACEPTIVE DEVICES; FOMENTATION; TREATMENT OR PROTECTION OF EYES OR EARS; BANDAGES, DRESSINGS OR ABSORBENT PADS; FIRST-AID KITS (dental prosthetics A61C) [2006.01]
Topical skin compositions for treating wrinkles
Patent No. 10391049
Inventor(s): David Gan (Southlake, TX), Michelle Hines (Hickory Creek, TX), Tiffany Florence (Dallas, TX), Wanli Zhao (Dallas, TX)
Assignee(s): Mary Kay Inc. (Addison, TX)
Law Firm: Norton Rose Fulbright US LLP (Local + 13 other metros)
Application No., Date, Speed: 16246029 on 01/11/2019 (228 days app to issue)
Abstract: Disclosed is a method of treating a fine line or wrinkle in a person”s skin. The method includes topically applying to the fine line or wrinkle a composition comprising an effective amount of [i]Commiphora mukul [/i]resin or an extract thereof that includes oleo gum resin. Topical application of the composition to the fine line or wrinkle reduces the appearance of the fine line or wrinkle.
[A61K] PREPARATIONS FOR MEDICAL, DENTAL, OR TOILET PURPOSES (devices or methods specially adapted for bringing pharmaceutical products into particular physical or administering forms A61J 3/00; chemical aspects of, or use of materials for deodorisation of air, for disinfection or sterilisation, or for bandages, dressings, absorbent pads or surgical articles A61L; soap compositions C11D)
Antisense antibacterial compounds and methods
Patent No. 10391098
Inventor(s): David Greenberg (Coppell, TX)
Assignee(s): Board of Regents, The University of Texas System (Austin, TX), Oregon State University (Corvallis, OR)
Law Firm: Parker Highlander PLLC (1 non-local offices)
Application No., Date, Speed: 14714104 on 05/15/2015 (1565 days app to issue)
Abstract: Provided are antisense oligomers targeted against or genes associated with a biochemical pathway and/or cellular process, and related compositions and methods of using the oligomers and compositions to treat an infected mammalian subject, for example, as primary antimicrobials or as adjunctive therapies with classic antimicrobials.
[A61K] PREPARATIONS FOR MEDICAL, DENTAL, OR TOILET PURPOSES (devices or methods specially adapted for bringing pharmaceutical products into particular physical or administering forms A61J 3/00; chemical aspects of, or use of materials for deodorisation of air, for disinfection or sterilisation, or for bandages, dressings, absorbent pads or surgical articles A61L; soap compositions C11D)
Active photocatalytic oxidation
Patent No. 10391194
Inventor(s): Andrew Eide (Rockwall, TX)
Assignee(s): DBG GROUP INVESTMENTS, LLC (Dallas, TX)
Law Firm: Workman Nydegger (2 non-local offices)
Application No., Date, Speed: 15835363 on 12/07/2017 (628 days app to issue)
Abstract: An active oxidation and purifying system is provided to increase or maximize the rate of photocatalytic oxidation and ambient air purification capacity by providing both direct ultraviolet (UV) light and reflected UV light directed to the surface and apertures of active cell panels coated with a photocatalytic material. In one example, the active cells also include a plurality of apertures disposed in a transverse manner from the first surface to the second surface of the active cell. Furthermore, a first set of the apertures could be disposed about 45 degrees relative to a median axis along the first and second surfaces, while a second set of apertures could be disposed about negative 45 degrees relative to the same median axis in order to increase the surface area impinged by the direct and reflected UV light.
[A61L] METHODS OR APPARATUS FOR STERILISING MATERIALS OR OBJECTS IN GENERAL; DISINFECTION, STERILISATION, OR DEODORISATION OF AIR; CHEMICAL ASPECTS OF BANDAGES, DRESSINGS, ABSORBENT PADS, OR SURGICAL ARTICLES; MATERIALS FOR BANDAGES, DRESSINGS, ABSORBENT PADS, OR SURGICAL ARTICLES (preservation of bodies or disinfecting characterised by the agent employed A01N; preserving, e.g. sterilising, food or foodstuffs A23; preparations for medical, dental or toilet purposes A61K) [4]
Medical device with selectively retractable needle cap
Patent No. 10391264
Inventor(s): Ni Zhu (Plano, TX), Thomas J. Shaw (Frisco, TX)
Assignee(s): Retractable Technologies, Inc (Little Elm, TX)
Law Firm: Ross Barnes LLP (1 non-local offices)
Application No., Date, Speed: 14679847 on 04/06/2015 (1604 days app to issue)
Abstract: A medical device having a forwardly-projecting needle and a selectively-movable needle cap that can be variously positioned to cover all or a portion of the needle, depending upon whether the device is, for example, being transported, aspirated or used to inject a therapeutic fluid. The device can optionally be configured to enable retraction of the needle into the body for safe disposal following use.
[A61M] DEVICES FOR INTRODUCING MEDIA INTO, OR ONTO, THE BODY (introducing media into or onto the bodies of animals A61D 7/00; means for inserting tampons A61F 13/26; devices for administering food or medicines orally A61J; containers for collecting, storing or administering blood or medical fluids A61J 1/05); DEVICES FOR TRANSDUCING BODY MEDIA OR FOR TAKING MEDIA FROM THE BODY (surgery A61B; chemical aspects of surgical articles A61L; magnetotherapy using magnetic elements placed within the body A61N 2/10); DEVICES FOR PRODUCING OR ENDING SLEEP OR STUPOR [5]
Medical device with distal torque control
Patent No. 10391274
Inventor(s): Brian Giles (Dallas, TX)
Assignee(s): UNASSIGNED
Law Firm: Knobbe, Martens, Olson Bear LLP (9 non-local offices)
Application No., Date, Speed: 15204800 on 07/07/2016 (1146 days app to issue)
Abstract: A catheter with a distal end that rotates through the conversion of linear motion to rotational motion, thus the distal end may be rotated without longitudinally advancing or retracting the distal end. The catheter includes a tube with a single helix or a dual chirality helix cut into the tube, a distal end segment, means for linear displacement of the helix, and means for coupling the junction point of the helix to the distal segment.
[A61M] DEVICES FOR INTRODUCING MEDIA INTO, OR ONTO, THE BODY (introducing media into or onto the bodies of animals A61D 7/00; means for inserting tampons A61F 13/26; devices for administering food or medicines orally A61J; containers for collecting, storing or administering blood or medical fluids A61J 1/05); DEVICES FOR TRANSDUCING BODY MEDIA OR FOR TAKING MEDIA FROM THE BODY (surgery A61B; chemical aspects of surgical articles A61L; magnetotherapy using magnetic elements placed within the body A61N 2/10); DEVICES FOR PRODUCING OR ENDING SLEEP OR STUPOR [5]
Systems, methods, and devices for evaluating lead placement based on generated visual representations of sacrum and lead
Patent No. 10391321
Inventor(s): Norbert Kaula (Arvada, CO), Steven Siegel (North Oaks, MN), Yohannes Iyassu (Denver, CO)
Assignee(s): NUVECTRA CORPORATION (Plano, TX)
Law Firm: Haynes and Boone, LLP (Local + 13 other metros)
Application No., Date, Speed: 15688454 on 08/28/2017 (729 days app to issue)
Abstract: A method of evaluating an implantation of a lead is disclosed. Via a graphical user interface of an electronic device, a visual representation of a sacrum of the patient and a lead that is implanted in the sacrum is displayed. The lead includes a plurality of electrode contacts. An evaluation is made as to how well the lead has been implanted in the sacrum based on the visual representation of the sacrum and the lead. The evaluating comprises: determining whether the lead is inserted in a predetermined region of the sacrum, determining how far a predetermined one of the electrode contacts is located from an edge of the sacrum, and determining a degree of curvature of the lead.
[A61N] ELECTROTHERAPY; MAGNETOTHERAPY; RADIATION THERAPY; ULTRASOUND THERAPY (measurement of bioelectric currents A61B; surgical instruments, devices or methods for transferring non-mechanical forms of energy to or from the body A61B 18/00; anaesthetic apparatus in general A61M; incandescent lamps H01K; infra-red radiators for heating H05B) [6]
Aerodynamic golf club head
Patent No. 10391366
Inventor(s): Jeffrey J. Albertsen (Plano, TX), Michael Scott Burnett (McKinney, TX)
Assignee(s): TAYLOR MADE GOLF COMPANY, INC. (Carlsbad, CA)
Law Firm: Dawsey Co., LPA (1 non-local offices)
Application No., Date, Speed: 15959896 on 04/23/2018 (491 days app to issue)
Abstract: An aerodynamic golf club head producing reduced aerodynamic drag forces via the curvature of a crown section. At least a portion of the crown section may be composed of low density materials, including nonmetallic materials.
[A63B] APPARATUS FOR PHYSICAL TRAINING, GYMNASTICS, SWIMMING, CLIMBING, OR FENCING; BALL GAMES; TRAINING EQUIPMENT (apparatus for passive exercising, massage A61H)
O P E R A T I O N S & T R A N S P O R T
Coating application with automated brushing
Patent No. 10391514
Inventor(s): Dan LeLievre (Cambridge, , CA), Frank Zolli (Brantford, , CA), Michael Horn (Kitchener, , CA)
Assignee(s): Toyota Motor Engineering Manufacturing North America, Inc. (Plano, TX)
Law Firm: Darrow Mustafa PC (2 non-local offices)
Application No., Date, Speed: 15628980 on 06/21/2017 (797 days app to issue)
Abstract: Arrangements described herein include coating application systems and methods for controlling such systems. The system can include an application end configured to be operatively connected to a robot arm. The application end can include one or more nozzles to dispense a coating onto a workpiece. The application end can further include one or more brushes to brush a portion of the coating dispensed onto the workpiece. The brush can be moveable between a retracted position and a deployed position. In some arrangements, the systems can include a cleaning tool to remove excess coating from the brush after brushing.
[B05C] APPARATUS FOR APPLYING LIQUIDS OR OTHER FLUENT MATERIALS TO SURFACES, IN GENERAL (spraying apparatus, atomising apparatus, nozzles B05B; plant for applying liquids or other fluent materials to objects by electrostatic spraying B05B 5/08) [2]
Modular robot with smart device
Patent No. 10391631
Inventor(s): Douglas A. Moore (Livermore, CA), Joseph M. A. Djugash (San Jose, CA)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Snell Wilmer LLP (5 non-local offices)
Application No., Date, Speed: 15451313 on 03/06/2017 (904 days app to issue)
Abstract: A wearable smart device is configured to be positioned on and external to a robot having a robot sensor for sensing robot data and a robot input/output port. The wearable smart device includes a device sensor capable of detecting device data corresponding to an environment of the wearable smart device. The wearable smart device also includes a device input/output port. The wearable smart device also includes a device processor coupled to the robot sensor via the robot input/output port and the device input/output port. The device processor is also coupled to the device sensor and configured to control the robot based on the robot data and the device data.
[B25J] MANIPULATORS; CHAMBERS PROVIDED WITH MANIPULATION DEVICES (robotic devices for individually picking fruits, vegetables, hops or the like A01D 46/30; needle manipulators for surgery A61B 17/062; manipulators associated with rolling mills B21B 39/20; manipulators associated with forging machines B21J 13/10; means for holding wheels or parts thereof B60B 30/00; cranes B66C; arrangements for handling fuel or other materials which are used within nuclear reactors G21C 19/00; structural combination of manipulators with cells or rooms shielded against radiation G21F 7/06) [5]
Shaving systems
Patent No. 10391654
Inventor(s): Craig A. Provost (Boston, MA), Douglas R. Kohring (Arrowsic, ME), John W. Griffin (Moultonborough, NH), William E. Tucker (Attleboro, MA)
Assignee(s): ShaveLogic, Inc. (Dallas, TX)
Law Firm: Leber IP Law (2 non-local offices)
Application No., Date, Speed: 16009938 on 06/15/2018 (438 days app to issue)
Abstract: Replaceable shaving assemblies are disclosed that include a blade unit, an interface element configured to removeably connect the blade unit to a handle, on which the blade unit is pivotably mounted, and a return element disposed between the blade unit and interface element. The return element serves as interface piece, connector and pivot all in one. Shaving systems including such shaving assemblies are also disclosed, as are methods of using such shaving systems.
[B26B] HAND-HELD CUTTING TOOLS NOT OTHERWISE PROVIDED FOR (for harvesting A01D; for horticulture, for forestry A01G; for butchering or meat treatment A22; for manufacturing or repairing footwear A43D; nail clippers or cutters A45D 29/02; kitchen equipment A47J; for surgical purposes A61B 17/00; for metal B23D; cutting by abrasive fluid jets B24C 5/02; plier-like tools with cutting edges B25B 7/22; pincers B25C 11/02; handles for hand implements, in general B25G; guillotine-type cutters B26D; for erasing B43L 19/00; for textile materials D06H)
Writing board and method of use
Patent No. 10391811
Inventor(s): Kevin Geldard (Haltom City, TX)
Assignee(s): UNASSIGNED
Law Firm: Eldredge Law Firm, LLC (2 non-local offices)
Application No., Date, Speed: 14589183 on 01/05/2015 (1695 days app to issue)
Abstract: A writing board system includes a writing device and a board having a powder coating substrate and a thermosetting powder coating resin applied to the powder coating substrate. A method includes preparing the powder coating substrate and spraying the thermosetting powder coating resin applied to the powder coating substrate.
[B32B] LAYERED PRODUCTS, i.e. PRODUCTS BUILT-UP OF STRATA OF FLAT OR NON-FLAT, e.g. CELLULAR OR HONEYCOMB, FORM
Automatically deployable vehicle shade system
Patent No. 10391842
Inventor(s): Danil V. Prokhorov (Canton, MI)
Assignee(s): Toyota Motor Engineering Manufacturing North America, Inc. (Plano, TX)
Law Firm: Darrow Mustafa PC (2 non-local offices)
Application No., Date, Speed: 15292110 on 10/12/2016 (1049 days app to issue)
Abstract: A computing system for a vehicle includes one or more processors and a memory for storing data and program instructions usable by the one or more processors. The one or more processors are configured to execute instructions stored in the memory to determine if a virtual straight line connecting a predetermined location within a vehicle with a light source external to the vehicle passes through a window of the vehicle. If the straight line passes through a window, it is determined if the straight line will pass through any deployable vehicle shade if the shade is deployed. If the straight line will pass through a shade if the shade is deployed and the shade through which the straight line will pass is not already deployed, the vehicle may be operated so as to deploy the shade through which the straight line will pass if the shade is deployed.
[B60J] WINDOWS, WINDSCREENS, NON-FIXED ROOFS, DOORS, OR SIMILAR DEVICES FOR VEHICLES; REMOVABLE EXTERNAL PROTECTIVE COVERINGS SPECIALLY ADAPTED FOR VEHICLES (fastening, suspending, closing, or opening of such devices E05)
Vehicle display screen safety and privacy system
Patent No. 10391844
Inventor(s): Suhas E. Chelian (San Jose, CA)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Snell Wilmer LLP (5 non-local offices)
Application No., Date, Speed: 15967282 on 04/30/2018 (484 days app to issue)
Abstract: A system for improving safety while providing privacy for a vehicle. The system includes a display screen located within the vehicle, configured to alternate between a displaying state and a non-displaying state. The system includes a window configured to alternate between an opaque state and a transparent state. The system includes an electronic control unit (ECU) configured to determine whether the display screen is powered on. The ECU is configured to alternate the display screen between the displaying state and the non-displaying state at a predetermined frequency when the display screen is powered on. The ECU is configured to alternate the window between the opaque state and the transparent state at the predetermined frequency, the display screen being in the displaying state when the window is in the opaque state and the display screen being in the non-displaying state when the window is in the transparent state.
[B60J] WINDOWS, WINDSCREENS, NON-FIXED ROOFS, DOORS, OR SIMILAR DEVICES FOR VEHICLES; REMOVABLE EXTERNAL PROTECTIVE COVERINGS SPECIALLY ADAPTED FOR VEHICLES (fastening, suspending, closing, or opening of such devices E05)
System to balance high voltage battery for vehicle
Patent No. 10391864
Inventor(s): Justin J. Chow (Los Angeles, CA), Tapan V. Patel (Lakewood, CA)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Snell Wilmer LLP (5 non-local offices)
Application No., Date, Speed: 15427913 on 02/08/2017 (930 days app to issue)
Abstract: A system includes a battery pack designed to store electrical energy at a rated voltage and having a first and second battery module, each having a plurality of battery cells, and at least one switch selectively coupled to the battery modules. The system further includes an on-board charger that receives electrical power. The system further includes an ECU that determines a current voltage of the battery modules. The ECU also controls the at least one switch to transfer the electrical power to a combination of the battery modules until the current voltage of the first battery module or the second battery module reaches the rated voltage. The ECU also controls the at least one switch to transfer the electrical power to the first battery module when the current voltage of the first battery module is less than the current voltage of the second battery module.
[B60L] PROPULSION OF ELECTRICALLY-PROPELLED VEHICLES (arrangements or mounting of electrical propulsion units or of plural diverse prime-movers for mutual or common propulsion in vehicles B60K 1/00, B60K 6/20; arrangements or mounting of electrical gearing in vehicles B60K 17/12, B60K 17/14; preventing wheel slip by reducing power in rail vehicles B61C 15/08; dynamo-electric machines H02K; control or regulation of electric motors H02P); SUPPLYING ELECTRIC POWER FOR AUXILIARY EQUIPMENT OF ELECTRICALLY-PROPELLED VEHICLES (electric coupling devices combined with mechanical couplings of vehicles B60D 1/64; electric heating for vehicles B60H 1/00); ELECTRODYNAMIC BRAKE SYSTEMS FOR VEHICLES IN GENERAL (control or regulation of electric motors H02P); MAGNETIC SUSPENSION OR LEVITATION FOR VEHICLES; MONITORING OPERATING VARIABLES OF ELECTRICALLY-PROPELLED VEHICLES; ELECTRIC SAFETY DEVICES FOR ELECTRICALLY-PROPELLED VEHICLES [4]
Support systems for portable electronic devices
Patent No. 10391951
Inventor(s): Andrew B. Severance (Fort Worth, TX), Eric L. Parks (Denton, TX), Jason K. Smith (Denton, TX), Wade G. Matthews (Argyle, TX)
Assignee(s): Safran Seats USA LLC (Gainesville, TX)
Law Firm: Kilpatrick Townsend Stockton LLP (14 non-local offices)
Application No., Date, Speed: 15517694 on 11/18/2015 (1378 days app to issue)
Abstract: Described are passenger seats that include a system for storing objects disposed on a rear side of the passenger seat. The system may include a cavity and a divider wall disposed within the cavity, wherein the divider wall separates a lower portion of the cavity into at least two compartments including a personal electronic device compartment on a rear side of the cavity and a secondary compartment on a forward side of the cavity.
[B60R] VEHICLES, VEHICLE FITTINGS, OR VEHICLE PARTS, NOT OTHERWISE PROVIDED FOR (fire prevention, containment or extinguishing specially adapted for vehicles A62C 3/07)
Efficient acceleration semi-autonomous feature
Patent No. 10392001
Inventor(s): Geoffrey D. Gaither (Brighton, MI), Joshua D. Payne (Ann Arbor, MI)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Snell Wilmer LLP (5 non-local offices)
Application No., Date, Speed: 15675551 on 08/11/2017 (746 days app to issue)
Abstract: A system includes a power source to generate power to propel the vehicle, and a speed sensor to detect a current speed. The system also includes a camera to detect image data corresponding to a current roadway, and a GPS sensor to detect location data corresponding to a current location of the vehicle. The system also includes an ECU. The ECU is designed to determine a target vehicle speed based on at least one of the image data or the location data. The ECU is also designed to calculate an energy-efficient acceleration pattern to accelerate the vehicle from the current speed to the target vehicle speed based on a goal to minimize energy usage of the power source. The ECU is also designed to control the power source to accelerate the vehicle from the current speed to the target vehicle speed using the energy-efficient acceleration pattern.
[B60K] ARRANGEMENT OR MOUNTING OF PROPULSION UNITS OR OF TRANSMISSIONS IN VEHICLES; ARRANGEMENT OR MOUNTING OF PLURAL DIVERSE PRIME-MOVERS IN VEHICLES; AUXILIARY DRIVES FOR VEHICLES; INSTRUMENTATION OR DASHBOARDS FOR VEHICLES; ARRANGEMENTS IN CONNECTION WITH COOLING, AIR INTAKE, GAS EXHAUST OR FUEL SUPPLY OF PROPULSION UNITS IN VEHICLES [2006.01]
Navigation-enhanced battery state of charge maintenance
Patent No. 10392003
Inventor(s): Thomas S. Hawley (Ann Arbor, MI)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Sheppard, Mullin, Richter Hampton LLP (7 non-local offices)
Application No., Date, Speed: 15669762 on 08/04/2017 (753 days app to issue)
Abstract: Systems and methods provide control the amount of battery SOC of a hybrid vehicle prior to reaching a downgrade section of roadway in order to offset the amount of energy that the hybrid vehicle will recuperate when traveling the downgrade. Navigation systems and methods are used to identify upcoming road conditions, such as downgrades. In this way, the battery SOC of the hybrid vehicle can maintain the capacity to allow a motor of the hybrid vehicle to assist in decelerating the hybrid vehicle during the downgrade if need be. Additionally, a situation where the battery is fully charged before reaching the end of the downgrade is avoided, which if not, could result in overcharging the battery, or having to switch to an engine-only mode of travel, where a driver must supplement engine braking with friction braking.
[B60W] CONJOINT CONTROL OF VEHICLE SUB-UNITS OF DIFFERENT TYPE OR DIFFERENT FUNCTION; CONTROL SYSTEMS SPECIALLY ADAPTED FOR HYBRID VEHICLES; ROAD VEHICLE DRIVE CONTROL SYSTEMS FOR PURPOSES NOT RELATED TO THE CONTROL OF A PARTICULAR SUB-UNIT [2006.01]
Systems and methods of decoupling vehicle steering assemblies with indication of vehicle direction
Patent No. 10392045
Inventor(s): Jason J. Hallman (Saline, MI)
Assignee(s): Toyota Motor Engineering Manufacturing North America, Inc. (Plano, TX)
Law Firm: Dinsmore Shohl LLP (14 non-local offices)
Application No., Date, Speed: 15444930 on 02/28/2017 (910 days app to issue)
Abstract: A vehicle includes a steering column assembly including a steering column. A steering wheel apparatus is connected to the steering column. The steering wheel apparatus includes a steering wheel hub that is connected to the steering column and a steering wheel rim that is connected to the steering wheel hub. A clutch mechanism selectively decouples the steering wheel rim from the steering wheel hub thereby allowing rotation of the steering wheel hub within the steering wheel rim.
[B62D] MOTOR VEHICLES; TRAILERS (steering, or guiding on a desired track, of agricultural machines or implements A01B 69/00; wheels, castors, axles, increasing wheel adhesion B60B; vehicle tyres, tyre inflation or tyre changing B60C; connections between vehicles of a train or the like B60D; vehicles for use on rail and road, amphibious or convertible vehicles B60F; suspension arrangements B60G; heating, cooling, ventilating or other air treating devices B60H; windows, windscreens, non-fixed roofs, doors or similar devices, protective coverings for vehicles not in use B60J; propulsion plant arrangements, auxiliary drives, transmissions, controls, instrumentation or dashboards B60K; electric equipment or propulsion of electrically-propelled vehicles B60L; power supply for electrically-propelled vehicles B60M; passenger accommodation not otherwise provided for B60N; adaptations for load transportation or to carry special loads or objects B60P; arrangement of signalling or lighting devices, the mounting or supporting thereof or circuits therefor, for vehicles in general B60Q; vehicles, vehicle fittings or vehicle parts, not otherwise provided for B60R; servicing, cleaning, repairing, supporting, lifting, or manoeuvring, not otherwise provided for B60S; brake arrangements, brake control systems or parts thereof B60T; air-cushion vehicles B60V; motorcycles, accessories therefor B62J, B62K; testing of vehicles G01M)
High stiffness hub assemblies for rotor systems
Patent No. 10392098
Inventor(s): Frank Bradley Stamps (Colleyville, TX), Jouyoung Jason Choi (Southlake, TX), Richard Erler Rauber (Euless, TX), Tyler Wayne Baldwin (Keller, TX)
Assignee(s): Bell Textron Inc. (Fort Worth, TX)
Law Firm: Lawrence Youst PLLC (Local)
Application No., Date, Speed: 16289438 on 02/28/2019 (180 days app to issue)
Abstract: A high stiffness hub assembly for a rotor system operable to rotate with a mast of a rotorcraft. The hub assembly includes a yoke and a constant velocity joint assembly. The yoke has a plurality of blade arms each configured to hold a rotor blade. The constant velocity joint assembly provides a torque path from the mast to the yoke that includes a trunnion assembly, a plurality of drive links and a plurality of pillow blocks. The trunnion assembly is coupled to the mast and has a plurality of outwardly extending trunnions. Each drive link has a leading bearing coupled to one of the trunnions and a trailing bearing coupled to one of the pillow blocks. Each pillow block is independently mounted between an upper surface of the yoke and a hub plate.
[B63H] MARINE PROPULSION OR STEERING (propulsion of air-cushion vehicles B60V 1/14; peculiar to submarines, other than nuclear propulsion, B63G; peculiar to torpedoes F42B 19/00)
System and method for assisting in rotor speed control
Patent No. 10392105
Inventor(s): Eric O”Neill (Great Mills, MD), Jignesh Patel (Trophy Club, TX), Joseph M. Schaeffer (Cedar Hill, TX)
Assignee(s): Bell Helicopter Textron Inc. (Fort Worth, TX)
Law Firm: Timmer Law Group, PLLC (1 non-local offices)
Application No., Date, Speed: 15642279 on 07/05/2017 (783 days app to issue)
Abstract: A method of assisting in rotor speed control in a rotorcraft can include measuring a rotor speed with a sensor; detecting a droop in the rotor speed beyond a lower droop limit; and commanding a decrease in collective in response to the rotor speed drooping beyond the lower droop limit. A system of assisting in rotor speed control in a rotorcraft, the system can include: a computer having a control law, the control law operable to generate a decrease collective command to an actuator in response to a rotor speed decreasing below a lower droop limit; wherein the lower droop limit is below a normal lower rotor speed range.
[B64C] AEROPLANES; HELICOPTERS (air-cushion vehicles B60V)
Mutually symbiotic aircraft systems
Patent No. 10392109
Inventor(s): Brett Rodney Zimmerman (Fort Worth, TX), Frank Bradley Stamps (Fort Worth, TX), John William Lloyd (Fort Worth, TX), Joseph Scott Drennan (Fort Worth, TX)
Assignee(s): Bell Textron Inc. (Fort Worth, TX)
Law Firm: Lawrence Youst PLLC (Local)
Application No., Date, Speed: 15341887 on 11/02/2016 (1028 days app to issue)
Abstract: An aircraft system includes a wing member and a plurality of unmanned aircraft systems selectively connectable to the wing member. The wing member has a generally airfoil cross-section, a leading edge and a trailing edge. The unmanned aircraft systems have a connected flight mode while coupled to the wing member and an independent flight mode when detached from the wing member. In the connected flight mode, the unmanned aircraft systems are operable to provide propulsion to the wing member to enable flight. The unmanned aircraft systems are operable to be launched from the wing member to perform aerial missions in the independent flight mode and are operable to be recovered by the wing member and returned to the connected flight mode. Thereafter, in the connected flight mode, the unmanned aircraft systems are operable to be resupplied by the wing member.
[B64C] AEROPLANES; HELICOPTERS (air-cushion vehicles B60V)
Turbine engine fleet wash management system
Patent No. 10392964
Inventor(s): George F. Griffiths (Southlake, TX)
Assignee(s): Rolls-Royce Corporation (Indianapolis, IN)
Law Firm: Barnes Thornburg LLP (Local + 12 other metros)
Application No., Date, Speed: 15796117 on 10/27/2017 (669 days app to issue)
Abstract: A turbine engine fleet wash management system is configured to electronically communicate with a turbine engine system, a fleet management service, and a cleaning management service. The turbine engine fleet wash system causes a cleaning of a turbine engine to occur based on information received from the turbine engine system and other sources. The turbine engine fleet wash management system includes a cleaning schedule optimizer that generates a cleaning schedule based on engine health monitoring data, engine operation data, maintenance schedules for the turbine engine, and cleaning regimen data. The cleaning schedule optimizer estimates turbine engine performance improvements based on the selected cleaning regimen, and calculating an estimate of carbon credits earned based on the predicted improvement in turbine engine performance.
[B08B] CLEANING IN GENERAL; PREVENTION OF FOULING IN GENERAL (brushes A46; devices for domestic or like cleaning A47L; separation of particles from liquids or gases B01D; separation of solids B03, B07; spraying or applying liquids or other fluent materials to surfaces in general B05; cleaning devices for conveyors B65G 45/10; concurrent cleaning, filling and closing of bottles B67C 7/00; inhibiting corrosion or incrustation in general C23; cleaning streets, permanent ways, beaches or land E01H; parts, details or accessories of swimming or splash baths or pools, specially adapted for cleaning E04H 4/16; preventing or removing electrostatic charges H05F)
Tethered air intake snorkel
Patent No. 10393076
Inventor(s): Jakin C. Wilson (Prosper, TX), Stephen E. Freeman (McKinney, TX)
Assignee(s): Toyota Motor North America, Inc. (Plano, TX)
Law Firm: Darrow Mustafa PC (2 non-local offices)
Application No., Date, Speed: 16117160 on 08/30/2018 (362 days app to issue)
Abstract: A tethered air intake snorkel for a vehicle includes a snorkel head comprising a head sidewall defining a head air conduit, an air intake comprising an intake opening into the head air conduit on an intake end, and a head attachment flange; a snorkel body comprising a body sidewall defining a body air conduit, an outer attachment flange configured for mating engagement with and attachment to the head attachment flange on an outer end, and an inner attachment flange on an inner end; and a flexible tether that extends between a head attachment end and a body attachment end and is configured to tether the snorkel head to the snorkel body, the head attachment end configured for disposition within the head air conduit and attachment to the head sidewall, the body attachment end configured for disposition within the body air conduit and attachment to the body sidewall.
[B60K] ARRANGEMENT OR MOUNTING OF PROPULSION UNITS OR OF TRANSMISSIONS IN VEHICLES; ARRANGEMENT OR MOUNTING OF PLURAL DIVERSE PRIME-MOVERS IN VEHICLES; AUXILIARY DRIVES FOR VEHICLES; INSTRUMENTATION OR DASHBOARDS FOR VEHICLES; ARRANGEMENTS IN CONNECTION WITH COOLING, AIR INTAKE, GAS EXHAUST OR FUEL SUPPLY OF PROPULSION UNITS IN VEHICLES [2006.01]
Integrated fault-tolerant augmented area viewing system
Patent No. 10395541
Inventor(s): Aishwarya Dubey (Plano, TX), Ian Carl Byers (Northville, MI), Jonathan Elliot Bergsagel (Richardson, TX), Sunita Nadampalli (McKinney, TX), Thomas Ray Shelburne (South Lyon, MI)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 14874112 on 10/02/2015 (1425 days app to issue)
Abstract: An integrated fault-tolerant augmented area viewing system includes, for example, a subsystem processor for receiving a safety signal for blind spot monitoring from a blind spot sensor and for generating a subsystem processor video output signal in response to the received safety signal. Selector circuitry selects the subsystem processor video output signal or a master controller video output signal received from a master controller and generates a selected video output signal in response. The selector circuitry performs the selection of the video output signal selection in response to receiving a safety request signal generated in response to a user action. A buffer outputs the selected video output signal for displaying on a display for viewing by the user.
[B60R] VEHICLES, VEHICLE FITTINGS, OR VEHICLE PARTS, NOT OTHERWISE PROVIDED FOR (fire prevention, containment or extinguishing specially adapted for vehicles A62C 3/07)
Color-changing lighting dynamic control
Patent No. 10398003
Inventor(s): Scott Eddins (Southlake, TX)
Assignee(s): Inception Innovations, Inc. (Southlake, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15399675 on 01/05/2017 (964 days app to issue)
Abstract: A control gateway for colored or color-changing lighting fixtures to allow access to local and remote control systems with real time control with power backup for security triggering using an established color code to indicate the nature of the emergency.
[B60Q] ARRANGEMENT OF SIGNALLING OR LIGHTING DEVICES, THE MOUNTING OR SUPPORTING THEREOF OR CIRCUITS THEREFOR, FOR VEHICLES IN GENERAL [4]
C H E M I S T R Y & M E T A L L U R G Y
Composition and method of manufacturing overbased sulfonate modified lithium carboxylate grease
Patent No. 10392577
Inventor(s): J. Andrew Waynick (Lantana, TX)
Assignee(s): NCH CORPORATION (Irving, TX)
Law Firm: Ross Barnes LLP (1 non-local offices)
Application No., Date, Speed: 15594006 on 05/12/2017 (837 days app to issue)
Abstract: An overbased sulfonate modified lithium carboxylate grease composition and method of manufacture comprising overbased calcium sulfonate, overbased magnesium sulfonate, or both added to a source of lithium hydroxide, base oil, and optionally one or more acids when a complex grease is desired. When overbased sulfonate is added, the amount of dicarboxylic acid relative monocarboxylic acid may be reduced. Additionally, the amount of lithium hydroxide added may be less than stoichiometrically needed to react with the acids. A sulfonate modified lithium grease with improved thickener yield and dropping point may be made without multiple heating and cooling cycles or using a pressurized kettle.
[C10M] LUBRICATING COMPOSITIONS (well drilling compositions C09K 8/02); USE OF CHEMICAL SUBSTANCES EITHER ALONE OR AS LUBRICATING INGREDIENTS IN A LUBRICATING COMPOSITION (mould release, i.e. separating, agents for metals B22C 3/00, for plastics or substances in a plastic state, in general B29C 33/56, for glass C03B 40/02; textile lubricating compositions D06M 11/00, D06M 13/00, D06M 15/00; immersion oils for microscopy G02B 21/33) [4]
Micro-RNA family that modulates extracellular matrix genes and uses thereof
Patent No. 10392618
Inventor(s): Eric N. Olson (Dallas, TX)
Assignee(s): THE BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM (Austin, TX)
Law Firm: Cooley LLP (14 non-local offices)
Application No., Date, Speed: 15640220 on 06/30/2017 (788 days app to issue)
Abstract: The present invention relates to the identification of a microRNA family, designated miR-29a-c, that is a key regulator of fibrosis in cardiac tissue. The inventors show that members of the miR-29 family are down-regulated in the heart tissue in response to stress, and are up-regulated in heart tissue of mice that are resistant to both stress and fibrosis. Also provided are methods of modulating expression and activity of the miR-29 family of miRNAs as a treatment for fibrotic disease, including cardiac hypertrophy, skeletal muscle fibrosis other fibrosis related diseases and collagen loss-related disease.
[C12N] MICROORGANISMS OR ENZYMES; COMPOSITIONS THEREOF (biocides, pest repellants or attractants, or plant growth regulators containing microorganisms, viruses, microbial fungi, enzymes, fermentates, or substances produced by, or extracted from, microorganisms or animal material A01N 63/00; medicinal preparations A61K; fertilisers C05F); PROPAGATING, PRESERVING, OR MAINTAINING MICROORGANISMS; MUTATION OR GENETIC ENGINEERING; CULTURE MEDIA (microbiological testing media C12Q 1/00) [3]
F I X E D C O N S T R U C T I O N S
Multi-roll granule application
Patent No. 10392805
Inventor(s): Patrick Mishler (Dundalk, MD)
Assignee(s): Building Materials Investment Corporation (Dallas, TX)
Law Firm: Womble Bond Dickinson (US) LLP (14 non-local offices)
Application No., Date, Speed: 14482895 on 09/10/2014 (1812 days app to issue)
Abstract: A method and apparatus for applying or dropping granules onto the asphalt coated surface of a moving sheet in shingle manufacturing is disclosed. The method includes sharing each drop between two or more blend rolls with a subsequent blend roll or rolls applying a partial drop directly on top of partial drops already applied by a first blend roll or rolls. High production speeds can be accommodated since each roll can be operated at slower rotation rates and with slower acceleration and deceleration requirements than would be required if the full granule drop were applied during the same time interval with a single blend roll.
[E04D] ROOF COVERINGS; SKY-LIGHTS; GUTTERS; ROOF-WORKING TOOLS (coverings of outer walls by plaster or other porous material E04F 13/00)
Smart fence
Patent No. 10392829
Inventor(s): Peter Lakmanaswamy-Bakthan (McKinney, TX), Veena Peter (McKinney, TX), Vega Peter (McKinney, TX)
Assignee(s): UNASSIGNED
Law Firm: No Counsel
Application No., Date, Speed: 15371570 on 12/07/2016 (993 days app to issue)
Abstract: A remotely controlled fence includes one or more sensors for sensing an unauthorized entry; an image capturing device to capture the image of the unauthorized object; a speaker; a microphone; a humidifier to create a chill out area; a display unit for showing the weather temperature of the surroundings; a radio FM device for a musical chanson and a medium for news to the listener; a lighting unit; solar panel hoods; and a communication interface to transmit the related information to the user, the fence is optimized to control all functions using a mobile app or a web technology with a user interacting device such as a computer, tablet, smartphone and the like.
[E04H] BUILDINGS OR LIKE STRUCTURES FOR PARTICULAR PURPOSES; SWIMMING OR SPLASH BATHS OR POOLS; MASTS; FENCING; TENTS OR CANOPIES, IN GENERAL (foundations E02D) [4]
Systems and methods for controlling the blinds
Patent No. 10392860
Inventor(s): Eric Barnett (Fort Worth, TX)
Assignee(s): UNASSIGNED
Law Firm: Eldredge Law Firm (2 non-local offices)
Application No., Date, Speed: 15067306 on 03/11/2016 (1264 days app to issue)
Abstract: The present invention provides a device to control the tilt angle of window blinds. The device is capable of working with existing home automation control systems. The device is configured to operate in one or more modes such as, a primary mode and a secondary mode. In the primary mode of operation of the device is controlled by the home automation controller using a wireless mesh network protocol or a home automation protocol. In the secondary mode, the device 604 is operate independent of the mesh network in a standalone manner.
[E06B] FIXED OR MOVABLE CLOSURES FOR OPENINGS IN BUILDINGS, VEHICLES, FENCES, OR LIKE ENCLOSURES, IN GENERAL, e.g. DOORS, WINDOWS, BLINDS, GATES (shades or blinds for greenhouses A01G 9/22; curtains A47H; lids for car boots or bonnets B62D 25/10; sky-lights E04B 7/18; sunshades, awnings E04F 10/00)
Centralizing and protective adapter for downhole torch and method of use
Patent No. 10392888
Inventor(s): Amy Stephens (Mansfield, TX), Antony F. Grattan (Mansfield, TX), Cory Huggins (Mansfield, TX), Douglas J. Streibich (Fort Worth, TX), Michael C. Robertson (Mansfield, TX), William F. Boelte (New Iberia, LA)
Assignee(s): ROBERTSON INTELLECTUAL PROPERTIES, LLC (Mansfield, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15250771 on 08/29/2016 (1093 days app to issue)
Abstract: Apparatus and adapter are usable for aligning downhole torch apparatuses and cutting devices, including axial pyro torches, circulating pyro torches, and radial cutting and perforating torches, within a wellbore for removal of one or more downhole obstructions. The torch and/or cutting apparatus comprises a body having a nozzle adapted to project a fuel load, such as molten thermite or molten thermite with a polymer, in a direction aligned with the obstruction. The adapter comprises protruding elements for eliminating or diminishing damage to the area surrounding the obstruction, including the inner walls of the wellbore and/or casing, and can further comprise centralizers for alignment of the apparatus with the obstruction, within the wellbore.
[E21B] EARTH OR ROCK DRILLING (mining, quarrying E21C; making shafts, driving galleries or tunnels E21D); OBTAINING OIL, GAS, WATER, SOLUBLE OR MELTABLE MATERIALS OR A SLURRY OF MINERALS FROM WELLS [5]
Multi-zone actuation system using wellbore darts
Patent No. 10392910
Inventor(s): Matthew Merron (Carrollton, TX), Zachary Walton (Carrollton, TX)
Assignee(s): Halliburton Energy Services, Inc. (Houston, TX)
Law Firm: McGuireWoods LLP (Local + 9 other metros)
Application No., Date, Speed: 14654597 on 08/01/2014 (1852 days app to issue)
Abstract: Sliding sleeve assemblies including a completion body with an inner flow passageway and one or more ports enabling fluid communication between the inner flow passageway and an exterior of the completion body. A sliding sleeve is arranged within the completion body and has a sleeve mating profile defined on an inner surface, the sliding sleeve being movable between a closed position, where the one or more ports are occluded, and an open position, where the one or more ports are exposed. A plurality of wellbore darts are used and each has a body and a common dart profile that is matable with the sleeve mating profile. One or more sensors are positioned on the completion body to detect the plurality of wellbore darts traversing the inner flow passageway. An actuation sleeve is arranged within the completion body and movable to expose the sleeve mating profile.
[E21B] EARTH OR ROCK DRILLING (mining, quarrying E21C; making shafts, driving galleries or tunnels E21D); OBTAINING OIL, GAS, WATER, SOLUBLE OR MELTABLE MATERIALS OR A SLURRY OF MINERALS FROM WELLS [5]
Fracturing utilizing an air/fuel mixture
Patent No. 10392915
Inventor(s): Edwin E. Wilson (Colleyville, TX)
Assignee(s): Twin Disc, Inc. (Racine, WI)
Law Firm: Boyle Fredrickson S.C. (1 non-local offices)
Application No., Date, Speed: 15736503 on 06/16/2016 (1167 days app to issue)
Abstract: A method of producing subterranean fractures in geologic formations for the extraction of hydrocarbons includes flowing an air and fuel mixture into a well hole. The well hole may then be sealed with a packer plug creating a compression chamber with the air and fuel mixture. A liquid, such as water, may be pumped into the well hole to create pressure in the compression chamber. The build-up of pressure eventually causes auto-ignition of the air and fuel mixture which fractures the formation. The water may then rush into the compression chamber which thermally shocks the area causing additional fractures. The water may vaporize to steam and thoroughly disinfect the well hole eliminating the need for added biocides.
[E21B] EARTH OR ROCK DRILLING (mining, quarrying E21C; making shafts, driving galleries or tunnels E21D); OBTAINING OIL, GAS, WATER, SOLUBLE OR MELTABLE MATERIALS OR A SLURRY OF MINERALS FROM WELLS [5]
M E C H A N I C A L E N G I N E E R I N G
LIGHTING | HEATING | WEAPONS | BLASTING
Climate controlling mechanisms for car seats/strollers
Patent No. 10392044
Inventor(s): Jennifer Repp (Colleyville, TX)
Assignee(s): UNASSIGNED
Law Firm: No Counsel
Application No., Date, Speed: 14856258 on 09/16/2015 (1441 days app to issue)
Abstract: A climate controlling mechanism may be provided for car seats/strollers that may be temperature regulated and may include a fail safe such that the climate controlling mechanism may shut down if not within the desired temperature range. The climate controlling mechanism may be built into a car seat/stroller and/or incorporated into a blanket or covering to be placed over a child. The climate controlling mechanism also may be portable. Further, the climate controlling mechanism may be self-charging or the climate controlling mechanism may be plugged into a car charger or other outlet in order to cool and/or heat.
[F28F] DETAILS OF HEAT-EXCHANGE OR HEAT-TRANSFER APPARATUS, OF GENERAL APPLICATION (heat-transfer, heat-exchange or heat-storage materials C09K 5/00; water or air traps, air venting F16)
Connecting rod and crosshead assembly for enhancing the performance of a reciprocating pump
Patent No. 10393113
Inventor(s): Bryan Wagner (Fort Worth, TX)
Assignee(s): S.P.M. FLOW CONTROL, INC. (Fort Worth, TX)
Law Firm: Foley Lardner LLP (Local + 13 other metros)
Application No., Date, Speed: 15185143 on 06/17/2016 (1166 days app to issue)
Abstract: A method and apparatus for a reciprocating pump assembly, including a crosshead and a connecting rod. The crosshead includes a main body having a cylindrical bore formed therethrough and defining a bearing surface, and a window formed through the main body and into the cylindrical bore. The connecting rod includes a small end disposed within the cylindrical bore and a beam portion extending through the window and being connected to the small end. In an exemplary embodiment, a bearing including a tubular body and a cutout is disposed within the cylindrical bore. In another exemplary embodiment, a clamp engages both the main body of the crosshead and the respective opposing end portions of the small end, thus reducing axial displacement of the small end relative to the crosshead.
[F04B] POSITIVE-DISPLACEMENT MACHINES FOR LIQUIDS; PUMPS (engine fuel-injection pumps F02M; machines for liquids, or pumps, of rotary-piston or oscillating-piston type F04C; non-positive-displacement pumps F04D; pumping of fluid by direct contact of another fluid or by using inertia of fluid to be pumped F04F; crankshafts, crossheads, connecting-rods F16C; flywheels F16F; gearings for interconverting rotary motion and reciprocating motion in general F16H; pistons, piston-rods, cylinders, in general F16J; ion pumps H01J 41/12; electrodynamic pumps H02K 44/02)
Power end frame assembly for reciprocating pump
Patent No. 10393182
Inventor(s): Chandu Kumar (Fort Worth, TX), Christopher P. Buckley (Tomball, TX), Donald Keith Plemons (Fort Worth, TX), Jacob A. Bayyouk (Richardson, TX), Joseph H. Byrne (Hudson Oaks, TX), Kourosh Momenkhani (Dallas, TX), Sean P. Mo
Assignee(s): S.P.M. Flow Control, Inc. (Fort Worth, TX)
Law Firm: Foley Lardner LLP (Local + 13 other metros)
Application No., Date, Speed: 14808513 on 07/24/2015 (1495 days app to issue)
Abstract: A plate segment for a reciprocating pump power end frame assembly, the power end frame assembly having a pair of end plate segments and at least one middle plate segment disposed between the end plate segments. The plate segment consists of the middle plate segment or one of the pair of end plate segments and includes a plate having a front wall, a rear wall, a top wall, a bottom wall and a pair of sidewalls and at least one opening forming a bearing support surface, the opening extending through the plate. The plate segment further includes at least one extension extending from at least one of the sidewalls of the plate at a position to align with and contact a corresponding extension on an adjacently positioned plate.
[F16C] SHAFTS; FLEXIBLE SHAFTS; MECHANICAL MEANS FOR TRANSMITTING MOVEMENT IN A FLEXIBLE SHEATHING; ELEMENTS OF CRANKSHAFT MECHANISMS; PIVOTS; PIVOTAL CONNECTIONS; ROTARY ENGINEERING ELEMENTS OTHER THAN GEARING, COUPLING, CLUTCH OR BRAKE ELEMENTS; BEARINGS [5]
Multidirectional vent limiting devices for use with fluid regulators
Patent No. 10393282
Inventor(s): Bruno Jean Michel Cheron (McKinney, TX), Hoden Ali Farah (Plano, TX), Roy Ronald Pelfrey (Sherman, TX), Tung Kim Nguyen (McKinney, TX)
Assignee(s): EMERSON PROCESS MANAGEMENT REGULATOR TECHNOLOGIES, INC. (McKinney, TX)
Law Firm: Hanley, Flight Zimmerman, LLC (1 non-local offices)
Application No., Date, Speed: 15597525 on 05/17/2017 (832 days app to issue)
Abstract: Multidirectional vent limiting devices for use with fluid regulators are described. In some examples, a vent limiting device includes a housing having an interior surface, a fluid inlet, a fluid outlet, and a first fluid passageway in fluid communication with and located between the fluid inlet and the fluid outlet. The interior surface includes a first sealing surface that defines a portion of the first fluid passageway. In some examples, the vent limiting device further includes a stem and a poppet. In some examples, the stem is rigidly coupled to the interior surface of the housing. In some examples, the poppet includes a second sealing surface that defines a portion of the first fluid passageway, and a radial bore that defines a second fluid passageway in fluid communication with and located between the fluid inlet and the fluid outlet. In some examples, the poppet is slidable along the stem between an open position and a closed position. In some examples, the second sealing surface contacts the first sealing surface when the poppet is in the closed position to close off the first fluid passageway.
[F16K] VALVES; TAPS; COCKS; ACTUATING-FLOATS; DEVICES FOR VENTING OR AERATING
Regulating overtravel in bi-furcated plugs for use in valve assemblies
Patent No. 10393283
Inventor(s): Thomas Henry Cunningham (North Easton, MA)
Assignee(s): Dresser, LLC (Addison, TX)
Law Firm: Paul Frank + Collins P.C. (1 non-local offices)
Application No., Date, Speed: 15714584 on 09/25/2017 (701 days app to issue)
Abstract: A gap control device that works with a plug on a valve assembly for use in high-temperature applications. The plug may include two parts and a compressible seal that, when compressed, engages with an adjacent wall of a cylinder or ”cage” typical of a trim assembly. In one embodiment, the gap control device forms a hard stop that expands in response to high temperatures. This feature prevents excess over-travel between the two parts of the plug in the high-temperature applications so as to limit stress and wear on the compressible seal.
[F16K] VALVES; TAPS; COCKS; ACTUATING-FLOATS; DEVICES FOR VENTING OR AERATING
Sealing gasket with corrugated insert for sealing restrained or non-restrained plastic pipelines
Patent No. 10393296
Inventor(s): Guido Quesada (San Jose, , CR)
Assignee(s): S B Technical Products, Inc. (Fort Worth, TX)
Law Firm: Whitaker Chalk Swindle Schwartz PLLC (2 non-local offices)
Application No., Date, Speed: 15661234 on 07/27/2017 (761 days app to issue)
Abstract: A pipe sealing gasket is shown which is designed to be received within a raceway provided within a socket end of a female bell plastic pipe end which is assembled with a mating male spigot pipe end to form a plastic pipe joint. The raceway in the female bell plastic pipe end is preformed during manufacture and the gasket is installed thereafter. The gasket has a rubber body portion which is reinforced by a hard corrugated ring-shaped insert. The hard corrugated ring-shaped insert acts to prevent extrusion of the gasket during a variety of pressure conditions as well as preventing displacement during field assembly.
[F16J] PISTONS; CYLINDERS; PRESSURE VESSELS IN GENERAL; SEALINGS
P H Y S I C S
Light sensor system for correcting or equalizing color signals by removing infrared componet from color signals and method for processing light sensor signals
Patent No. 10393577
Inventor(s): Dan Jacobs (McKinney, TX), David Mehrl (Plano, TX), Kerry Glover (Rockwall, TX)
Assignee(s): ams AG (Unterpremstaetten, , AT)
Law Firm: Fish Richardson P.C. (Local + 13 other metros)
Application No., Date, Speed: 14423101 on 08/21/2013 (2197 days app to issue)
Abstract: Color light sensors are used to sense colored light and a full spectrum light in order to generate at least three color channel signals and a clear channel signal. An infrared component IR is calculated by summing up the color channel signals with individual weighting factors and subtracting a weighted clear channel signal.
[G01J] MEASUREMENT OF INTENSITY, VELOCITY, SPECTRAL CONTENT, POLARISATION, PHASE OR PULSE CHARACTERISTICS OF INFRA-RED, VISIBLE OR ULTRA-VIOLET LIGHT; COLORIMETRY; RADIATION PYROMETRY [2]
Cavity enhancement methods, systems and devices, and methods of measuring same
Patent No. 10393648
Inventor(s): Purnendu K Dasgupta (Arlington, TX)
Assignee(s): BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM (Austin, TX)
Law Firm: FisherBroyles LLP (Local + 20 other metros)
Application No., Date, Speed: 15492800 on 04/20/2017 (859 days app to issue)
Abstract: A system for increasing light throughput in cavity enhanced spectrometry, and a model for cavity enhanced absorption measurements are presented. The cavity has an entrance mirror, an opposed exit mirror and a detector positioned adjacent the exit mirror. An input aperture is defined in the entrance mirror to allow light from a source to enter the cavity. The input aperture improves light throughput without significant departure from the theoretically predicted amplification of absorbance. This results in improvement of detection limits, even with mirrors of modest reflectivity and inexpensive detectors.
[G01N] INVESTIGATING OR ANALYSING MATERIALS BY DETERMINING THEIR CHEMICAL OR PHYSICAL PROPERTIES (measuring or testing processes other than immunoassay, involving enzymes or microorganisms C12M, C12Q)
Memory loopback systems and methods
Patent No. 10393803
Inventor(s): David D. Wilmoth (Allen, TX)
Assignee(s): Micron Technology, Inc. (Boise, ID)
Law Firm: Fletcher Yoder, P.C. (1 non-local offices)
Application No., Date, Speed: 15693114 on 08/31/2017 (726 days app to issue)
Abstract: One embodiment of the present disclosure describes a memory system that may include one or more memory devices that may store data. The memory devices may receive command signals to access the stored data as a loopback signal. The memory devices may operate in a normal operational mode, a loopback operational mode, a retrieval operational mode, a non-inverting pass-through operational sub-mode, and an inverting pass-through operational sub-mode. The operational modes facilitate the transmission of the loopback signal for the purpose of monitoring of memory device operations. A selective inversion technique, which uses the operational modes, may protect the loopback signal integrity during transmission.
[G01R] MEASURING ELECTRIC VARIABLES; MEASURING MAGNETIC VARIABLES (indicating correct tuning of resonant circuits H03J 3/12)
Extended signal paths in microfabricated sensors
Patent No. 10393826
Inventor(s): Roozbeh Parsa (Portola Valley, CA), William French (San Jose, CA)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15348966 on 11/10/2016 (1020 days app to issue)
Abstract: A microfabricated sensor includes a first reflector and a second reflector in a sensor cell, separated by a cavity path segment through a sensor cavity in the sensor cell. A signal window is part of the sensor cell. A signal emitter and a signal detector are disposed outside of the sensor cavity. The signal emitter is separated from the first reflector by an emitter path segment which extends through the signal window. The second reflector is separated from the second reflector by a detector path segment which extends through the signal window.
[G01R] MEASURING ELECTRIC VARIABLES; MEASURING MAGNETIC VARIABLES (indicating correct tuning of resonant circuits H03J 3/12)
Polyhedral sensor arrangement and method for operating a polyhedral sensor arrangement
Patent No. 10393851
Inventor(s): David Mehrl (Plano, TX), Kerry Glover (Rockwall, TX)
Assignee(s): ams AG (Unterpremstaetten, , AT)
Law Firm: Fish Richardson P.C. (Local + 13 other metros)
Application No., Date, Speed: 15811473 on 11/13/2017 (652 days app to issue)
Abstract: A sensor arrangement comprises at least a first, a second, and a third light sensor. A three-dimensional framework comprises at least a first, a second, and a third connection means which are connected to the at least first, second, and third light sensor, respectively. The first, the second, and the third connection means are configured to align the at least first, second, and third light sensor along a first, second, and third face of a polyhedron-like volume, respectively, such that the sensor arrangement encloses the polyhedron-like volume. The invention also relates to a method for operating the sensor arrangement.
[G01S] RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
Automatic tracking of faults by slope decomposition
Patent No. 10393899
Inventor(s): Ethan Nowak (McKinney, TX)
Assignee(s): ExxonMobil Upstream Research Company (Spring, TX)
Law Firm: ExxonMobil Upstream Research Company-Law Department (2 non-local offices)
Application No., Date, Speed: 14486881 on 09/15/2014 (1807 days app to issue)
Abstract: Method for locating fault lines or surfaces in 2-D or 3-D seismic data based on the fact that fault discontinuities in the space domain span a wide range in a local slowness (slope) domain, whereas other dipping events in the space domain data, such as noise, tend to be coherent, and hence will appear focused in the slowness dimension. Therefore, the method comprises decomposing the seismic data ([b]102[/b]) by a transformation to the local slowness domain, preferably using Gaussian slowness period packets as the local slowness or slope decomposition technique, thereby avoiding problems with the data stationary assumption. In the local slowness domain, faults may be identified ([b]104[/b]) using the principle mentioned above, i.e. that faults are represented as a truncation in the space domain data, hence they will appear broadband in the slowness dimension.
[G03B] APPARATUS OR ARRANGEMENTS FOR TAKING PHOTOGRAPHS OR FOR PROJECTING OR VIEWING THEM; APPARATUS OR ARRANGEMENTS EMPLOYING ANALOGOUS TECHNIQUES USING WAVES OTHER THAN OPTICAL WAVES; ACCESSORIES THEREFOR (optical parts of such apparatus G02B; photosensitive materials or processes for photographic purposes G03C; apparatus for processing exposed photographic materials G03D) [4]
Eyeglasses with interchangeable lenses
Patent No. 10394049
Inventor(s): Jonathan McCann (Van Alstyne, TX), Mark Niiro (Dallas, TX)
Assignee(s): Roka Sports, Inc. (Austin, TX)
Law Firm: Clearpat Services, LLC (no location found)
Application No., Date, Speed: 16157972 on 10/11/2018 (320 days app to issue)
Abstract: An eyeglass assembly with a bridge frame having temple tab thru-holes and lens retention receivers; a nose bridge insert; at least one lens in a single lens configuration with tabs configured to insert into the lens retention receivers of the bridge frame such that the lens tabs, or a portion thereof, protrude through temple tab thru-holes. In some embodiments, the eyeglasses are frameless, having first and second temple lugs with temple tab thru-holes and lens locking features; at least one lens in a single lens configuration having lens tabs, lens retention steps, lug locking notches; and a nose bridge insert. In some embodiments, the eyeglass assembly has a bridge frame with an integral nose bridge, two lenses, each lens having a lens tab, and a lens retention step, further having a lens hook. In still further embodiments, the eyeglass assembly comprises lens receiving portions with unique capture features to retain lenses having lens tabs, lens retention steps and/or hooks and capture features configured to removably capture and retain the lens in the assembly. Other embodiments further comprise a rocker frame.
[G02C] SPECTACLES; SUNGLASSES OR GOGGLES INSOFAR AS THEY HAVE THE SAME FEATURES AS SPECTACLES; CONTACT LENSES
Systems and methods for manufacturing optimization
Patent No. 10394195
Inventor(s): Aditya Narayan Das (Irving, TX), Harry E. Stephanou (Fort Worth, TX)
Assignee(s): Board of Regents, The University of Texas System (Austin, TX)
Law Firm: Thomas | Horstmeyer, LLP (no location found)
Application No., Date, Speed: 14062183 on 10/24/2013 (2133 days app to issue)
Abstract: In one embodiment, a manufacturing process is optimized by enabling a user to specify a product to be manufactured, enabling the user to specify a manufacturing system for manufacturing the product, enabling the user to select parameters for the product and the manufacturing system, and automatically calculating manufacturing metrics for the manufacturing process based upon the user-specified models and user selections.
[G05B] CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS (fluid-pressure actuators or systems acting by means of fluids in general F15B; valves per se F16K; characterised by mechanical features only G05G; sensitive elements, see the appropriate subclasses, e.g. G12B, subclasses of G01, H01; correcting units, see the appropriate subclasses, e.g. H02K)
Failover navigation for remotely operated aerial vehicles
Patent No. 10394240
Inventor(s): Paul E. I. Pounds (Brisbane, , AU)
Assignee(s): Olaeris, Inc. (Burleson, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15499788 on 04/27/2017 (852 days app to issue)
Abstract: The present invention extends to methods, systems, devices, and apparatus for failover navigation for remotely operated aerial vehicles. During flight, a primary guidance system uses a higher resolution map for an area to guide a remotely operated aerial vehicle around obstacles (e.g., buildings) in the area. Failure of the primary guidance system is detected during flight. The remotely operated aerial vehicle switches over to a secondary guidance system in response to detecting the failure. The secondary guidance system formulates a flight path to a safer location based on a lower resolution map of the area. The formulated flight path minimizes crossings between different boundaries represented in the lower resolution map. The formulated flight path is biased towards safety over efficiency.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Changing station for wearable computer band
Patent No. 10394297
Inventor(s): Joseph Sung Han (Plano, TX)
Assignee(s): UNASSIGNED
Law Firm: No Counsel
Application No., Date, Speed: 15189946 on 06/22/2016 (1161 days app to issue)
Abstract: A band-changing station for changing the band of a wearable electronic device includes a station adapted to receive the electronic display portion of a wearable device and the band portion of a wearable electronic device. The station includes a track configured to accept the electronic portion of the wearable electronic device and a mechanism to couple or decouple the electronic display to and from the band portion. A receiver for the electronic portion may be adapted to transition into and out of alignment with one or more bands for coupling or decoupling purposes.
[G04D] APPARATUS OR TOOLS SPECIALLY DESIGNED FOR MAKING OR MAINTAINING CLOCKS OR WATCHES
Empathetic image selection
Patent No. 10394511
Inventor(s): Marlentae A. Johnson (Irving, TX), Michael A. Lau (Arlington, TX), Roberto R. Rodriguez (Irving, TX), Romelia H. Flores (Keller, TX), Ronald J. Rutkowski (Irving, TX), Travis W. Chun (Coppell, TX)
Assignee(s): International Business Machines Corporation (Armonk, NY)
Law Firm: Schmeiser, Olsen Watts (6 non-local offices)
Application No., Date, Speed: 15693640 on 09/01/2017 (725 days app to issue)
Abstract: An approach is provided for selecting and displaying image(s). A user and user profile information corresponding to the user are identified. A sentiment of the user is identified by determining that user is in proximity to a digital picture frame in a room, receiving a measurement of ambient lighting of the room from a light sensor coupled to the digital picture frame, and determining an emotional state of the user based on the ambient lighting. Based on the user profile, an association is determined between the sentiment of the user and sentiment(s), which are determined to be conveyed by image(s). Based on the ambient lighting, the association between the sentiment of the user and the sentiment(s), and the image(s) conveying the sentiment(s), the image(s) are selected from multiple images. The selected image(s) are displayed on a display included in the digital picture frame.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Media balancer employing selectable evaluation source
Patent No. 10394601
Inventor(s): Darren Grant Davis (Dallas, TX)
Assignee(s): iHeartMedia Management Services, Inc. (San Antonio, TX)
Law Firm: Garlick Markison (1 non-local offices)
Application No., Date, Speed: 15668935 on 08/04/2017 (753 days app to issue)
Abstract: A media balancer can assist in selecting replacement media items to be used in generating one or more target schedules from a single master schedule. The media balancer can receive option parameters indicating preferences related to generation of the target schedule. Based on these option parameters, the media balancer can select one of multiple different media schedulers to assist in evaluating potential replacement media items. The media balancer can transmit to the media scheduler selected, information associated with the option parameters, and a request to perform an evaluation of potential replacement media items based on those option parameters. The media balancer can receive the results of the evaluation performed by the selected media scheduler, and use those results to generate target schedules by replacing at least one original media item included in the master schedule with a replacement media item.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Virtual container processing on high performance computing processors
Patent No. 10394603
Inventor(s): Francois Caron (Montreal, , CA), Mark Temple Cobbold (Stittsville, , CA)
Assignee(s): GENBAND US LLC (Plano, TX)
Law Firm: Fogarty LLP (3 non-local offices)
Application No., Date, Speed: 15663029 on 07/28/2017 (760 days app to issue)
Abstract: A method includes, with a first execution unit of a processor, executing instructions for a processing task on behalf of a first virtual container. The first virtual container is configured to utilize computing resources of the first execution unit without demanding more computing resources than the first execution unit provides. The first execution unit may have exclusive access to a first arithmetic logic unit (ALU). The method further includes, with a second execution unit of the processor, processing instructions for the processing task on behalf of a second virtual container. The second virtual container is configured to utilize computing resources of the first execution unit without demanding more computing resources than the first execution unit provides. The second execution unit may have exclusive access to a second Arithmetic Logic Unit (ALU). The first execution unit and the second execution unit operate in parallel.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
First read solution for memory
Patent No. 10394649
Inventor(s): Alon Eyal (Zichron Yaacov, , IL), Eran Sharon (Rishon Lezion, , IL), Evgeny Mekhanik (Rehovot, , IL), Idan Alrod (Herzliya, , IL), Liang Pang (Fremont, CA)
Assignee(s): SanDisk Technologies LLC (Addison, TX)
Law Firm: Vierra Magen Marcus LLP (2 non-local offices)
Application No., Date, Speed: 15921184 on 03/14/2018 (531 days app to issue)
Abstract: Techniques are provided for improving the accuracy of read operations of memory cells, where the threshold voltage of a memory cell can shift depending on when the read operation occurs. A memory cell is sensed by discharging a sense node into a bit line and detecting an amount of discharge at two sense times relative to a trip voltage. A bit of data is stored in first and second latches based on the two sense times, to provide first and second pages of data. The pages are evaluated using parity check equations and one of the pages which satisfies the most equations is selected. In another option, word line voltages are grounded and then floated to prevent coupling up of the word line. A weak pulldown to ground can gradually discharge a coupled up voltage of the word lines.
[G11C] STATIC STORES (information storage based on relative movement between record carrier and transducer G11B; semiconductor devices for storage H01L, e.g. H01L 27/108-H01L 27/11597; pulse technique in general H03K, e.g. electronic switches H03K 17/00)
Collaborative data sharing and data modification application
Patent No. 10394689
Inventor(s): David Gerard Ledet (Allen, TX)
Assignee(s): OPEN INVENTION NETWORK LLC (Durham, NC)
Law Firm: No Counsel
Application No., Date, Speed: 15181637 on 06/14/2016 (1169 days app to issue)
Abstract: Sharing data with various user devices may offer an opportunity for various software testing and troubleshooting procedures to optimally process software code and provide testing results to those interested parties. In one example method of operation, a procedure provides receiving a modification to software code stored in a first file, identifying an oversight level of a user profile associated with a user device that performed the modification to the software code, creating a second file including the software code modification and an identifier identifying the modification, creating a number of notifications identifying the second file and the software code modification, and transmitting the notifications to a plurality of user devices having an oversight level that is greater than or equal to the oversight level of the user profile.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Testing an application in a production infrastructure temporarily provided by a cloud computing environment
Patent No. 10394696
Inventor(s): Anilkumar Baddula (Plano, TX), Anoop Kunjuramanpillai (McKinney, TX), Daniel Tresnak (Frisco, TX), Karthik Gunapati (Irving, TX), Leonardo Gomide (Dallas, TX), Nathan Gloier (Frisco, TX), Raveender Kommera (Flower Mound,
Assignee(s): Capital One Services, LLC (McLean, VA)
Law Firm: Harrity Harrity, LLP (1 non-local offices)
Application No., Date, Speed: 16289314 on 02/28/2019 (180 days app to issue)
Abstract: A device receives test parameters associated with testing an application that utilizes source data, and causes source containers, for the source data, to be temporarily created in a cloud computing environment, based on the test parameters. The device provides the source data to the source containers in the cloud computing environment, and causes other containers, for the application, to be temporarily created in the cloud computing environment, based on the test parameters. The device creates a file for testing the application with the source containers and the other containers, based on the test parameters, and causes the application to be executed with the source containers and the other containers, based on the file. The device receives results associated with executing the application with the source containers and the other containers.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
System and method for false sharing prediction
Patent No. 10394714
Inventor(s): Chen Tian (Union City, CA), Tongping Liu (Amherst, MA), Ziang Hu (Union City, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Slater Matsil, LLP (Local + 1 other metros)
Application No., Date, Speed: 15393524 on 12/29/2016 (971 days app to issue)
Abstract: In one embodiment, a method for predicting false sharing includes running code on a plurality of cores and determining whether there is potential false sharing between a first cache line and a second cache line, and where the first cache line is adjacent to the second cache line. The method also includes tracking the potential false sharing and reporting the potential false sharing.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Slot/sub-slot prefetch architecture for multiple memory requestors
Patent No. 10394718
Inventor(s): Joseph R. M. Zbiciak (San Jose, CA), Kai Chirca (Richardson, TX), Matthew D. Pierson (Murphy, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15899138 on 02/19/2018 (554 days app to issue)
Abstract: A prefetch unit generates a prefetch address in response to an address associated with a memory read request received from the first or second cache. The prefetch unit includes a prefetch buffer that is arranged to store the prefetch address in an address buffer of a selected slot of the prefetch buffer, where each slot of the prefetch unit includes a buffer for storing a prefetch address, and two sub-slots. Each sub-slot includes a data buffer for storing data that is prefetched using the prefetch address stored in the slot, and one of the two sub-slots of the slot is selected in response to a portion of the generated prefetch address. Subsequent hits on the prefetcher result in returning prefetched data to the requestor in response to a subsequent memory read request received after the initial received memory read request.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Serialization scheme for storing data and lightweight indices on devices with append-only bands
Patent No. 10394786
Inventor(s): Chi Young Ku (San Ramon, CA), Guangyu Shi (Cupertino, CA), Masood Mortazavi (Santa Clara, CA), Stephen Morgan (San Jose, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Conley Rose, P.C. (3 non-local offices)
Application No., Date, Speed: 14690612 on 04/20/2015 (1590 days app to issue)
Abstract: A method comprising receiving a plurality of data records, storing the data records as data segments in a storage element, receiving a plurality of descriptors for each data segment, wherein each descriptor describes an aspect of data contained in the data segments, employing a first user-defined function to resolve a first minimum descriptor for each data segment and a first maximum descriptor for each data segment, composing a lightweight index for the data segments, wherein the lightweight index comprises the first minimum descriptor for each data segment and the first maximum descriptor for each data segment, and appending the lightweight index to the data segments in the storage element.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
System, methods, and program product to trace content genealogy
Patent No. 10394880
Inventor(s): Candace Helgerson (Denver, CO), Cynthia Parrish (Littleton, CO), Taras Markian Bugir (Golden, CO)
Assignee(s): IMAGINE COMMUNICATIONS CORP. (Frisco, TX)
Law Firm: Tarolli, Sundheim, Covell Tummino LLP (1 non-local offices)
Application No., Date, Speed: 15490649 on 04/18/2017 (861 days app to issue)
Abstract: Embodiments of systems, program products, and methods to manage content and distribution of media are provided. An embodiment of a system, for example, can include a communication network for transmitting media files, a content management server having a processor and memory coupled to the processor, a database accessible to the processor of the content management server and including media files associated with metadata records, a plurality of content management developer computers to provide content management developers with online access over the communication network to the media files and associated metadata records to thereby edit the metadata records, a plurality of user computers accessible to the communication network to provide the users with access to the media files over the communication network to thereby view and edit at least portions of respective metadata records. The system also includes content management program product stored in the memory of the content management server to manage content and distribution of media.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Community-based investigative tools
Patent No. 10394900
Inventor(s): Adam Christopher Edwards (Fort Worth, TX)
Assignee(s): Securus Technologies, Inc. (Carrollton, TX)
Law Firm: Fogarty LLP (3 non-local offices)
Application No., Date, Speed: 13705153 on 12/04/2012 (2457 days app to issue)
Abstract: Systems and methods for developing, deploying, providing, and/or operating community-based investigative tools are disclosed. In some embodiments, a method may include receiving a query from a user (e.g., an investigator, etc.), the user associated with a given one of a plurality of controlled-environment facilities (e.g., a prison, jail, etc.), each of the plurality of facilities having access to a distinct database configured to store data relating to its respective residents (e.g., inmates). The method may also include determining an access level of the given one of the plurality of facilities. The method may further include retrieving information from one or more of the distinct databases in response to the query, the retrieved information commensurate with the access level. In some implementations, a database accessible to a first facility may not be accessible to a second facility unless the first and second facilities are members of the same investigative community.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
User-trained searching application system and method
Patent No. 10394917
Inventor(s): Paul Greenwood (Dallas, TX)
Assignee(s): WEBUSAL LLC (Marina Del Rey, CA)
Law Firm: The Danamraj Law Group, P.C. (Local)
Application No., Date, Speed: 15487949 on 04/14/2017 (865 days app to issue)
Abstract: System, apparatus, user equipment, and associated computer program and computing methods are provided for suggesting websites that are relevant based on the user”s browsing history and past search results. In one aspect, a hosted computer application stores the user”s browsing history and search results using a cloud-based storage facility, and computing methods, using machine learning techniques, are operative to predict websites the user may want to visit next. Example machine learning techniques may be configured to identify patterns and map data elements in order to predict which website(s) the user might like to visit in a search/browsing session. The training of example machine learning techniques is driven by user interaction, e.g., allowing the removal of non-relevant or less relevant websites from the suggested websites via a suitable user interface.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Method and apparatus for automatically assembling components in a computer-aided design (CAD) environment
Patent No. 10394967
Inventor(s): Gaurav Sawant (Pune, , IN), Maruthi Pavan (Pune, , IN), Prashant Deodhar (Pune, , IN), Ravi Vithalani (Pune, , IN), Sagar Inamdar (Pune, , IN), Sandesh Kadam (Pune, , IN), Sarang Kandekar (Pune, , IN), Yogesh Kavte (Pune, , IN)
Assignee(s): Siemens Product Lifecycle Management Software Inc. (Plano, TX)
Law Firm: Lempia Summerfield Katz LLC (1 non-local offices)
Application No., Date, Speed: 14818089 on 08/04/2015 (1484 days app to issue)
Abstract: A method and apparatus for automatically assembling components in a computer-aided design (CAD) environment is disclosed. In one embodiment, the method includes identifying a source component and a target component in the CAD environment. The source component and the target component represent different parts of a real-world object. The method also includes computing one or more assembly solutions for assembling the source component and the target component based on a set of rules. Each of the assembly solutions defines a constraint relationship between the source component and the target component. The method also includes automatically generating constraints between geometric entities of the source component and geometric entities of the target component based on the one or more assembly solutions. The method includes outputting a geometric model including the assembled source component and target component on a graphical user interface.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Methods and systems for reducing false positive findings
Patent No. 10395041
Inventor(s): Adam Youngberg (Allen, TX), David Filbey (Plano, TX), Kishore Prabakaran Fernando (Little Elm, TX)
Assignee(s): CAPITAL ONE SERVICES, LLC (McLean, VA)
Law Firm: Troutman Sanders LLP (9 non-local offices)
Application No., Date, Speed: 16177236 on 10/31/2018 (300 days app to issue)
Abstract: A system for validating software security analysis findings includes a non-transitory computer readable medium and a processor. The non-transitory computer readable medium stores a source truth dataset including criteria for validating characteristics of findings. The processor receives a finding from a software security analysis tool that performs scan on application code. The processor identifies a characteristic from the finding. The processor selects a criterion from the non-transitory computer readable medium for validating the identified characteristic. The processor determines a validity score for the finding based on whether the selected criterion is met. The processor determines whether the finding is false positive by comparing the validity score to a predetermined validity threshold. If the finding is true positive, a graphical user interface displays the finding.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Transportation system disruption management apparatus and methods
Patent No. 10395197
Inventor(s): Deepak Warrier (Euless, TX), Remi Salam (Irving, TX), Timothy Jon Niznik (Flower Mound, TX)
Assignee(s): AMERICAN AIRLINES, INC. (Fort Worth, TX)
Law Firm: Haynes and Boone, LLP (Local + 13 other metros)
Application No., Date, Speed: 13755766 on 01/31/2013 (2399 days app to issue)
Abstract: A system and method for receiving data associated with a plurality of travel legs; identifying a resources delay relating to a delay necessary to provide a travel leg from the plurality of travel legs with resources required for the departure of the travel leg, and an existing delay associated with the travel leg; determining a projected arrival delay and a projected departure delay based on the resources delay and the existing delay; outputting parameters relating to the projected arrival delay and the projected departure delay; receiving operation parameters; and generating a proposed operation plan using the projected arrival delay, the projected departure delay, and the operation parameters. In an exemplary embodiment, each of the travel legs is an airline flight.
[G06Q] DATA PROCESSING SYSTEMS OR METHODS, SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL, SUPERVISORY OR FORECASTING PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL, SUPERVISORY OR FORECASTING PURPOSES, NOT OTHERWISE PROVIDED FOR [2006.01]
Apparatus for automated monitoring and managing of inventory
Patent No. 10395211
Inventor(s): Allen Fosha (Frisco, TX), Chris Allison (Frisco, TX), Kuntesh R. Chokshi (Plano, TX)
Assignee(s): Frito-Lay North America, Inc. (Plano, TX)
Law Firm: Carstens Cahoon, LLP (Local)
Application No., Date, Speed: 15201721 on 07/05/2016 (1148 days app to issue)
Abstract: An apparatus for monitoring inventory on a shelf. The invention describes an apparatus for determining the number of packages on a shelf or hanger. The number of packages on a shelf or hanger is determined by detecting the presence of a package on the shelf and adding all detections together to determine the number of product on a shelf. In another embodiment, the product is identified by an identifying device such as an SKU reader. Thus, the quantity and type of product located on a shelf or hanger is known. Such information allows a store to know the type and quantity of packages needed to restock a specific shelf.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Image analysis and identification using machine learning with output personalization
Patent No. 10395313
Inventor(s): Arjun Dugal (Dallas, TX), Geoffrey Dagley (McKinney, TX), Jason Richard Hoover (Grapevine, TX), Micah Price (Plano, TX), Qiaochu Tang (The Colony, TX), Raman Bajaj (Frisco, TX), Sanjiv Yajnik (Dallas, TX), Stephen Mic
Assignee(s): Capital One Services, LLC (McLean, VA)
Law Firm: Finnegan, Henderson, Farabow, Garrett Dunner, LLP (9 non-local offices)
Application No., Date, Speed: 15916124 on 03/08/2018 (537 days app to issue)
Abstract: A system for processing an image including a vehicle using machine learning can include a processor in communication with a client device, and a storage medium storing instructions that, when executed, cause the processor to perform operations including: receiving an image of a vehicle from the client device; extracting one or more features from the image; based on the extracted features and using a machine learning algorithm, determining a make and a model of the vehicle; obtaining user information relating to a financing request for the vehicle; determining a real-time quote for the vehicle based on the make, the model, and the user information; and transmitting the real-time quote for display on the client device.
[G06Q] DATA PROCESSING SYSTEMS OR METHODS, SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL, SUPERVISORY OR FORECASTING PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL, SUPERVISORY OR FORECASTING PURPOSES, NOT OTHERWISE PROVIDED FOR [2006.01]
Collections of linked databases
Patent No. 10395326
Inventor(s): Brian N. Smith (Plymouth Meeting, PA), Heather A. McGuire (Plymouth Meeting, PA), Michael J. Markus (Plymouth Meeting, PA), Peter M. Kionga-Kamau (Charlottesville, VA)
Assignee(s): 3DEGREES LLC (Plano, TX)
Law Firm: Fay Sharpe LLP (1 non-local offices)
Application No., Date, Speed: 11686421 on 03/15/2007 (4548 days app to issue)
Abstract: In accordance with the teachings described herein, systems and methods are provided for conducting a search of a network for information related to a topic specified by a search initiator. A query may be generated that includes search information and a first-degree contact. The first-degree contact may be an electronic record that represents a member of the social network, and the search information may identify the topic. One or more electronic records that each represent a social-network member may be searched using the query to identify one or more social-network members that are identified in connection with the topic and who are directly or indirectly associated with the first-degree contact.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Evaluating vendor communications for accuracy and quality
Patent No. 10395330
Inventor(s): Alan C. Edwards (Allen, TX), Dustin M. Dorris (North Richland Hills, TX), Shilpa Mudhiganti (Frisco, TX)
Assignee(s): International Business Machines Corporation (Armonk, NY)
Law Firm: No Counsel
Application No., Date, Speed: 15045820 on 02/17/2016 (1287 days app to issue)
Abstract: Mechanisms are provided for monitoring quality and correctness of content in communications handled by a vendor. The mechanisms sample a set of communications handled by the vendor to generate a sample set of communications and extract content from the sample set of communications. The mechanisms compare the extracted content with expected content of communications handled by the vendor and analyze the extracted content and the expected content to thereby identify differences between the extracted content and the expected content based on results of the analysis. In addition, the mechanisms determine a level of significance of the differences and generate a notification of whether or not to modify the communications, or an operation of the vendor, based on the determined level of significance of differences.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Selective retention of forensic information
Patent No. 10395331
Inventor(s): Gary K. Thornton (Carrollton, TX)
Assignee(s): INTERNATIONAL BUSINESS MACHINES CORPORATION (Armonk, NY)
Law Firm: Cantor Colburn LLP (7 non-local offices)
Application No., Date, Speed: 14959491 on 12/04/2015 (1362 days app to issue)
Abstract: Embodiments include method, systems and computer program products for selective retention of data in a computational system. Aspects include receiving a monitored data element. Aspects also include assigning an initial storage ranking to the monitored data element to create a ranked data element. Aspects also include determining a threshold storage ranking. Aspects also include comparing the initial storage ranking to the threshold storage ranking. Aspects also include, based on the comparison indicating that the initial storage ranking is greater than the threshold storage ranking, storing the ranked data element in a long-term storage. Aspects also include based upon the comparison indicating that the initial storage ranking is less than the threshold storage ranking, discarding the ranked data element.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Method to compute sliding window block sum using instruction based selective horizontal addition in vector processor
Patent No. 10395381
Inventor(s): Dipan Kumar Mandal (Bangalore, , IN), Jayasree Sankaranarayanan (Kerala, , IN)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16291405 on 03/04/2019 (176 days app to issue)
Abstract: Disclosed techniques relate to forming a block sum of picture elements employing a vector dot product instruction to sum packed picture elements and the mask producing a vector of masked horizontal picture element. The block sum is formed from plural horizontal sums via vector single instruction multiple data (SIMD) addition.
[G06T] IMAGE DATA PROCESSING OR GENERATION, IN GENERAL [2006.01]
System and method for providing optimal braille output based on spoken and sign language
Patent No. 10395555
Inventor(s): Joseph M. A. Djugash (San Jose, CA), Rajiv Dayal (Santa Clara, CA)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Snell Wilmer LLP (5 non-local offices)
Application No., Date, Speed: 14673303 on 03/30/2015 (1611 days app to issue)
Abstract: A system for determining output text based on spoken language and sign language includes a camera configured to detect image data corresponding to a word in sign language. The system also includes a microphone configured to detect audio data corresponding to the word in spoken language. The system also includes a processor configured to receive the image data from the camera and convert the image data into an image based text word. The processor is also configured to receive the audio data from the microphone and convert the audio data into an audio based text word. The processor is also configured to determine an optimal word by selecting one of the image based text word or the audio based text word based on a comparison of the image based text word and the audio based text word.
[G09B] EDUCATIONAL OR DEMONSTRATION APPLIANCES; APPLIANCES FOR TEACHING, OR COMMUNICATING WITH, THE BLIND, DEAF OR MUTE; MODELS; PLANETARIA; GLOBES; MAPS; DIAGRAMS
Memory device with a latching mechanism
Patent No. 10395701
Inventor(s): Michael V. Ho (Allen, TX), Vijayakrishna J. Vankayala (Allen, TX)
Assignee(s): Micron Technology, Inc. (Boise, ID)
Law Firm: Perkins Coie LLP (17 non-local offices)
Application No., Date, Speed: 15975716 on 05/09/2018 (475 days app to issue)
Abstract: A memory device includes a timing circuit configured to: receive an input signal, wherein the input signal is one signal within a group of input signals (e.g., multiple bits or nibbles) that are communicated according to a sequence with each of the input signals individually in serial to parallel operations, and generate a grouped latching timing signal based on the received input signal, wherein the timing signal corresponds to nibbles of the data.
[G11C] STATIC STORES (information storage based on relative movement between record carrier and transducer G11B; semiconductor devices for storage H01L, e.g. H01L 27/108-H01L 27/11597; pulse technique in general H03K, e.g. electronic switches H03K 17/00)
Memory device with a clocking mechanism
Patent No. 10395702
Inventor(s): Jason M. Brown (Allen, TX), Todd A. Dauenbaugh (Richardson, TX), Vijayakrishna J. Vankayala (Allen, TX)
Assignee(s): Micron Technology, Inc. (Boise, ID)
Law Firm: Perkins Coie LLP (17 non-local offices)
Application No., Date, Speed: 15977125 on 05/11/2018 (473 days app to issue)
Abstract: A memory device includes a first data driver configured to send a first data according to a first clock signal; a first data port electrically coupled to the first data driver, the first data port configured to receive the first data; a second data driver configured to send a second data according to a second clock signal, wherein the second clock signal does not match the first clock signal; and a second data port electrically coupled to the second data driver, the second data port configured to receive the second data.
[G11C] STATIC STORES (information storage based on relative movement between record carrier and transducer G11B; semiconductor devices for storage H01L, e.g. H01L 27/108-H01L 27/11597; pulse technique in general H03K, e.g. electronic switches H03K 17/00)
Optical receiver systems and devices with detector array including a plurality of substrates disposed in an edge to edge array
Patent No. 10396117
Inventor(s): Laila Mattos (Dallas, TX)
Assignee(s): Waymo LLC (Mountain View, CA)
Law Firm: McDonnell Boehnen Hulbert Berghoff LLP (1 non-local offices)
Application No., Date, Speed: 15294335 on 10/14/2016 (1047 days app to issue)
Abstract: The present disclosure relates to optical receiver systems. An example system includes a plurality of substrates disposed in an edge-to-edge array along a primary axis. Each respective substrate of the plurality of substrates includes a plurality of detector elements. Each detector element of the plurality of detector elements generates a respective detector signal in response to light received by the detector element. The plurality of detector elements is arranged with a detector pitch between adjacent detector elements of the plurality of detector elements. Each respective substrate of the plurality of substrates also includes a signal receiver circuit configured to receive the detector signals generated by the plurality of detector elements. The respective substrates of the plurality of substrates are disposed such that the detector pitch is maintained between adjacent detector elements on their respective substrates.
[G01S] RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
Ground switching for speaker current sense
Patent No. 10396779
Inventor(s): Mohit Chawla (Belgaluru, , IN)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15852132 on 12/22/2017 (613 days app to issue)
Abstract: A circuit includes a pair of high side transistors, a pair of low side transistors, a first sense resistor coupled to one of the low side transistors at a first sense node, and a second sense resistor coupled to another of the low side transistors at a second sense node. The first and second sense resistors couple together at a ground node. The circuit includes a first switch network coupled to the first sense resistor, a second switch network coupled to the second sense resistor, a first pair of switches configured to selectively provide a potential of the ground node or a potential of the first sense node as a ground potential to the first switch network, and a second pair of switches configured to selectively provide the potential of the ground node or a potential of the second sense node as a ground potential to the second switch network.
[G01R] MEASURING ELECTRIC VARIABLES; MEASURING MAGNETIC VARIABLES (indicating correct tuning of resonant circuits H03J 3/12)
Transformation based filter for interpolation or decimation
Patent No. 10396829
Inventor(s): Jaiganesh Balakrishnan (Bangalore, , IN), Sundarrajan Rangachari (Bangalore, , IN), Suvam Nandi (Bangalore, , IN)
Assignee(s): TEXAS INTSTUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16110478 on 08/23/2018 (369 days app to issue)
Abstract: A digital filter for interpolation or decimation and a device incorporating the digital filter is disclosed. The digital filter includes a filter block, a first transformation circuit coupled to the filter block and an input stream coupled to provide input values to a component selected from the filter block and the first transformation circuit. The filter block includes a pair of sub-filters having respective transformed coefficients, the respective transformed coefficients of a first sub-filter of the pair of sub-filters being symmetric and the respective transformed coefficients of a second sub-filter of the pair of sub-filters being anti-symmetric. The first transformation circuit is coupled to perform a first transformation; the filter block and the first transformation circuit together provide suppression of undesired spectral images in final outputs of the digital filter.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Service link selection control method and device
Patent No. 10397120
Inventor(s): Linda Dunbar (Plano, TX)
Assignee(s): Huawei Technologies Co., Ltd. (Shenzhen, , CN)
Law Firm: Leydig, Voit Mayer, Ltd. (7 non-local offices)
Application No., Date, Speed: 15280682 on 09/29/2016 (1062 days app to issue)
Abstract: Disclosed are a flow classifier, policy and charging rules function unit and controller. The flow classifier receives a service chain selection control policy sent by a policy and charging rules function unit. The service chain selection control policy includes a corresponding relation between an application type and an identifier of a service chain. The service chain is a path formed by a forwarding device and a value-added service device both of which a service flow with the application type needs to pass through. The flow classifier detects the service flow with the application type based on the service chain selection control policy and adds the identifier of the service chain to a message of the service flow. The flow classifier sends the message of the service flow with the added identifier of the service chain to a forwarding device directly connected to the flow classifier.
[G01R] MEASURING ELECTRIC VARIABLES; MEASURING MAGNETIC VARIABLES (indicating correct tuning of resonant circuits H03J 3/12)
Collaborative sign-on
Patent No. 10397214
Inventor(s): Daniel J. Butterfield (Flower Mound, TX), Gregory P. Fitzpatrick (Keller, TX), Tsz S. Cheng (Grand Prairie, TX)
Assignee(s): INTERNATIONAL BUSINESS MACHINES CORPORATION (Armonk, NY)
Law Firm: Cuenot, Forsythe Kim, LLC (2 non-local offices)
Application No., Date, Speed: 15914914 on 03/07/2018 (538 days app to issue)
Abstract: An authentication approval request can be received by a first system from a second system. The first system can determine whether the user is required to be logged into at least a second online account hosted by at least a third system unrelated to the second system in order to approve the authentication request. If the user is required to be logged into at least the second online account in order to approve the authentication request, the first system can determine whether the user presently is logged into at least the second online account in at least one presently active user session. If the user presently is logged into at least the second online account in at least one presently active user session, the first system can communicate to the second system a response indicating that the user is approved for authentication with the second system.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
System and method to standardize and improve implementation efficiency of user interface content
Patent No. 10397304
Inventor(s): Dana Ballinger (Flower Mound, TX)
Assignee(s): Excentus Corporation (Dallas, TX)
Law Firm: RegitzMauck PLLC (no location found)
Application No., Date, Speed: 15883281 on 01/30/2018 (574 days app to issue)
Abstract: A system and method to improve implementation efficiency of user interface content by using standard content attributes used across all platforms and devices to implement a lowest common denominator programming system. Standardized content attributes are used to produce a universal content framework that is implemented identically across various devices and platforms, resulting in a consistent and standardized user experience. The invention allows programming functionality to be universally applied and usable with any device and platform so that significant computer programming and updating inefficiencies are eliminated.
[G06F] ELECTRIC DIGITAL DATA PROCESSING (computer systems based on specific computational models G06N)
Remotely controlled robotic sensor ball
Patent No. 10397527
Inventor(s): Omar Barlas (Fort Worth, TX)
Assignee(s): UNASSIGNED
Law Firm: No Counsel
Application No., Date, Speed: 15206153 on 07/08/2016 (1145 days app to issue)
Abstract: A remotely controlled robotic sensor ball and method of operation thereof. The robotic sensor ball includes an outer shell forming a ball, control circuitry positioned within the outer shell, a camera operably connected to the control circuitry, a propulsion system inside the outer shell, and one or more connectors. The control circuitry includes at least one processor, memory, and a wireless communication interface. The camera is configured to generate video signals of a view exterior to the outer shell. The propulsion system configured to cause the outer shell to rotate in response to instructions received via the wireless communication interface. The one or more connectors are configured to operably connect one or more sensors to the control circuitry. The one or more sensors are connectable in a modular manner.
[G05D] SYSTEMS FOR CONTROLLING OR REGULATING NON-ELECTRIC VARIABLES (for continuous casting of metals B22D 11/16; valves per se F16K; sensing non-electric variables, see the relevant subclasses of G01; for regulating electric or magnetic variables G05F)
E L E C T R I C I T Y
Systems and methods for dynamically identifying a patient support surface and patient monitoring
Patent No. 10390738
Inventor(s): Derek del Carpio (Corinth, TX), Kenneth Chapman (Charlotte, NC), Matt Clark (Frisco, TX)
Assignee(s): CareView Communications, Inc. (Lewisville, TX)
Law Firm: Meister Seelig Fein LLP (1 non-local offices)
Application No., Date, Speed: 16031004 on 07/10/2018 (413 days app to issue)
Abstract: Various patient monitoring systems can include a sensor configured to collect three dimensional information. The systems can identify a location of a patient support surface based on the three dimensional information. The systems can set a two dimensional planar threshold based on the patient support surface. The systems can identify a patient location above the patient support surface based on the three dimensional information and compare the patient location to the two dimensional planar threshold. Exceeding the threshold can be indicative of a high risk of a patient fall. An alert can be generated based on the threshold being exceeded. The systems can repeat the identification of the patient support surface location and the setting of the threshold to account for changes in the patient area.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Electromagnetic charge sharing and low force vehicle movement device and system
Patent No. 10391872
Inventor(s): Geoffrey David Gaither (Brighton, MI), Joshua D. Payne (Ann Arbor, MI), Nathan C. Westover (New Hudson, MI)
Assignee(s): TOYOTA MOTOR ENGINEERING MANUFACTURING NORTH AMERICA, INC. (Plano, TX)
Law Firm: Snell Wilmer LLP (5 non-local offices)
Application No., Date, Speed: 15644583 on 07/07/2017 (781 days app to issue)
Abstract: Methods, systems, and device for charging and/or moving a vehicle. The charging and force movement system includes a high voltage battery for providing an electrical charge. The charging and force movement system includes an inductive loop configured to charge or move a second vehicle. The charging and force movement system includes an electronic control unit that is connected to at least one of the high voltage battery or the inductive loop. The electronic control unit is configured to determine whether the first vehicle is in a charging mode or in a force movement mode and control the high voltage battery and the inductive loop to receive from or provide a charge to the second vehicle when in the charging mode and repel or attract the second vehicle when in the force movement mode.
[H02J] CIRCUIT ARRANGEMENTS OR SYSTEMS FOR SUPPLYING OR DISTRIBUTING ELECTRIC POWER; SYSTEMS FOR STORING ELECTRIC ENERGY (power supply circuits for apparatus for measuring X-radiation, gamma radiation, corpuscular radiation or cosmic radiation G01T 1/175; electric power supply circuits specially adapted for use in electronic time-pieces with no moving parts G04G 19/00; for digital computers G06F 1/18; for discharge tubes H01J 37/248; circuits or apparatus for the conversion of electric power, arrangements for control or regulation of such circuits or apparatus H02M; interrelated control of several motors, control of a prime-mover/generator combination H02P; control of high-frequency power H03L; additional use of power line or power network for transmission of information H04B)
Through-substrate conductor support
Patent No. 10392246
Inventor(s): John Charles Ehmke (Garland, TX), Virgil Cotoco Ararao (McKinney, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15433704 on 02/15/2017 (923 days app to issue)
Abstract: In described examples, a first device on a first surface of a substrate is coupled to a structure arranged on a second surface of the substrate. In at least one example, a first conductor arranged on the first surface is coupled to circuitry of the first device. An elevated portion of the first conductor is supported by disposing an encapsulate and curing the encapsulate. The first conductor is severed by cutting the encapsulate and the first conductor. A second conductor is coupled to the first conductor. The second conductor is coupled to the structure arranged on the second surface of the substrate.
[H01L] SEMICONDUCTOR DEVICES; ELECTRIC SOLID STATE DEVICES NOT OTHERWISE PROVIDED FOR (use of semiconductor devices for measuring G01; resistors in general H01C; magnets, inductors, transformers H01F; capacitors in general H01G; electrolytic devices H01G 9/00; batteries, accumulators H01M; waveguides, resonators, or lines of the waveguide type H01P; line connectors, current collectors H01R; stimulated-emission devices H01S; electromechanical resonators H03H; loudspeakers, microphones, gramophone pick-ups or like acoustic electromechanical transducers H04R; electric light sources in general H05B; printed circuits, hybrid circuits, casings or constructional details of electrical apparatus, manufacture of assemblages of electrical components H05K; use of semiconductor devices in circuits having a particular application, see the subclass for the application) [2]
Data storage device for a device accessory
Patent No. 10394296
Inventor(s): Eyal Felix Hakoun (Milpitas, CA), Manohar Prasad Kashyap (Milpitas, CA), Vadim Shain (Milpitas, CA)
Assignee(s): SANDISK TECHNOLOGIES LLC (Plano, TX)
Law Firm: Vierra Magen Marcus LLP (2 non-local offices)
Application No., Date, Speed: 15879751 on 01/25/2018 (579 days app to issue)
Abstract: An apparatus includes a first interface of an accessory of a wireless device. The first interface is configured to communicate with the wireless device using a wired communication technique. The apparatus includes a second interface of the accessory. The second interface is configured to communicate with the wireless device using a wireless communication technique. The apparatus also includes a data storage device of the accessory. The apparatus further includes a controller of the accessory. The controller is coupled to the first interface, to the second interface, and to the data storage device. The controller is configured to activate the first interface in response to a message received via the second interface.
[H04M] TELEPHONIC COMMUNICATION (circuits for controlling other apparatus via a telephone cable and not involving telephone switching apparatus G08)
Managing converged IT infrastructure with generic object instances
Patent No. 10394703
Inventor(s): Joshua P. Onffroy (Upton, MA), Michael Holloway (Point Pleasant, NJ), Rajesh Nandyalam (Whitinsville, MA), Stephen C. Steir (Hopkinton, MA)
Assignee(s): VCE IP Holding Company LLC (Richardson, TX)
Law Firm: Womble Bond Dickinson (US) LLP (14 non-local offices)
Application No., Date, Speed: 13731337 on 12/31/2012 (2430 days app to issue)
Abstract: An improved technique for managing an electronic system suitable for providing users with information technology resources, such as compute, storage, and network resources, builds an object model instance of data center components to represent the data center components as a unified entity, which administrators can access as a single-point source for information about the components. In some examples, the object model instance also serves as a single-point for management control of the electronic system. The object model instance is populated with information obtained from a discovery process, where components are queried to report their actual configuration and state, as well as physical and logical relationships among them.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Signal line switch arrangement with multiple paths between a charge pump and a transistor control terminal
Patent No. 10394740
Inventor(s): Huanzhang Huang (Plano, TX), Shita Guo (Dallas, TX), Yanfei Jiang (Frisco, TX), Yanli Fan (Dallas, TX), Yonghui Tang (Plano, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16126665 on 09/10/2018 (351 days app to issue)
Abstract: An apparatus includes a transistor with a control terminal, a first current terminal, and a second current terminal. The apparatus also includes a charge pump coupled to the control terminal of the transistor via a first and second paths. The first path comprises a first resistor and the second path comprises a second resistor in series with a diode. The first resistor has a higher resistance value than the second resistor.
[H03K] PULSE TECHNIQUE (measuring pulse characteristics G01R; modulating sinusoidal oscillations with pulses H03C; transmission of digital information H04L; discriminator circuits detecting phase difference between two signals by counting or integrating cycles of oscillation H03D 3/04; automatic control, starting, synchronisation or stabilisation of generators of electronic oscillations or pulses where the type of generator is irrelevant or unspecified H03L; coding, decoding or code conversion, in general H03M) [4]
Peak detector circuit
Patent No. 10395070
Inventor(s): Eleazar Walter Kenyon (Tucker, GA)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15808607 on 11/09/2017 (656 days app to issue)
Abstract: A peak detector circuit includes a first capacitor coupled to an inverter and a first switch in parallel with the inverter. An input of the inverter couples to second and third switches. The second switch couples to an input voltage node. The third switch couples to an output voltage node of the peak detector circuit. The peak detector circuit includes a second capacitor coupled to the third switch and a third capacitor coupled to the second capacitor by way of a fourth switch. The third capacitor couples via a fifth switch to a power supply voltage node or a ground. A periodic control signal causes the first, second, and third switches to repeatedly open and close and a second control signal causes the fourth and fifth switches to open and close to adjust an output voltage on the output voltage node towards an input voltage on the input voltage node.
[H03K] PULSE TECHNIQUE (measuring pulse characteristics G01R; modulating sinusoidal oscillations with pulses H03C; transmission of digital information H04L; discriminator circuits detecting phase difference between two signals by counting or integrating cycles of oscillation H03D 3/04; automatic control, starting, synchronisation or stabilisation of generators of electronic oscillations or pulses where the type of generator is irrelevant or unspecified H03L; coding, decoding or code conversion, in general H03M) [4]
Dynamically providing to a person feedback pertaining to utterances spoken or sung by the person
Patent No. 10395671
Inventor(s): Alan D. Emery (North Richland Hills, TX), Janki Y. Vora (Dallas, TX), Mathews Thomas (Flower Mound, TX)
Assignee(s): INTERNATIONAL BUSINESS MACHINES CORPORATION (Armonk, NY)
Law Firm: Cuenot, Forsythe Kim, LLC (2 non-local offices)
Application No., Date, Speed: 15721946 on 10/01/2017 (695 days app to issue)
Abstract: Utterances spoken or sung by a first person can be received, in real time, from a mobile communication device. A location of the mobile communication device can be determined to be in an area designated as a quiet zone. A key indicator that indicates at least one characteristic of the detected utterances spoken or sung by the first person can be generated. Based, at least in part, on the key indicator, a determination can be made that the first person is speaking or singing too loudly in the area designated as the quiet zone. Responsive to determining that the first person is speaking or singing too loudly in the area designated as the quiet zone, feedback indicating that the first person is speaking or singing too loudly in the area designated as the quiet zone can be communicated to the mobile communication device.
[H04R] LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS (producing sounds with frequency not determined by supply frequency G10K) [6]
Method of etching microelectronic mechanical system features in a silicon wafer
Patent No. 10395940
Inventor(s): Ercan Mehmet Dede (Ann Arbor, MI), Feng Zhou (South Lyon, MI), Kenneth E. Goodson (Portola Valley, CA), Ki Wook Jung (Santa Clara, CA), Mehdi Asheghi (Palo Alto, CA)
Assignee(s): Toyota Motor Engineering Manufacturing North America, Inc. (Plano, TX)
Law Firm: Dinsmore Shohl, LLP (5 non-local offices)
Application No., Date, Speed: 15919889 on 03/13/2018 (532 days app to issue)
Abstract: A method of etching features in a silicon wafer includes coating a top surface and a bottom surface of the silicon wafer with a mask layer having a lower etch rate than an etch rate of the silicon wafer, removing one or more portions of the mask layer to form a mask pattern in the mask layer on the top surface and the bottom surface of the silicon wafer, etching one or more top surface features into the top surface of the silicon wafer through the mask pattern to a depth plane located between the top surface and the bottom surface of the silicon wafer at a depth from the top surface, coating the top surface and the one or more top surface features with a metallic coating, and etching one or more bottom surface features into the bottom surface of the silicon wafer through the mask pattern to the target depth plane.
[H01L] SEMICONDUCTOR DEVICES; ELECTRIC SOLID STATE DEVICES NOT OTHERWISE PROVIDED FOR (use of semiconductor devices for measuring G01; resistors in general H01C; magnets, inductors, transformers H01F; capacitors in general H01G; electrolytic devices H01G 9/00; batteries, accumulators H01M; waveguides, resonators, or lines of the waveguide type H01P; line connectors, current collectors H01R; stimulated-emission devices H01S; electromechanical resonators H03H; loudspeakers, microphones, gramophone pick-ups or like acoustic electromechanical transducers H04R; electric light sources in general H05B; printed circuits, hybrid circuits, casings or constructional details of electrical apparatus, manufacture of assemblages of electrical components H05K; use of semiconductor devices in circuits having a particular application, see the subclass for the application) [2]
Dam laminate isolation substrate
Patent No. 10395971
Inventor(s): Chang-Yen Ko (New Taipei, , TW), Chih-Chien Ho (New Taipei, , TW), Chung-Ming Cheng (New Taipei, , TW), Megan Chang (New Taipei, , TW)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15852532 on 12/22/2017 (613 days app to issue)
Abstract: An apparatus includes a lead frame, a dam and adhesive on portions of the lead frame, and an integrated circuit die having a portion on the dam and another portion on the adhesive. The lead frame can include two portions, or two lead frames. The dam can bridge a space between the two lead frames. The dam can be smaller than the integrated circuit die in at least a width dimension of the dam relative to a width dimension of the integrated circuit die, providing that the integrated circuit die overhangs the dam on each side of the width dimension of the dam. Adhesive is located between the integrated circuit die and each lead frame, adjacent to and on each side of the dam. The dam prevents adhesive from spreading into the space between the lead frames.
[H01L] SEMICONDUCTOR DEVICES; ELECTRIC SOLID STATE DEVICES NOT OTHERWISE PROVIDED FOR (use of semiconductor devices for measuring G01; resistors in general H01C; magnets, inductors, transformers H01F; capacitors in general H01G; electrolytic devices H01G 9/00; batteries, accumulators H01M; waveguides, resonators, or lines of the waveguide type H01P; line connectors, current collectors H01R; stimulated-emission devices H01S; electromechanical resonators H03H; loudspeakers, microphones, gramophone pick-ups or like acoustic electromechanical transducers H04R; electric light sources in general H05B; printed circuits, hybrid circuits, casings or constructional details of electrical apparatus, manufacture of assemblages of electrical components H05K; use of semiconductor devices in circuits having a particular application, see the subclass for the application) [2]
Leadframe inductor
Patent No. 10396016
Inventor(s): Jonathan Almeria Noquil (Bethlehem, PA), Joyce Marie Mullenix (San Jose, CA), Kristen Nguyen Parrish (Dallas, TX), Osvalod Jorge Lopez (Annadale, NJ), Roberto Giampiero Massolini (Pavia, , IT)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15395429 on 12/30/2016 (970 days app to issue)
Abstract: One example includes a device that is comprised of a die, a leadframe, and an electrically conductive material. The die includes a circuit therein. The leadframe is coupled with the die and the circuit therein. The electrically conductive material is disposed in a space above the die opposite the leadframe, the electrically conductive material being coupled to the leadframe and configured as one or more turns thereof to form at least one inductor.
[H01L] SEMICONDUCTOR DEVICES; ELECTRIC SOLID STATE DEVICES NOT OTHERWISE PROVIDED FOR (use of semiconductor devices for measuring G01; resistors in general H01C; magnets, inductors, transformers H01F; capacitors in general H01G; electrolytic devices H01G 9/00; batteries, accumulators H01M; waveguides, resonators, or lines of the waveguide type H01P; line connectors, current collectors H01R; stimulated-emission devices H01S; electromechanical resonators H03H; loudspeakers, microphones, gramophone pick-ups or like acoustic electromechanical transducers H04R; electric light sources in general H05B; printed circuits, hybrid circuits, casings or constructional details of electrical apparatus, manufacture of assemblages of electrical components H05K; use of semiconductor devices in circuits having a particular application, see the subclass for the application) [2]
Hall sensor with buried hall plate
Patent No. 10396122
Inventor(s): Ajit Sharma (Dallas, TX), Keith Ryan Green (Prosper, TX), Rajni J. Aggarwal (Garland, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: Rose Alyssa Keagy (no location found)
Application No., Date, Speed: 15639327 on 06/30/2017 (788 days app to issue)
Abstract: A CMOS integrated circuit includes a Hall sensor having a Hall plate formed in a first isolation layer which is formed concurrently with a second isolation layer under a MOS transistor. A first shallow well with a conductivity type opposite from the first isolation layer is formed over, and extending to, the Hall plate. The first shallow well is formed concurrently with a second shallow well under the MOS transistor. The Hall sensor may be a horizontal Hall sensor for sensing magnetic fields oriented perpendicular to the top surface of the substrate of the integrated circuit, or may be a vertical Hall sensor for sensing magnetic fields oriented parallel to the top surface of the substrate of the integrated circuit.
[H01L] SEMICONDUCTOR DEVICES; ELECTRIC SOLID STATE DEVICES NOT OTHERWISE PROVIDED FOR (use of semiconductor devices for measuring G01; resistors in general H01C; magnets, inductors, transformers H01F; capacitors in general H01G; electrolytic devices H01G 9/00; batteries, accumulators H01M; waveguides, resonators, or lines of the waveguide type H01P; line connectors, current collectors H01R; stimulated-emission devices H01S; electromechanical resonators H03H; loudspeakers, microphones, gramophone pick-ups or like acoustic electromechanical transducers H04R; electric light sources in general H05B; printed circuits, hybrid circuits, casings or constructional details of electrical apparatus, manufacture of assemblages of electrical components H05K; use of semiconductor devices in circuits having a particular application, see the subclass for the application) [2]
Integration of strained silicon germanium PFET device and silicon NFET device for finFET structures
Patent No. 10396185
Inventor(s): Bruce B. Doris (Slingerlands, NY), Hong He (Schenectady, NY), Junli Wang (Slingerlands, NY), Nicolas J. Loubet (Guilderland, NY)
Assignee(s): STMICROELECTRONICS, INC (Coppell, TX)
Law Firm: Cantor Colburn LLP (7 non-local offices)
Application No., Date, Speed: 15635890 on 06/28/2017 (790 days app to issue)
Abstract: A method of forming a finFET transistor device includes forming a crystalline, compressive strained silicon germanium (cSiGe) layer over a substrate; masking a first region of the cSiGe layer so as to expose a second region of the cSiGe layer; subjecting the exposed second region of the cSiGe layer to an implant process so as to amorphize a bottom portion thereof and transform the cSiGe layer in the second region to a relaxed SiGe (rSiGe) layer; performing an annealing process so as to recrystallize the rSiGe layer; epitaxially growing a tensile strained silicon layer on the rSiGe layer; and patterning fin structures in the tensile strained silicon layer and in the first region of the cSiGe layer.
[H01L] SEMICONDUCTOR DEVICES; ELECTRIC SOLID STATE DEVICES NOT OTHERWISE PROVIDED FOR (use of semiconductor devices for measuring G01; resistors in general H01C; magnets, inductors, transformers H01F; capacitors in general H01G; electrolytic devices H01G 9/00; batteries, accumulators H01M; waveguides, resonators, or lines of the waveguide type H01P; line connectors, current collectors H01R; stimulated-emission devices H01S; electromechanical resonators H03H; loudspeakers, microphones, gramophone pick-ups or like acoustic electromechanical transducers H04R; electric light sources in general H05B; printed circuits, hybrid circuits, casings or constructional details of electrical apparatus, manufacture of assemblages of electrical components H05K; use of semiconductor devices in circuits having a particular application, see the subclass for the application) [2]
Electrostatic discharge device
Patent No. 10396199
Inventor(s): Akram A. Salman (Plano, TX), Aravind C. Appaswamy (Plano, TX), Farzan Farbiz (Royal Oak, MI), Gianluca Boselli (Plano, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15624741 on 06/16/2017 (802 days app to issue)
Abstract: A semiconductor device includes a body and a transistor fabricated into the body. Isolation material at least partially encases the body. Biasing is coupled to the isolation material, wherein the biasing is for changing the electric potential of the isolation material in response to an electrostatic discharge event.
[H02H] EMERGENCY PROTECTIVE CIRCUIT ARRANGEMENTS (indicating or signalling undesired working conditions G01R, e.g. G01R 31/00, G08B; locating faults along lines G01R 31/08; emergency protective devices H01H)
Battery pack for coordinate measurement machine
Patent No. 10396319
Inventor(s): Jason Elliot Nabors (Grand Prairie, TX)
Assignee(s): UNASSIGNED
Law Firm: Dunlap Bennett Ludwig PLLC (2 non-local offices)
Application No., Date, Speed: 15179488 on 06/10/2016 (1173 days app to issue)
Abstract: A Battery Pack for portable CMM technology. The battery gives the CMM a longer operating period and extends battery time. The battery pack is configured to work with different operating voltages required by measurement equipment made by various manufactures”. The battery pack also provides a common mounting platform adapted to be utilized with the standard 3-8 threaded equipment and accessories.
[H01M] PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY [2]
Alignment determination for antennas
Patent No. 10396426
Inventor(s): Scott L. Michaelis (Plano, TX)
Assignee(s): CommScope Technologies LLC (Hickory, NC)
Law Firm: Myers Bigel, P.A. (1 non-local offices)
Application No., Date, Speed: 14418171 on 08/15/2014 (1838 days app to issue)
Abstract: An exemplary alignment module for a base station antenna has one or more accelerometers and one or more magnetometers. The one or more accelerometers are used to determine tilt and roll angles of the antenna, while the yaw angle of the antenna is determined using the one or more magnetometers and the determined tilt and roll angles. Using multiple accelerometers and/or multiple magnetometers can improve accuracy of angle determination. A service provider can determine when to re-align the antenna by monitoring the tilt, roll, and yaw angles remotely to detect changes in antenna orientation. Yaw angle determination can also take into account offset values corresponding to soft-iron effects, hard-iron effects, and factory calibration. The need to re-calibrate offset values following changes in local magnetic environment can be detected by comparing different sensor signals, such as the different magnetic fields detected by a plurality of magnetometers.
[H01Q] AERIALS (radiators or aerials for microwave heating H05B 6/72)
Low profile, ultra-wide band, low frequency modular phased array antenna with coincident phase center
Patent No. 10396461
Inventor(s): Brian W. Johansen (McKinney, TX), James M. Irion, II (Allen, TX), Justin A. Kasemodel (McKinney, TX), Justin E. Stroup (Anna, TX)
Assignee(s): RAYTHEON COMPANY (Waltham, MA)
Law Firm: Cantor Colburn LLP (7 non-local offices)
Application No., Date, Speed: 15246015 on 08/24/2016 (1098 days app to issue)
Abstract: An antenna is provided and includes a radiator assembly extending along a first plane, a patterned ferrite layer extending along a second plane and a band stop frequency selective surface (FSS) extending along a third plane. The third plane of the band stop FSS is axially interposed between the first plane of the radiator assembly and the second plane of the patterned ferrite layer.
[H01Q] AERIALS (radiators or aerials for microwave heating H05B 6/72)
VCSELs having mode control and device coupling
Patent No. 10396529
Inventor(s): Gary Landry (Allen, TX), Jim Tatum (Plano, TX)
Assignee(s): Finisar Corporation (Sunnyvale, CA)
Law Firm: Maschoff Brennan (5 non-local offices)
Application No., Date, Speed: 15986297 on 05/22/2018 (462 days app to issue)
Abstract: A VCSEL can include: an active region configured to emit light; a blocking region over or under the active region, the blocking region defining a plurality of channels therein; a plurality of conductive channel cores in the plurality of channels of the blocking region, wherein the plurality of conductive channel cores and blocking region form an isolation region; a top electrical contact; and a bottom electrical contact electrically coupled with the top electrical contact through the active region and plurality of conductive channel cores. At least one conductive channel core is a light emitter, and others can be spare light emitters, photodiodes, modulators, and combinations thereof. A waveguide can optically couple two or more of the conductive channel cores. In some aspects, the plurality of conductive channel cores are optically coupled to form a common light emitter that emits light (e.g., single mode) from the plurality of conductive channel cores.
[H01S] DEVICES USING STIMULATED EMISSION
ESD protection charge pump active clamp for low-leakage applications
Patent No. 10396550
Inventor(s): Farzan Farbiz (Dallas, TX), James P. Di Sarro (Plano, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15281379 on 09/30/2016 (1061 days app to issue)
Abstract: Disclosed examples include an electrostatic discharge protection circuit including a shunt transistor coupled between first and second power supply nodes, a sensing circuit to deliver a control voltage signal to turn on the shunt transistor in response to a detected change in a voltage of the first power supply node resulting from an ESD stress event, and a charge pump circuit to boost the control voltage signal in response to the control voltage signal turning the shunt transistor on.
[H02H] EMERGENCY PROTECTIVE CIRCUIT ARRANGEMENTS (indicating or signalling undesired working conditions G01R, e.g. G01R 31/00, G08B; locating faults along lines G01R 31/08; emergency protective devices H01H)
Geolocation using guided surface waves
Patent No. 10396566
Inventor(s): James D. Lilly (Silver Spring, MD), James F. Corum (Morgantown, WV), Kenneth L. Corum (Plymouth, NH), Michael J. D”Aurelio (Marietta, GA)
Assignee(s): CPG Technologies, LLC (Italy, TX)
Law Firm: Thomas Horstemeyer, LLP (1 non-local offices)
Application No., Date, Speed: 14850042 on 09/10/2015 (1447 days app to issue)
Abstract: Disclosed are various approaches for determining a location using guided surface waves. A guided surface wave is received. A field strength of a guided surface wave is identified. A phase of the guided surface wave is identified. A distance from a guided surface waveguide probe that launched the guided surface wave is calculated. A location is determined based at least in part on the distance from the guided surface waveguide probe.
[H02J] CIRCUIT ARRANGEMENTS OR SYSTEMS FOR SUPPLYING OR DISTRIBUTING ELECTRIC POWER; SYSTEMS FOR STORING ELECTRIC ENERGY (power supply circuits for apparatus for measuring X-radiation, gamma radiation, corpuscular radiation or cosmic radiation G01T 1/175; electric power supply circuits specially adapted for use in electronic time-pieces with no moving parts G04G 19/00; for digital computers G06F 1/18; for discharge tubes H01J 37/248; circuits or apparatus for the conversion of electric power, arrangements for control or regulation of such circuits or apparatus H02M; interrelated control of several motors, control of a prime-mover/generator combination H02P; control of high-frequency power H03L; additional use of power line or power network for transmission of information H04B)
Battery charger with user interface
Patent No. 10396568
Inventor(s): Kent Poteet (Lucas, TX), Tom Kawamura (Plano, TX)
Assignee(s): TRAXXAS LP (McKinney, TX)
Law Firm: No Counsel
Application No., Date, Speed: 14504398 on 10/01/2014 (1791 days app to issue)
Abstract: A battery single charger may accommodate Li-type and Ni-type batteries, having default charge settings and user-adjustable charge parameters in an advanced mode. Lithium Polymer (LiPo) batteries equipped with RFID technology and integrated balance taps may communicate with a device such as a battery charger equipped with similar technology providing information such as chemistry type, cell count, recommended charge rates, number of charges on the battery, among other types of information. Several safety features may be included.
[H02J] CIRCUIT ARRANGEMENTS OR SYSTEMS FOR SUPPLYING OR DISTRIBUTING ELECTRIC POWER; SYSTEMS FOR STORING ELECTRIC ENERGY (power supply circuits for apparatus for measuring X-radiation, gamma radiation, corpuscular radiation or cosmic radiation G01T 1/175; electric power supply circuits specially adapted for use in electronic time-pieces with no moving parts G04G 19/00; for digital computers G06F 1/18; for discharge tubes H01J 37/248; circuits or apparatus for the conversion of electric power, arrangements for control or regulation of such circuits or apparatus H02M; interrelated control of several motors, control of a prime-mover/generator combination H02P; control of high-frequency power H03L; additional use of power line or power network for transmission of information H04B)
Variable power energy harvesting system
Patent No. 10396590
Inventor(s): Brett Smith (McKinney, TX), Eric Blackall (Richardson, TX), Ross E. Teggatz (The Colony, TX), Wayne T. Chen (Plano, TX)
Assignee(s): TRIUNE SYSTEMS, LLC (Plano, TX)
Law Firm: Jackson Walker LLP (Local + 3 other metros)
Application No., Date, Speed: 15595731 on 05/15/2017 (834 days app to issue)
Abstract: The disclosed invention provides examples of preferred embodiments including systems for harvesting energy from variable output energy harvesting apparatus. The systems include energy harvesting apparatus for providing energy input to a switched mode power supply and a control loop for dynamically adjusting energy harvesting apparatus input to the switched mode power supply, whereby system output power is substantially optimized to the practical. Exemplary embodiments of the invention include systems for harvesting energy using solar cells in boost, buck, and buck-boost configurations.
[H02J] CIRCUIT ARRANGEMENTS OR SYSTEMS FOR SUPPLYING OR DISTRIBUTING ELECTRIC POWER; SYSTEMS FOR STORING ELECTRIC ENERGY (power supply circuits for apparatus for measuring X-radiation, gamma radiation, corpuscular radiation or cosmic radiation G01T 1/175; electric power supply circuits specially adapted for use in electronic time-pieces with no moving parts G04G 19/00; for digital computers G06F 1/18; for discharge tubes H01J 37/248; circuits or apparatus for the conversion of electric power, arrangements for control or regulation of such circuits or apparatus H02M; interrelated control of several motors, control of a prime-mover/generator combination H02P; control of high-frequency power H03L; additional use of power line or power network for transmission of information H04B)
Reconfigurable low-noise amplifier (LNA)
Patent No. 10396714
Inventor(s): Charles Forrest Campbell (Allen, TX)
Assignee(s): Qorvo US, Inc. (Greensboro, NC)
Law Firm: Withrow Terranova, P.L.L.C. (1 non-local offices)
Application No., Date, Speed: 15660554 on 07/26/2017 (762 days app to issue)
Abstract: A reconfigurable low-noise amplifier (LNA) is disclosed. The reconfigurable LNA includes amplifier circuitry having a gate terminal coupled to an input terminal, a source terminal coupled to a fixed voltage node, and a drain terminal coupled to an output terminal. The reconfigurable LNA further includes a gamma inverting network (GIN) coupled between the input terminal and the fixed voltage node, wherein the GIN has a first switch configured to disable the GIN during operation at first frequencies within a lower frequency band relative to a higher frequency band and to enable the GIN during operation at second frequencies within the higher frequency band.
[H03F] AMPLIFIERS (measuring, testing G01R; optical parametric amplifiers G02F; circuit arrangements with secondary emission tubes H01J 43/30; masers, lasers H01S; dynamo-electric amplifiers H02K; control of amplification H03G; coupling arrangements independent of the nature of the amplifier, voltage dividers H03H; amplifiers capable only of dealing with pulses H03K; repeater circuits in transmission lines H04B 3/36, H04B 3/58; application of speech amplifiers in telephonic communication H04M 1/60, H04M 3/40)
Method of forming an integrated resonator with a mass bias
Patent No. 10396746
Inventor(s): Byron Neville Burgess (Allen, TX), Stuart M. Jacobsen (Frisco, TX), William Robert Krenik (Garland, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 14970676 on 12/16/2015 (1350 days app to issue)
Abstract: A method of forming an integrated resonator apparatus includes depositing alternating dielectric layers of lower and higher acoustic impedance materials over a substrate. First and second resonator electrodes are formed over the alternating dielectric layers, with a piezoelectric layer located between the first and second resonator electrodes. A mass bias is formed over the first and second resonator electrodes. The mass bias, first and second electrodes, piezoelectric layer, and alternating dielectric layers may be encapsulated with a plastic mold fill.
[H03H] IMPEDANCE NETWORKS, e.g. RESONANT CIRCUITS; RESONATORS (measuring, testing G01R; arrangements for producing a reverberation or echo sound G10K 15/08; impedance networks or resonators consisting of distributed impedances, e.g. of the waveguide type, H01P; control of amplification, e.g. bandwidth control of amplifiers, H03G; tuning resonant circuits, e.g. tuning coupled resonant circuits, H03J; networks for modifying the frequency characteristics of communication systems H04B)
Parasitic capacitance cancellation using dummy transistors
Patent No. 10396766
Inventor(s): Ani Xavier (Kottayam, , IN), Basavaraj G. Gorguddi (Bangalore, , IN)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15854741 on 12/26/2017 (609 days app to issue)
Abstract: In some examples, an apparatus includes a plurality of first transistors coupled to a first input terminal and a first output terminal. The apparatus also includes a plurality of second transistors coupled to a second input terminal and a second output terminal. The apparatus further includes a plurality of first dummy transistors coupled to the first input terminal and the second output terminal. The apparatus also includes a plurality of second dummy transistors coupled to the second input terminal and the first output terminal.
[H03K] PULSE TECHNIQUE (measuring pulse characteristics G01R; modulating sinusoidal oscillations with pulses H03C; transmission of digital information H04L; discriminator circuits detecting phase difference between two signals by counting or integrating cycles of oscillation H03D 3/04; automatic control, starting, synchronisation or stabilisation of generators of electronic oscillations or pulses where the type of generator is irrelevant or unspecified H03L; coding, decoding or code conversion, in general H03M) [4]
Circuits with low-pass filters and differential amplifiers
Patent No. 10396768
Inventor(s): Michael Schultz (Munich, , DE), Robert Callaghan Taft (Munich, , DE)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15951973 on 04/12/2018 (502 days app to issue)
Abstract: A circuit comprises a first set of serially-connected inverters comprising an input port, the first set of serially-connected inverters comprising a first subset of serially-connected inverters, the first subset of serially-connected inverters odd in number and comprising an input port and an output port; a first low-pass filter comprising an input port coupled to the output port of the first subset of serially-connected inverters, and an output port; a second low-pass filter comprising an input port coupled to the input port of the first subset of serially-connected inverters, and an output port; and a first differential amplifier comprising a first input port coupled to output port of the first low-pass filter, a second input port coupled to the output port of the second low-pass filter, and an output port coupled to the input port of the first set of serially-connected inverters.
[H03K] PULSE TECHNIQUE (measuring pulse characteristics G01R; modulating sinusoidal oscillations with pulses H03C; transmission of digital information H04L; discriminator circuits detecting phase difference between two signals by counting or integrating cycles of oscillation H03D 3/04; automatic control, starting, synchronisation or stabilisation of generators of electronic oscillations or pulses where the type of generator is irrelevant or unspecified H03L; coding, decoding or code conversion, in general H03M) [4]
Current mode logic driver with level shifter
Patent No. 10396794
Inventor(s): Steven Ernest Finn (Chamblee, GA)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16364246 on 03/26/2019 (154 days app to issue)
Abstract: A driver circuit includes a first termination resistor and a distributed amplifier comprising a plurality of pairs of input transistors and comprising inductors coupled between each pair of input transistors. The driver circuit also includes a distributed current-mode level shifter coupled to the first termination resistor. The distributed current-mode level shifter includes a first plurality of inductors coupled in series between the first termination resistor and the distributed amplifier and a first plurality of capacitive devices. Each capacitive device is coupled to a power supply node and to a node interconnecting two of the series-coupled inductors.
[H03F] AMPLIFIERS (measuring, testing G01R; optical parametric amplifiers G02F; circuit arrangements with secondary emission tubes H01J 43/30; masers, lasers H01S; dynamo-electric amplifiers H02K; control of amplification H03G; coupling arrangements independent of the nature of the amplifier, voltage dividers H03H; amplifiers capable only of dealing with pulses H03K; repeater circuits in transmission lines H04B 3/36, H04B 3/58; application of speech amplifiers in telephonic communication H04M 1/60, H04M 3/40)
Wide capture range reference-less frequency detector
Patent No. 10396805
Inventor(s): Gong Lei (Sunnyvale, CA), Hung-Yi Lee (Cupertino, CA), Liang Gu (San Jose, CA), Mamatha Deshpande (San Jose, CA), Miao Liu (Pudong District, , CN), Shou-Po Shih (Cupertino, CA), Yen Dang (San Jose, CA), Yifan Gu (Santa
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Schwegman Lundberg Woessner, P.A. (11 non-local offices)
Application No., Date, Speed: 16119462 on 08/31/2018 (361 days app to issue)
Abstract: A reference-less frequency detector circuit includes a sampling circuit that is configured to generate a frequency control voltage and a switch circuit control signal based on a frequency difference between a clock signal frequency and an input data rate. The frequency control voltage has a frequency down indication and a frequency up indication. A voltage-to-current converter circuit is coupled to the sampling circuit and is configured to convert the frequency control voltage to a frequency control current based on the switch circuit control signal. The voltage-to-current converter circuit includes an output switch circuit controlled by the switch control signal and is configured to have substantially equal respective latencies for the frequency down indication and the frequency up indication.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Reference voltage control circuit for a two-step flash analog-to-digital converter
Patent No. 10396814
Inventor(s): Jafar Sadique Kaviladath (Kozhikode, , IN), Neeraj Shrivastava (Bengaluru, , IN)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16211259 on 12/06/2018 (264 days app to issue)
Abstract: A circuit, which is usable in a flash analog-to-digital converter, includes a first switch configured to provide a first reference voltage to a first reference node responsive to a first control signal and a second switch configured to provide the first reference voltage to a second reference node responsive to a second control signal. A third switch is coupled to the first switch and is configured to provide a second reference voltage to the first reference node responsive to a clock signal. Further, a fourth switch is coupled to the second switch and configured to provide the second reference voltage to the second reference node responsive to the clock signal.
[H03M] CODING, DECODING OR CODE CONVERSION, IN GENERAL (using fluidic means F15C 4/00; optical analogue/digital converters G02F 7/00; coding, decoding or code conversion, specially adapted for particular applications, see the relevant subclasses, e.g. G01D, G01R, G06F, G06T, G09G, G10L, G11B, G11C, H04B, H04L, H04M, H04N; ciphering or deciphering for cryptography or other purposes involving the need for secrecy G09C) [4]
Long preamble and duty cycle based coexistence mechanism for power line communication (PLC) networks
Patent No. 10396852
Inventor(s): Kumaran Vijayasankar (Allen, TX), Ramanuja Vedantham (Allen, TX), Tarkesh Pande (Richardson, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATION (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15946041 on 04/05/2018 (509 days app to issue)
Abstract: Embodiments of methods and systems for supporting coexistence of multiple technologies in a Power Line Communication (PLC) network are disclosed. A long coexistence preamble sequence may be transmitted by a device that has been forced to back off the PLC channel multiple times. The long coexistence sequence provides a way for the device to request channel access from devices on the channel using other technology. The device may transmit a data packet after transmitting the long coexistence preamble sequence. A network duty cycle time may also be defined as a maximum allowed duration for nodes of the same network to access the channel. When the network duty cycle time occurs, all nodes will back off the channel for a duty cycle extended inter frame space before transmitting again. The long coexistence preamble sequence and the network duty cycle time may be used together.
[H04B] TRANSMISSION [4]
Advanced CSI reporting in advanced wireless communication systems
Patent No. 10396866
Inventor(s): Eko Onggosanusi (Coppell, TX), Md. Saifur Rahman (Plano, TX)
Assignee(s): Samsung Electronics Co., Ltd. (Suwon-si, , KR)
Law Firm: No Counsel
Application No., Date, Speed: 15718631 on 09/28/2017 (698 days app to issue)
Abstract: A method of a user equipment (UE) for a channel state information (CSI) feedback in an advanced communication system. The method comprises receiving, from a base station (BS), CSI configuration information to report a wideband periodic CSI including a pre-coding matrix indicator (PMI), a rank indicator (RI) and a relative power indicator (RPI) based on a linear combination (LC) codebook, wherein the PMI comprises a first PMI (i[subscript]1[/subscript]) indicating a plurality of beams and a second PMI (i[subscript]2[/subscript]) indicating a plurality of weights for linear combination of the plurality of beams; determining, based on the CSI configuration information, the RI and the RPI indicating a power of weights assigned to the plurality of beams; and transmitting, to the BS over an uplink channel, a first CSI feedback comprising the RI and RPI in a first periodic reporting instance out of a plurality of periodic reporting instances.
[H04B] TRANSMISSION [4]
System and method for multiplexing control and data channels in a multiple input, multiple output communications system
Patent No. 10396870
Inventor(s): Weimin Xiao (Hoffman Estates, IL), Ying Jin (Shanghai, , CN), Yufei Blankenship (Kildeer, IL)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Slater Matsil, LLP (Local + 1 other metros)
Application No., Date, Speed: 15940723 on 03/29/2018 (516 days app to issue)
Abstract: A system and method for system and method for multiplexing control and data channels in a multiple input, multiple output (MIMO) communications system are provided. A method for transmitting control symbols and data symbols on multiple MIMO layers includes selecting a first set of codewords from N[subscript]cw [/subscript]codewords, distributing control symbols onto the first set of layers, placing data symbols of the first set of codewords onto the first set of layers, placing data symbols of the (N[subscript]cw[/subscript]-N[subscript]cw1[/subscript]) remaining codewords to remaining layers if N[subscript]cw[/subscript]N[subscript]cw1[/subscript], and transmitting the multiple MIMO layers. The first set of codewords is associated with a first set of layers from the multiple MIMO layers, and the N[subscript]cw [/subscript]codewords are to be transmitted simultaneously and the first set of codewords comprises N[subscript]cw1 [/subscript]MIMO codewords, where N[subscript]cw [/subscript]and N[subscript]cw1 [/subscript]are integers greater than or equal to 1. The remaining layers are MIMO layers from the multiple MIMO layers not in the first set of layers.
[H04B] TRANSMISSION [4]
Probabilistic constellation shaping using set-partitioned M-QAM
Patent No. 10396899
Inventor(s): Inwoong Kim (Allen, TX), Olga I. Vassilieva (Plano, TX), Paparao Palacharla (Richardson, TX), Tadashi Ikeuchi (Plano, TX)
Assignee(s): Fujitsu Limited (Kawasaki, , JP)
Law Firm: Baker Botts L.L.P. (Local + 8 other metros)
Application No., Date, Speed: 16107141 on 08/21/2018 (371 days app to issue)
Abstract: Systems and methods for constellation shaping of M-QAM modulation formats in optical transport networks may receive binary data to be transmitted as an optical signal and partition symbols of an M-QAM constellation in the complex plane into two non-overlapping subsets of symbols, The systems and methods may include assigning respective probabilities to each symbol in the first subset of symbols dependent on a target probability distribution for the first subset, mapping at least a portion of the received binary data to the symbols in the first subset, including generating a respective codeword for each symbol in the first subset, in a first symbol period, providing data representing the respective codewords mapped to the symbols in the first subset to an optical modulator for transmission, and refraining from providing any data representing codewords mapped to the symbols in the second subset to the optical modulator until a second symbol period.
[H04B] TRANSMISSION [4]
Apparatus and mechanism to support multiple time domains in a single soc for time sensitive network
Patent No. 10396922
Inventor(s): Chunhua Hu (Plano, TX), Denis Beaudoin (Rowlett, TX), Eric Hansen (McKinney, TX), Thomas Anton Leyrer (Geisenhausen, , DE), Venkateswar Reddy Kowkutla (Allen, TX)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15891227 on 02/07/2018 (566 days app to issue)
Abstract: A system on a chip (SOC) is configured to support multiple time domains within a time-sensitive networking (TSN) environment. TSN extends Ethernet networks to support a deterministic and high-availability communication on Layer 2 (data link layer of open system interconnect ”OSI” model) for time coordinated capabilities such as industrial automation and control applications. Processors in a system may have an application time domain separate from the communication time domain. In addition, each type time domain may also have multiple potential time masters to drive synchronization for fault tolerance. The SoC supports multiple time domains driven by different time masters and graceful time master switching. Timing masters may be switched at run-time in case of a failure in the system. Software drives the SoC to establish communication paths through a sync router to facilitate communication between time providers and time consumers. Multiple time sources are supported.
[H04J] MULTIPLEX COMMUNICATION (peculiar to transmission of digital information H04L 5/00; systems for the simultaneous or sequential transmission of more than one television signal H04N 7/08; in exchanges H04Q 11/00)
Methods and systems for asynchronous time division duplex by radio base station
Patent No. 10396946
Inventor(s): Farooq Khan (Allen, TX)
Assignee(s): Phazr, Inc. (Allen, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15811580 on 11/13/2017 (652 days app to issue)
Abstract: A method of wireless communication using time division duplex over widely spaced frequency bands by a radio base station includes transmitting millimeter wave band downlink signals comprising a plurality of first transmission time intervals (TTIs) and receiving millimeter wave band uplink signals comprising at least one second TTI. The number of first TTIs is greater than the number of second TTIs. The method includes transmitting sub-7 GHz band downlink signals comprising at least one third TTI and receiving sub-7 GHz band uplink signals comprising a plurality of fourth TTIs. The number of third TTIs is less than the number of fourth TTIs.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Clock recovery system and method for near field communication with active load modulation
Patent No. 10396975
Inventor(s): Jonathan C.H. Hung (Plano, TX), Thomas Michael Maguire (Plano, TX)
Assignee(s): Maxim Integrated Products, Inc. (San Jose, CA)
Law Firm: No Counsel
Application No., Date, Speed: 15631517 on 06/23/2017 (795 days app to issue)
Abstract: A system includes a tank circuit, a synchronization circuit, a transmitter, and a control circuit. The tank circuit is configured to receive a first signal transmitted from a near field communication reader. The synchronization circuit is configured to synchronize a clock to the first signal. The transmitter is configured to transmit data using the clock from the tank circuit to the near field communication reader using active load modulation. The control circuit is configured to disable the synchronization circuit during a modulation period of the active load modulation and to reduce energy remaining in the tank circuit at an end of the modulation period.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Wireless carrier network performance analysis and troubleshooting
Patent No. 10397043
Inventor(s): Rafael Sanchez-Mejias (Dallas, TX)
Assignee(s): TUPL, Inc. (Bellevue, WA)
Law Firm: No Counsel
Application No., Date, Speed: 15212110 on 07/15/2016 (1138 days app to issue)
Abstract: An analytic application may provide analysis of performance data for a wireless carrier network to determine root causes of issues. Performance data for network components of the wireless carrier network and device components of user devices that use the network may be obtained. The performance data is processed by aggregating multiple datasets of the performance data into aggregated performance data according to one or more grouping parameters or converge a plurality of datasets of the performance data into converged performance data according to a unitary storage schema. Analysis may be performed on the aggregated performance data or the converged performance data to detect an issue affecting the wireless carrier network or to generate a solution to the issue. The aggregate performance data and the converged performance data may include non-real time data or real time data. Accordingly, the issue or the solution to the issue may be provided for presentation.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Weighted next hop selection at a router using an equal cost multipath process
Patent No. 10397097
Inventor(s): Fangping Liu (San Jose, CA), Serhat Nazim Avci (Milpitas, CA), Zhenjiang Li (San Jose, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Vierra Magen Marcus LLP (2 non-local offices)
Application No., Date, Speed: 15409484 on 01/18/2017 (951 days app to issue)
Abstract: A routing technique provides a routing table which assigns weights in the process of selecting a next hop at a router, while still using an equal cost multipath selection process at the router. The routing table is configured to cross reference an IP address prefix set to a number of next hops which can be all, or fewer than all, available next hops. This occurs in each row of the table for a different IP address prefix set. Subsets of the next hops are identified in each row in a manner which results in the next hops being selected according to specified weights. An estimate of traffic to the different IP address prefix set is also considered. The routing table can be configured based on announce and withdraw messages received from a link weight translator of a controller.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Service function chaining across multiple subnetworks
Patent No. 10397108
Inventor(s): Farhad P. Sunavala (Santa Clara, CA), Fei Rao (Santa Clara, CA), Henry Louis Fourie (Santa Clara, CA), Hong Zhang (Santa Clara, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: FutureWei Technologies, Inc. (2 non-local offices)
Application No., Date, Speed: 15412282 on 01/23/2017 (946 days app to issue)
Abstract: A method for service function chaining across subnetworks includes receiving a packet at a virtual switch integration bridge from a first service function (SF) that is in a service function chain (SFC) and that is on a first subnetwork, determining a next SF in the SFC in a different subnetwork, and sending the received packet directly from the virtual switch integration bridge to the next SF.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
System and method for granting virtualized network function life cycle management
Patent No. 10397132
Inventor(s): Aijuan Feng (Shenzhen, , CN), Haitao Xia (Beijing, , CN), Zhixian Xiang (Frisco, TX)
Assignee(s): FutureWei Technologies, Inc. (Plano, TX)
Law Firm: FutureWei Technologies, Inc. (2 non-local offices)
Application No., Date, Speed: 15638246 on 06/29/2017 (789 days app to issue)
Abstract: A virtualized network function (VNF) life cycle management (LCM) method is disclosed that includes sending, by a virtualized network function manager (VNFM), a grant request for a VNF LCM operation to a network functions virtualization orchestrator (NFVO), wherein the grant request comprises a requested wide area network (WAN) connectivity requirement for connecting multiple sites that virtualized network function components (VNFCs) of the virtualized network function (VNF) instance are placed in, and the VNF comprises at least two VNFCs placed in different sites. In this embodiment the method also includes receiving, by the VNFM, a grant response from the network functions virtualization orchestrator (NFVO), wherein the grant response comprises WAN Infrastructure Manager (WIM) information and a granted WAN connectivity requirement approved by the NFVO.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Mobility management using identifier-locator addressing (ILA)
Patent No. 10397184
Inventor(s): Niranjan B. Avula (Frisco, TX)
Assignee(s): Verizon Patent and Licensing Inc. (Basking Ridge, NJ)
Law Firm: No Counsel
Application No., Date, Speed: 15792521 on 10/24/2017 (672 days app to issue)
Abstract: A device can receive, from a network device, a request to create an internet protocol (IP) session for a user device. The device can allocate an IP address for the user device and a first tunnel endpoint identifier associated with a tunnel. The IP address can include a first set of bits associated with a location identifier and a second set of bits associated with a device identifier. The device can provide a response to the network device, and can receive a request that includes a second tunnel endpoint identifier associated with the tunnel. The device can provide the IP address and the first and second tunnel endpoint identifiers to be stored using a data structure. The device can provide a response to the network device indicating to establish the downlink portion of the IP session, and can perform one or more actions associated with managing the IP session.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Dynamic transmission of encrypted data
Patent No. 10397194
Inventor(s): Emil Dides (Coppell, TX)
Assignee(s): eBay Inc. (San Jose, CA)
Law Firm: Schwegman Lundberg Woessner, P.A. (11 non-local offices)
Application No., Date, Speed: 15208435 on 07/12/2016 (1141 days app to issue)
Abstract: Embodiments of the present disclosure may be used to securely transmit data between multiple computing devices. Among other things, this can greatly extend the range of data transmissions in comparison to fixed-position wireless beacons and access points.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Hierarchical pattern matching for deep packet analysis
Patent No. 10397263
Inventor(s): Wei Xu (Dublin, CA), Yan Sun (Santa Clara, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Conley Rose, P.C. (3 non-local offices)
Application No., Date, Speed: 15496322 on 04/25/2017 (854 days app to issue)
Abstract: A method comprising receiving, by a network element, a data packet, searching, by the network element, the received data packet at a first hierarchical level to determine whether a substring of a string of a regular expression exists in the received data packet, searching, by the network element when the search of the received data packet at the first hierarchical level finds a match, the received data packet at a second hierarchical level to determine whether the string of the regular expression exists in the received data packet, and transmitting, by the network element, the received data packet to a next network element along an original path of the received data packet without searching the received data packet at a third hierarchical level when the search of the received data packet at the first or second hierarchical level does not find a match.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Providing session initiation protocol request contents method and system
Patent No. 10397282
Inventor(s): Jan Hendrik Lucas Bakker (Keller, TX)
Assignee(s): BlackBerry Limited (Waterloo, Ontario, , CA)
Law Firm: Conley Rose, P.C. (3 non-local offices)
Application No., Date, Speed: 15658091 on 07/24/2017 (764 days app to issue)
Abstract: An embodiment provides a user equipment that includes a processor configured to receive a Session Initiation Protocol (SIP) NOTIFY message transmitted by a network component as a result of a registration event. The SIP NOTIFY message contains at least a portion of information included in a first SIP message sent between a first user equipment and the network component. Another embodiment provides method and apparatus for a network node to determine whether filter criteria include one or more indicators that specify the need for information, and including in a second SIP message the information specified by the one or more indicators.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Providing audio announcement to called parties
Patent No. 10397387
Inventor(s): Kevin V. Nguyen (Allen, TX), M. Gregory Smith (Fairview, TX), Monica Rose Martino (Plano, TX)
Assignee(s): I D YOU, LLC (Allen, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16140858 on 09/25/2018 (336 days app to issue)
Abstract: The present disclosure describes a system, method, and computer-readable medium for providing audio announcement of communications to a called party in a communication network. The method includes receiving communication from a calling party and performing a lookup of information relating to the calling party in a database via an Internet Protocol connection based on an identifier of at least one of the calling party and the called party. The information comprises one or more audio files. The method then provides the audio announcement to a called party based on the audio files.
[H04M] TELEPHONIC COMMUNICATION (circuits for controlling other apparatus via a telephone cable and not involving telephone switching apparatus G08)
Device function disablement during vehicle motion
Patent No. 10397396
Inventor(s): Ira L. Allen (Dallas, TX)
Assignee(s): International Business Machines Corporation (Armonk, NY)
Law Firm: Schmeiser, Olsen Watts (6 non-local offices)
Application No., Date, Speed: 16047064 on 07/27/2018 (396 days app to issue)
Abstract: A method and system for disabling functions of a movement detection enabled device is provided. The method includes monitoring a movement detection signal of the movement detection enabled device in a vehicle and determining that the vehicle is currently in motion. An electronic tag in the vehicle is detected and instructions associated with the movement detection enabled device are retrieved. It is determined that the movement detection enabled device is located within a specified proximity to a driver location of the vehicle and that a user of the device is a driver of the vehicle. In response, specified functions of the movement detection enabled device are disabled.
[H04M] TELEPHONIC COMMUNICATION (circuits for controlling other apparatus via a telephone cable and not involving telephone switching apparatus G08)
IP-enabled information delivery
Patent No. 10397399
Inventor(s): Monica Rose Martino (Plano, TX), Taylor Cleghorn (Plano, TX)
Assignee(s): ACCUDATA TECHNOLOGIES, INC. (Allen, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15883643 on 01/30/2018 (574 days app to issue)
Abstract: A method, system, and computer readable medium comprising instructions for providing Internet protocol enabled information delivery are provided. Information from a calling party is received at an Internet protocol enabled device. A lookup of information relating to the calling party is performed in a database via an Internet protocol connection. A message is received from the database comprising information relating to the calling party.
[H04M] TELEPHONIC COMMUNICATION (circuits for controlling other apparatus via a telephone cable and not involving telephone switching apparatus G08)
Message exchange
Patent No. 10397410
Inventor(s): David Woody (Allen, TX), Stephen Hodge (Aubrey, TX)
Assignee(s): Value-Added Communications, Inc. (Reston, VA)
Law Firm: Sterne, Kessler, Goldstein Fox P.L.L.C. (2 non-local offices)
Application No., Date, Speed: 15878130 on 01/23/2018 (581 days app to issue)
Abstract: Disclosed is a voice message exchange system and method for improving communication between an inmate and a third party by enabling the inmate to leave a message when a call is not answered and further allowing the third party who receives the message to reply with a message to the inmate. Additionally, outside parties that meet the institution”s requirements can leave messages for inmates at any time. The present invention can be used as an add-on to legacy inmate call management systems or incorporated internally into an inmate call management system. The system also provides monitoring, controlling, recording, and billing means.
[H04M] TELEPHONIC COMMUNICATION (circuits for controlling other apparatus via a telephone cable and not involving telephone switching apparatus G08)
Correcting lag in imaging devices
Patent No. 10397504
Inventor(s): Joshua Lund (Dallas, TX)
Assignee(s): Kidde Technologies, Inc. (Wilson, NC), Sensors Unlimited, Inc. (Princeton, NJ)
Law Firm: Locke Lord LLP (Local + 12 other metros)
Application No., Date, Speed: 15431179 on 02/13/2017 (925 days app to issue)
Abstract: A method of correcting lag in an imaging pixel includes receiving a current frame pixel value and determining a current filter coefficient using the current frame pixel value. A pixel output is determined from a product of the current frame pixel value and current frame filter coefficient. The product of a first prior frame pixel value and corresponding first prior frame filter coefficient is added to the pixel output to generate a corrected pixel output to more closely indicates incident illumination on the imaging pixel during an integration period from which the current frame pixel value was obtained.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Inverse scan order for significance map coding of transform coefficients in video coding
Patent No. 10397577
Inventor(s): Joel Sole Rojals (La Jolla, CA), Marta Karczewicz (San Diego, CA), Rajan Laxman Joshi (San Diego, CA)
Assignee(s): Velos Media, LLC (Plano, TX)
Law Firm: Nixon Vanderhye P.C. (2 non-local offices)
Application No., Date, Speed: 13413526 on 03/06/2012 (2730 days app to issue)
Abstract: This disclosure describes techniques for coding transform coefficients associated with a block of residual video data in a video coding process. Aspects of this disclosure include the selection of a scan order for both significance map coding and level coding, as well as the selection of contexts for entropy coding consistent with the selected scan order. This disclosure proposes a harmonization of the scan order to code both the significance map of the transform coefficients as well as to code the levels of the transform coefficient. It is proposed that the scan order for the significance map should be in the inverse direction (i.e., from the higher frequencies to the lower frequencies). This disclosure also proposes that transform coefficients be scanned in sub-sets as opposed to fixed sub-blocks. In particular, transform coefficients are scanned in a sub-set consisting of a number of consecutive coefficients according to the scan order.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Processor instructions for accelerating video coding
Patent No. 10397591
Inventor(s): Chaitanya Satish Ghone (Pune, , IN), Dipan Kumar Mandal (Bangalore, , IN), Hetul Sanghvi (Richardson, TX), Mahesh Madhukar Mehendale (Bangalore, , IN), Mihir Narendra Mody (Bangalore, , IN), Naresh Kumar Yadav (Noida, , IN), Niraj
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 14684334 on 04/11/2015 (1599 days app to issue)
Abstract: A control processor for a video encode-decode engine is provided that includes an instruction pipeline. The instruction pipeline includes an instruction fetch stage coupled to an instruction memory to fetch instructions, an instruction decoding stage coupled to the instruction fetch stage to receive the fetched instructions, and an execution stage coupled to the instruction decoding stage to receive and execute decoded instructions. The instruction decoding stage and the instruction execution stage are configured to decode and execute a set of instructions in an instruction set of the control processor that are designed specifically for accelerating video sequence encoding and encoded video bit stream decoding.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Method for deriving a motion vector
Patent No. 10397613
Inventor(s): Christopher A. Segall (Camas, WA)
Assignee(s): Velos Media, LLC (Plano, TX)
Law Firm: Grable Martin Fulton PLLC (Local + 1 other metros)
Application No., Date, Speed: 15650565 on 07/14/2017 (774 days app to issue)
Abstract: A method for decoding video includes creating a first list of motion vectors from at least one neighboring block in a current frame of the video and creating a second list of motion vectors from at least one previous block in a temporally earlier frame of the video. A third list of motion vectors is created based upon the first list and the second list. Based upon receiving a motion vector competition control parameter selecting one of the motion vectors from the third list, wherein the second list of motion vectors is further based upon a flooring function.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Use of parallel data programming for device integration
Patent No. 10397635
Inventor(s): Kulvir S. Bhogal (Fort Worth, TX)
Assignee(s): International Business Machines Corporation (Armonk, NY)
Law Firm: Greg Goshorn, P.C. (1 non-local offices)
Application No., Date, Speed: 14811193 on 07/28/2015 (1491 days app to issue)
Abstract: Provided are techniques for detecting a presentation of media content on a first display device; synchronizing contextual data corresponding to the media content with the media content; transmitting the contextual metadata corresponding to the media content to a second display device in response to the detecting, wherein the second display device is a different device than the first display device; and presenting the contextual metadata, in synchronization with the media content, on the second display device in conjunction with the presentation of the media content on the first display device.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Methods and systems for synchronizing data streams across multiple client devices
Patent No. 10397636
Inventor(s): Peter Aubrey Bartholomew Griess (Dallas, TX)
Assignee(s): Facebook, Inc. (Menlo Park, CA)
Law Firm: Morgan, Lewis Bockius LLP (13 non-local offices)
Application No., Date, Speed: 16041516 on 07/20/2018 (403 days app to issue)
Abstract: An electronic device has one or more processors, a display, and memory. The memory stores one or more programs configured for execution by the one or more processors. The device receives, from a content delivery network, a program manifest including one or more video segments of a video. The electronic device parses the program manifest to identify a timeline for the video that spans the video segments. The electronic device receives, from a social-networking server, a playback offset for the video. In accordance with the playback offset and the timeline for the video, the electronic device determines a designated video segment and a playback position within the designated video segment. The electronic device then plays the video segments sequentially on the electronic device, commencing at the playback position within the designated video segment.
[H04N] PICTORIAL COMMUNICATION, e.g. TELEVISION [4]
Direct current mode digital-to-analog converter to class D amplifier
Patent No. 10397701
Inventor(s): Jasjot Singh Chadha (Bangalore, , IN), Lars Risbo (Hvalsoe, , DK), Ryan Erik Lind (Knoxville, TN)
Assignee(s): TEXAS INSTRUMENTS INCORPORATED (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16175907 on 10/31/2018 (300 days app to issue)
Abstract: A system includes a class D amplifier and a current steering digital-to-analog converter (DAC) directly connected to the class D amplifier. The system also includes a common mode servo circuit coupled to a node interconnecting the current steering DAC to the class D amplifier. The common servo circuit amplifies a difference between a common mode signal determined from the node and a reference voltage and generates a feedback current to the node based on the amplified difference. A feed-forward common-mode compensation circuit is included to reduce an alternating current (AC) ripple from the class D amplifier. The feed-forward common-mode compensation circuit includes first and second resistors coupled to respective outputs of the class D amplifier. A current mirror is coupled to the first and second resistors and is configured to sink a current from the node to ground that approximates a common mode feedback current of the class D amplifier.
[H04R] LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS (producing sounds with frequency not determined by supply frequency G10K) [6]
Method for auto-discovery in networks implementing network slicing
Patent No. 10397791
Inventor(s): Kiran Makhijani (Los Gatos, CA), Padmadevi Pillay-Esnault (San Jose, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Conley Rose, P.C. (3 non-local offices)
Application No., Date, Speed: 15729405 on 10/10/2017 (686 days app to issue)
Abstract: A method implemented by a service rendezvous point (SRP) comprises receiving, by a receiver of the SRP, a plurality of register messages from a plurality of service switch points (SSPs), each of the register messages comprising at least one of resource information or service information, each of the SSPs being associated with a different network domain, sending, by a transmitter of the SRP, a plurality of report messages to the plurality of SSPs, each of the report messages comprising resource allocation information for each of the network domains for a service, the resource allocation information including an amount of resources to be allocated at the each of the network domains for the service, and maintaining, at a memory of the SRP, a SSP database storing at least one of the resource allocation information of each of the network domains, the resource information of each of the network domains, and the service information of each of the network domains.
[H04W] WIRELESS COMMUNICATION NETWORKS [2009.01]
Fingerprinting root cause analysis in cellular systems
Patent No. 10397810
Inventor(s): Jin Yang (Bridgewater, NJ), Kai Yang (Bridgewater, NJ), Ruilin Liu (Hillsborough, NJ), Yanjia Sun (Downingtown, PA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Vierra Magen Marcus LLP (2 non-local offices)
Application No., Date, Speed: 14991598 on 01/08/2016 (1327 days app to issue)
Abstract: A processor implemented method of identifying a root cause of degraded network quality in a wireless network. The method includes accessing historical network performance data, the performance data including a time sequenced measure of performance indicators for the network. The method evaluates the historical performance data to determine regularly occurring associations between indicators to define a set of rules characterizing the associations of the wireless network, and stores the set of rules in a data structure. The wireless network is monitored by accessing analysis data reporting time sequenced performance indicator data. Next, anomalies are detected in a performance indicator in the analysis data and matched to at least one rule in the set of rules. The method outputs an indication of a cause of degradation in the wireless network resulting from the anomaly in the performance indicator.
[H04W] WIRELESS COMMUNICATION NETWORKS [2009.01]
Method and arrangement in a wireless communication network
Patent No. 10397826
Inventor(s): Janne Peisa (Espoo, , FI), Johan Torsner (Masaby, , FI), Michael Meyer (Aachen, , DE)
Assignee(s): Unwired Planet, LLC (Plano, TX)
Law Firm: Nixon Vanderhye P.C. (2 non-local offices)
Application No., Date, Speed: 15915407 on 03/08/2018 (537 days app to issue)
Abstract: Method and arrangement in a first node for requesting a status report from a second node. The first node and the second node are both comprised within a wireless communication network. The status report comprises positive and/or negative acknowledgement of data sent from the first node, to be received by the second node. The first node comprises a first counter configured to count the number of transmitted Protocol Data Units, PDUs, and a second counter configured to count the number of transmitted data bytes. The method and arrangements comprises initializing the first and the second counter to zero, transmitting data to be received by the second node, comparing the value of the first and the second counters with a first threshold limit value and a second threshold limit value and requesting a status report from the second node if any of the threshold limit values is reached or exceeded.
[H04L] TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION (arrangements common to telegraphic and telephonic communication H04M) [4]
Scheduling and handover of a vehicular connection with periodic messaging
Patent No. 10397838
Inventor(s): Guowei Ouyang (Beijing, , CN), Mazin Al-Shalash (Frisco, TX), Nathan Edward Tenny (Poway, CA), Zhenzhen Cao (Santa Clara, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Schwegman Lundberg Woessner, P.A. (11 non-local offices)
Application No., Date, Speed: 15943146 on 04/02/2018 (512 days app to issue)
Abstract: The method provided in this embodiment improves the capabilities of automatic driving and ADAS of electric vehicles. The method can be applied to vehicle networking, such as V2X, LTE-V, V2X, etc. The method includes receiving, from the mobile device, an indication of a requirement for transmission resources, comprising at least an indication that the resources are required with a periodicity, transmitting, to the mobile device, an assignment of a first scheduling configuration for the device-to-device connection, transmitting, to the mobile device, an indication to begin use of periodically recurring radio resources, and handing over responsibility for providing radio resources for the device-to-device connection from the network node to a target network node such that the availability of radio resources with the periodicity is substantially maintained.
[H04W] WIRELESS COMMUNICATION NETWORKS [2009.01]
Resource and power allocation indication in beam-based access system
Patent No. 10397930
Inventor(s): Bin Liu (San Diego, CA), Pengfei Xia (San Diego, CA), Richard Stirling-Gallacher (San Diego, CA)
Assignee(s): Futurewei Technologies, Inc. (Plano, TX)
Law Firm: Slater Matsil, LLP (Local + 1 other metros)
Application No., Date, Speed: 16235782 on 12/28/2018 (242 days app to issue)
Abstract: A method for resource and power allocation indication in a beam-based access system is provided. In an embodiment, a method for signaling power allocation in a beam-based access system includes determining, by a transmit point (TP), a relative effective transmit power offset between a control beam and a data beam. The method also includes signaling, by the TP, the relative effective transmit power offset to a user equipment (UE). The UE performs automatic gain control (AGC) on a control channel and a data channel according to the relative effective transmit power offset signaled by the TP.
[H04W] WIRELESS COMMUNICATION NETWORKS [2009.01]
System, method, and computer-readable medium for schedule-based telecommunication policies
Patent No. 10397962
Inventor(s): Andrew Silver (Frisco, TX)
Assignee(s): Tango Networks, Inc. (Richardson, TX)
Law Firm: No Counsel
Application No., Date, Speed: 15232690 on 08/09/2016 (1113 days app to issue)
Abstract: A system, method and computer-readable medium for enforcing user telecommunication privileges on a per-schedule basis are provided. Enterprise members may have a schedule associated therewith that defines scheduled locations of the users. Telecommunication service privileges may be coordinated with the users” schedules such that communication services are disabled at particular times based on the users” schedules. In other implementations, particular users may have telecommunication services disabled by an administrator in the event of a catastrophe or emergency. By this mechanism, users that are not proximate to a particular catastrophe or emergency area according to the users” schedule may have services disabled while other users that are located more proximate to the emergency may have their telecommunication services enabled. In this manner, the demand on a cellular network may be alleviated thereby increasing the likelihood that users directly impacted by the emergency may receive and place calls or access data services.
[H04W] WIRELESS COMMUNICATION NETWORKS [2009.01]
Method and apparatus for calculating an average value of an inaccessible current from an accessible current
Patent No. 10397992
Inventor(s): Isaac Cohen (Dix Hills, NY)
Assignee(s): Texas Instruments Incorporated (Dallas, TX)
Law Firm: No Counsel
Application No., Date, Speed: 16284761 on 02/25/2019 (183 days app to issue)
Abstract: In a power converter, a circuit determines an average value of an inaccessible current from an average value of an accessible current and a value of the operating duty cycle of the converter. A method of measuring an average value of an inaccessible current from a measured value of a current, in a power converter, by a duty cycle of a pulse width modulation (PWM) signal, representing a duty cycle of the power converter. Coupling a voltage representing the measured value to an input of a low pass filter during a time period (D) and coupling the input of the low pass filter to a reference voltage during a time period (1D).
[H05B] ELECTRIC HEATING; ELECTRIC LIGHTING NOT OTHERWISE PROVIDED FOR
System and method for migrating agents between mobile devices
Patent No. RE047585 (Reissue)
Inventor(s): Mark Gerard (Plano, TX), Robert W. Peterson (Plano, TX)
Assignee(s): OL SECURITY LIMITED LIABILITY COMPANY (Wilmington, DE)
Law Firm: Schwabe, Williamson Wyatt (3 non-local offices)
Application No., Date, Speed: 15441140 on 02/23/2017 (915 days app to issue)
Abstract: Mobile agents can be deployed to location aware mobile devices within specific regions of interest to achieve specific goals in respect of events occurring in the region of interest. In order to ensure that the agent can persist within the region of interest until the agent goals are achieved, the agent is configured to locate other devices within the region of interest and to propagate itself, by moving or copying itself, to those other devices. When a device hosting the agent exits the region of interest, the agent is terminated, thereby freeing device resources. Patent Class: N/A
DESIGN PATENTS
Chair
Patent No. D857415
Inventor(s): Chris Brandel (Chicago, IL), Dan Rucker (Chicago, IL), Daniel Grabowski (East Grand Rapids, MI), Matthew Banach (Gumee, IL), Michael J. Sawadski (Mount Prospect, IL)
Assignee(s): PARAGON FURNITURE, INC. (Arlington, TX)
Law Firm: Ferguson Braswell Fraser Kubasta PC (3 non-local offices)
Application No., Date, Speed: 29680611 on 02/18/2019 (190 days app to issue)
Abstract: No Abstract Patent Class: N/A
Bottle
Patent No. D857509
Inventor(s): Jenny DeMarco Staab (Addison, TX), Tammy Schriewer (Addison, TX)
Assignee(s): Mary Kay Inc. (Addison, TX)
Law Firm: Norton Rose Fulbright US LLP (Local + 13 other metros)
Application No., Date, Speed: 29675593 on 01/03/2019 (236 days app to issue)
Abstract: No Abstract Patent Class: N/A
Grip for a gem tester
Patent No. D857535
Inventor(s): Daniel L. Kessler (Dallas, TX), Henry M. Kessler (Dallas, TX)
Assignee(s): Sy Kessler Sales, Inc. (Dallas, TX)
Law Firm: Griggs Bergen LLP (Local)
Application No., Date, Speed: 29642478 on 03/29/2018 (516 days app to issue)
Abstract: No Abstract Patent Class: N/A
Cage assembly for a model vehicle
Patent No. D857555
Inventor(s): Adam Cole Ewing (McKinney, TX), Otto Karl Allmendinger (Rowlett, TX)
Assignee(s): TRAXXAS LP (McKinney, TX)
Law Firm: No Counsel
Application No., Date, Speed: 29632876 on 01/10/2018 (594 days app to issue)
Abstract: No Abstract Patent Class: N/A
Aircraft
Patent No. D857607
Inventor(s): Berlin Benfield (Grapevine, TX), Brent Ross (Flower Mound, TX), Kendall Goodman (Southlake, TX), Nathan Wu (Irving, TX), Steven Ivans (Ponder, TX)
Assignee(s): Bell Helicopter Textron Inc. (Fort Worth, TX)
Law Firm: Timmer Law Group, PLLC (1 non-local offices)
Application No., Date, Speed: 29628792 on 12/07/2017 (628 days app to issue)
Abstract: No Abstract Patent Class: N/A
Single door for electrical panel enclosure
Patent No. D857639
Inventor(s): Jason S. Mevius (McKinney, TX), Ken Huggins (Plano, TX)
Assignee(s): Cooper Technologies Company (Houston, TX)
Law Firm: Stinson LLP (6 non-local offices)
Application No., Date, Speed: 29584833 on 11/17/2016 (1013 days app to issue)
Abstract: No Abstract Patent Class: N/A
Rear side molding for a model vehicle
Patent No. D857807
Inventor(s): Jonathan Scott Wood (Plano, TX)
Assignee(s): TRAXXAS LP (McKinney, TX)
Law Firm: No Counsel
Application No., Date, Speed: 29623942 on 10/27/2017 (669 days app to issue)
Abstract: No Abstract Patent Class: N/A
Air conditioning housing
Patent No. D857862
Inventor(s): Stephen William O”Brien (Fort Worth, TX)
Assignee(s): TSI Products, Inc. (Arlington, TX)
Law Firm: Hitchcock Evert LLP (Local)
Application No., Date, Speed: 29585841 on 11/29/2016 (1001 days app to issue)
Abstract: No Abstract Patent Class: N/A
Multi-layer shingle
Patent No. D857931
Inventor(s): Olan Leitch (Bakersfield, CA)
Assignee(s): Building Materials Investment Corporation (Dallas, TX)
Law Firm: Venable LLP (7 non-local offices)
Application No., Date, Speed: 29608385 on 06/21/2017 (797 days app to issue)
Abstract: No Abstract Patent Class: N/A
Single-layer shingle
Patent No. D857932
Inventor(s): Olan Leitch (Bakersfield, CA)
Assignee(s): Building Materials Investment Corporation (Dallas, TX)
Law Firm: Venable LLP (7 non-local offices)
Application No., Date, Speed: 29608390 on 06/21/2017 (797 days app to issue)
Abstract: No Abstract Patent Class: N/A
Elongate light
Patent No. D857963
Inventor(s): Brian P. Johnson (Fishersville, VA)
Assignee(s): London Johnson, Inc. (Dallas, TX)
Law Firm: Perkins Coie LLP (17 non-local offices)
Application No., Date, Speed: 29578629 on 09/22/2016 (1069 days app to issue)
Abstract: No Abstract Patent Class: N/A
All logos and brand images are the property of their respective owners. All company, product and service names used in this website are for identification purposes only. Any trademarks cited herein are the property of their respective owners.
The feature image is an artist’s concept and/or artistic impression for illustration and editorial display purposes only unless otherwise stated in the image caption. The image(s) do not represent any condition at present, or in the future, and are not intended to represent specific patents unless otherwise stated in the photo description and/or photo credit(s).
As of June 12, 2018, unassigned patents with a local inventor may be included.
For additional details on patents granted, search the USPTO Patent Full-Text and Image Database.
Get on the list.
Dallas Innovates, every day.
Sign up here to get what’s new and next in Dallas-Fort Worth.


Story 194
Medical students - what worries you about becoming a new doctor?
Newly qualified doctors - what do you wish you had known sooner?
Medical school teaches us a lot, but there are many things we are expected to absorb intuitively from our placements or from our peers. Like, how do you survive a night shift? How exactly do you do the essential admin tasks such as writing a discharge letter? How do relationships and dating work around the transition to being a new doctors? And so much more.
Sharp Scratch is the podcast where medical students and newly qualified doctors figure out all those topics that we need to know but that medical school doesn’t really teach us. Every second Friday, listen to us - Laura, Ryhan, Declan and Chidera - being honest about the gaps in our knowledge and learning from the experts.
Sharp Scratch is sponsored by Medical Protection.

Story 195
Tee times won't be announced until Friday, May 10, but we have our first known pairing for the 2019 PGA Championship at Bethpage Black.
PGA of America Chief Championships Officer Kerry Haigh revealed that this year's pairings will continue to honor the tradition of putting the current reigning major champions together for the first two rounds.
Following Tiger Woods' win at the Masters, he finds himself in this major champions grouping for the first time since 2008. He will join reigning PGA Championship and two-time U.S. Open champion Brooks Koepka and reigning Open Champion Francesco Molinari.
https://twitter.com/PGAChampionship/status/1123224251258015746
History tells us that his star-studded group should deliver plenty of exciting golf throughout the week.
Brooks Koepka is in the hunt to capture his second Wanamaker Trophy and would become the first golfer in history to hold concurrent back-to-back major championships. He also has six top-10 finishes over his past nine major championship appearances.
Francesco Molinari also is coming in on a major hot streak. He will arrive with three consecutive top-10 finishes in majors — a win at The Open, T6 at the PGA Championship at Bellerive and a T5 finish at the Masters.
Finally, Tiger Woods will look to keep his strong major performances at Bethpage Black going. In addition to the much talked about win at the 2002 U.S. Open, Tiger also finished T6 at the 2009 U.S. Open during a rough weather week in New York.
The 2019 PGA Championship tees off on Thursday, May 16.
Download the 2019 PGA Championship app

Story 196
Conclusions Of 20 000 consecutive patients undergoing a blood test for any clinical reason at our hospital, one in 20 had an hs-cTnI greater than the recommended ULN. These data highlight the need for clinical staff to interpret hs-cTnI concentrations carefully, particularly when applying the recommended ULN to diagnose acute myocardial infarction, in order to avoid misdiagnosis in the absence of an appropriate clinical presentation.
Results The 99th centile of hs-cTnI for the whole population was 296 ng/L compared with the manufacturer’s quoted level of 40 ng/L (currently used clinically as the upper limit of normal; ULN). Hs-cTnI concentrations were greater than 40 ng/L in one in 20 (5.4%, n=1080) of the total population. After excluding participants diagnosed as having acute myocardial infarction (n=122) and those in whom hs-cTnI was requested for clinical reasons (n=1707), the 99th centile was 189 ng/L for the remainder (n=18 171). The 99th centile was 563 ng/L for inpatients (n=4759) and 65 ng/L for outpatients (n=9280). Patients from the emergency department (n=3706) had a 99th centile of 215 ng/L, with 6.07% (n=225) greater than the recommended ULN. 39.02% (n=48) of all patients from the critical care units (n=123) and 14.16% (n=67) of all medical inpatients had an hs-cTnI concentration greater than the recommended ULN.
The objective of the CHARIOT study was to determine the true distribution of the highly sensitive cardiac troponin I (hs-cTnI) concentration, and more specifically the 99th centile, in a population of consecutive inpatients and outpatients in our hospital. Our hypothesis was that the true 99th centile of hs-cTnI in this population would differ from the manufacturer recommended ULN for this assay. This difference would highlight the potential for misinterpretation of a concentration greater than this threshold in routine clinical practice, particularly when making a diagnosis of acute myocardial infarction and especially type 1 myocardial infarction.
The International Federation of Clinical Chemistry and Laboratory Medicine Task Force on Clinical Applications of Bio-Markers currently recommends that the 99th centile for any assay can be calculated using 300 “healthy” men and 300 “healthy” women. 23 However, several factors are known to affect an individual’s troponin, 23 including age, 24 sex, 25 glomerular filtration rate, 26 left ventricular function, 27 and the presence of major inflammatory conditions. 28 Therefore, whether the clinically applied concept of a ULN for the hs-cTn assay is appropriate requires closer scrutiny, particularly when it has been derived from a limited number of healthy individuals. Importantly, the approaches to determining the recommended 99th centile are also variable. 29 30 31
Both of these potential issues may be compounded in clinical practice by the increasing sensitivity of the available assays that are able to detect troponin at much lower concentrations than previously. 5 Consequently, new highly sensitive cardiac troponin (hs-cTn) assays 17 18 19 20 21 allow for rapid exclusion of acute myocardial infarction, and thereby enable patients to be discharged early from hospital. Furthermore, modern hs-cTn assays can detect troponin in more than 50% of the general population, with some assays able to detect troponin in everyone. 22 The appropriate interpretation of raised hs-cTn, specifically in relation to the diagnosis of type 1 myocardial infarction, is therefore dependent on a clinical presentation consistent with this diagnosis, and, in particular, a history of cardiac-sounding chest pain, according to the guidelines.
Secondly, the assay specific 99th centile (upper limit of normal; ULN) is generally applied as a binary “rule in” or “rule out” threshold for acute myocardial infarction. Recent trial data confirm the veracity of using early cardiac troponin concentrations to confidently exclude a diagnosis of acute myocardial infarction 13 14 15 16 ; however, the assumption that a concentration greater than the recommended threshold implies acute myocardial infarction (and in particular type 1 myocardial infarction) is often inappropriate.
Firstly, raised cardiac troponin concentrations, particularly in patients not presenting with a typical history of cardiac pain, are often caused by myocardial injury or type 2 myocardial infarction. 6 7 These conditions, which are secondary to ischaemia caused by increased oxygen demand or decreased supply rather than a plaque erosion, 8 9 10 are not well recognised when the troponin test is requested or the result interpreted. Correct diagnosis is important because most patients with type 2 myocardial infarction have not been shown to benefit from the same aggressive pharmacotherapy and invasive investigation and treatment that are offered as standard in patients with type 1 myocardial infarction. 11 Some exceptions include spontaneous coronary dissection, coronary embolism, and coronary spasm. 10 12 Misinterpretation may lead to inappropriate management, including prolonged antiplatelet therapy and invasive coronary angiography, with or without revascularisation.
Under most circumstances, the troponin assay is requested by frontline clinical staff to determine whether a patient is having a type 1 myocardial infarction caused by coronary plaque rupture or erosion. Robust evidence has shown symptomatic and prognostic benefit from applying early pharmacological and interventional treatment strategies in these patients. However, particularly with the advent of newer assays, this strategy has two potential challenges.
The use of increasingly sensitive troponin assays for excluding or diagnosing acute myocardial infarction has become universal. A diagnosis of acute myocardial infarction is defined, in the context of an appropriate clinical presentation, by a rise or fall in cardiac troponin concentration, now the gold standard biomarker, 1 2 with at least one value greater than the 99th centile derived from a reference population of healthy individuals. 3 4 5
The British Cardiac Patients Association assisted the researchers in reviewing the study protocol, particularly with reference to the lack of consent from participants. As part of our study application, a letter of support for our methods from the chairman of the association was sent to the Health Research Authority and the Confidentiality Advisory Group.
We defined the 99th centile for the study population using a non-parametric procedure based on frequency tables. Statistical analyses were performed using IBM SPSS version 22.0 (Armonk, New York, NY, USA). We used Stata 14.0 (College Station, TX, USA) to perform multiple logistic regressions to identify factors associated with highly sensitive troponin levels greater than 40 ng/L. Variables in the model included age, male sex, serum sodium, estimated glomerular filtration rate, and location when the biochemistry test was requested.
The baseline demographic data collected for the study were limited to those derived from electronic request forms for blood tests and, for inpatients, from electronic discharge summary codes. These data, together with the troponin levels and other study data, were saved on a bespoke database for later analysis.
The Beckman Coulter Access AccuTnI+3 assay (Brea, CA, USA) is used in routine clinical practice at our hospital. We applied this assay to measure hs-cTnI concentrations in the study population. The manufacturer’s recommended 99th centile (ULN) is 40 ng/L, which is the level we use in routine clinical practice. The coefficient of variation of the assay is less than 10% at 40 ng/L; the limit of quantification (10% of the coefficient of variation) is 20 ng/L; the limit of detection is 8 ng/L; and the limit of blank is 5 ng/L. For patients in whom troponin had not been requested for clinical reasons, we measured the hs-cTnI level using serum that was surplus to clinical need. An automated, bespoke system was installed in biochemistry to ensure that each patient was only included once in the study. We collected serum in serum separator tubes and stored it at room temperature for up to 24 hours before hs-cTnI levels were measured using the DxI800 platform (Beckman Coulter). We performed quality control of the assay on a daily basis, which is routine in clinical practice.
As part of the ethical committee process, we sought approval from the Confidentiality Advisory Group based on two unusual aspects of the methods. Firstly, patients did not know that an extra blood assay was being performed and consent was not sought or required. Secondly, except for patients who had an hs-cTnI test as part of their routine clinical care as requested by their supervising doctor, test results were nested and not revealed to either patients or their supervising clinical team; this was regardless of whether the level was greater than the recommended ULN.
This was a prospective, observational study of 20 000 consecutive patients aged at least 18 years in whom a biochemistry blood test was requested for clinical reasons by their supervising doctor at our institution, University Hospital Southampton (United Kingdom). It was conducted between 29 June 2017 and 24 August 2017. We included patients regardless of the setting in which the blood test was requested. Therefore, the study population consisted of outpatients and inpatients, attendees at the emergency department, elective and emergency admissions, and every specialty within the hospital. For each patient included in the study, only one troponin measurement was performed on the first biochemistry blood sample that became available during the study period. That patient was then excluded from further sampling so that a consecutive series of 20 000 different patients were included. During some of our analyses, we excluded patients in whom a troponin was requested for clinical reasons by the supervising doctor, and those in whom a diagnosis of acute myocardial infarction was made. This was determined by reviewing the electronic blood request forms submitted to the biochemistry department and by electronic discharge summaries.
When we excluded all patients who had been diagnosed with myocardial infarction or had hs-cTnI tests requested by the clinical team (n=1829), a multivariable analysis was undertaken. This analysis assessed the independent predictors of a patient having an hs-cTnI concentration greater than the recommended ULN (40 ng/L). Advancing age (odds ratio 1.03, 95% confidence interval 1.03 to 1.04, P<0.001), male sex (1.33, 1.14 to 1.54, P<0.001), and decreasing estimated glomerular filtration rate (0.98, 0.97 to 0.98, P<0.001) were shown to be independent predictors. Furthermore, compared with the outpatient population, inpatient location was an independent predictor of hs-cTnI concentration greater than the ULN: emergency department (2.79, 2.26 to 3.43, P<0.001); resuscitation room (9.91, 7.3 to 13.46, P<0.001); critical care units (36.62, 23.86 to 56.2, P<0.001); cardiac wards (9.08, 6.44 to 12.81, P<0.001); acute surgical unit (2.52, 1.47 to 4.33, P<0.001); medical wards (4.74, 3.45 to 6.50, P<0.001); medicine for older people wards (3.70, 2.16 to 6.34, P<0.001); and orthopaedic wards (2.24, 1.23 to 4.05, P=0.008; table 3 ). Supplementary table 3 shows independent predictors for the full cohort (n=20 000).
The 99th centiles for men and women were 373 and 236 ng/L, respectively. A total of 6.6% (n=622) of men and 4.38% (n=463) of women had hs-cTnI concentrations greater than the ULN. Significant differences were seen in mean hs-cTnI levels when comparing men with women (62 v 31 ng/L, P=0.021).
There was an association between increasing age and distribution of troponin concentration. Supplementary tables 1 and 2, and figure 3 show centiles (25th, 50th, 75th, and 99th) and proportion of patients with hs-cTnI greater than the ULN according to age.
In the critical care setting (three intensive care units and two high dependency units; n=123), 39.02% (n=48) had hs-cTnI concentrations greater than the ULN. When we excluded all patients diagnosed as having myocardial infarction or who had an hs-cTnI test requested by the clinical team, 14.16% (n=67) of all medical inpatients (excluding those on cardiac wards) had an hs-cTnI concentration greater than the recommended ULN. For the medicine for older people wards, 20.8% (n=20) had an hs-cTnI concentration greater than the recommended ULN; for patients managed on the acute surgical unit, the corresponding figures were 4.62% (n=16), and for those on orthopaedic wards, 5.24% (n=13). In none of these patients was an acute myocardial infarction suspected or diagnosed ( table 2 ; fig 2 ).
A total of 5708 patients had their blood sampling in the emergency department. Of this group, 1551 (27.2%) had hs-cTnI concentrations requested by doctors in the department. The 99th centile for the remaining emergency department population (n=3706) was 215 ng/L, with 6.07% (n=225) having hs-cTnI concentrations greater than the recommended ULN. Of patients managed in the resuscitation room of the emergency department (n=426), 19.48% (n=83) had hs-cTnI concentrations greater than the ULN.
We stratified patients according to their location when the biochemistry test was requested. Specifically, the study included 9280 (51.1%) hospital outpatients in whom the observed 99th centile was 65 ng/L, with hs-cTnI concentrations greater than the recommended ULN in 2% (n=186). There were 4759 (26.2%) inpatients and the 99th centile for this group was 563 ng/L; the hs-cTnI concentration was greater than the recommended ULN in 7.29% (n=347).
Of the 1707 patients in whom hs-cTnI concentrations were requested by the clinical team, 73% (n=1246) had presented with chest pain; arrhythmia (n=52) and suspected blackouts (n=63) were the next most common reasons for the test.
The 99th centile hs-cTnI concentration for the whole study population (n=20 000) was 296 ng/L, with one in 20 (5.4%; n=1080) patients having an hs-cTnI concentration greater than the manufacturer’s recommended ULN (40 ng/L). When we excluded all patients diagnosed as having acute myocardial infarction on discharge from hospital or in whom an hs-cTnI test had been requested for clinical reasons, 18 171 patients remained. The 99th centile in these patients was 189 ng/L, with 4.6% (n=836) having a level greater than 40 ng/L ( fig 1 ). Table 1 presents the baseline characteristics.
Discussion
In this large study, we found that one in 20 consecutive inpatients and outpatients at a large UK hospital had a troponin level greater than the manufacturer recommended 99th centile (ULN) for the assay. We also showed that the true 99th centile varies according to the clinical setting, age and sex of the patient, and location when the biochemistry test was requested. Two per cent of outpatients and 39% of patients in critical care units had a hs-cTnI concentration greater than the recommended ULN.
These results have important clinical implications that are almost certainly relevant to the application of all modern hs-cTn assays. Firstly, they confirmed our hypothesis that the true 99th centile for a general hospital population is not consistent with the recommended ULN. Secondly, these data raise important questions about the applicability of the quoted ULN as an arbiter of type 1 acute myocardial infarction in patients who do not give a typical history consistent with this diagnosis. Previous evidence for using “negative” hs-cTnI levels to “rule out” acute myocardial infarction is clear cut and robust.14151632 The Fourth Universal Definition3 recommends a diagnosis of acute myocardial infarction when there is clinical evidence of acute myocardial ischaemia and when an increase or decrease in cardiac troponin levels is detected. However, using the recommended ULN as a “rule in” test for acute myocardial infarction might not be appropriate in patients presenting with atypical symptoms and other comorbidities, such as in the emergency department or on acute medical and surgical wards. This approach could expose patients to inappropriate pharmacological and invasive treatments that have only been shown to be beneficial in true type 1 myocardial infarction populations.
These data demonstrate the importance of interpreting hs-cTnI results with caution in individual patients. The risk of potential systematic misdiagnosis of acute myocardial infarction is particularly shown by the observed 99th centile for hs-cTnI in our emergency department population (215 ng/L) and acute medical admissions (1459 ng/L). In addition, about 40% of patients in some clinical settings have hs-cTnI levels greater than the recommended ULN. It is important for frontline clinical staff to understand that using a single cutoff of hs-cTnI to diagnose acute myocardial infarction might be inappropriate and that the ULN of the assay depends on the setting and the clinical characteristics of patients. We would advocate that clinical staff are aware of the current guidelines for diagnosing acute myocardial infarction, which are not always adhered to, and also that they have a very clear indication for requesting the test.
Our analysis highlighted several factors that are associated with raised hs-cTnI levels according to the recommended threshold, including mode of presentation. We found that 7.29% of all inpatients in this study had a raised hs-cTnI concentration, including 6.07% of the emergency department population and 19.48% of patients admitted to the resuscitation room. It is more predictable that nearly 40% of patients admitted to a critical care setting have an elevated concentration. In addition, the observed 99th centile for hs-cTnI concentrations was 65 ng/L in outpatients, and 2% of these patients who attended the hospital only for an outpatient clinic appointment had a concentration greater than the recommended ULN. These results highlight the need for a review of the distribution of the hs-cTn assay in a hospital setting. Further research is also required to determine whether there is an association between absolute troponin concentration and cardiovascular outcome in such populations.
Other factors that were clearly associated with increasing hs-cTn concentrations were age and sex. Specifically, we found that almost double the proportion of patients in their 60s had hs-cTnI concentrations greater than the ULN compared with patients in their 50s. In addition, levels tended to be higher in men than in women. These observations lend weight to the concept that there should be age and sex specific recommendations for the ULN.
Comparison with other studies Previous literature in this field has confirmed the use of the newer hs-cTn assays for early exclusion of acute myocardial infarction in a robust and safe manner.14151632 However, interpretation of a single hs-cTnI concentration above the supplied ULN as being an indicator of acute myocardial infarction, and, more specifically, type 1 myocardial infarction, by frontline clinical staff could lead to misdiagnosis and inappropriate investigations and treatment. Our data indicate that the prevalence of troponin levels above the supplied ULN in an important proportion of patients in whom there is no clinical suspicion of acute myocardial infarction should raise a cautionary note. Our findings raise important and interesting questions about the potential implications of the observed distribution of hs-cTnI in the hospital population. Specifically, are the levels that we found in these patients, for whom the suspicion of acute myocardial infarction is low (for example, outpatients), actually abnormal? Do the levels indicate myocardial injury in their own right, and if so, are they associated with adverse outcome, perhaps as biomarkers for future cardiovascular risk? An accumulating body of evidence suggests that hs-cTn concentrations in populations of patients with stable chronic disease states, of cardiac and non-cardiac origin, are associated with risk of cardiovascular events.33343536373839404142 Notably, in the outpatient population it has been reported that hs-cTnI has been shown to be associated with an increased risk of vascular events and all cause mortality.4344 It is conceivable that the raised hs-cTn concentrations in a patient with stable disease always indicates myocardial injury or unwellness: the so-called “never means nothing” hypothesis.45
Implications of this study The results of the CHARIOT study have important clinical implications that might be relevant to the application of all modern hs-cTn assays. The notion of using a single binary value greater than the supplied ULN of any assay to diagnose whether a patient has had an acute myocardial infarction is flawed. This is highlighted by the observed 99th centile in the study population, which is over seven times higher than the ULN recommended by the manufacturer. Furthermore, the observed frequency of hs-cTnI greater than the recommended ULN, regardless of location, in patients in whom there was no clinical suspicion of acute myocardial infarction or myocardial injury raises concerns about using a 99th centile value from a “healthy population.” In particular, it might be inappropriate to apply the recommended 99th centile when managing patients who are typically older, have more comorbidities, a higher incidence of subclinical cardiac disease, and are in a worse physical condition than the healthy reference population. The results of this study should highlight that although hs-cTnI can contribute to the diagnosis of acute myocardial infarction, frontline clinical staff should use this test in conjunction with other key factors, such as clinical history and other investigations.92425294647484950 At present, using the 99th centile to help rule out a diagnosis of acute myocardial infarction is clear cut and is based on a “healthy” reference population. However, the recommended threshold and its application to patients presenting to hospital to rule in acute myocardial infarction is problematic, particularly when the degree of suspicion is low and other factors might contribute to the cardiac troponin concentration. Currently, the implications of detecting a hs-cTnI concentration above the supplied ULN, in terms of outcome and management, are unclear in patients in whom there is low clinical suspicion of acute myocardial infarction. A more considered approach to applying hs-cTnI concentrations would be to tailor the ULN according to the patient’s baseline characteristics and comorbidities. The feasibility of using this approach, however, has not been investigated. Further data about the potential association between hs-cTnI level and cardiovascular risk are required.
Limitations of this study There were a number of limitations. This is an observational study of a large number of consecutive patients. Therefore, the level of detail about management and diagnoses can only be obtained from the best records available for each patient, which included electronic blood request or discharge summary data, and formalised coding records. In addition, we did not examine clinical outcomes because this was not part of our objective. We also used discharge codes in our analysis for diagnosing acute myocardial infarction, but these final diagnoses were not independently verified. Finally, this study looked at hs-cTnI concentrations in 20 000 patients based on a single sample for each patient; as a result, we could not differentiate between acute and chronic myocardial injury.

