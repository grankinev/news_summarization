{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Блок предобработки текста\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = stop_words + ['china', 'chinese','china\\'s','china’s'] #в стоп список включаем слова, которые являются перекрестными в разных темах\n",
    "lemmatizator = WordNetLemmatizer()\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "\n",
    "#функция предобработки\n",
    "def prepare_text(text, stop = stop_words, tokenizer = tokenizer):\n",
    "    \"\"\" \n",
    "    Возвращает тексты: \n",
    "        * лемматизированные,\n",
    "        * без стоп-слов, \n",
    "        * в нижнем регистре, \n",
    "        * все слова длиннее 3 символов\n",
    "\n",
    "    text: string\n",
    "        Текст \n",
    "\n",
    "    parameters:  \n",
    "        stop: список из стоп-слов\n",
    "        tokenizer: токенизатор для текста, поданного на вход\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    words = [lemmatizator.lemmatize(token) for token in tokens]\n",
    "    words = [item for item in words if item not in stop]\n",
    "    words = [item for item in words if len(item)>3]\n",
    "    \n",
    "    return ' '.join(words)#words  #здесь выбираем формат вывода: в виде отдельных токенов или в форме связной строки-текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def china_summary_reuters(depth):\n",
    "    \"\"\"\n",
    "    Подготовка резюме по основным новостям по Китаю\n",
    "    depth - количество заголовков для просмотра на странице с последними новостями по Китаю\n",
    "    \"\"\"\n",
    "      \n",
    "    #Выгружаем все свежие заголовки про Китай\n",
    "    r1 = requests.get('https://www.reuters.com/places/china', headers={'Cache-Control': 'no-cache'})\n",
    "    #r1 = requests.get('https://www.reuters.com/search/news?blob=metals')\n",
    "    coverpage =  r1.content\n",
    "    soup = BeautifulSoup(coverpage, 'html5lib')\n",
    "    coverpage_news_r = soup.find_all('h2', class_='FeedItemHeadline_headline')\n",
    "\n",
    "    #Опционально можно вывести отдельно все заголовки:\n",
    "#     for i in range(0, len(coverpage_news_r)):\n",
    "#         print(coverpage_news_r[i].get_text())\n",
    "#         print('///')\n",
    "\n",
    "    # Опционально можно парсить все статьи по существующим заголовкам без ограничения глубины\n",
    "    #number_of_articles = len(coverpage_news_r)\n",
    "    \n",
    "    # Empty lists for content, links and titles\n",
    "    news_contents = []\n",
    "    list_links = []\n",
    "    list_titles = []\n",
    "\n",
    "    #замеряем время\n",
    "    start_time = time.time()\n",
    "    print('---Формируется подборка статей---')\n",
    "\n",
    "    #формируем массив статей\n",
    "    for n in range(0, depth):\n",
    "\n",
    "\n",
    "        # Getting the link of the article\n",
    "        link = coverpage_news_r[n].find('a')['href']\n",
    "        list_links.append(link)\n",
    "\n",
    "        # Getting the title\n",
    "        title = coverpage_news_r[n].find('a').get_text()\n",
    "        list_titles.append(title)\n",
    "\n",
    "        # Reading the content (it is divided in paragraphs)\n",
    "        article = requests.get(link)\n",
    "        article_content = article.content\n",
    "        soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "        body = soup_article.find_all('div', class_='StandardArticleBody_body')\n",
    "        try:\n",
    "            x = body[0].find_all('p')\n",
    "        except:\n",
    "            pass\n",
    "        # Unifying the paragraphs\n",
    "        list_paragraphs = []\n",
    "        for p in np.arange(0, len(x)):\n",
    "            paragraph = x[p].get_text()\n",
    "            list_paragraphs.append(paragraph)\n",
    "            final_article = \" \".join(list_paragraphs)\n",
    "\n",
    "        news_contents.append(final_article)\n",
    "    print(\"--- Подборка сформирована. Затрачено %s секунд ---\" % (time.time() - start_time))\n",
    "    \n",
    "    #Проходим по массиву выгруженных новостей и выполняем предобработку\n",
    "    print('---Предобработка---')\n",
    "    prepared_texts = []\n",
    "    for item in news_contents:\n",
    "        prepared_texts.append(prepare_text(item))\n",
    "    print('---Предобработка выполнена---')\n",
    "    print('///')\n",
    "    #задаем ключевые слова по темам\n",
    "    topics_econ = ['economy', 'inflation', 'cpi', 'gdp', 'output', 'pboc', 'central bank', 'money market', 'RRR','trade']\n",
    "\n",
    "    # отбор новостей по ключевым словам и суммаризация\n",
    "    i = 0\n",
    "    for item in prepared_texts:\n",
    "        counter = 0\n",
    "        for word in item.split(' '):\n",
    "            if word in topics_econ:\n",
    "                counter += 1\n",
    "        if counter > 2:\n",
    "            print('Economic story %s' % i)\n",
    "            print(summarize(item, word_count=60))\n",
    "            print('Ссылка на статью:', list_links[i])\n",
    "            print('///')\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Формируется подборка статей---\n",
      "--- Подборка сформирована. Затрачено 2.1223766803741455 секунд ---\n",
      "---Предобработка---\n",
      "---Предобработка выполнена---\n",
      "///\n",
      "Economic story 0\n",
      "bengaluru (reuters) yuan slip year-end deeper last u.s. dollar 2008 global financial crisis authority nudge partly managed currency u.s.-china trade rumble reuters poll showed.\n",
      "news emerging market currencies.” analyst divided expected move u.s.-china trade relations, anticipating deterioration continuation status rest forecast improvement.\n",
      "“unless interim trade deal materializes, think economic monetary easing pressure weaken, even though likely paced pboc,” said khoon goh, head asia research singapore, referring people’s bank china.\n",
      "Ссылка на статью: https://www.reuters.com/article/us-usa-trump-whistleblower/trump-publicly-asks-china-to-probe-biden-even-amid-impeachment-inquiry-idUSKBN1WI0BC\n",
      "///\n",
      "Economic story 1\n",
      "washington (reuters) u.s. president donald trump’s surprising request thursday start investigation democratic rival biden family, would breaking stated rules: meddle another nation’s internal politics.\n",
      "“the might tempted help trump better trade deal, doubt interfere directly u.s. politics,” agreed bonnie glaser, asia expert center strategic international studies.\n",
      "official likely already know absolutely everything know hunter biden’s china-related activity business dealings, thanks beijing’s long-standing practice surveillance.\n",
      "Ссылка на статью: https://www.reuters.com/article/us-forex-poll-yuan/chinas-yuan-to-slip-to-new-decade-lows-as-trade-war-drags-on-reuters-poll-idUSKBN1WJ09K\n",
      "///\n"
     ]
    }
   ],
   "source": [
    "china_summary_reuters(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
