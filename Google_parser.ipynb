{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "googlenews = GoogleNews()\n",
    "\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "from newspaper import fulltext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googleparser (topic, depth):\n",
    "    '''\n",
    "    topic - тема новостного запроса\n",
    "    depth - число опрашиваемых страниц поисковой выдачи\n",
    "    \n",
    "    Возвращает два списка: с текстами новостей и с проблемными ссылками \n",
    "    \n",
    "    '''\n",
    "    # 1. формирование массива ссылок\n",
    "    gnews_links = []\n",
    "    gnews=[]\n",
    "    googlenews.search(topic)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('--- Формируется массив ссылок... ---')\n",
    "\n",
    "    for i in range(1,depth):\n",
    "        googlenews.clear()\n",
    "        googlenews.getpage(i)\n",
    "        for j in range(0, len(googlenews.gettext())):\n",
    "            gnews.append(googlenews.gettext()[j])\n",
    "            gnews_links.append(googlenews.getlinks()[j])\n",
    "\n",
    "    print(\"--- На формирование массива затрачено %s секунд ---\" % (time.time() - start_time))             \n",
    "    print('--- Завершено. Получено %s ссылок ---' % len(gnews_links))   \n",
    "    \n",
    "    # 2. выгрузка новостей и формирование массива текстов\n",
    "    \n",
    "    body = []\n",
    "    count = 0\n",
    "    error_link = [] #массив с битыми ссылками\n",
    "\n",
    "    #замеряем время\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('--- Выгружаются новости... ---')\n",
    "\n",
    "    for url in gnews_links:\n",
    "        try:\n",
    "            html = requests.get(url).text\n",
    "            text = fulltext(html)\n",
    "            body.append(text)\n",
    "        except:\n",
    "            error_link.append(gnews_links[count]) #иногда попадаются проблемные ссылки. Здесь мы будем сохранять их \n",
    "            pass\n",
    "        count += 1\n",
    "\n",
    "    print(\"--- Завершено. На выгрузку затрачено %s секунд ---\" % (time.time() - start_time))             \n",
    "    return body, error_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Формируется массив ссылок... ---\n",
      "--- На формирование массива затрачено 2.4598488807678223 секунд ---\n",
      "--- Заврешено. Сформировано 10 статей ---\n",
      "--- Выгружаются новости... ---\n",
      "--- Завершено. На выгрузку затрачено 7.461597919464111 секунд ---\n"
     ]
    }
   ],
   "source": [
    "body, error = googleparser ('China', 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
